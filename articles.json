[{"content": "Python is an interpreted high-level programming language for general-purpose programming. Created by Guido van Rossum and first released in 1991, Python has a design philosophy that emphasizes code readability, notably using significant whitespace. It provides constructs that enable clear programming on both small and large scales.[26]Python features a dynamic type system and automatic memory management. It supports multiple programming paradigms, including object-oriented, imperative, functional and procedural, and has a large and comprehensive standard library.[27]Python interpreters are available for many operating systems. CPython, the reference implementation of Python, is open source software[28] and has a community-based development model, as do nearly all of its variant implementations. CPython is managed by the non-profit Python Software Foundation.History[edit]Python was conceived in the late 1980s,[29] and its implementation began in December 1989[30] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC language (itself inspired by SETL)[31] capable of exception handling and interfacing with the Amoeba operating system.[7] Van Rossum remains Python's principal author. His continuing central role in Python's development is reflected in the title given to him by the Python community: Benevolent Dictator For Life (BDFL).On the origins of Python, Van Rossum wrote in 1996:[32]\n...In December 1989, I was looking for a hobby programming project that would keep me occupied during the week around Christmas. My office ... would be closed, but I had a home computer, and not much else on my hands. I decided to write an interpreter for the new scripting language I had been thinking about lately: a descendant of ABC that would appeal to Unix/C hackers. I chose Python as a working title for the project, being in a slightly irreverent mood (and a big fan of Monty Python's Flying Circus).\n\u2014 Guido van Rossum\nPython 2.0 was released on 16 October 2000 and had many major new features, including a cycle-detecting garbage collector and support for Unicode. With this release, the development process became more transparent and community-backed.[33]Python 3.0 (initially called Python 3000 or py3k) was released on 3 December 2008 after a long testing period. It is a major revision of the language that is not completely backward-compatible with previous versions.[34] However, many of its major features have been backported to the Python 2.6.x[35] and 2.7.x version series, and releases of Python 3 include the 2to3 utility, which automates the translation of Python 2 code to Python 3.[36]Python 2.7's end-of-life date was initially set at 2015, then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3.[37][38]Python 3.6 had changes regarding UTF-8 (in Windows, PEP 528 and PEP 529) and Python 3.7.0b1 (PEP 540) adds a new UTF-8 Mode (and overrides POSIX locale).In January 2017, Google announced work on a Python 2.7 to Go transcompiler to improve performance under concurrent workloads.[39]Features and philosophy[edit]Python is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of its features support functional programming and aspect-oriented programming (including by metaprogramming[40] and metaobjects (magic methods)).[41] Many other paradigms are supported via extensions, including design by contract[42][43] and logic programming.[44]Python uses dynamic typing, and a combination of reference counting and a cycle-detecting garbage collector for memory management. It also features dynamic name resolution (late binding), which binds method and variable names during program execution.Python's design offers some support for functional programming in the Lisp tradition. It has filter(), map(), and reduce() functions; list comprehensions, dictionaries, and sets; and generator expressions.[45] The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.[46]The language's core philosophy is summarized in the document The Zen of Python (PEP 20), which includes aphorisms such as:[47]\nBeautiful is better than ugly\nExplicit is better than implicit\nSimple is better than complex\nComplex is better than complicated\nReadability counts\nRather than having all of its functionality built into its core, Python was designed to be highly extensible. This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.[29]While offering choice in coding methodology, the Python philosophy rejects exuberant syntax (such as that of Perl) in favor of a simpler, less-cluttered grammar. As Alex Martelli put it: To describe something as 'clever' is not considered a compliment in the Python culture.[48] Python's philosophy rejects the Perl there is more than one way to do it approach to language design in favor of there should be one\u2014and preferably only one\u2014obvious way to do it.[47]Python's developers strive to avoid premature optimization, and reject patches to non-critical parts of CPython that would offer marginal increases in speed at the cost of clarity.[49] When speed is important, a Python programmer can move time-critical functions to extension modules written in languages such as C, or use PyPy, a just-in-time compiler. Cython is also available, which translates a Python script into C and makes direct C-level API calls into the Python interpreter.An important goal of Python's developers is keeping it fun to use. This is reflected in the language's name\u2014a tribute to the British comedy group Monty Python[50]\u2014and in occasionally playful approaches to tutorials and reference materials, such as examples that refer to spam and eggs (from a famous Monty Python sketch) instead of the standard foo and bar.[51][52]A common neologism in the Python community is pythonic, which can have a wide range of meanings related to program style. To say that code is pythonic is to say that it uses Python idioms well, that it is natural or shows fluency in the language, that it conforms with Python's minimalist philosophy and emphasis on readability. In contrast, code that is difficult to understand or reads like a rough transcription from another programming language is called unpythonic.Users and admirers of Python, especially those considered knowledgeable or experienced, are often referred to as Pythonists, Pythonistas, and Pythoneers.[53][54]Syntax and semantics[edit]Python is meant to be an easily readable language. Its formatting is visually uncluttered, and it often uses English keywords where other languages use punctuation. Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are optional. It has fewer syntactic exceptions and special cases than C or Pascal.[55]Indentation[edit]Python uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block.[56] Thus, the program's visual structure accurately represents the program's semantic structure.[1] This feature is also sometimes termed the off-side rule.Statements and control flow[edit]Python's statements include (among others):\nThe assignment statement (token '=', the equals sign). This operates differently than in traditional imperative programming languages, and this fundamental mechanism (including the nature of Python's version of variables) illuminates many other features of the language. Assignment in C, e.g., x = 2, translates to typed variable name x receives a copy of numeric value 2. The (right-hand) value is copied into an allocated storage location for which the (left-hand) variable name is the symbolic address. The memory allocated to the variable is large enough (potentially quite large) for the declared type. In the simplest case of Python assignment, using the same example, x = 2, translates to (generic) name x receives a reference to a separate, dynamically allocated object of numeric (int) type of value 2. This is termed binding the name to the object. Since the name's storage location doesn't contain the indicated value, it is improper to call it a variable. Names may be subsequently rebound at any time to objects of greatly varying types, including strings, procedures, complex objects with data and methods, etc. Successive assignments of a common value to multiple names, e.g., x = 2; y = 2; z = 2 result in allocating storage to (at most) three names and one numeric object, to which all three names are bound. Since a name is a generic reference holder it is unreasonable to associate a fixed data type with it. However at a given time a name will be bound to some object, which will have a type; thus there is dynamic typing.\nThe if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if).\nThe for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block.\nThe while statement, which executes a block of code as long as its condition is true.\nThe try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses; it also ensures that clean-up code in a finally block will always be run regardless of how the block exits.\nThe class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming.\nThe def statement, which defines a function or method.\nThe with statement, from Python 2.5 released on September 2006,[57] which encloses a code block within a context manager (for example, acquiring a lock before the block of code is run and releasing the lock afterwards, or opening a file and then closing it), allowing Resource Acquisition Is Initialization (RAII)-like behavior and replaces a common try/finally idiom.[58]\nThe pass statement, which serves as a NOP. It is syntactically needed to create an empty code block.\nThe assert statement, used during debugging to check for conditions that ought to apply.\nThe yield statement, which returns a value from a generator function. From Python 2.5, yield is also an operator. This form is used to implement coroutines.\nThe import statement, which is used to import modules whose functions or variables can be used in the current program. There are four ways of using import: import <module name> or from <module name> import * or import numpy as np or from numpy import pi as Pie.\nThe print statement was changed to the print() function in Python 3.[59]\nPython does not support tail call optimization or first-class continuations, and, according to Guido van Rossum, it never will.[60][61] However, better support for coroutine-like functionality is provided in 2.5, by extending Python's generators.[62] Before 2.5, generators were lazy iterators; information was passed unidirectionally out of the generator. From Python 2.5, it is possible to pass information back into a generator function, and from Python 3.3, the information can be passed through multiple stack levels.[63]Expressions[edit]Some Python expressions are similar to languages such as C and Java, while some are not:\nAddition, subtraction, and multiplication are the same, but the behavior of division differs. There are two types of divisions in Python. They are floor division and integer division.[64] Python also added the ** operator for exponentiation.\nFrom Python 3.5, the new @ infix operator was introduced. It is intended to be used by libraries such as NumPy for matrix multiplication.[65][66]\nIn Python, == compares by value, versus Java, which compares numerics by value[67] and objects by reference.[68] (Value comparisons in Java on objects can be performed with the equals() method.) Python's is operator may be used to compare object identities (comparison by reference). In Python, comparisons may be chained, for example a <= b <= c.\nPython uses the words and, or, not for its boolean operators rather than the symbolic &&, ||, ! used in Java and C.\nPython has a type of expression termed a list comprehension. Python 2.4 extended list comprehensions into a more general expression termed a generator expression.[45]\nAnonymous functions are implemented using lambda expressions; however, these are limited in that the body can only be one expression.\nConditional expressions in Python are written as x if c else y[69] (different in order of operands from the c ? x : y operator common to many other languages).\nPython makes a distinction between lists and tuples. Lists are written as [1, 2, 3], are mutable, and cannot be used as the keys of dictionaries (dictionary keys must be immutable in Python). Tuples are written as (1, 2, 3), are immutable and thus can be used as the keys of dictionaries, provided all elements of the tuple are immutable. The + operator can be used to concatenate two tuples, which does not directly modify their contents, but rather produces a new tuple containing the elements of both provided tuples. Thus, given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5), which is then assigned back to t, thereby effectively modifying the contents of t, while conforming to the immutable nature of tuple objects. Parentheses are optional for tuples in unambiguous contexts.[70]\nPython features sequence unpacking where multiple expressions, each evaluating to anything that can be assigned to (a variable, a writable property, etc.), are associated in the identical manner to that forming tuple literals and, as a whole, are put on the left hand side of the equal sign in an assignment statement. The statement expects an iterable object on the right hand side of the equal sign that produces the same number of values as the provided writable expressions when iterated through, and will iterate through it, assigning each of the produced values to the corresponding expression on the left.[citation needed]\nPython has a string format operator %. This functions analogous to printf format strings in C, e.g. spam=%s eggs=%d % (blah, 2) evaluates to spam=blah eggs=2. In Python 3 and 2.6+, this was supplemented by the format() method of the str class, e.g. spam={0} eggs={1}.format(blah, 2). Python 3.6 added f-strings: blah = blah; eggs = 2; f'spam={blah} eggs={eggs}'.[71]\nPython has various kinds of string literals:\n\nStrings delimited by single or double quote marks. Unlike in Unix shells, Perl and Perl-influenced languages, single quote marks and double quote marks function identically. Both kinds of string use the backslash (\\) as an escape character. String interpolation became available in Python 3.6 as formatted string literals.[71]\nTriple-quoted strings, which begin and end with a series of three single or double quote marks. They may span multiple lines and function like here documents in shells, Perl and Ruby.\nRaw string varieties, denoted by prefixing the string literal with an r. Escape sequences are not interpreted; hence raw strings are useful where literal backslashes are common, such as regular expressions and Windows-style paths. Compare @-quoting in C#.\n\n\nPython has array index and array slicing expressions on lists, denoted as a[key], a[start:stop] or a[start:stop:step]. Indexes are zero-based, and negative indexes are relative to the end. Slices take elements from the start index up to, but not including, the stop index. The third slice parameter, called step or stride, allows elements to be skipped and reversed. Slice indexes may be omitted, for example a[:] returns a copy of the entire list. Each element of a slice is a shallow copy.\nIn Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby. This leads to duplicating some functionality. For example:\nList comprehensions vs. for-loops\nConditional expressions vs. if blocks\nThe eval() vs. exec() built-in functions (in Python 2, exec is a statement); the former is for expressions, the latter is for statements.\nStatements cannot be a part of an expression, so list and other comprehensions or lambda expressions, all being expressions, cannot contain statements. A particular case of this is that an assignment statement such as a = 1 cannot form part of the conditional expression of a conditional statement. This has the advantage of avoiding a classic C error of mistaking an assignment operator = for an equality operator == in conditions: if (c = 1) { ... } is syntactically valid (but probably unintended) C code but if c = 1: ... causes a syntax error in Python.Methods[edit]Methods on objects are functions attached to the object's class; the syntax instance.method(argument) is, for normal methods and functions, syntactic sugar for Class.method(instance, argument). Python methods have an explicit self parameter to access instance data, in contrast to the implicit self (or this) in some other object-oriented programming languages (e.g., C++, Java, Objective-C, or Ruby).[72]Typing[edit]Python uses duck typing and has typed objects but untyped variable names. Type constraints are not checked at compile time; rather, operations on an object may fail, signifying that the given object is not of a suitable type. Despite being dynamically typed, Python is strongly typed, forbidding operations that are not well-defined (for example, adding a number to a string) rather than silently attempting to make sense of them.Python allows programmers to define their own types using classes, which are most often used for object-oriented programming. New instances of classes are constructed by calling the class (for example, SpamClass() or EggsClass()), and the classes are instances of the metaclass type (itself an instance of itself), allowing metaprogramming and reflection.Before version 3.0, Python had two kinds of classes: old-style and new-style.[73] The syntax of both styles is the same, the difference being whether the class object is inherited from, directly or indirectly (all new-style classes inherit from object and are instances of type). In versions of Python 2 from Python 2.2 onwards, both kinds of classes can be used. Old-style classes were eliminated in Python 3.0.The long term plan is to support gradual typing[74] and from Python 3.5, the syntax of the language allows specifying static types but they are not checked in the default implementation, CPython. An experimental optional static type checker named mypy supports compile-time type checking.[75]Mathematics[edit]Python has the usual C arithmetic operators (+, -, *, /, %). It also has ** for exponentiation, e.g. 5**3 == 125 and 9**0.5 == 3.0, and a new matrix multiply @ operator is included in version 3.5.[77] Additionally, it has a unary operator (~), which essentially inverts all the bits of its one argument. For integers, this means ~x=-x-1.[78] Other operators include bitwise shift operators x << y, which shifts x to the left y places, the same as x*(2**y) , and x >> y, which shifts x to the right y places, the same as x/(2**y) .[79]The behavior of division has changed significantly over time:[80]\nPython 2.1 and earlier use the C division behavior. The / operator is integer division if both operands are integers, and floating-point division otherwise. Integer division rounds towards 0, e.g. 7/3 == 2 and -7/3 == -2.\nPython 2.2 changes integer division to round towards negative infinity, e.g. 7/3 == 2 and -7/3 == -3. The floor division // operator is introduced. So 7//3 == 2, -7//3 == -3, 7.5//3 == 2.0 and -7.5//3 == -3.0. Adding from __future__ import division causes a module to use Python 3.0 rules for division (see next).\nPython 3.0 changes / to be always floating-point division. In Python terms, the pre-3.0 / is classic division, the version-3.0 / is real division, and // is floor division.\nRounding towards negative infinity, though different from most languages, adds consistency. For instance, it means that the equation (a + b)//b == a//b + 1 is always true. It also means that the equation b*(a//b) + a%b == a is valid for both positive and negative values of a. However, maintaining the validity of this equation means that while the result of a%b is, as expected, in the half-open interval [0, b), where b is a positive integer, it has to lie in the interval (b, 0] when b is negative.[81]Python provides a round function for rounding a float to the nearest integer. For tie-breaking, versions before 3 use round-away-from-zero: round(0.5) is 1.0, round(-0.5) is \u22121.0.[82] Python 3 uses round to even: round(1.5) is 2, round(2.5) is 2.[83]Python allows boolean expressions with multiple equality relations in a manner that is consistent with general use in mathematics. For example, the expression a < b < c tests whether a is less than b and b is less than c. C-derived languages interpret this expression differently: in C, the expression would first evaluate a < b, resulting in 0 or 1, and that result would then be compared with c.[84][page needed]Python has extensive built-in support for arbitrary precision arithmetic. Integers are transparently switched from the machine-supported maximum fixed-precision (usually 32 or 64 bits), belonging to the python type int, to arbitrary precision, belonging to the python type long, where needed. The latter have an L suffix in their textual representation.[85] (In Python 3, the distinction between the int and long types was eliminated; this behavior is now entirely contained by the int class.) The Decimal type/class in module decimal (since version 2.4) provides decimal floating point numbers to arbitrary precision and several rounding modes.[86] The Fraction type in module fractions (since version 2.6) provides arbitrary precision for rational numbers.[87]Due to Python's extensive mathematics library, and the third-party library NumPy that further extends the native capabilities, it is frequently used as a scientific scripting language to aid in problems such as numerical data processing and manipulation.Libraries[edit]Python's large standard library, commonly cited as one of its greatest strengths,[88] provides tools suited to many tasks. For Internet-facing applications, many standard formats and protocols such as MIME and HTTP are supported. It includes modules for creating graphical user interfaces, connecting to relational databases, generating pseudorandom numbers, arithmetic with arbitrary precision decimals,[89] manipulating regular expressions, and unit testing.Some parts of the standard library are covered by specifications (for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows PEP 333[90]), but most modules are not. They are specified by their code, internal documentation, and test suites (if supplied). However, because most of the standard library is cross-platform Python code, only a few modules need altering or rewriting for variant implementations.As of March 2018,[update] the Python Package Index (PyPI), the official repository for third-party Python software, contains over 130,000[91] packages with a wide range of functionality, including:\nGraphical user interfaces\nWeb frameworks\nMultimedia\nDatabases\nNetworking\nTest frameworks\nAutomation\nWeb scraping[92]\nDocumentation\nSystem administration\nScientific computing\nText processing\nImage processing\nDevelopment environments[edit]Most Python implementations (including CPython) include a read\u2013eval\u2013print loop (REPL), permitting them to function as a command line interpreter for which the user enters statements sequentially and receives results immediately.Other shells, including IDLE and IPython, add further abilities such as auto-completion, session state retention and syntax highlighting.As well as standard desktop integrated development environments (see Wikipedia's Python IDE article), there are Web browser-based IDEs; SageMath (intended for developing science and math-related Python programs); PythonAnywhere, a browser-based IDE and hosting environment; and Canopy IDE, a commercial Python IDE emphasizing scientific computing.[93]Implementations[edit]Reference implementation[edit]CPython is the reference implementation of Python. It is written in C, meeting the C89 standard with several select C99 features.[94] It compiles Python programs into an intermediate bytecode[95] which is then executed by its virtual machine.[96] CPython is distributed with a large standard library written in a mixture of C and native Python. It is available for many platforms, including Windows and most modern Unix-like systems. Platform portability was one of its earliest priorities.[97]Other implementations[edit]PyPy is a fast, compliant[98] interpreter of Python 2.7 and 3.5. Its just-in-time compiler brings a significant speed improvement over CPython.[99]Stackless Python is a significant fork of CPython that implements microthreads; it does not use the C memory stack, thus allowing massively concurrent programs. PyPy also has a stackless version.[100]MicroPython is a Python 3 variant optimised for microcontrollers.Unsupported implementations[edit]Other just-in-time Python compilers have been developed, but are now unsupported:\nGoogle began a project named Unladen Swallow in 2009 with the aim of speeding up the Python interpreter fivefold by using the LLVM, and of improving its multithreading ability to scale to thousands of cores.[101]\nPsyco is a just-in-time specialising compiler that integrates with CPython and transforms bytecode to machine code at runtime. The emitted code is specialised for certain data types and is faster than standard Python code.\nIn 2005, Nokia released a Python interpreter for the Series 60 mobile phones named PyS60. It includes many of the modules from the CPython implementations and some additional modules to integrate with the Symbian operating system. The project has been kept up-to-date to run on all variants of the S60 platform, and several third-party modules are available. The Nokia N900 also supports Python with GTK widget libraries, enabling programs to be written and run on the target device.[102]Cross-compilers to other languages[edit]There are several compilers to high-level object languages, with either unrestricted Python, a restricted subset of Python, or a language similar to Python as the source language:\nJython compiles into Java byte code, which can then be executed by every Java virtual machine implementation. This also enables the use of Java class library functions from the Python program.\nIronPython follows a similar approach in order to run Python programs on the .NET Common Language Runtime.\nThe RPython language can be compiled to C, Java bytecode, or Common Intermediate Language, and is used to build the PyPy interpreter of Python.\nPyjs compiles Python to JavaScript.\nCython compiles Python to C and C++.\nPythran compiles Python to C++.\nSomewhat dated Pyrex (latest release in 2010) and Shed Skin (latest release in 2013) compile to C and C++ respectively.\nGoogle's Grumpy compiles Python to Go.\nNuitka compiles Python into C++ [103]\nPerformance[edit]A performance comparison of various Python implementations on a non-numerical (combinatorial) workload was presented at EuroSciPy '13.[104]Development[edit]Python's development is conducted largely through the Python Enhancement Proposal (PEP) process, the primary mechanism for proposing major new features, collecting community input on issues and documenting Python design decisions.[105] Outstanding PEPs are reviewed and commented on by the Python community and Guido Van Rossum, Python's Benevolent Dictator For Life.[105]Enhancement of the language corresponds with development of the CPython reference implementation. The mailing list python-dev is the primary forum for the language's development. Specific issues are discussed in the Roundup bug tracker maintained at python.org.[106] Development originally took place on a self-hosted source-code repository running Mercurial, until Python moved to GitHub in January 2017.[107]CPython's public releases come in three types, distinguished by which part of the version number is incremented:\nBackward-incompatible versions, where code is expected to break and need to be manually ported. The first part of the version number is incremented. These releases happen infrequently\u2014for example, version 3.0 was released 8 years after 2.0.\nMajor or feature releases, about every 18 months, are largely compatible but introduce new features. The second part of the version number is incremented. Each major version is supported by bugfixes for several years after its release.[108]\nBugfix releases, which introduce no new features, occur about every 3 months and are made when a sufficient number of bugs have been fixed upstream since the last release. Security vulnerabilities are also patched in these releases. The third and final part of the version number is incremented.[109]\nMany alpha, beta, and release-candidates are also released as previews and for testing before final releases. Although there is a rough schedule for each release, they are often delayed if the code is not ready. Python's development team monitors the state of the code by running the large unit test suite during development, and using the BuildBot continuous integration system.[110]The community of Python developers has also contributed over 86,000[111] software modules (as of 20 August 2016[update]) to the Python Package Index (PyPI), the official repository of third-party Python libraries.The major academic conference on Python is PyCon. There are also special Python mentoring programmes, such as Pyladies.Naming[edit]Python's name is derived from the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language. Monty Python references appear frequently in Python code and culture;[112] for example, the metasyntactic variables often used in Python literature are spam and eggs instead of the traditional foo and bar.[112][113] The official Python documentation also contains various references to Monty Python routines.[114][115]The prefix Py- is used to show that something is related to Python. Examples of the use of this prefix in names of Python applications or libraries include Pygame, a binding of SDL to Python (commonly used to create games); PyQt and PyGTK, which bind Qt and GTK to Python respectively; and PyPy, a Python implementation originally written in Python.Uses[edit]Since 2003, Python has consistently ranked in the top ten most popular programming languages in the TIOBE Programming Community Index where, as of January 2018[update], it is the fourth most popular language (behind Java, C, and C++).[116] It was selected Programming Language of the Year in 2007 and 2010.[117]An empirical study found that scripting languages, such as Python, are more productive than conventional languages, such as C and Java, for programming problems involving string manipulation and search in a dictionary, and determined that memory consumption was often better than Java and not much worse than C or C++.[118]Large organizations that use Python include Wikipedia, Google,[119] Yahoo!,[120] CERN,[121] NASA,[122] Facebook, Amazon, Instagram, Spotify[citation needed] and some smaller entities like ILM[123] and ITA.[124] The social news networking site Reddit is written entirely in Python.Python can serve as a scripting language for web applications, e.g., via mod_wsgi for the Apache web server.[125] With Web Server Gateway Interface, a standard API has evolved to facilitate these applications. Web frameworks like Django, Pylons, Pyramid, TurboGears, web2py, Tornado, Flask, Bottle and Zope support developers in the design and maintenance of complex applications. Pyjs and IronPython can be used to develop the client-side of Ajax-based applications. SQLAlchemy can be used as data mapper to a relational database. Twisted is a framework to program communications between computers, and is used (for example) by Dropbox.Libraries such as NumPy, SciPy and Matplotlib allow the effective use of Python in scientific computing,[126][127] with specialized libraries such as Biopython and Astropy providing domain-specific functionality. SageMath is a mathematical software with a notebook programmable in Python: its library covers many aspects of mathematics, including algebra, combinatorics, numerical mathematics, number theory, and calculus. The Python language re-implemented in Java platform is used for numeric and statistical calculations with 2D/3D visualization by the DMelt project.[128][129]Python has been successfully embedded in many software products as a scripting language, including in finite element method software such as Abaqus, 3D parametric modeler like FreeCAD, 3D animation packages such as 3ds Max, Blender, Cinema 4D, Lightwave, Houdini, Maya, modo, MotionBuilder, Softimage, the visual effects compositor Nuke, 2D imaging programs like GIMP,[130] Inkscape, Scribus and Paint Shop Pro,[131] and musical notation programs like scorewriter and capella. GNU Debugger uses Python as a pretty printer to show complex structures such as C++ containers. Esri promotes Python as the best choice for writing scripts in ArcGIS.[132] It has also been used in several video games,[133][134] and has been adopted as first of the three available programming languages in Google App Engine, the other two being Java and Go.[135] Python is also used in algorithmic trading and quantitative finance.[136] Python can also be implemented in APIs of online brokerages that run on other languages by using wrappers.[137]Python has been used in artificial intelligence projects.[138][139][140][141] As a scripting language with modular architecture, simple syntax and rich text processing tools, Python is often used for natural language processing.[142]Many operating systems include Python as a standard component. It ships with most Linux distributions, AmigaOS 4, FreeBSD, NetBSD, OpenBSD and macOS, and can be used from the command line (terminal). Many Linux distributions use installers written in Python: Ubuntu uses the Ubiquity installer, while Red Hat Linux and Fedora use the Anaconda installer. Gentoo Linux uses Python in its package management system, Portage.Python is used extensively in the information security industry, including in exploit development.[143][144]Most of the Sugar software for the One Laptop per Child XO, now developed at Sugar Labs, is written in Python.[145]The Raspberry Pi single-board computer project has adopted Python as its main user-programming language.LibreOffice includes Python, and intends to replace Java with Python. Its Python Scripting Provider is a core feature[146] since Version 4.0 from 7 February 2013.Languages influenced by Python[edit]Python's design and philosophy have influenced many other programming languages:\nBoo uses indentation, a similar syntax, and a similar object model.[147]\nCobra uses indentation and a similar syntax, and its Acknowledgements document lists Python first among languages that influenced it.[148] However, Cobra directly supports design-by-contract, unit tests, and optional static typing.[149]\nCoffeeScript, a programming language that cross-compiles to JavaScript, has Python-inspired syntax.\nECMAScript borrowed iterators, generators and list comprehensions from Python.[150]\nGo is described as incorporating the development speed of working in a dynamic language like Python.[151]\nGroovy was motivated by the desire to bring the Python design philosophy to Java.[152]\nJulia was designed with true macros [.. and to be] as usable for general programming as Python [and] should be as fast as C.[22] Calling to or from Julia is possible; to with PyCall.jl and a Python package pyjulia allows calling, in the other direction, from Python.\nKotlin (programming language) is a functional programming language with an interactive shell similar to python. However, Kotlin is strongly typed with access to standard Java libraries.[153]\nOCaml has an optional syntax named twt (The Whitespace Thing), inspired by Python and Haskell.[154]\nRuby's creator, Yukihiro Matsumoto, has said: I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That's why I decided to design my own language.[155]\nSwift, a programming language developed by Apple, has some Python-inspired syntax.[156]\nPython's development practices have also been emulated by other languages. For example, the practice of requiring a document describing the rationale for, and issues surrounding, a change to the language (in Python, a PEP) is also used in Tcl[157] and Erlang.[158]Python received TIOBE's Programming Language of the Year awards in 2007 and 2010. The award is given to the language with the greatest growth in popularity over the year, as measured by the TIOBE index.[159]See also[edit]\nComparison of integrated development environments for Python\nComparison of programming languages\nList of programming languages\npip (package manager)\nOff-side rule\nReferences[edit]Further reading[edit]\nDowney, Allen B. (May 2012). Think Python: How to Think Like a Computer Scientist (Version 1.6.6 ed.). ISBN 978-0-521-72596-5. \nHamilton, Naomi (5 August 2008). The A-Z of Programming Languages: Python. Computerworld. Archived from the original on 29 December 2008. Retrieved 31 March 2010. \nLutz, Mark (2013). Learning Python (5th ed.). O'Reilly Media. ISBN 978-0-596-15806-4. \nPilgrim, Mark (2004). Dive Into Python. Apress. ISBN 978-1-59059-356-1. \nPilgrim, Mark (2009). Dive Into Python 3. Apress. ISBN 978-1-4302-2415-0. [permanent dead link]\nSummerfield, Mark (2009). Programming in Python 3 (2nd ed.). Addison-Wesley Professional. ISBN 978-0-321-68056-3. \nExternal links[edit]\nOfficial website\nPython at Curlie (based on DMOZ)\n", "subtitles": ["History", "Features and philosophy", "Syntax and semantics", "Libraries", "Development environments", "Implementations", "Development", "Naming", "Uses", "Languages influenced by Python", "See also", "References", "Further reading", "External links"], "title": "Python (programming language)"},
{"content": "A method in object-oriented programming (OOP) is a procedure associated with a message and an object. An object is mostly made up of data and behavior, which form the interface that an object presents to the outside world. Data is represented as properties of the object and behavior as methods. For example, a Window object would have methods such as open and close, while its state (whether it is opened or closed) would be a property.In class-based programming, methods are defined in a class, and objects are instances of a given class. One of the most important capabilities that a method provides is method overriding. The same name (e.g., area) can be used for multiple different kinds of classes. This allows the sending objects to invoke behaviors and to delegate the implementation of those behaviors to the receiving object. A method in Java programming sets the behavior of a class object. For example, an object can send an area message to another object and the appropriate formula is invoked whether the receiving object is a rectangle, circle, triangle, etc.Methods also provide the interface that other classes use to access and modify the data properties of an object. This is known as encapsulation. Encapsulation and overriding are the two primary distinguishing features between methods and procedure calls.[1]Overriding and overloading[edit]Method overriding and overloading are two of the most significant ways that a method differs from a conventional procedure or function call. Overriding refers to a subclass redefining the implementation of a method of its superclass. For example, findArea may be a method defined on a shape class. The various subclasses: rectangle, circle, triangle, etc. would each define the appropriate formula to calculate their area. The idea is to look at objects as black boxes so that changes to the internals of the object can be made with minimal impact on the other objects that use it. This is known as encapsulation and is meant to make code easier to maintain and re-use.Method overloading, on the other hand, refers to differentiating the code used to handle a message based on the parameters of the method. If one views the receiving object as the first parameter in any method then overriding is just a special case of overloading where the selection is based only on the first argument.[2] The following simple Java example illustrates the difference:[3]Accessor, mutator and manager methods[edit]Accessor methods are used to read data values of an object. Mutator methods are used to modify the data of an object. Manager methods are used to initialize and destroy objects of a class, e.g. constructors and destructors.These methods provide an abstraction layer that facilitates encapsulation and modularity. For example, if a bank-account class provides a getBalance() accessor method to retrieve the current balance (rather than directly accessing the balance data fields), then later revisions of the same code can implement a more complex mechanism for balance retrieval (e.g., a database fetch), without the dependent code needing to be changed. The concepts of encapsulation and modularity are not unique to object-oriented programming. Indeed, in many ways the object-oriented approach is simply the logical extension of previous paradigms such as abstract data types and structured programming.[4]Constructors[edit]A constructor is a method that is called at the beginning of an object's lifetime to create and initialize the object, a process called construction (or instantiation). Initialization may include an acquisition of resources. Constructors may have parameters but usually, do not return values in most languages. See the following example in Java:Destructors[edit]A destructor is a method that is called automatically at the end of an object's lifetime, a process called destruction. Destruction in most languages does not allow destructor method arguments nor return values. Destruction can be implemented so as to perform cleanup chores and other tasks at object destruction.Finalizers[edit]In garbage-collected languages, such as Java, C#, and Python, destructors are known as finalizers. They have a similar purpose and function to destructors, but because of the differences between languages that utilize garbage-collection and languages with manual memory management, the sequence in which they are called is different.Abstract methods[edit]An abstract method is one with only a signature and no implementation body. It is often used to specify that a subclass must provide an implementation of the method. Abstract methods are used to specify interfaces in some computer languages.[5]Example[edit]The following Java code shows an abstract class that needs to be extended:The following subclass extends the main class:Class methods[edit]Class methods are methods that are called on a class rather than an instance. They are typically used as part of an object meta-model. I.e, for each class, defined an instance of the class object in the meta-model is created. Meta-model protocols allow classes to be created and deleted. In this sense, they provide the same functionality as constructors and destructors described above. But in some languages such as the Common Lisp Object System (CLOS) the meta-model allows the developer to dynamically alter the object model at run time: e.g., to create new classes, redefine the class hierarchy, modify properties, etc.Special methods[edit]Special methods are very language-specific and a language may support none, some, or all of the special methods defined here. A language's compiler may automatically generate default special methods or a programmer may be allowed to optionally define special methods. Most special methods cannot be directly called, but rather the compiler generates code to call them at appropriate times.Static methods[edit]Static methods are meant to be relevant to all the instances of a class rather than to any specific instance. They are similar to static variables in that sense. An example would be a static method to sum the values of all the variables of every instance of a class. For example, if there were a Product class it might have a static method to compute the average price of all products.In Java, a commonly used static method is:\nMath.max(double a, double b)\nThis static method has no owning object and does not run on an instance. It receives all information from its arguments.[6]A static method can be invoked even if no instances of the class exist yet. Static methods are called static because they are resolved at compile time based on the class they are called on and not dynamically as in the case with instance methods, which are resolved polymorphically based on the runtime type of the object.Copy-assignment operators[edit]Copy-assignment operators define actions to be performed by the compiler when a class object is assigned to a class object of the same type.Operator methods[edit]Operator methods define or redefine operator symbols and define the operations to be performed with the symbol and the associated method parameters. C++ Example:Member functions in C++[edit]Some procedural languages were extended with object-oriented capabilities to leverage the large skill sets and legacy code for those languages but still provide the benefits of object-oriented development. Perhaps the most well-known example is C++, an object-oriented extension of the C programming language. Due to the design requirements to add the object-oriented paradigm on to an existing procedural language, message passing in C++ has some unique capabilities and terminologies. For example, in C++ a method is known as a member function. C++ also has the concept of virtual functions which are member functions that can be overridden in derived classes and allow for dynamic dispatch.Virtual functions[edit]Virtual functions are the means by which a C++ class can achieve polymorphic behavior. Non-virtual member functions, or regular methods, are those that do not participate in polymorphism.C++ Example:See also[edit]\nProperty (programming)\nRemote method invocation\nSubroutine, also called subprogram, routine, procedure, or function\nNotes[edit]References[edit]", "subtitles": ["Overriding and overloading", "Accessor, mutator and manager methods", "Abstract methods", "Class methods", "Special methods", "Member functions in C++", "See also", "Notes", "References"], "title": "Method (computer programming)"},
{"content": "In computer programming, a subroutine is a sequence of program instructions that perform a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed.Subprograms may be defined within programs, or separately in libraries that can be used by multiple programs. In different programming languages, a subroutine may be called a procedure, a function, a routine, a method, or a subprogram. The generic term callable unit is sometimes used.[1]The name subprogram suggests a subroutine behaves in much the same way as a computer program that is used as one step in a larger program or another subprogram. A subroutine is often coded so that it can be started (called) several times and from several places during one execution of the program, including from other subroutines, and then branch back (return) to the next instruction after the call, once the subroutine's task is done. Maurice Wilkes, David Wheeler, and Stanley Gill are credited with the invention of this concept, which they termed a closed subroutine,[2][3] contrasted with an open subroutine or macro.[4]Subroutines are a powerful programming tool,[5] and the syntax of many programming languages includes support for writing and using them. Judicious use of subroutines (for example, through the structured programming approach) will often substantially reduce the cost of developing and maintaining a large program, while increasing its quality and reliability.[6] Subroutines, often collected into libraries, are an important mechanism for sharing and trading software. The discipline of object-oriented programming is based on objects and methods (which are subroutines attached to these objects or object classes).In the compiling method called threaded code, the executable program is basically a sequence of subroutine calls.Main concepts[edit]The content of a subroutine is its body, which is the piece of program code that is executed when the subroutine is called or invoked.A subroutine may be written so that it expects to obtain one or more data values from the calling program (to replace its parameters or formal parameters). The calling program provides actual values for these parameters, called arguments. Different programming languages may use different conventions for passing arguments:The subroutine may return a computed value to its caller (its return value), or provide various result values or output parameters. Indeed, a common use of subroutines is to implement mathematical functions, in which the purpose of the subroutine is purely to compute one or more results whose values are entirely determined by the arguments passed to the subroutine. (Examples might include computing the logarithm of a number or the determinant of a matrix.)A subroutine call may also have side effects such as modifying data structures in a computer memory, reading from or writing to a peripheral device, creating a file, halting the program or the machine, or even delaying the program's execution for a specified time. A subprogram with side effects may return different results each time it is called, even if it is called with the same arguments. An example is a random number function, available in many languages, that returns a different pseudo-random number each time it is called. The widespread use of subroutines with side effects is a characteristic of imperative programming languages.A subroutine can be coded so that it may call itself recursively, at one or more places, to perform its task. This method allows direct implementation of functions defined by mathematical induction and recursive divide and conquer algorithms.A subroutine whose purpose is to compute one boolean-valued function (that is, to answer a yes/no question) is sometimes called a predicate. In logic programming languages, often[vague] all subroutines are called predicates, since they primarily[vague] determine success or failure.[citation needed]Language support[edit]High-level programming languages usually include specific constructs to:\ndelimit the part of the program (body) that makes up the subroutine\nassign an identifier (name) to the subroutine\nspecify the names and data types of its parameters and return values\nprovide a private naming scope for its temporary variables\nidentify variables outside the subroutine that are accessible within it\ncall the subroutine\nprovide values to its parameters\nthe main program contains the address of the subprogram\nthe sub program contains the address of next instruction of the function call in main program\nspecify the return values from within its body\nreturn to the calling program\ndispose of the values returned by a call\nhandle any exceptional conditions encountered during the call\npackage subroutines into a module, library, object, class, etc.\nSome programming languages, such as Pascal, Fortran, Ada and many dialects of BASIC, distinguish between functions or function subprograms, which provide an explicit return value to the calling program, and subroutines or procedures, which do not. In those languages, function calls are normally embedded in expressions (e.g., a sqrt function may be called as y = z + sqrt(x)). Procedure calls either behave syntactically as statements (e.g., a print procedure may be called as if x > 0 then print(x) or are explicitly invoked by a statement such as CALL or GOSUB (e.g. call print(x)). Other languages, such as C and Lisp, do not distinguish between functions and subroutines.In strictly functional programming languages such as Haskell, subprograms can have no side effects, which means that various internal states of the program will not change. Functions will always return the same result if repeatedly called with the same arguments. Such languages typically only support functions, since subroutines that do not return a value have no use unless they can cause a side effect.In programming languages such as C, C++, and C#, subroutines may also simply be called functions, not to be confused with mathematical functions or functional programming, which are different concepts.A language's compiler will usually translate procedure calls and returns into machine instructions according to a well-defined calling convention, so that subroutines can be compiled separately from the programs that call them. The instruction sequences corresponding to call and return statements are called the procedure's prologue and epilogue.Advantages[edit]The advantages of breaking a program into subroutines include:\nDecomposing a complex programming task into simpler steps: this is one of the two main tools of structured programming, along with data structures\nReducing duplicate code within a program\nEnabling reuse of code across multiple programs\nDividing a large programming task among various programmers, or various stages of a project\nHiding implementation details from users of the subroutine\nImproving traceability (i.e. most languages offer ways to obtain the call trace which includes the names of the involved subroutines and perhaps even more information such as file names and line numbers); by not decomposing the code into subroutines, debugging would be impaired severely\nDisadvantages[edit]Invoking a subroutine (versus using in-line code) imposes some computational overhead in the call mechanism.A subroutine typically requires standard housekeeping code \u2013 both at entry to, and exit from, the function (function prologue and epilogue \u2013 usually saving general purpose registers and return address as a minimum).History[edit]The idea of a subroutine was worked out after computing machines had already existed for some time. The arithmetic and conditional jump instructions were planned ahead of time and have changed relatively little; but the special instructions used for procedure calls have changed greatly over the years. The earliest computers and microprocessors, such as the Small-Scale Experimental Machine and the RCA 1802, did not have a single subroutine call instruction. Subroutines could be implemented, but they required programmers to use the call sequence\u2014a series of instructions\u2014at each call site. Some very early computers and microprocessors, such as the IBM 1620, the Intel 8008, and the PIC microcontrollers, have a single-instruction subroutine call that uses dedicated hardware stack to store return addresses\u2014such hardware supports only a few levels of subroutine nesting, but can support recursive subroutines. Machines before the mid 1960s\u2014such as the UNIVAC I, the PDP-1, and the IBM 1130\u2014typically use a calling convention which saved the instruction counter in the first memory location of the called subroutine. This allows arbitrarily deep levels of subroutine nesting, but does not support recursive subroutines. The PDP-11 (1970) is one of the first computers with a stack-pushing subroutine call instruction; this feature supports both arbitrarily deep subroutine nesting and also supports recursive subroutines.[7]Language support[edit]In the very early assemblers, subroutine support was limited. Subroutines were not explicitly separated from each other or from the main program, and indeed the source code of a subroutine could be interspersed with that of other subprograms. Some assemblers would offer predefined macros to generate the call and return sequences. By the 1960s, assemblers usually had much more sophisticated support for both inline and separately assembled subroutines that could be linked together.Subroutine libraries[edit]Even with this cumbersome approach, subroutines proved very useful. For one thing they allowed use of the same code in many different programs. Moreover, memory was a very scarce resource on early computers, and subroutines allowed significant savings in the size of programs.Many early computers loaded the program instructions into memory from a punched paper tape. Each subroutine could then be provided by a separate piece of tape, loaded or spliced before or after the main program (or mainline[8]); and the same subroutine tape could then be used by many different programs. A similar approach applied in computers which used punched cards for their main input. The name subroutine library originally meant a library, in the literal sense, which kept indexed collections of tapes or card-decks for collective use.Return by indirect jump[edit]To remove the need for self-modifying code, computer designers eventually provided an indirect jump instruction, whose operand, instead of being the return address itself, was the location of a variable or processor register containing the return address.On those computers, instead of modifying the subroutine's return jump, the calling program would store the return address in a variable so that when the subroutine completed, it would execute an indirect jump that would direct execution to the location given by the predefined variable.Jump to subroutine[edit]Another advance was the jump to subroutine instruction, which combined the saving of the return address with the calling jump, thereby minimizing overhead significantly.In the IBM System/360, for example, the branch instructions BAL or BALR, designed for procedure calling, would save the return address in a processor register specified in the instruction. To return, the subroutine had only to execute an indirect branch instruction (BR) through that register. If the subroutine needed that register for some other purpose (such as calling another subroutine), it would save the register's contents to a private memory location or a register stack.In systems such as the HP 2100, the JSB instruction would perform a similar task, except that the return address was stored in the memory location that was the target of the branch. Execution of the procedure would actually begin at the next memory location. In the HP 2100 assembly language, one would write, for example\n       ...\n       JSB MYSUB    (Calls subroutine MYSUB.)\n BB    ...          (Will return here after MYSUB is done.)\nto call a subroutine called MYSUB from the main program. The subroutine would be coded as\n MYSUB NOP          (Storage for MYSUB's return address.)\n AA    ...          (Start of MYSUB's body.)\n       ...\n       JMP MYSUB,I  (Returns to the calling program.)\nThe JSB instruction placed the address of the NEXT instruction (namely, BB) into the location specified as its operand (namely, MYSUB), and then branched to the NEXT location after that (namely, AA = MYSUB + 1). The subroutine could then return to the main program by executing the indirect jump JMP MYSUB,I which branched to the location stored at location MYSUB.Compilers for Fortran and other languages could easily make use of these instructions when available. This approach supported multiple levels of calls; however, since the return address, parameters, and return values of a subroutine were assigned fixed memory locations, it did not allow for recursive calls.Incidentally, a similar method was used by Lotus 1-2-3, in the early 1980s, to discover the recalculation dependencies in a spreadsheet. Namely, a location was reserved in each cell to store the return address. Since circular references are not allowed for natural recalculation order, this allows a tree walk without reserving space for a stack in memory, which was very limited on small computers such as the IBM PC.Call stack[edit]Most modern implementations of a subroutine call use a call stack, a special case of the stack data structure, to implement subroutine calls and returns. Each procedure call creates a new entry, called a stack frame, at the top of the stack; when the procedure returns, its stack frame is deleted from the stack, and its space may be used for other procedure calls. Each stack frame contains the private data of the corresponding call, which typically includes the procedure's parameters and internal variables, and the return address.The call sequence can be implemented by a sequence of ordinary instructions (an approach still used in reduced instruction set computing (RISC) and very long instruction word (VLIW) architectures), but many traditional machines designed since the late 1960s have included special instructions for that purpose.The call stack is usually implemented as a contiguous area of memory. It is an arbitrary design choice whether the bottom of the stack is the lowest or highest address within this area, so that the stack may grow forwards or backwards in memory; however, many architectures chose the latter.[citation needed]Some designs, notably some Forth implementations, used two separate stacks, one mainly for control information (like return addresses and loop counters) and the other for data. The former was, or worked like, a call stack and was only indirectly accessible to the programmer through other language constructs while the latter was more directly accessible.When stack-based procedure calls were first introduced, an important motivation was to save precious memory.[citation needed] With this scheme, the compiler does not have to reserve separate space in memory for the private data (parameters, return address, and local variables) of each procedure. At any moment, the stack contains only the private data of the calls that are currently active (namely, which have been called but haven't returned yet). Because of the ways in which programs were usually assembled from libraries, it was (and still is) not uncommon to find programs that include thousands of subroutines, of which only a handful are active at any given moment.[citation needed] For such programs, the call stack mechanism could save significant amounts of memory. Indeed, the call stack mechanism can be viewed as the earliest and simplest method for automatic memory management.However, another advantage of the call stack method is that it allows recursive subroutine calls, since each nested call to the same procedure gets a separate instance of its private data.Delayed stacking [edit]One disadvantage of the call stack mechanism is the increased cost of a procedure call and its matching return.[clarification needed] The extra cost includes incrementing and decrementing the stack pointer (and, in some architectures, checking for stack overflow), and accessing the local variables and parameters by frame-relative addresses, instead of absolute addresses. The cost may be realized in increased execution time, or increased processor complexity, or both.This overhead is most obvious and objectionable in leaf procedures or leaf functions, which return without making any procedure calls themselves.[9][10][11] To reduce that overhead, many modern compilers try to delay the use of a call stack until it is really needed.[citation needed] For example, the call of a procedure P may store the return address and parameters of the called procedure in certain processor registers, and transfer control to the procedure's body by a simple jump. If procedure P returns without making any other call, the call stack is not used at all. If P needs to call another procedure Q, it will then use the call stack to save the contents of any registers (such as the return address) that will be needed after Q returns.C and C++ examples[edit]In the C and C++ programming languages, subprograms are termed functions (further classified as member functions when associated with a class, or free functions[12] when not). These languages use the special keyword void to indicate that a function takes no parameters (especially in C) or does not return any value. Note that C/C++ functions can have side-effects, including modifying any variables whose addresses are passed as parameters (i.e., passed by reference). Examples:The function does not return a value and has to be called as a stand-alone function, e.g., function1();This function returns a result (the number 5), and the call can be part of an expression, e.g., x + function2()This function converts a number between 0 and 6 into the initial letter of the corresponding day of the week, namely 0 to 'S', 1 to 'M', ..., 6 to 'S'. The result of calling it might be assigned to a variable, e.g., num_day = function3(number);.This function does not return a value but modifies the variable whose address is passed as the parameter; it would be called with function4(&variable_to_increment);.Small Basic example[edit]In the example above, Example() calls the subroutine[13].To define the actual subroutine, the Sub keyword must be used, with the subroutine name following Sub. After content has followed, EndSub must be typed.Visual Basic 6 examples[edit]In the Visual Basic 6 language, subprograms are termed functions or subs (or methods when associated with a class). Visual Basic 6 uses various terms called types to define what is being passed as a parameter. By default, an unspecified variable is registered as a variant type and can be passed as ByRef (default) or ByVal. Also, when a function or sub is declared, it is given a public, private, or friend designation, which determines whether it can be accessed outside the module or project that it was declared in.\nBy value [ByVal] \u2013 a way of passing the value of an argument to a procedure by passing a copy of the value, instead of passing the address. As a result, the variable's actual value can't be changed by the procedure to which it is passed.\nBy reference [ByRef] \u2013 a way of passing the value of an argument to a procedure by passing an address of the variable, instead of passing a copy of its value. This allows the procedure to access the actual variable. As a result, the variable's actual value can be changed by the procedure to which it is passed. Unless otherwise specified, arguments are passed by reference.\nPublic (optional) \u2013 indicates that the function procedure is accessible to all other procedures in all modules. If used in a module that contains an Option Private, the procedure is not available outside the project.\nPrivate (optional) \u2013 indicates that the function procedure is accessible only to other procedures in the module where it is declared.\nFriend (optional) \u2013 used only in a class module. Indicates that the Function procedure is visible throughout the project, but not visible to a controller of an instance of an object.\nThe function does not return a value and has to be called as a stand-alone function, e.g., Function1This function returns a result (the number 5), and the call can be part of an expression, e.g., x + Function2()This function converts a number between 0 and 6 into the initial letter of the corresponding day of the week, namely 0 to 'M', 1 to 'T', ..., 6 to 'S'. The result of calling it might be assigned to a variable, e.g., num_day = Function3(number).This function does not return a value but modifies the variable whose address is passed as the parameter; it would be called with Function4(variable_to_increment).PL/I example[edit]In PL/I a called procedure may be passed a descriptor providing information about the argument, such as string lengths and array bounds. This allows the procedure to be more general and eliminates the need for the programmer to pass such information. By default PL/I passes arguments by reference. A (trivial) subroutine to change the sign of each element of a two-dimensional array might look like:\n  change_sign: procedure(array);\n    declare array(*,*) float;\n    array = -array;\n    end change_sign;\nThis could be called with various arrays as follows:\n  /* first array bounds from -5 to +10 and 3 to 9 */\n  declare array1 (-5:10, 3:9)float;\n  /* second array bounds from 1 to 16 and 1 to 16 */\n  declare array2 (16,16) float;\n  call change_sign(array1);\n  call change_sign(array2);\nLocal variables, recursion and reentrancy[edit]A subprogram may find it useful to make use of a certain amount of scratch space; that is, memory used during the execution of that subprogram to hold intermediate results. Variables stored in this scratch space are termed local variables, and the scratch space is termed an activation record. An activation record typically has a return address that tells it where to pass control back to when the subprogram finishes.A subprogram may have any number and nature of call sites. If recursion is supported, a subprogram may even call itself, causing its execution to suspend while another nested execution of the same subprogram occurs. Recursion is a useful means to simplify some complex algorithms and break down complex problems. Recursive languages generally provide a new copy of local variables on each call. If the programmer desires the value of local variables to stay the same between calls, they can be declared static in some languages, or global values or common areas can be used. Here is an example of recursive subroutine in C/C++ to find Fibonacci numbers:Early languages like Fortran did not initially support recursion because variables were statically allocated, as well as the location for the return address. Most computers before the late 1960s such as the PDP-8 did not have support for hardware stack registers.[citation needed]Modern languages after ALGOL such as PL/1 and C almost invariably use a stack, usually supported by most modern computer instruction sets to provide a fresh activation record for every execution of a subprogram. That way, the nested execution is free to modify its local variables without concern for the effect on other suspended executions in progress. As nested calls accumulate, a call stack structure is formed, consisting of one activation record for each suspended subprogram. In fact, this stack structure is virtually ubiquitous, and so activation records are commonly termed stack frames.Some languages such as Pascal and Ada also support nested subroutines, which are subroutines callable only within the scope of an outer (parent) subroutine. Inner subroutines have access to the local variables of the outer subroutine that called them. This is accomplished by storing extra context information within the activation record, also termed a display.If a subprogram can be executed properly even when another execution of the same subprogram is already in progress, that subprogram is said to be reentrant. A recursive subprogram must be reentrant. Reentrant subprograms are also useful in multi-threaded situations, since multiple threads can call the same subprogram without fear of interfering with each other. In the IBM CICS transaction processing system, quasi-reentrant was a slightly less restrictive, but similar, requirement for application programs that were shared by many threads.In a multi-threaded environment, there is generally more than one stack. An environment that fully supports coroutines or lazy evaluation may use data structures other than stacks to store their activation records.Overloading[edit]In strongly typed languages, it is sometimes desirable to have a number of functions with the same name, but operating on different types of data, or with different parameter profiles. For example, a square root function might be defined to operate on reals, complex values or matrices. The algorithm to be used in each case is different, and the return result may be different. By writing three separate functions with the same name, the programmer has the convenience of not having to remember different names for each type of data. Further if a subtype can be defined for the reals, to separate positive and negative reals, two functions can be written for the reals, one to return a real when the parameter is positive, and another to return a complex value when the parameter is negative.In object-oriented programming, when a series of functions with the same name can accept different parameter profiles or parameters of different types, each of the functions is said to be overloaded.Here is an example of subroutine overloading in C++:In this code there are two functions of same name but they have different parameters.As another example, a subroutine might construct an object that will accept directions, and trace its path to these points on screen. There are a plethora of parameters that could be passed in to the constructor (colour of the trace, starting x and y co-ordinates, trace speed). If the programmer wanted the constructor to be able to accept only the color parameter, then he could call another constructor that accepts only color, which in turn calls the constructor with all the parameters passing in a set of default values for all the other parameters (X and Y would generally be centered on screen or placed at the origin, and the speed would be set to another value of the coder's choosing).Closures[edit]A closure is a subprogram together with the values of some of its variables captured from the environment in which it was created. Closures were a notable feature of the Lisp programming language, introduced by John McCarthy. Depending on the implementation, closures can serve as a mechanism for side-effects.Conventions[edit]A wide number of conventions for the coding of subroutines have been developed. Pertaining to their naming, many developers have adopted the approach that the name of a subroutine should be a verb when it does a certain task, an adjective when it makes some inquiry, and a noun when it is used to substitute variables.Some programmers suggest that a subroutine should perform only one task, and if a subroutine does perform more than one task, it should be split up into more subroutines. They argue that subroutines are key components in code maintenance, and their roles in the program must remain distinct.Proponents of modular programming (modularizing code) advocate that each subroutine should have minimal dependency on other pieces of code. For example, the use of global variables is generally deemed unwise by advocates for this perspective, because it adds tight coupling between the subroutine and these global variables. If such coupling is not necessary, their advice is to refactor subroutines to accept passed parameters instead. However, increasing the number of parameters passed to subroutines can affect code readability.Return codes[edit]Besides its main or normal effect, a subroutine may need to inform the calling program about exceptional conditions that may have occurred during its execution. In some languages and programming standards, this is often done through a return code, an integer value placed by the subroutine in some standard location, which encodes the normal and exceptional conditions.In the IBM System/360, where a return code was expected from the subroutine, the return value was often designed to be a multiple of 4\u2014so that it could be used as a direct branch table index into a branch table often located immediately after the call instruction to avoid extra conditional tests, further improving efficiency. In the System/360 assembly language, one would write, for example:\n           BAL  14,SUBRTN01    go to subroutine, storing return address in R14\n           B    TABLE(15)      use returned value in reg 15 to index the branch table, \n*                              branching to the appropriate branch instr.\nTABLE      B    OK             return code =00   GOOD                  }\n           B    BAD            return code =04   Invalid input         } Branch table\n           B    ERROR          return code =08   Unexpected condition  }\nOptimization of subroutine calls[edit]There is a significant runtime overhead in a calling a subroutine, including passing the arguments, branching to the subprogram, and branching back to the caller. The overhead often includes saving and restoring certain processor registers, allocating and reclaiming call frame storage, etc.. In some languages, each subroutine call also implies automatic testing of the subroutine's return code, or the handling of exceptions that it may raise. In object-oriented languages, a significant source of overhead is the intensively used dynamic dispatch for method calls.There are some seemingly obvious optimizations of procedure calls that cannot be applied if the procedures may have side effects. For example, in the expression (f(x)-1)/(f(x)+1), the function f must be called twice, because the two calls may return different results. Moreover, the value of x must be fetched again before the second call, since the first call may have changed it. Determining whether a subprogram may have a side effect is very difficult (indeed, undecidable).[citation needed] So, while those optimizations are safe in purely functional programming languages, compilers of typical imperative programming usually have to assume the worst.Inlining[edit]A method used to eliminate this overhead is inline expansion or inlining of the subprogram's body at each call site (versus branching to the subroutine and back). Not only does this avoid the call overhead, but it also allows the compiler to optimize the procedure's body more effectively by taking into account the context and arguments at that call. The inserted body can be optimized by the compiler. Inlining however, will usually increase the code size, unless the program contains only one call to the subroutine, or the subroutine body is less code than the call overhead.See also[edit]\nFunction (mathematics)\nMethod (computer programming)\nEvaluation strategy\nModular programming\nTransclusion\nOperator overloading\nFunctional programming\nCommand-query separation\nCoroutines, subprograms that call each other as if both were the main programs\nEvent handler, a subprogram that is called in response to an input event or interrupt\nReferences[edit]", "subtitles": ["Main concepts", "Language support", "Advantages", "Disadvantages", "History", "C and C++ examples", "Small Basic example", "Visual Basic 6 examples", "PL/I example", "Local variables, recursion and reentrancy", "Overloading", "Closures", "Conventions", "Optimization of subroutine calls", "See also", "References"], "title": "Subroutine"},
{"content": "In computer science, a generator is a special routine that can be used to control the iteration behaviour of a loop. In fact, all generators are iterators.[1] A generator is very similar to a function that returns an array, in that a generator has parameters, can be called, and generates a sequence of values. However, instead of building an array containing all the values and returning them all at once, a generator yields the values one at a time, which requires less memory and allows the caller to get started processing the first few values immediately. In short, a generator looks like a function but behaves like an iterator.Generators can be implemented in terms of more expressive control flow constructs, such as coroutines or first-class continuations.[2] Generators, also known as semicoroutines,[3] are a special case of (and weaker than) coroutines, in that they always yield control back to the caller (when passing a value back), rather than specifying a coroutine to jump to; see comparison of coroutines with generators.Uses[edit]Generators are usually invoked inside loops.[4] The first time that a generator invocation is reached in a loop, an iterator object is created that encapsulates the state of the generator routine at its beginning, with arguments bound to the corresponding parameters. The generator's body is then executed in the context of that iterator until a special yield action is encountered; at that time, the value provided with the yield action is used as the value of the invocation expression. The next time the same generator invocation is reached in a subsequent iteration, the execution of the generator's body is resumed after the yield action, until yet another yield action is encountered. In addition to the yield action, execution of the generator body can also be terminated by a finish action, at which time the innermost loop enclosing the generator invocation is terminated. In more complicated situations, a generator may be used manually outside of a loop to create an iterator, which can then be used in various ways.Because generators compute their yielded values only on demand, they are useful for representing streams, such as sequences that would be expensive or impossible to compute at once. These include e.g. infinite sequences and live data streams.When eager evaluation is desirable (primarily when the sequence is finite, as otherwise evaluation will never terminate), one can either convert to a list, or use a parallel construction that creates a list instead of a generator. For example, in Python a generator g can be evaluated to a list l via l = list(g), while in F# the sequence expression seq { ... } evaluates lazily (a generator or sequence) but [ ... ] evaluates eagerly (a list).In the presence of generators, loop constructs of a language \u2013 such as for and while \u2013 can be reduced into a single loop ... end loop construct; all the usual loop constructs can then be comfortably simulated by using suitable generators in the right way. For example, a ranged loop like for x = 1 to 10 can be implemented as iteration through a generator, as in Python's for x in xrange(1, 10). Further, break can be implemented as sending finish to the generator and then using continue in the loop.Timeline[edit]Generators first appeared in CLU (1975),[5] were a prominent feature in the string manipulation language Icon (1977) and are now available in Python,[6] C#,[7] Ruby, the later versions of ECMAScript (as of ES6/ES2015) and other languages. In CLU and C#, generators are called iterators, and in Ruby, enumerators.Lisp[edit]The final Common Lisp standard does not natively provide generators, yet various library implementations exist, such as SERIES documented in CLtL2 or pygen.CLU[edit]A yield statement is used to implement iterators over user-defined data abstractions.[8]Icon[edit]Every expression (including loops) is a generator. The language has many generators built-in and even implements some of the logic semantics using the generator mechanism (logical disjunction or OR is done this way).Printing squares from 0 to 20 can be achieved using a co-routine by writing:\n   local squares, j\n   squares := create (seq(0) ^ 2)\n   every j := |@squares do\n      if j <= 20 then\n         write(j)\n      else\n         break\nHowever, most of the time custom generators are implemented with the suspend keyword which functions exactly like the yield keyword in CLU.Jq[edit]As in Icon, in jq every expression is a generator. The infinite generator of primes can serve as an example:\ndef primes:\n    def sieve(g):\n        first(g) as $n\n        | $n, sieve(g | select((. % $n) != 0))\n    ;\n    sieve(range(2; infinite))\n;\nC[edit]C does not have generator functions as a language construct, but, as they are a subset of coroutines, but it is simple to implement them using any framework that implements stackful coroutines, such as libdill.[9]. On POSIX platforms, when the cost of context switching per iteration is not a concern, and/or full parallelism rather than merely concurrency is desired, a very simple generator function framework can be implemented using pthreads and pipes.C++[edit]It is possible to introduce generators into C++ using pre-processor macros. The resulting code might have aspects very different from native C++. but the generator syntax can be very uncluttered. A very good example can be found at.[10] The set of pre-processor macros defined in this source allow generators defined with the syntax as in the following example:This can then be iterated using:Moreover, C++11 allows foreach loops to be applied to any class that provides the begin and end functions. It's then possible to write generator-like classes by defining both the iterable methods (begin and end) and the iterator methods (operator!=, operator++ and operator*) in the same class. For example, it is possible to write the following program:A basic range implementation would look like that:Perl[edit]Perl does not natively provide generators, but support is provided by the Coro::Generator module which uses the Coro co-routine framework. Example usage:Tcl[edit]In Tcl 8.6, the generator mechanism is founded on named coroutines.Haskell[edit]In Haskell, with its lazy evaluation model, everything is a generator - every datum created with a non-strict data constructor is generated on demand. For example,where (:) is a non-strict list constructor, cons, and $ is just a called-with operator, used for parenthesization. This uses the standard adaptor function,which re-fetches values agreeable with a predicate, and stops requesting new values as soon as a non-agreeable one is encountered. The shared storage access is used as a universal mediator in Haskell. List comprehensions can be freely used:Racket[edit]Racket provides several related facilities for generators. First, its for-loop forms work with sequences, which are a kind of a producer:and these sequences are also first-class values:Some sequences are implemented imperatively (with private state variables) and some are implemented as (possibly infinite) lazy lists. Also, new struct definitions can have a property that specifies how they can be used as sequences.But more directly, Racket comes with a generator library for a more traditional generator specification. For example,Note that the Racket core implements powerful continuation features, providing general (re-entrant) continuations that are composable, and also delimited continuations. Using this, the generator library is implemented in Racket.PHP[edit]The community of PHP implemented generators in PHP 5.5. Details can be found in the original RFC about Generator.Ruby[edit]Ruby supports generators (starting from version 1.9) in the form of the built-in Enumerator class.Java[edit]Java has had a standard interface for implementing iterators since its early days, and since Java 5, the foreach construction makes it easy to loop over objects that provide the java.lang.Iterable interface. (The Java collections framework and other collections frameworks, typically provide iterators for all collections.)However, Java does not have generators built into the language. This means that creating iterators is often much trickier than in languages with built-in generators, especially when the generation logic is complex. Because all state must be saved and restored every time an item is to be yielded from an iterator, it is not possible to store state in local variables or use built-in looping routines, as when generators are available; instead, all of this must be manually simulated, using object fields to hold local state and loop counters.Even simple iterators built this way tend to be significantly bulkier than those using generators, with a lot of boilerplate code.The original example above could be written in Java 7 as:An infinite Fibonacci sequence could also be written in Java 7 as an Iterator:Also an infinite Fibonacci sequence could also be written using java 8 Stream interface:Or get an Iterator from the Java 8 super-interface BaseStream of Stream interface.C#[edit]An example C# 2.0 generator (the yield is available since C# version 2.0): Both of these examples utilize Generics, but this is not required. yield keyword also helps in implementing custom stateful iterations over a collection as discussed in this discussion[11].It is possible to use multiple yield return statements and they are applied in sequence on each iteration:XL[edit]In XL, iterators are the basis of 'for' loops:F#[edit]F# provides generators via sequence expressions, since version 1.9.1.[12] These can define a sequence (lazily evaluated, sequential access) via seq { ... }, a list (eagerly evaluated, sequential access) via [ ... ] or an array (eagerly evaluated, indexed access) via [| ... |] that contain code that generates values. For example,forms a sequence of squares of numbers from 0 to 14 by filtering out numbers from the range of numbers from 0 to 25.Python[edit]Generators were added to Python in version 2.2.[6] An example generator:In Python, a generator can be thought of as an iterator that contains a frozen stack frame. Whenever the iterator's next() method is called, Python resumes the frozen frame, which executes normally until the next yield statement is reached. The generator's frame is then frozen again, and the yielded value is returned to the caller.PEP 380 (implemented in Python 3.3) adds the yield from expression, allowing a generator to delegate part of its operations to another generator.[13]Generator expressions[edit]Python has a syntax modeled on that of list comprehensions, called a generator expression that aids in the creation of generators. The following extends the example above by using a generator expression to compute squares from the countfrom generator function:ECMAScript[edit]ECMAScript 6 (a.k.a. Harmony) introduced generator functions.An infinite Fibonacci sequence can be written using a function generator:R[edit]The iterators package can be used for this purpose.[14][15]See also[edit]\nList comprehension for another construct that generates a sequence of values\nIterator for the concept of producing a list one element at a time\nIteratee for an alternative\nLazy evaluation for producing values when needed\nCorecursion for potentially infinite data by recursion instead of yield\nCoroutine for even more generalization from subroutine\nContinuation for generalization of control flow\nNotes[edit]References[edit]\nStephan Murer, Stephen Omohundro, David Stoutamire and Clemens Szyperski: Iteration abstraction in Sather. ACM Transactions on Programming Languages and Systems, 18(1):1-15 (1996) [1]\n", "subtitles": ["Uses", "Timeline", "See also", "Notes", "References"], "title": "Generator (computer programming)"},
{"content": "In computer programming, an assertion is a statement that a predicate (Boolean-valued function, i.e. a true\u2013false expression) is expected to always be true at that point in the code. If an assertion evaluates to false at run time, an assertion failure results, which typically causes the program to crash, or to throw an assertion exception.Details[edit]The following code contains two assertions, x > 0 and x > 1, and they are indeed true at the indicated points during execution:Programmers can use assertions to help specify programs and to reason about program correctness. For example, a precondition\u2014an assertion placed at the beginning of a section of code\u2014determines the set of states under which the programmer expects the code to execute. A postcondition\u2014placed at the end\u2014describes the expected state at the end of execution. For example: x > 0 { x++ } x > 1.The example above uses the notation for including assertions used by C. A. R. Hoare in his 1969 article.[1] That notation cannot be used in existing mainstream programming languages. However, programmers can include unchecked assertions using the comment feature of their programming language. For example, in C:The braces included in the comment help distinguish this use of a comment from other uses.Libraries may provide assertion features as well. For example, in C using glibc with C99 support:Several modern programming languages include checked assertions \u2013 statements that are checked at runtime or sometimes statically. If an assertion evaluates to false at runtime, an assertion failure results, which typically causes execution to abort. This draws attention to the location at which the logical inconsistency is detected and can be preferable to the behaviour that would otherwise result.The use of assertions helps the programmer design, develop, and reason about a program.Usage[edit]In languages such as Eiffel, assertions form part of the design process; other languages, such as C and Java, use them only to check assumptions at runtime. In both cases, they can be checked for validity at runtime but can usually also be suppressed.Assertions in design by contract[edit]Assertions can function as a form of documentation: they can describe the state the code expects to find before it runs (its preconditions), and the state the code expects to result in when it is finished running (postconditions); they can also specify invariants of a class. Eiffel integrates such assertions into the language and automatically extracts them to document the class. This forms an important part of the method of design by contract.This approach is also useful in languages that do not explicitly support it: the advantage of using assertion statements rather than assertions in comments is that the program can check the assertions every time it runs; if the assertion no longer holds, an error can be reported. This prevents the code from getting out of sync with the assertions.Assertions for run-time checking[edit]An assertion may be used to verify that an assumption made by the programmer during the implementation of the program remains valid when the program is executed. For example, consider the following Java code:In Java, % is the remainder operator (modulo), and in Java, if its first operand is negative, the result can also be negative (unlike the modulo used in mathematics). Here, the programmer has assumed that total is non-negative, so that the remainder of a division with 2 will always be 0 or 1. The assertion makes this assumption explicit: if countNumberOfUsers does return a negative value, the program may have a bug.A major advantage of this technique is that when an error does occur it is detected immediately and directly, rather than later through its often obscure side-effects. Since an assertion failure usually reports the code location, one can often pin-point the error without further debugging.Assertions are also sometimes placed at points the execution is not supposed to reach. For example, assertions could be placed at the default clause of the switch statement in languages such as C, C++, and Java. Any case which the programmer does not handle intentionally will raise an error and the program will abort rather than silently continuing in an erroneous state. In D such an assertion is added automatically when a switch statement doesn't contain a default clause.In Java, assertions have been a part of the language since version 1.4. Assertion failures result in raising an AssertionError when the program is run with the appropriate flags, without which the assert statements are ignored. In C, they are added on by the standard header assert.h defining assert (assertion) as a macro that signals an error in the case of failure, usually terminating the program. In C++, both assert.h and cassert headers provide the assert macro.The danger of assertions is that they may cause side effects either by changing memory data or by changing thread timing. Assertions should be implemented carefully so they cause no side effects on program code.Assertion constructs in a language allow for easy test-driven development (TDD) without the use of a third-party library.Assertions during the development cycle[edit]During the development cycle, the programmer will typically run the program with assertions enabled. When an assertion failure occurs, the programmer is immediately notified of the problem. Many assertion implementations will also halt the program's execution: this is useful, since if the program continued to run after an assertion violation occurred, it might corrupt its state and make the cause of the problem more difficult to locate. Using the information provided by the assertion failure (such as the location of the failure and perhaps a stack trace, or even the full program state if the environment supports core dumps or if the program is running in a debugger), the programmer can usually fix the problem. Thus assertions provide a very powerful tool in debugging.Assertions in production environment[edit]When a program is deployed to production, assertions are typically turned off, to avoid any overhead or side effects they may have. In some cases assertions are completely absent from deployed code, such as in C/C++ assertions via macros. In other cases, such as Java, assertions are present in the deployed code, and can be turned on in the field for debugging.[2]Assertions may also be used to promise the compiler that a given edge condition is not actually reachable, thereby permitting certain optimizations that would not otherwise be possible. In this case, disabling the assertions could actually reduce performance.Static assertions[edit]Assertions that are checked at compile time are called static assertions.Static assertions are particularly useful in compile time template metaprogramming, but can also be used in low-level languages like C by introducing illegal code if (and only if) the assertion fails. C11 and C++11 support static assertions directly through static_assert. In earlier C versions, a static assertion can be implemented, for example, like this:If the (BOOLEAN CONDITION) part evaluates to false then the above code will not compile because the compiler will not allow two case labels with the same constant. The boolean expression must be a compile-time constant value, for example (sizeof(int)==4) would be a valid expression in that context. This construct does not work at file scope (i.e. not inside a function), and so it must be wrapped inside a function.Another popular[3] way of implementing assertions in C is:If the (BOOLEAN CONDITION) part evaluates to false then the above code will not compile because arrays may not have a negative length. If in fact the compiler allows a negative length then the initialization byte (the '!' part) should cause even such over-lenient compilers to complain. The boolean expression must be a compile-time constant value, for example (sizeof(int)==4) would be a valid expression in that context.Both of these methods require a method of constructing unique names. Modern compilers support a __COUNTER__ preprocessor define that facilitates the construction of unique names, by returning monotonically increasing numbers for each compilation unit.[4]D provides static assertions through the use of static assert,.[5]Disabling assertions[edit]Most languages allow assertions to be enabled or disabled globally, and sometimes independently. Assertions are often enabled during development and disabled during final testing and on release to the customer. Not checking assertions avoids the cost of evaluating the assertions while (assuming the assertions are free of side effects) still producing the same result under normal conditions. Under abnormal conditions, disabling assertion checking can mean that a program that would have aborted will continue to run. This is sometimes preferable.Some languages, including C and C++, completely remove assertions at compile time using the preprocessor. Java requires an option to be passed to the run-time engine in order to enable assertions. Absent the option, assertions are bypassed, but they always remain in the code unless optimised away by a JIT compiler at run-time or excluded by an if(false) condition at compile time, thus they need not have a run-time space or time cost in Java either.Programmers can build checks into their code that are always active by bypassing or manipulating the language's normal assertion-checking mechanisms.Comparison with error handling[edit]Assertions are distinct from routine error-handling. Assertions document logically impossible situations and discover programming errors: if the impossible occurs, then something fundamental is clearly wrong with the program. This is distinct from error handling: most error conditions are possible, although some may be extremely unlikely to occur in practice. Using assertions as a general-purpose error handling mechanism is unwise: assertions do not allow for recovery from errors; an assertion failure will normally halt the program's execution abruptly; and assertions are often disabled in production code. Assertions also do not display a user-friendly error message.Consider the following example of using an assertion to handle an error:Here, the programmer is aware that malloc will return a NULL pointer if memory is not allocated. This is possible: the operating system does not guarantee that every call to malloc will succeed. If an out of memory error occurs the program will immediately abort. Without the assertion, the program would continue running until ptr was dereferenced, and possibly longer, depending on the specific hardware being used. So long as assertions are not disabled, an immediate exit is assured. But if a graceful failure is desired, the program has to handle the failure. For example, a server may have multiple clients, or may hold resources that will not be released cleanly, or it may have uncommitted changes to write to a datastore. In such cases it is better to fail a single transaction than to abort abruptly.Another error is to rely on side effects of expressions used as arguments of an assertion. One should always keep in mind that assertions might not be executed at all, since their sole purpose is to verify that a condition which should always be true does in fact hold true. Consequently, if the program is considered to be error-free and released, assertions may be disabled and will no longer be evaluated.Consider another version of the previous example:This might look like a smart way to assign the return value of malloc to ptr and check if it is NULL in one step, but the malloc call and the assignment to ptr is a side effect of evaluating the expression that forms the assert condition. When the NDEBUG parameter is passed to the compiler, as when the program is considered to be error-free and released, the assert() statement is removed, so malloc() isn't called, rendering ptr uninitialised. This could potentially result in a segmentation fault or similar null pointer error much further down the line in program execution, causing bugs that may be sporadic and/or difficult to track down. Programmers sometimes use a similar VERIFY(X) define to alleviate this problem.Modern compilers may issue a warning when encountering the above code.[6]History[edit]In 1947 reports by von Neumann and Goldstine[7] on their design for the IAS machine, they described algorithms using an early version of flow charts, in which they included assertions: It may be true, that whenever C actually reaches a certain point in the flow diagram, one or more bound variables will necessarily possess certain specified values, or possess certain properties, or satisfy certain properties with each other. Furthermore, we may, at such a point, indicate the validity of these limitations. For this reason we will denote each area in which the validity of such limitations is being asserted, by a special box, which we call an assertion box.The assertional method for proving correctness of programs was advocated by Alan Turing. In a talk Checking a Large Routine at Cambridge, June 24, 1949 Turing suggested: How can one check a large routine in the sense of making sure that it's right? In order that the man who checks may not have too difficult a task, the programmer should make a number of definite assertions which can be checked individually, and from which the correctness of the whole program easily follows.[8]See also[edit]\nAssertion definition language\nDesign by contract\nException handling\nHoare logic\nStatic code analysis\nJava Modeling Language\nInvariant (computer science)\nReferences[edit]External links[edit]\nProgramming With Assertions in Java by Qusay H. Mahmoud, (Oracle Corp.), 2005\nA historical perspective on runtime assertion checking in software development by Lori A. Clarke, David S. Rosenblum in: ACM SIGSOFT Software Engineering Notes 31(3):25-37, 2006\nThe benefits of programming with assertions by Philip Guo (Stanford University), 2008\nAssertions: a personal perspective by C.A.R. Hoare in: Annals of the History of Computing, IEEE, Volume: 25, Issue: 2 (2003), Page(s): 14 - 25\nMy Compiler Does Not Understand Me by Poul-Henning Kamp in: ACM Queue 10(5), May 2012\n", "subtitles": ["Details", "Usage", "Disabling assertions", "Comparison with error handling", "History", "See also", "References", "External links"], "title": "Assertion (software development)"},
{"content": "In computer science, a NOP, no-op, or NOOP (pronounced no op; short for no operation) is an assembly language instruction, programming language statement, or computer protocol command that does nothing.Machine set of directions[edit]Some computer instruction sets include an instruction whose explicit purpose is to not change the state of any of the programmer-accessible registers, status flags, or memory. It often takes a well-defined number of clock cycles to execute. In other instruction sets, a NOP can be simulated by executing an instruction having operands that cause the same effect; e.g., on the SPARC processor, the instruction sethi 0, %g0 is the recommended solution.A NOP is most commonly used for timing purposes, to force memory alignment, to prevent hazards, to occupy a branch delay slot, to render void an existing instruction such as a jump, or as a place-holder to be replaced by active instructions later on in program development (or to replace removed instructions when reorganizing would be problematic or time-consuming). In some cases, a NOP can have minor side effects; for example, on the Motorola 68000 series of processors, the NOP opcode causes a synchronization of the pipeline.[1]Listed below are the NOP instruction for some CPU architectures:From a hardware design point of view, unmapped areas of a bus are often designed to return zeroes; since the NOP slide behavior is often desirable, it gives a bias to coding it with the all-zeroes opcode.Code[edit]NOP is sometimes used as a description for the action performed by a function or a sequence of programming language statements if the function or code has no effect (it might also be called redundant code). A common compiler optimization is the detection and removal of this kind of code. Such code may be required by the grammar of the programming language, which does not allow a blank.Ada[edit]In Ada, the null statement serves as a NOP.[6] As the syntax forbids that control statements or functions be empty, the null statement must be used to specify that no action is required. (Thus, if the programmer forgets to write a sequence of statements, the program will fail to compile.)C and derivatives[edit]The second line below is an example of a single C statement that behaves like a NOP. In practice, most compilers will not generate code for this statement:\n  int i = 0;\n  i+1;\nThis statement performs an addition and discards the result. Indeed, any statement without side effects (and that does not affect control flow, e.g., break, return) can be removed, as the result of the computation is discarded.The simplest possible statement in C that behaves like a NOP is the so-called null statement, which is just a semi-colon in a context requiring a statement. (A compiler is not required to generate a NOP instruction in this case; typically, no instructions whatsoever would be generated.)\n  ;\nAlternatively, an empty block (compound statement) may be used, and may be more legible:\n  {}\nIn some cases, such as the body of a function, a block must be used, but this can be empty. In C, statements cannot be empty \u2013 simple statements must end with a ; (semicolon) while compound statements are enclosed in {} (braces), which does not itself need a following semicolon. Thus in contexts where a statement is grammatically required, some such null statement can be used.The null statement is useless by itself, but it can have a syntactic use in a wider context, e.g., within the context of a loop:alternatively,or more tersely:(note that the last form may be confusing, and as such generates a warning with some compilers or compiler options, as semicolon usually indicates an end of function call instruction when placed after a round parenthesis on the end of line).The above code continues calling the function getchar() until it returns a \n (newline) character, essentially fast-forwarding the current reading location of standard input to the beginning of next line.Fortran[edit]In Fortran, the CONTINUE statement is used in some contexts such as the last statement in a DO loop, although it can be used anywhere, and does not have any functionality.Pascal[edit]As with C, the ; used by itself can be used as a null statement. In fact, due to the specification of the language, in a BEGIN / END block, the semicolon is optional before the END statement, thus a semicolon used there is superfluous.Also, a block consisting of BEGIN END; may be used as a placeholder to indicate no action, even if placed inside another BEGIN / END block.Python[edit]The Python programming language has a pass statement which has no effect when executed and thus serves as a NOP. It is primarily used to ensure correct syntax due to Python's indentation-sensitive syntax; for example the syntax for definition of a class requires an indented block with the class logic, which has to be expressed as pass when it should be empty.jQuery[edit]The jQuery library provides a function jQuery.noop(), which does nothing.[7]Angular[edit]The Angular framework provides angular.noop function that performs no operations.Shell Scripting (bash, zsh, etc)[edit]The ':' [colon] character is a shell builtin that has similar effect to a NOP (a do-nothing operation). It's not technically an NOP, as it changes the special parameter $? (exit status of last command) to 0. It may be considered a synonym for the shell builtin 'true', and its exit status is true (0).[8][9][10]Lodash[edit]The Lodash library provides a function _.noop(), which returns undefined and does nothing.[11]NOP protocol commands[edit]Many computer protocols, such as telnet, include a NOP command that a client can issue to request a response from the server without requesting any other actions. Such a command can be used to ensure the connection is still alive or that the server is responsive. A NOOP command is part of the following protocols (this is a partial list):\ntelnet\nFTP\nSMTP\nX11\nPOP3\nNNTP\nfinger\nIMAP4\nBitTorrent\nCharacter encoding: the null control character\nNote that unlike the other protocols listed, the IMAP4 NOOP command has a specific purpose - it allows the server to send any pending notifications to the client.While most telnet or FTP servers respond to a NOOP command with OK or +OK, some programmers have added quirky responses to the client. For example, the ftpd daemon of MINIX responds to NOOP with the message:[12]\n200 NOOP to you too!\nCracking[edit]NOPs are often involved when cracking software that checks for serial numbers, specific hardware or software requirements, presence or absence of hardware dongles, etc. This is accomplished by altering functions and subroutines to bypass security checks and instead simply return the expected value being checked for. Because most of the instructions in the security check routine will be unused, these would be replaced with NOPs, thus removing the software's security functionality without attracting any attention.Security exploits[edit]The NOP opcode can be used to form a NOP slide, which allows code to execute when the exact value of the instruction pointer is indeterminate (e.g., when a buffer overflow causes a function's return address on the stack to be overwritten).See also[edit]\nComputer architecture\nHLT (x86 instruction)\nIdentity function \u2013 the functional programming equivalent to NOOP\nxyzzy (command) \u2013 a command sometimes used instead of NOOP\nIEFBR14\nFiller text\nComment (computer programming) \u2013 annotations generally for programmers that are ignored by compilers and interpreters\nReferences[edit]", "subtitles": ["Machine set of directions", "Code", "NOP protocol commands", "Cracking", "Security exploits", "See also", "References"], "title": "NOP"},
{"content": "A computer file is a computer resource for recording data discretely in a computer storage device. Just as words can be written to paper, so can information be written to a computer file.There are different types of computer files, designed for different purposes. A file may be designed to store a picture, a written message, a video, a computer program, or a wide variety of other kinds of data. Some types of files can store several types of information at once.By using computer programs, a person can open, read, change, and close a computer file. Computer files may be reopened, modified, and copied an arbitrary number of times.Typically, files are organised in a file system, which keeps track of where the files are located on disk and enables user access.Etymology[edit]The word file derives from the Latin filum (a thread).[1]File was used publicly in the context of computer storage as early as February 1950: In a Radio Corporation of America (RCA) advertisement in Popular Science Magazine[2] describing a new memory vacuum tube it had developed, RCA stated: the results of countless computations can be kept 'on file' and taken out again. Such a 'file' now exists in a 'memory' tube developed at RCA Laboratories. Electronically it retains figures fed into calculating machines, holds them in storage while it memorizes new ones - speeds intelligent solutions through mazes of mathematics.In 1952, file denoted, inter alia, information stored on punched cards.[3]In early use, the underlying hardware, rather than the contents stored on it, was denominated a file. For example, the IBM 350 disk drives were denominated disk files.[4] The introduction, circa 1961, by the Burroughs MCP and the MIT Compatible Time-Sharing System of the concept of a file system that managed several virtual files on one storage device is the origin of the contemporary denotation of the word. Although the contemporary register file demonstrates the early concept of files, its use has greatly decreased.File contents[edit]On most modern operating systems, files are organized into one-dimensional arrays of bytes. The format of a file is defined by its content since a file is solely a container for data, although, on some platforms the format is usually indicated by its filename extension, specifying the rules for how the bytes must be organized and interpreted meaningfully. For example, the bytes of a plain text file (.txt in Windows) are associated with either ASCII or UTF-8 characters, while the bytes of image, video, and audio files are interpreted otherwise. Most file types also allocate a few bytes for metadata, which allows a file to carry some basic information about itself.Some file systems can store arbitrary (not interpreted by the file system) file-specific data outside of the file format, but linked to the file, for example extended attributes or forks. On other file systems this can be done via sidecar files or software-specific databases. All those methods, however, are more susceptible to loss of metadata than are container and archive file formats.File size[edit]At any instant in time, a file might have a size, normally expressed as number of bytes, that indicates how much storage is associated with the file. In most modern operating systems the size can be any non-negative whole number of bytes up to a system limit. Many older operating systems kept track only of the number of blocks or tracks occupied by a file on a physical storage device. In such systems, software employed other methods to track the exact byte count (e.g., CP/M used a special control character, Ctrl-Z, to signal the end of text files).The general definition of a file does not require that its size have any real meaning, however, unless the data within the file happens to correspond to data within a pool of persistent storage. A special case is a zero byte file; these files can be newly created files that have not yet had any data written to them, or may serve as some kind of flag in the file system, or are accidents (the results of aborted disk operations). For example, the file to which the link /bin/ls points in a typical Unix-like system probably has a defined size that seldom changes. Compare this with /dev/null which is also a file, but its size may be obscure. (This is misleading because /dev/null is not really a file: in Unix-like systems, all resources, including devices, are accessed like files, but there is still a real distinction between files and devices\u2014at core, they behave differently\u2014and the obscurity of the size of /dev/null is one manifestation of this. As a character device, /dev/null has no size.)Organization of data in a file[edit]Information in a computer file can consist of smaller packets of information (often called records or lines) that are individually different but share some common traits. For example, a payroll file might contain information concerning all the employees in a company and their payroll details; each record in the payroll file concerns just one employee, and all the records have the common trait of being related to payroll\u2014this is very similar to placing all payroll information into a specific filing cabinet in an office that does not have a computer. A text file may contain lines of text, corresponding to printed lines on a piece of paper. Alternatively, a file may contain an arbitrary binary image (a BLOB) or it may contain an executable.The way information is grouped into a file is entirely up to how it is designed. This has led to a plethora of more or less standardized file structures for all imaginable purposes, from the simplest to the most complex. Most computer files are used by computer programs which create, modify or delete the files for their own use on an as-needed basis. The programmers who create the programs decide what files are needed, how they are to be used and (often) their names.In some cases, computer programs manipulate files that are made visible to the computer user. For example, in a word-processing program, the user manipulates document files that the user personally names. Although the content of the document file is arranged in a format that the word-processing program understands, the user is able to choose the name and location of the file and provide the bulk of the information (such as words and text) that will be stored in the file.Many applications pack all their data files into a single file called an archive file, using internal markers to discern the different types of information contained within. The benefits of the archive file are to lower the number of files for easier transfer, to reduce storage usage, or just to organize outdated files. The archive file must often be unpacked before next using.Operations[edit]The most basic operations that programs can perform on a file are:\nCreate a new file\nChange the access permissions and attributes of a file\nOpen a file, which makes the file contents available to the program\nRead data from a file\nWrite data to a file\nClose a file, terminating the association between it and the program\nFiles on a computer can be created, moved, modified, grown, shrunk, and deleted. In most cases, computer programs that are executed on the computer handle these operations, but the user of a computer can also manipulate files if necessary. For instance, Microsoft Word files are normally created and modified by the Microsoft Word program in response to user commands, but the user can also move, rename, or delete these files directly by using a file manager program such as Windows Explorer (on Windows computers) or by command lines (CLI).In Unix-like systems, user-space programs do not operate directly, at a low level, on a file. Only the kernel deals with files, and it handles all user-space interaction with files in a manner that is transparent to the user-space programs. The operating system provides a level of abstraction, which means that interaction with a file from user-space is simply through its filename (instead of its filehandle). For example, rm filename will not delete the file itself, but only a link to the file. There can be many links to a file, but when they are all removed, the kernel considers that file's memory space free to be reallocated. This free space is commonly considered a security risk (due to the existence of file recovery software). Any secure-deletion program uses kernel-space (system) functions to wipe the file's data.Identifying and organizing[edit]In modern computer systems, files are typically accessed using names (filenames). In some operating systems, the name is associated with the file itself. In others, the file is anonymous, and is pointed to by links that have names. In the latter case, a user can identify the name of the link with the file itself, but this is a false analogue, especially where there exists more than one link to the same file.Files (or links to files) can be located in directories. However, more generally, a directory can contain either a list of files or a list of links to files. Within this definition, it is of paramount importance that the term file includes directories. This permits the existence of directory hierarchies, i.e., directories containing sub-directories. A name that refers to a file within a directory must be typically unique. In other words, there must be no identical names within a directory. However, in some operating systems, a name may include a specification of type that means a directory can contain an identical name for more than one type of object such as a directory and a file.In environments in which a file is named, a file's name and the path to the file's directory must uniquely identify it among all other files in the computer system\u2014no two files can have the same name and path. Where a file is anonymous, named references to it will exist within a namespace. In most cases, any name within the namespace will refer to exactly zero or one file. However, any file may be represented within any namespace by zero, one or more names.Any string of characters may or may not be a well-formed name for a file or a link depending upon the context of application. Whether or not a name is well-formed depends on the type of computer system being used. Early computers permitted only a few letters or digits in the name of a file, but modern computers allow long names (some up to 255 characters) containing almost any combination of unicode letters or unicode digits, making it easier to understand the purpose of a file at a glance. Some computer systems allow file names to contain spaces; others do not. Case-sensitivity of file names is determined by the file system. Unix file systems are usually case sensitive and allow user-level applications to create files whose names differ only in the case of characters. Microsoft Windows supports multiple file systems, each with different policies[which?] regarding case-sensitivity. The common FAT file system can have multiple files whose names differ only in case if the user uses a disk editor to edit the file names in the directory entries. User applications, however, will usually not allow the user to create multiple files with the same name but differing in case.Most computers organize files into hierarchies using folders, directories, or catalogs. The concept is the same irrespective of the terminology used. Each folder can contain an arbitrary number of files, and it can also contain other folders. These other folders are referred to as subfolders. Subfolders can contain still more files and folders and so on, thus building a tree-like structure in which one master folder (or root folder \u2014 the name varies from one operating system to another) can contain any number of levels of other folders and files. Folders can be named just as files can (except for the root folder, which often does not have a name). The use of folders makes it easier to organize files in a logical way.When a computer allows the use of folders, each file and folder has not only a name of its own, but also a path, which identifies the folder or folders in which a file or folder resides. In the path, some sort of special character\u2014such as a slash\u2014is used to separate the file and folder names. For example, in the illustration shown in this article, the path /Payroll/Salaries/Managers uniquely identifies a file called Managers in a folder called Salaries, which in turn is contained in a folder called Payroll. The folder and file names are separated by slashes in this example; the topmost or root folder has no name, and so the path begins with a slash (if the root folder had a name, it would precede this first slash).Many (but not all) computer systems use extensions in file names to help identify what they contain, also known as the file type. On Windows computers, extensions consist of a dot (period) at the end of a file name, followed by a few letters to identify the type of file. An extension of .txt identifies a text file; a .doc extension identifies any type of document or documentation, commonly in the Microsoft Word file format; and so on. Even when extensions are used in a computer system, the degree to which the computer system recognizes and heeds them can vary; in some systems, they are required, while in other systems, they are completely ignored if they are presented.Protection[edit]Many modern computer systems provide methods for protecting files against accidental and deliberate damage. Computers that allow for multiple users implement file permissions to control who may or may not modify, delete, or create files and folders. For example, a given user may be granted only permission to read a file or folder, but not to modify or delete it; or a user may be given permission to read and modify files or folders, but not to execute them. Permissions may also be used to allow only certain users to see the contents of a file or folder. Permissions protect against unauthorized tampering or destruction of information in files, and keep private information confidential from unauthorized users.Another protection mechanism implemented in many computers is a read-only flag. When this flag is turned on for a file (which can be accomplished by a computer program or by a human user), the file can be examined, but it cannot be modified. This flag is useful for critical information that must not be modified or erased, such as special files that are used only by internal parts of the computer system. Some systems also include a hidden flag to make certain files invisible; this flag is used by the computer system to hide essential system files that users should not alter.Storage[edit]Any file that has any useful purpose, must have some physical manifestation. That is, a file (an abstract concept) in a real computer system must have a real physical analogue if it is to exist at all.In physical terms, most computer files are stored on some type of data storage device. For example, most operating systems store files on a hard disk. Hard disks have been the ubiquitous form of non-volatile storage since the early 1960s.[5] Where files contain only temporary information, they may be stored in RAM. Computer files can be also stored on other media in some cases, such as magnetic tapes, compact discs, Digital Versatile Discs, Zip drives, USB flash drives, etc. The use of solid state drives is also beginning to rival the hard disk drive.In Unix-like operating systems, many files have no associated physical storage device. Examples are /dev/null and most files under directories /dev, /proc and /sys. These are virtual files: they exist as objects within the operating system kernel.As seen by a running user program, files are usually represented either by a File control block or by a file handle. A File control block (FCB) is an area of memory which is manipulated to establish a filename etc. and then passed to the operating system as a parameter, it was used by older IBM operating systems and early PC operating systems including CP/M and early versions of MS-DOS. A file handle is generally either an opaque data type or an integer, it was introduced in around 1961 by the ALGOL-based Burroughs MCP running on the Burroughs B5000 but is now ubiquitous.Back up[edit]When computer files contain information that is extremely important, a back-up process is used to protect against disasters that might destroy the files. Backing up files simply means making copies of the files in a separate location so that they can be restored if something happens to the computer, or if they are deleted accidentally.There are many ways to back up files. Most computer systems provide utility programs to assist in the back-up process, which can become very time-consuming if there are many files to safeguard. Files are often copied to removable media such as writable CDs or cartridge tapes. Copying files to another hard disk in the same computer protects against failure of one disk, but if it is necessary to protect against failure or destruction of the entire computer, then copies of the files must be made on other media that can be taken away from the computer and stored in a safe, distant location.The grandfather-father-son backup method automatically makes three back-ups; the grandfather file is the oldest copy of the file and the son is the current copy.File systems and file managers[edit]The way a computer organizes, names, stores and manipulates files is globally referred to as its file system. Most computers have at least one file system. Some computers allow the use of several different file systems. For instance, on newer MS Windows computers, the older FAT-type file systems of MS-DOS and old versions of Windows are supported, in addition to the NTFS file system that is the normal file system for recent versions of Windows. Each system has its own advantages and disadvantages. Standard FAT allows only eight-character file names (plus a three-character extension) with no spaces, for example, whereas NTFS allows much longer names that can contain spaces. You can call a file Payroll records in NTFS, but in FAT you would be restricted to something like payroll.dat (unless you were using VFAT, a FAT extension allowing long file names).File manager programs are utility programs that allow users to manipulate files directly. They allow you to move, create, delete and rename files and folders, although they do not actually allow you to read the contents of a file or store information in it. Every computer system provides at least one file-manager program for its native file system. For example, File Explorer (formerly Windows Explorer) is commonly used in Microsoft Windows operating systems, and Nautilus is common under several distributions of Linux.See also[edit]\nBlock (data storage)\nComputer file management\nData hierarchy\nFile camouflage\nFile copying\nFile conversion\nFile deletion\nFile directory\nFile manager\nFile system\nFilename\nFlat file database\nObject composition\nSoft copy\nNotes[edit]External links[edit]\nData Formats Computer file at Curlie (based on DMOZ)\n", "subtitles": ["Etymology", "File contents", "Identifying and organizing", "Protection", "Storage", "Back up", "File systems and file managers", "See also", "Notes", "External links"], "title": "Computer file"},
{"content": "Resource acquisition is initialization (RAII)[1] is a programming idiom[2] used in several object-oriented languages to describe a particular language behavior. In RAII, holding a resource is a class invariant, and is tied to object lifetime: resource allocation (or acquisition) is done during object creation (specifically initialization), by the constructor, while resource deallocation (release) is done during object destruction (specifically finalization), by the destructor. Thus the resource is guaranteed to be held between when initialization finishes and finalization starts (holding the resources is a class invariant), and to be held only when the object is alive. Thus if there are no object leaks, there are no resource leaks.RAII is associated most prominently with C++ where it originated, but also D, Ada, Vala, and Rust. The technique was developed for exception-safe resource management in C++[3] during 1984\u201389, primarily by Bjarne Stroustrup and Andrew Koenig,[4] and the term itself was coined by Stroustrup.[5] RAII is generally pronounced as an initialism, sometimes pronounced as R, A, double I.[6]Other names for this idiom include Constructor Acquires, Destructor Releases (CADRe) [7] and one particular style of use is called Scope-based Resource Management (SBRM).[8] This latter term is for the special case of automatic variables. RAII ties resources to object lifetime, which may not coincide with entry and exit of a scope. (Notably variables allocated on the free store have lifetimes unrelated to any given scope.) However, using RAII for automatic variables (SBRM) is the most common use case.C++11 example[edit]The following C++11 example demonstrates usage of RAII for file access and mutex locking:This code is exception-safe because C++ guarantees that all stack objects are destroyed at the end of the enclosing scope, known as stack unwinding. The destructors of both the lock and file objects are therefore guaranteed to be called when returning from the function, whether an exception has been thrown or not.[9]Local variables allow easy management of multiple resources within a single function: they are destroyed in the reverse order of their construction, and an object is destroyed only if fully constructed\u2014that is, if no exception propagates from its constructor.[10]Using RAII greatly simplifies resource management, reduces overall code size and helps ensure program correctness. RAII is therefore highly recommended in C++, and most of the C++ standard library follows the idiom.[11]Benefits[edit]The advantages of RAII as a resource management technique are that it provides encapsulation, exception safety (for stack resources), and locality (it allows acquisition and release logic to be written next to each other).Encapsulation is provided because resource management logic is defined once in the class, not at each call site. Exception safety is provided for stack resources (resources that are released in the same scope as they are acquired) by tying the resource to the lifetime of a stack variable (a local variable declared in a given scope): if an exception is thrown, and proper exception handling is in place, the only code that will be executed when exiting the current scope are the destructors of objects declared in that scope. Finally, locality of definition is provided by writing the constructor and destructor definitions next to each other in the class definition.Resource management therefore needs to be tied to the lifespan of suitable objects in order to gain automatic allocation and reclamation. Resources are acquired during initialization, when there is no chance of them being used before they are available, and released with the destruction of the same objects, which is guaranteed to take place even in case of errors.Comparing RAII with the finally construct used in Java, Stroustrup wrote that \u201cIn realistic systems, there are far more resource acquisitions than kinds of resources, so the resource acquisition is initialization technique leads to less code than use of a finally construct.\u201d[1]Typical uses[edit]The RAII design is often used for controlling mutex locks in multi-threaded applications. In that use, the object releases the lock when destroyed. Without RAII in this scenario the potential for deadlock would be high and the logic to lock the mutex would be far from the logic to unlock it. With RAII, the code that locks the mutex essentially includes the logic that the lock will be released when execution leaves the scope of the RAII object.Another typical example is interacting with files: We could have an object that represents a file that is open for writing, wherein the file is opened in the constructor and closed when execution leaves the object's scope. In both cases, RAII ensures only that the resource in question is released appropriately; care must still be taken to maintain exception safety. If the code modifying the data structure or file is not exception-safe, the mutex could be unlocked or the file closed with the data structure or file corrupted.Ownership of dynamically allocated objects (memory allocated with new in C++) can also be controlled with RAII, such that the object is released when the RAII (stack-based) object is destroyed. For this purpose, the C++11 standard library defines the smart pointer classes std::unique_ptr for single-owned objects and std::shared_ptr for objects with shared ownership. Similar classes are also available through std::auto_ptr in C++98, and boost::shared_ptr in the Boost libraries.Clang and GCC cleanup extension for C[edit]Both Clang and GNU Compiler Collection implement a non-standard extension to the C language to support RAII: the cleanup variable attribute.[12] The following macro annotates a variable with a given destructor function that it will call when the variable goes out of scope:This macro can then be used as follows:In this example, the compiler arranges for the fclosep function to be called on logfile before example_usage returns.Limitations[edit]RAII only works for resources acquired and released (directly or indirectly) by stack-allocated objects, where there is a well-defined static object lifetime. Heap-allocated objects which themselves acquire and release resources are common in many languages, including C++. RAII depends on heap-based objects to be implicitly or explicitly deleted along all possible execution paths, in order to trigger its resource-releasing destructor (or equivalent).[13]:8:27 This can be achieved by using smart pointers to manage all heap objects, with weak-pointers for cyclically referenced objects.In C++, stack unwinding is only guaranteed to occur if the exception is caught somewhere. This is because If no matching handler is found in a program, the function terminate() is called; whether or not the stack is unwound before this call to terminate() is implementation-defined (15.5.1). (C++03 standard, \u00a715.3/9).[14] This behavior is usually acceptable, since the operating system releases remaining resources like memory, files, sockets, etc. at program termination.Reference counting[edit]Perl, Python (in the CPython implementation),[15] and PHP[16] manage object lifetime by reference counting, which makes it possible to use RAII. Objects that are no longer referenced are immediately destroyed or finalized and released, so a destructor or finalizer can release the resource at that time. However, it is not always idiomatic in such languages, and is specifically discouraged in Python (in favor of context managers and finalizers from the weakref package).However, object lifetimes are not necessarily bound to any scope, and objects may be destroyed non-deterministically or not at all. This makes it possible to accidentally leak resources that should have been released at the end of some scope. Objects stored in a static variable (notably a global variable) may not be finalized when the program terminates, so their resources are not released; CPython makes no guarantee of finalizing such objects, for instance. Further, objects with circular references will not be collected by a simple reference counter, and will live indeterminately long; even if collected (by more sophisticated garbage collection), destruction time and destruction order will be non-deterministic. In CPython there is a cycle detector which detects cycles and finalizes the objects in the cycle, though prior to CPython 3.4, cycles are not collected if any object in the cycle has a finalizer.[17]References[edit]Further reading[edit]External links[edit]\nSample Chapter Gotcha #67: Failure to Employ Resource Acquisition Is Initialization by Stephen Dewhurst\nInterview A Conversation with Bjarne Stroustrup by Bill Venners\nArticle The Law of The Big Two by Bjorn Karlsson and Matthew Wilson\nArticle Implementing the 'Resource Acquisition is Initialization' Idiom by Danny Kalev\nArticle RAII, Dynamic Objects, and Factories in C++ by Roland Pibinger\nRAII in Delphi One-liner RAII in Delphi by Barry Kelly\nRAII in Java by Yegor Bugayenko\n", "subtitles": ["C++11 example", "Benefits", "Typical uses", "Clang and GCC \"cleanup\" extension for C", "Limitations", "Reference counting", "References", "Further reading", "External links"], "title": "Resource acquisition is initialization"},
{"content": "Coroutines are computer-program components that generalize subroutines for non-preemptive multitasking, by allowing multiple entry points for suspending and resuming execution at certain locations. Coroutines are well-suited for implementing familiar program components such as cooperative tasks, exceptions, event loops, iterators, infinite lists and pipes.According to Donald Knuth, Melvin Conway coined the term coroutine in 1958 when he applied it to construction of an assembly program.[1] The first published explanation of the coroutine appeared later, in 1963.[2]Comparison with subroutines[edit]\nSubroutines are special cases of ... coroutines.\n\u2014 Donald Knuth.[3]\nWhen subroutines are invoked, execution begins at the start, and once a subroutine exits, it is finished; an instance of a subroutine only returns once, and does not hold state between invocations. By contrast, coroutines can exit by calling other coroutines, which may later return to the point where they were invoked in the original coroutine; from the coroutine's point of view, it is not exiting but calling another coroutine.[3] Thus, a coroutine instance holds state, and varies between invocations; there can be multiple instances of a given coroutine at once. The difference between calling another coroutine by means of yielding to it and simply calling another routine (which then, also, would return to the original point), is that the relationship between two coroutines which yield to each other is not that of caller-callee, but instead symmetric.Any subroutine can be translated to a coroutine which does not call yield.[4]Here is a simple example of how coroutines can be useful. Suppose you have a consumer-producer relationship where one routine creates items and adds them to a queue and another removes items from the queue and uses them. For reasons of efficiency, you want to add and remove several items at once. The code might look like this:\nvar q := new queue\n\ncoroutine produce\n    loop\n        while q is not full\n            create some new items\n            add the items to q\n        yield to consume\n\ncoroutine consume\n    loop\n        while q is not empty\n            remove some items from q\n            use the items\n        yield to produce\nThe queue is then completely filled or emptied before yielding control to the other coroutine using the yield command. The further coroutines calls are starting right after the yield, in the outer coroutine loop.Although this example is often used to introduce multithreading, two threads are not needed for this: the yield statement can be implemented by a jump directly from one routine into the other.Comparison with generators[edit]Generators, also known as semicoroutines,[5] are also a generalisation of subroutines, but are more limited than coroutines. Specifically, while both of these can yield multiple times, suspending their execution and allowing re-entry at multiple entry points, they differ in coroutines' ability to control where execution continues immediately after they yield, while generators cannot, instead transferring control back to the generator's caller.[6] That is, since generators are primarily used to simplify the writing of iterators, the yield statement in a generator does not specify a coroutine to jump to, but rather passes a value back to a parent routine.However, it is still possible to implement coroutines on top of a generator facility, with the aid of a top-level dispatcher routine (a trampoline, essentially) that passes control explicitly to child generators identified by tokens passed back from the generators:\nvar q := new queue\n\ngenerator produce\n    loop\n        while q is not full\n            create some new items\n            add the items to q\n        yield consume\n\ngenerator consume\n    loop\n        while q is not empty\n            remove some items from q\n            use the items\n        yield produce\n\nsubroutine dispatcher\n    var d := new dictionary(generator \u2192 iterator)\n    d[produce] := start produce\n    d[consume] := start consume\n    var current := produce\n    loop\n        current := next d[current]\nA number of implementations of coroutines for languages with generator support but no native coroutines (e.g. Python[7] before 2.5) use this or a similar model.Comparison with mutual recursion[edit]Using coroutines for state machines or concurrency is similar to using mutual recursion with tail calls, as in both cases the control changes to a different one of a set of routines. However, coroutines are more flexible and generally more efficient. Since coroutines yield rather than return, and then resume execution rather than restarting from the beginning, they are able to hold state, both variables (as in a closure) and execution point, and yields are not limited to being in tail position; mutually recursive subroutines must either use shared variables or pass state as parameters. Further, each mutually recursive call of a subroutine requires a new stack frame (unless tail call elimination is implemented), while passing control between coroutines uses the existing contexts and can be implemented simply by a jump.Common uses[edit]Coroutines are useful to implement the following:\nState machines within a single subroutine, where the state is determined by the current entry/exit point of the procedure; this can result in more readable code compared to use of goto, and may also be implemented via mutual recursion with tail calls.\nActor model of concurrency, for instance in video games. Each actor has its own procedures (this again logically separates the code), but they voluntarily give up control to central scheduler, which executes them sequentially (this is a form of cooperative multitasking).\nGenerators, and these are useful for streams \u2013 particularly input/output \u2013 and for generic traversal of data structures.\nCommunicating sequential processes where each sub-process is a coroutine. Channel inputs/outputs and blocking operations yield coroutines and a scheduler unblocks them on completion events.\nProgramming languages with native support[edit]Coroutines originated as an assembly language method, but are supported in some high-level programming languages. Early examples include Simula[8] and Modula-2. More recent examples are Ruby, Lua, Julia, and Go.Since continuations can be used to implement coroutines, programming languages that support them can also quite easily support coroutines.Implementations[edit]As of 2003[update], many of the most popular programming languages, including C and its derivatives, do not have direct support for coroutines within the language or their standard libraries. (This is, in large part, due to the limitations of stack-based subroutine implementation.) An exception is the C++ library Boost.Context, part of boost libraries, which supports context swapping on ARM, MIPS, PowerPC, SPARC and x86 on POSIX, Mac OS X and Windows. Coroutines can be built upon Boost.Context.In situations where a coroutine would be the natural implementation of a mechanism, but is not available, the typical response is to use a closure \u2013 a subroutine with state variables (static variables, often boolean flags) to maintain an internal state between calls, and to transfer control to the correct point. Conditionals within the code result in the execution of different code paths on successive calls, based on the values of the state variables. Another typical response is to implement an explicit state machine in the form of a large and complex switch statement or via a goto statement, particularly a computed goto. Such implementations are considered difficult to understand and maintain, and a motivation for coroutine support.Threads, and to a lesser extent fibers, are an alternative to coroutines in mainstream programming environments today. Threads provide facilities for managing the realtime cooperative interaction of simultaneously executing pieces of code. Threads are widely available in environments that support C (and are supported natively in many other modern languages), are familiar to many programmers, and are usually well-implemented, well-documented and well-supported. However, as they solve a large and difficult problem they include many powerful and complex facilities and have a correspondingly difficult learning curve. As such, when a coroutine is all that is needed, using a thread can be overkill.One important difference between threads and coroutines is that threads are typically preemptively scheduled while coroutines are not. Because threads can be rescheduled at any instant and can execute concurrently, programs using threads must be careful about locking. In contrast, because coroutines can only be rescheduled at specific points in the program and do not execute concurrently, programs using coroutines can often avoid locking entirely. (This property is also cited as a benefit of event-driven or asynchronous programming.)Since fibers are cooperatively scheduled, they provide an ideal base for implementing coroutines above.[20] However, system support for fibers is often lacking compared to that for threads.Implementations for C[edit]Several attempts have been made to implement coroutines in C with combinations of subroutines and macros. Simon Tatham's contribution,[21] based on Duff's device, is a good example of the genre, and is the basis for Protothreads. Tatham's comments provide a frank evaluation of the limitations of this approach: Of course, this trick violates every coding standard in the book... [but] any coding standard which insists on syntactic clarity at the expense of algorithmic clarity should be rewritten. If your employer fires you for using this trick, tell them that repeatedly as the security staff drag you out of the building. The main shortcoming of this approach is that, in not maintaining a separate stack frame for each coroutine, local variables are not preserved across multiple entries to the function.[21]A more reliable approach to implementing coroutines in C is to give up on absolute portability and write platform-specific implementations of functions to save and restore a coroutine context. Methods for achieving this include use of sigaltstack and a springboard function called from a signal handler[22][23], as well as less reliable techniques such as jumping the stack pointer into an allocation within the heap (or merely further down the stack) using a C99 variable-length array or alloca[24]. The setjmp and longjmp functions in the standard C library can then be used to implement the jumps between coroutines. Portability is an issue, as Harbison and Steele note, the setjmp and longjmp functions are notoriously difficult to implement, and the programmer would do well to make minimal assumptions about them.[25]C libraries complying to POSIX or the Single Unix Specification (SUSv3) provide such routines as getcontext, setcontext, makecontext and swapcontext. The setcontext family of functions is thus considerably more powerful than setjmp/longjmp, but conforming implementations are as rare if not rarer. These functions were declared obsolete in POSIX 1.2008 [26]. Aside from portability, the main shortcoming of this approach is that the coroutine's stack is a fixed size and cannot be grown during execution. Thus, programs tend to allocate much more stack than they actually need to avoid the potential for stack overflow.Due to the limits of standard libraries, some authors have written their own libraries for coroutines. Russ Cox's libtask library[27] is a good example of this genre. It uses the context functions if they are provided by the native C library; otherwise it provides its own implementations for ARM, PowerPC, Sparc, and x86. Other notable implementations include libpcl,[28] coro,[29] lthread,[30] libCoroutine,[31] libconcurrency,[32] libcoro,[33] ribs2,[34] libdill.[35], libco[23], and Protothreads.Implementations for C++[edit]\nC++ coroutines TS (Technical Specification), a standard for C++ language extensions for stackless coroutines, is under development. Visual C++, gcc, and Clang already support major portions in the std::experimental namespace. coroutines Technical Specification\nBoost.Coroutine - created by Oliver Kowalke, is the official released portable coroutine library of boost since version 1.53. The library relies on Boost.Context and supports ARM, MIPS, PowerPC, SPARC and X86 on POSIX, Mac OS X and Windows.\nBoost.Coroutine2 - also created by Oliver Kowalke, is a modernized portable coroutine library since boost version 1.59. It takes advantage of C++11 features, but removes the support for symmetric coroutines.\nMordor - In 2010, Mozy open sourced a C++ library implementing coroutines, with an emphasis on using them to abstract asynchronous I/O into a more familiar sequential model.[36]\nCO2 - stackless coroutine based on C++ preprocessor tricks, providing await/yield emulation.\nScummVM - The ScummVM project implements a light-weight version of coroutines based on Simon Tatham's article.\ntonbit::coroutine - C++11 single .h asymmetric coroutine implementation via ucontext / fiber\nCoroutines landed in Clang in May 2017, with libc++ implementation ongoing.[37]\nelle by Docker\nImplementations for C#[edit]\nMindTouch Dream - The MindTouch Dream REST framework provides an implementation of coroutines based on the C# 2.0 iterator pattern\nCaliburn - The Caliburn screen patterns framework for WPF uses C# 2.0 iterators to ease UI programming, particularly in asynchronous scenarios.\nPower Threading Library - The Power Threading Library by Jeffrey Richter implements an AsyncEnumerator that provides simplified Asynchronous Programming Model using iterator-based coroutines.\nServelat Pieces - The Servelat Pieces project by Yevhen Bobrov provides transparent asynchrony for Silverlight WCF services and ability to asynchronously call any synchronous method. The implementation is based on Caliburn's Coroutines iterator and C# iterator blocks.\n[9] - The .NET 2.0+ Framework now provides semi-coroutine (generator) functionality through the iterator pattern and yield keyword.\nC# 5.0 includes await syntax support.Implementations for D[edit]D (programming language) implements coroutines as its standard library class FiberGenerator makes it trivial to expose a fiber function as an InputRange, making any fiber compatible with existing range algorithms.Implementations for Java[edit]There are several implementations for coroutines in Java. Despite the constraints imposed by Java's abstractions, the JVM does not preclude the possibility.[38] There are four general methods used, but two break bytecode portability among standards-compliant JVMs.\nModified JVMs. It is possible to build a patched JVM to support coroutines more natively. The Da Vinci JVM has had patches created.[39]\nModified bytecode. Coroutine functionality is possible by rewriting regular Java bytecode, either on the fly or at compile time. Toolkits include Javaflow, Java Coroutines, and Coroutines.\nPlatform-specific JNI mechanisms. These use JNI methods implemented in the OS or C libraries to provide the functionality to the JVM.[citation needed]\nThread abstractions. Coroutine libraries which are implemented using threads may be heavyweight, though performance will vary based on the JVM's thread implementation.\nImplementations in Javascript[edit]\nFibjs - fibjs is a JavaScript runtime built on Chrome's V8 JavaScript engine. fibjs uses fibers-switch , sync style & non-blocking IO model to build scalable system.\nSince ECMAScript6, semi-coroutine (generator) functionality through the yield keyword is provided.\nImplementation in Mono[edit]The Mono Common Language Runtime has support for continuations,[40] from which coroutines can be built.Implementation in the .NET Framework as fibers[edit]During the development of the .NET Framework 2.0, Microsoft extended the design of the Common Language Runtime (CLR) hosting APIs to handle fiber-based scheduling with an eye towards its use in fiber-mode for SQL server.[41] Before release, support for the task switching hook ICLRTask::SwitchOut was removed due to time constraints.[42] Consequently, the use of the fiber API to switch tasks is currently not a viable option in the .NET Framework.Implementations for Python[edit]\nPython 2.5 implements better support for coroutine-like functionality, based on extended generators (PEP 342)\nPython 3.3 improves this ability, by supporting delegating to a subgenerator (PEP 380)\nPython 3.4 introduces a comprehensive asynchronous I/O framework as standardized in PEP 3156, which includes coroutines that leverage subgenerator delegation\nPython 3.5 introduces explicit support for coroutines with async/await syntax (PEP 0492).\nEventlet\nGreenlet\ngevent\nmultitask\nchiral\ncogen\nKamaelia\nShrapnel\nstackless python\nImplementations for Ruby[edit]\nRuby 1.9 supports coroutines natively which are implemented as fibers, which are semi-coroutines.[43]\nAn implementation by Marc De Scheemaecker\nImplementations for Perl[edit]\nCoro\nCoroutines are natively implemented in all Perl 6 backends.[44]Implementations for Rust[edit]There is a library for Rust that provides coroutines.[45] Generators are an experimental feature available in nightly rust that provides an implementation of coroutines with async/await.[46]Implementations for Scala[edit]Scala Coroutines is a coroutine implementation for Scala. This implementation is a library-level extension that relies on the Scala macro system to statically transform sections of the program into coroutine objects. As such, this implementation does not require modifications in the JVM, so it is fully portable between different JVMs and works with alternative Scala backends, such as Scala.js, which compiles to JavaScript.[47]Scala Coroutines rely on the coroutine macro that transforms a normal block of code into a coroutine definition. Such a coroutine definition can be invoked with the call operation, which instantiates a coroutine frame. A coroutine frame can be resumed with the resume method, which resumes the execution of the coroutine's body, until reaching a yieldval keyword, which suspends the coroutine frame. Scala Coroutines also expose a snapshot method, which effectively duplicates the coroutine.[48]Implementations for Smalltalk[edit]Since, in most Smalltalk environments, the execution stack is a first-class citizen, coroutines can be implemented without additional library or VM support.Implementations for Scheme[edit]Since Scheme provides full support for continuations, implementing coroutines is nearly trivial, requiring only that a queue of continuations be maintained.Implementation for Tool Command Language (Tcl)[edit]Since version 8.6, the Tool Command Language supports coroutines in the core language. [49]Implementations for Vala[edit]Vala implements native support for coroutines. They are designed to be used with a Gtk Main Loop, but can be used alone if care is taken to ensure that the end callback will never have to be called before doing, at least, one yield.Implementations in assembly languages[edit]Machine-dependent assembly languages often provide direct methods for coroutine execution. For example, in MACRO-11, the assembly language of the PDP-11 family of minicomputers, the \u201cclassic\u201d coroutine switch is effected by the instruction JSR PC,@(SP)+, which jumps to the address popped from the stack and pushes the current (i.e that of the next) instruction address onto the stack. On VAXen (in Macro-32) the comparable instruction is JSB @(SP)+. Even on a Motorola 6809 there is the instruction JSR [,S++]; note the ++, as 2 bytes (of address) are popped from the stack. This instruction is much used in the (standard) 'monitor' Assist 09.See also[edit]\nPipeline (Unix), a kind of coroutine used for communicating between programs[50]\nProtothreads, a stackless lightweight thread implementation using a coroutine like mechanism\nReferences[edit]Further reading[edit]\nAna Lucia de Moura; Roberto Ierusalimschy (2004). Revisiting Coroutines. CiteSeerX 10.1.1.58.4017 . doi:10.1145/1462166.1462167. \nExternal links[edit]\nSimon Tatham's C oriented comprehensive introduction to coroutines\nSoftpanorama coroutine page \u2013 contains extensive assembler coroutines links\n", "subtitles": ["Comparison with subroutines", "Comparison with generators", "Comparison with mutual recursion", "Common uses", "Programming languages with native support", "Implementations", "See also", "References", "Further reading", "External links"], "title": "Coroutine"},
{"content": "In computer science, a lock or mutex (from mutual exclusion) is a synchronization mechanism for enforcing limits on access to a resource in an environment where there are many threads of execution. A lock is designed to enforce a mutual exclusion concurrency control policy.Types[edit]Generally, locks are advisory locks, where each thread cooperates by acquiring the lock before accessing the corresponding data. Some systems also implement mandatory locks, where attempting unauthorized access to a locked resource will force an exception in the entity attempting to make the access.The simplest type of lock is a binary semaphore. It provides exclusive access to the locked data. Other schemes also provide shared access for reading data. Other widely implemented access modes are exclusive, intend-to-exclude and intend-to-upgrade.Another way to classify locks is by what happens when the lock strategy prevents progress of a thread. Most locking designs block the execution of the thread requesting the lock until it is allowed to access the locked resource. With a spinlock, the thread simply waits (spins) until the lock becomes available. This is efficient if threads are blocked for a short time, because it avoids the overhead of operating system process re-scheduling. It is inefficient if the lock is held for a long time, or if the progress of the thread that is holding the lock depends on preemption of the locked thread.Locks typically require hardware support for efficient implementation. This support usually takes the form of one or more atomic instructions such as test-and-set, fetch-and-add or compare-and-swap. These instructions allow a single process to test if the lock is free, and if free, acquire the lock in a single atomic operation.Uniprocessor architectures have the option of using uninterruptable sequences of instructions\u2014using special instructions or instruction prefixes to disable interrupts temporarily\u2014but this technique does not work for multiprocessor shared-memory machines. Proper support for locks in a multiprocessor environment can require quite complex hardware or software support, with substantial synchronization issues.The reason an atomic operation is required is because of concurrency, where more than one task executes the same logic. For example, consider the following C code:The above example does not guarantee that the task has the lock, since more than one task can be testing the lock at the same time. Since both tasks will detect that the lock is free, both tasks will attempt to set the lock, not knowing that the other task is also setting the lock. Dekker's or Peterson's algorithm are possible substitutes if atomic locking operations are not available.Careless use of locks can result in deadlock or livelock. A number of strategies can be used to avoid or recover from deadlocks or livelocks, both at design-time and at run-time. (The most common strategy is to standardize the lock acquisition sequences so that combinations of inter-dependent locks are always acquired in a specifically defined cascade order.)Some languages do support locks syntactically. An example in C# follows:The code lock(this) can lead to problems if the instance can be accessed publicly.[1]Similar to Java, C# can also synchronize entire methods, by using the MethodImplOptions.Synchronized attribute.[2][3]Granularity[edit]Before being introduced to lock granularity, one needs to understand three concepts about locks:\nlock overhead: the extra resources for using locks, like the memory space allocated for locks, the CPU time to initialize and destroy locks, and the time for acquiring or releasing locks. The more locks a program uses, the more overhead associated with the usage;\nlock contention: this occurs whenever one process or thread attempts to acquire a lock held by another process or thread. The more fine-grained the available locks, the less likely one process/thread will request a lock held by the other. (For example, locking a row rather than the entire table, or locking a cell rather than the entire row.);\ndeadlock: the situation when each of at least two tasks is waiting for a lock that the other task holds. Unless something is done, the two tasks will wait forever.\nThere is a tradeoff between decreasing lock overhead and decreasing lock contention when choosing the number of locks in synchronization.An important property of a lock is its granularity. The granularity is a measure of the amount of data the lock is protecting. In general, choosing a coarse granularity (a small number of locks, each protecting a large segment of data) results in less lock overhead when a single process is accessing the protected data, but worse performance when multiple processes are running concurrently. This is because of increased lock contention. The more coarse the lock, the higher the likelihood that the lock will stop an unrelated process from proceeding. Conversely, using a fine granularity (a larger number of locks, each protecting a fairly small amount of data) increases the overhead of the locks themselves but reduces lock contention. Granular locking where each process must hold multiple locks from a common set of locks can create subtle lock dependencies. This subtlety can increase the chance that a programmer will unknowingly introduce a deadlock.[citation needed]In a database management system, for example, a lock could protect, in order of increasing granularity, part of a field, a field, a record, a data page, or an entire table. Coarse granularity, such as using table locks, tends to give the best performance for a single user, whereas fine granularity, such as record locks, tends to give the best performance for multiple users.Database locks[edit]Database locks can be used as a means of ensuring transaction synchronicity. i.e. when making transaction processing concurrent (interleaving transactions), using 2-phased locks ensures that the concurrent execution of the transaction turns out equivalent to some serial ordering of the transaction. However, deadlocks become an unfortunate side-effect of locking in databases. Deadlocks are either prevented by pre-determining the locking order between transactions or are detected using waits-for graphs. An alternate to locking for database synchronicity while avoiding deadlocks involves the use of totally ordered global timestamps.There are mechanisms employed to manage the actions of multiple concurrent users on a database\u2014the purpose is to prevent lost updates and dirty reads. The two types of locking are pessimistic locking and optimistic locking:\nPessimistic locking: a user who reads a record with the intention of updating it places an exclusive lock on the record to prevent other users from manipulating it. This means no one else can manipulate that record until the user releases the lock. The downside is that users can be locked out for a very long time, thereby slowing the overall system response and causing frustration.\n\n\n\nWhere to use pessimistic locking: this is mainly used in environments where data-contention (the degree of users request to the database system at any one time) is heavy; where the cost of protecting data through locks is less than the cost of rolling back transactions, if concurrency conflicts occur. Pessimistic concurrency is best implemented when lock times will be short, as in programmatic processing of records. Pessimistic concurrency requires a persistent connection to the database and is not a scalable option when users are interacting with data, because records might be locked for relatively large periods of time. It is not appropriate for use in Web application development.\n\n\n\nOptimistic locking: this allows multiple concurrent users access to the database whilst the system keeps a copy of the initial-read made by each user. When a user wants to update a record, the application determines whether another user has changed the record since it was last read. The application does this by comparing the initial-read held in memory to the database record to verify any changes made to the record. Any discrepancies between the initial-read and the database record violates concurrency rules and hence causes the system to disregard any update request. An error message is generated and the user is asked to start the update process again. It improves database performance by reducing the amount of locking required, thereby reducing the load on the database server. It works efficiently with tables that require limited updates since no users are locked out. However, some updates may fail. The downside is constant update failures due to high volumes of update requests from multiple concurrent users - it can be frustrating for users.\n\n\n\nWhere to use optimistic locking: this is appropriate in environments where there is low contention for data, or where read-only access to data is required. Optimistic concurrency is used extensively in .NET to address the needs of mobile and disconnected applications,[4] where locking data rows for prolonged periods of time would be infeasible. Also, maintaining record locks requires a persistent connection to the database server, which is not possible in disconnected applications.\n\n\nDisadvantages[edit]Lock-based resource protection and thread/process synchronization have many disadvantages:\nContention: some threads/processes have to wait until a lock (or a whole set of locks) is released. If one of the threads holding a lock dies, stalls, blocks, or enters an infinite loop, other threads waiting for the lock may wait forever.\nOverhead: the use of locks adds overhead for each access to a resource, even when the chances for collision are very rare. (However, any chance for such collisions is a race condition.)\nDebugging: bugs associated with locks are time dependent and can be very subtle and extremely hard to replicate, such as deadlocks.\nInstability: the optimal balance between lock overhead and lock contention can be unique to the problem domain (application) and sensitive to design, implementation, and even low-level system architectural changes. These balances may change over the life cycle of an application and may entail tremendous changes to update (re-balance).\nComposability: locks are only composable (e.g., managing multiple concurrent locks in order to atomically delete item X from table A and insert X into table B) with relatively elaborate (overhead) software support and perfect adherence by applications programming to rigorous conventions.\nPriority inversion: a low-priority thread/process holding a common lock can prevent high-priority threads/processes from proceeding. Priority inheritance can be used to reduce priority-inversion duration. The priority ceiling protocol can be used on uniprocessor systems to minimize the worst-case priority-inversion duration, as well as prevent deadlock.\nConvoying: all other threads have to wait if a thread holding a lock is descheduled due to a time-slice interrupt or page fault.\nSome concurrency control strategies avoid some or all of these problems. For example, a funnel or serializing tokens can avoid the biggest problem: deadlocks. Alternatives to locking include non-blocking synchronization methods, like lock-free programming techniques and transactional memory. However, such alternative methods often require that the actual lock mechanisms be implemented at a more fundamental level of the operating software. Therefore, they may only relieve the application level from the details of implementing locks, with the problems listed above still needing to be dealt with beneath the application.In most cases, proper locking depends on the CPU providing a method of atomic instruction stream synchronization (for example, the addition or deletion of an item into a pipeline requires that all contemporaneous operations needing to add or delete other items in the pipe be suspended during the manipulation of the memory content required to add or delete the specific item). Therefore, an application can often be more robust when it recognizes the burdens it places upon an operating system and is capable of graciously recognizing the reporting of impossible demands.[citation needed]Lack of composability[edit]One of lock-based programming's biggest problems is that locks don't compose: it is hard to combine small, correct lock-based modules into equally correct larger programs without modifying the modules or at least knowing about their internals. Simon Peyton Jones (an advocate of software transactional memory) gives the following example of a banking application:[5] design a class Account that allows multiple concurrent clients to deposit or withdraw money to an account; and give an algorithm to transfer money from one account to another. The lock-based solution to the first part of the problem is:\nclass Account:\n    member balance : Integer\n    member mutex : Lock\n    method deposit(n : Integer)\n           mutex.lock()\n           balance \u2190 balance + n\n           mutex.unlock()\n    method withdraw(n : Integer)\n           deposit(\u2212n)\nThe second part of the problem is much more complicated. A transfer routine that is correct for sequential programs would be\nfunction transfer(from : Account, to : Account, amount : integer)\n    from.withdraw(amount)\n    to.deposit(amount)\nIn a concurrent program, this algorithm is incorrect because when one thread is halfway through transfer, another might observe a state where amount has been withdrawn from the first account, but not yet deposited into the other account: money has gone missing from the system. This problem can only be fixed completely by taking locks on both account prior to changing any of the two accounts, but then the locks have to be taken according to some arbitrary, global ordering to prevent deadlock:\nfunction transfer(from : Account, to : Account, amount : integer)\n    if from < to    // arbitrary ordering on the locks\n        from.lock()\n        to.lock()\n    else\n        to.lock()\n        from.lock()\n    from.withdraw(amount)\n    to.deposit(amount)\n    from.unlock()\n    to.unlock()\nThis solution gets more complicated when more locks are involved, and the transfer function needs to know about all of the locks, so they cannot be hidden.Language support[edit]Programming languages vary in their support for synchronization:\nThe ISO/IEC C standard provides a standard mutual exclusion (locks) API since C11. The current ISO/IEC C++ standard supports threading facilities since C++11. The OpenMP standard is supported by some compilers, and allows critical sections to be specified using pragmas. The POSIX pthread API provides lock support.[6] Visual C++ provides the synchronize attribute of methods to be synchronized, but this is specific to COM objects in the Windows architecture and Visual C++ compiler.[7] C and C++ can easily access any native operating system locking features.\nObjective-C provides the keyword @synchronized[8] to put locks on blocks of code and also provides the classes NSLock,[9] NSRecursiveLock,[10] and NSConditionLock[11] along with the NSLocking protocol[12] for locking as well.\nC# provides the lock keyword on a thread to ensure its exclusive access to a resource.\nVB.NET provides a SyncLock keyword like C#'s lock keyword.\nJava provides the keyword synchronized to lock code blocks, methods or objects[13] and libraries featuring concurrency-safe data structures.\nPython provides a low-level mutex mechanism without a keyword.[14]\nRuby provides a low-level mutex object and no keyword.[15]\nAda provides protected objects that have visible protected subprograms or entries[16] as well as rendezvous.[17]\nx86 assembly provides the LOCK prefix on certain operations to guarantee their atomicity.\nPHP provides a file based locking [18] as well as a Mutex class in the pthreads extension. [19]\nSee also[edit]\nCritical section\nDouble-checked locking\nFile locking\nLock-free and wait-free algorithms\nMonitor (synchronization)\nMutual exclusion\nRead/write lock pattern\nSemaphore (programming)\nReferences[edit]External links[edit]\nTutorial on Locks and Critical Sections\n", "subtitles": ["Types", "Granularity", "Database locks", "Disadvantages", "Language support", "See also", "References", "External links"], "title": "Lock (computer science)"},
{"content": "Exception handling syntax varies between programming languages, partly to cover semantic differences but largely to fit into each language's overall syntactic structure. Some languages do not call the relevant concept 'exception handling'; others may not have direct facilities for it, but can still provide means to implement it.Most commonly, error handling uses a try...[catch...][finally...] block, and errors are created via a throw statement, but there is significant variation in naming and syntax.Catalogue of exception handling syntaxes[edit]Ada[edit]\nException declarations\n\nRaising exceptions\n\nException handling and propagation\nAssembly language[edit]Most assembly languages will have a macro instruction or an interrupt address available for the particular system to intercept events such as illegal op codes, program check, data errors, overflow, divide by zero, and other such. IBM and Univac mainframes had the STXIT macro. Digital Equipment Corporation RT11 systems had trap vectors for program errors, i/o interrupts, and such. DOS has certain interrupt addresses. Microsoft Windows has specific module calls to trap program errors.Bash[edit]One can set a trap for multiple errors, responding to any signal with syntax like:\ntrap 'echo Error at line ${LINENO}' ERR\nBASIC[edit]An On Error goto/gosub structure is used in BASIC and is quite different from modern exception handling; in BASIC there is only one global handler whereas in modern exception handling, exception handlers are stacked.C[edit]The most common way to implement exception handling in standard C is to use setjmp/longjmp functions:Microsoft-specific[edit]Two types exist:\nStructured Exception Handling (SEH)\nVectored Exception Handling (VEH, introduced in Windows XP)\nExample of SEH in C programming language:C#[edit]C++[edit]In C++, a resource acquisition is initialization technique can be used to clean up resources in exceptional situations. C++ intentionally does not support finally.[1] The outer braces for the method are optional.ColdFusion Markup Language (CFML)[edit]Script syntax[edit]Adobe ColdFusion documentation[2]Tag syntax[edit]Adobe ColdFusion documentation[3]Railo-Lucee specific syntax[edit]Added to the standard syntax above, CFML dialects of Railo and Lucee allow a retry statement.[4]This statement returns processing to the start of the prior try block.CFScript example:Tag-syntax example:D[edit]In D, a finally clause or the resource acquisition is initialization technique can be used to clean up resources in exceptional situations.Delphi[edit]\nException declarations\n\nRaising exceptions\n\nException handling and propagation[5]\nErlang[edit]Haskell[edit]Haskell does not have special syntax for exceptions. Instead, a try/catch/finally/etc. interface is provided by functions.prints\n(1,42)\nin analogy with this C++Another example isIn purely functional code, if only one error condition exists, the Maybe type may be sufficient, and is an instance of Haskell's Monad class by default. More complex error propagation can be achieved using the Error or ErrorT monads, for which similar functionality (using `catch`) is supported.Java[edit]JavaScript[edit]Lisp[edit]Common Lisp[edit]Lua[edit]Lua uses the pcall and xpcall functions, with xpcall taking a function to act as a catch block.\nPredefined function\n\nAnonymous function\nObjective-C[edit]\nException declarations\n\nRaising exceptions\n\nException handling and propagation\nOCaml[edit]Perl[edit]The Perl mechanism for exception handling uses die to throw an exception when wrapped inside an eval { ... }; block. After the eval, the special variable $@ contains the value passed from die. However, scoping issues can make doing this correctly quite ugly:Perl 5.005 added the ability to throw objects as well as strings. This allows better introspection and handling of types of exceptions.The __DIE__ pseudo-signal can be trapped to handle calls to die. This is not suitable for exception handling since it is global. However it can be used to convert string-based exceptions from third-party packages into objects.The forms shown above can sometimes fail if the global variable $@ is changed between when the exception is thrown and when it is checked in the if ($@) statement. This can happen in multi-threaded environments, or even in single-threaded environments when other code (typically called in the destruction of some object) resets the global variable before the checking code. The following example shows a way to avoid this problem (see [1]). But at the cost of not being able to use return values:Several modules in the Comprehensive Perl Archive Network (CPAN) expand on the basic mechanism:\nError provides a set of exception classes and allows use of the try/throw/catch/finally syntax.\nTryCatch and Try::Tiny both allow use of try/catch/finally syntax instead of boilerplate to handle exceptions correctly.\nException::Class is a base class and class-maker for derived exception classes. It provides a full structured stack trace in $@->trace and $@->trace->as_string.\nFatal overloads previously defined functions that return true/false e.g., open, close, read, write, etc. This allows built-in functions and others to be used as if they threw exceptions.\nPHP[edit]PowerBuilder[edit]Exception handling is available in PowerBuilder versions 8.0 and above.\nTRY\n   // Normal execution path\nCATCH (ExampleException ee)\n   //  deal with the ExampleException\nFINALLY\n   // This optional section is executed upon termination of any of the try or catch blocks above\nEND TRY\nPowerShell[edit]Version 1.0[edit]Version 2.0[edit]Python[edit]R[edit]Rebol[edit]Rexx[edit]Ruby[edit]S-Lang[edit]\n try \n {\n    % code that might throw an exception\n }\n catch SomeError: \n { \n    % code that handles this exception\n }\n catch SomeOtherError:\n {  \n    % code that handles this exception\n }\n finally   % optional block\n {\n    % This code will always get executed\n }\nNew exceptions may be created using the new_exception function, e.g.,\n new_exception (MyIOError, IOError, My I/O Error);\nwill create an exception called MyIOError as a subclass of IOError. Exceptions may be generated using the throw statement, which can throw arbitrary S-Lang objects.Smalltalk[edit]The general mechanism is provided by the message on:do:.[6] Exceptions are just normal objects that subclass Error, you throw one by creating an instance and sending it a #signal message, e.g., MyException new signal. The handling mechanism (#on:do:) is again just a normal message implemented by BlockClosure. The thrown exception is passed as a parameter to the handling block closure, and can be queried, as well as potentially sending #resume to it, to allow execution flow to continue.Swift[edit]Exception handling is supported since Swift 2.Tcl[edit]Since Tcl 8.6, there is also a try command:VBScript[edit][7]Visual Basic[edit][7]Visual Basic .NET[edit]Visual Prolog[edit]http://wiki.visual-prolog.com/index.php?title=Language_Reference/Terms#Try-catch-finallyX++[edit]References[edit]See also[edit]\nException handling for the semantics of exception handling\nSyntax for definition of syntax in computer science\n", "subtitles": ["Catalogue of exception handling syntaxes", "References", "See also"], "title": "Exception handling syntax"},
{"content": "In object-oriented programming, a class is an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods).[1][2] In many languages, the class name is used as the name for the class (the template itself), the name for the default constructor of the class (a subroutine that creates objects), and as the type of objects generated by instantiating the class; these distinct concepts are easily conflated.[2]When an object is created by a constructor of the class, the resulting object is called an instance of the class, and the member variables specific to the object are called instance variables, to contrast with the class variables shared across the class.In some languages, classes are only a compile-time feature (new classes cannot be declared at runtime), while in other languages classes are first-class citizens, and are generally themselves objects (typically of type Class or similar). In these languages, a class that creates classes is called a metaclass.Class vs. type[edit]In casual use, people often refer to the class of an object, but narrowly speaking objects have type: the interface, namely the types of member variables, the signatures of member functions (methods), and properties these satisfy. At the same time, a class has an implementation (specifically the implementation of the methods), and can create objects of a given type, with a given implementation.[3] In the terms of type theory, a class is an implementation\u200d\u2014\u200ca concrete data structure and collection of subroutines\u200d\u2014\u200cwhile a type is an interface. Different (concrete) classes can produce objects of the same (abstract) type (depending on type system); for example, the type Stack might be implemented with two classes \u2013  SmallStack (fast for small stacks, but scales poorly) and ScalableStack (scales well but high overhead for small stacks). Similarly, a given class may have several different constructors.Types generally represent nouns, such as a person, place or thing, or something nominalized, and a class represents an implementation of these. For example, a Banana type might represent the properties and functionality of bananas in general, while the ABCBanana and XYZBanana classes would represent ways of producing bananas (say, banana suppliers or data structures and functions to represent and draw bananas in a video game). The ABCBanana class could then produce particular bananas: instances of the ABCBanana class would be objects of type Banana. Often only a single implementation of a type is given, in which case the class name is often identical with the type name.Design and implementation[edit]Classes are composed from structural and behavioral constituents.[4] Programming languages that include classes as a programming construct offer support, for various class-related features, and the syntax required to use these features varies greatly from one programming language to another.Structure[edit]A class contains data field descriptions (or properties, fields, data members, or attributes). These are usually field types and names that will be associated with state variables at program run time; these state variables either belong to the class or specific instances of the class. In most languages, the structure defined by the class determines the layout of the memory used by its instances. Other implementations are possible: for example, objects in Python use associative key-value containers.[5]Some programming languages support specification of invariants as part of the definition of the class, and enforce them through the type system. Encapsulation of state is necessary for being able to enforce the invariants of the class.Behavior[edit]The behavior of class or its instances is defined using methods. Methods are subroutines with the ability to operate on objects or classes. These operations may alter the state of an object or simply provide ways of accessing it.[6] Many kinds of methods exist, but support for them varies across languages. Some types of methods are created and called by programmer code, while other special methods\u2014such as constructors, destructors, and conversion operators\u2014are created and called by compiler-generated code. A language may also allow the programmer to define and call these special methods.[7][8]The concept of class interface[edit]Every class implements (or realizes) an interface by providing structure and behavior. Structure consists of data and state, and behavior consists of code that specifies how methods are implemented.[9] There is a distinction between the definition of an interface and the implementation of that interface; however, this line is blurred in many programming languages because class declarations both define and implement an interface. Some languages, however, provide features that separate interface and implementation. For example, an abstract class can define an interface without providing implementation.Languages that support class inheritance also allow classes to inherit interfaces from the classes that they are derived from.[example needed] In languages that support access specifiers, the interface of a class is considered to be the set of public members of the class, including both methods and attributes (via implicit getter and setter methods); any private members or internal data structures are not intended to be depended on by external code and thus are not part of the interface.Object-oriented programming methodology dictates that the operations of any interface of a class are to be independent of each other. It results in a layered design where clients of an interface use the methods declared in the interface. An interface places no requirements for clients to invoke the operations of one interface in any particular order. This approach has the benefit that client code can assume that the operations of an interface are available for use whenever the client has access to the object.[citation needed]Example[edit]The buttons on the front of your television set are the interface between you and the electrical wiring on the other side of its plastic casing. You press the power button to toggle the television on and off. In this example, your particular television is the instance, each method is represented by a button, and all the buttons together comprise the interface. (Other television sets that are the same model as yours would have the same interface.) In its most common form, an interface is a specification of a group of related methods without any associated implementation of the methods.A television set also has a myriad of attributes, such as size and whether it supports color, which together comprise its structure. A class represents the full description of a television, including its attributes (structure) and buttons (interface).Getting the total number of televisions manufactured could be a static method of the television class. This method is clearly associated with the class, yet is outside the domain of each individual instance of the class. Another example would be a static method that finds a particular instance out of the set of all television objects.Member accessibility[edit]The following is a common set of access specifiers:[10]\nPrivate (or class-private) restricts the access to the class itself. Only methods that are part of the same class can access private members.\nProtected (or class-protected) allows the class itself and all its subclasses to access the member.\nPublic means that any code can access the member by its name.\nAlthough many object-oriented languages support the above access specifiers, their semantics may differ.Object-oriented design uses the access specifiers in conjunction with careful design of public method implementations to enforce class invariants\u2014constraints on the state of the objects. A common usage of access specifiers is to separate the internal data of a class from its interface: the internal structure is made private, while public accessor methods can be used to inspect or alter such private data.Access specifiers do not necessarily control visibility, in that even private members may be visible to client external code. In some languages, an inaccessible but visible member may be referred to at run-time (for example, by a pointer returned from a member function), but an attempt to use it by referring to the name of the member from client code will be prevented by the type checker.[11]The various object-oriented programming languages enforce member accessibility and visibility to various degrees, and depending on the language's type system and compilation policies, enforced at either compile-time or run-time. For example, the Java language does not allow client code that accesses the private data of a class to compile. [12] In the C++ language, private methods are visible, but not accessible in the interface; however, they may be made invisible by explicitly declaring fully abstract classes that represent the interfaces of the class.[13]Some languages feature other accessibility schemes:\nInstance vs. class accessibility: Ruby supports instance-private and instance-protected access specifiers in lieu of class-private and class-protected, respectively. They differ in that they restrict access based on the instance itself, rather than the instance's class.[14]\nFriend: C++ supports a mechanism where a function explicitly declared as a friend function of the class may access the members designated as private or protected.[15]\nPath-based: Java supports restricting access to a member within a Java package, which is the logical path of the file. However, it is a common practice when extending a Java framework to implement classes in the same package as a framework class in order to access protected members. The source file may exist in a completely different location, and may be deployed to a different .jar file, yet still be in the same logical path as far as the JVM is concerned.[10]\nInter-class relationships[edit]In addition to the design of standalone classes, programming languages may support more advanced class design based upon relationships between classes. The inter-class relationship design capabilities commonly provided are compositional and hierarchical.Compositional[edit]Classes can be composed of other classes, thereby establishing a compositional relationship between the enclosing class and its embedded classes. Compositional relationship between classes is also commonly known as a has-a relationship.[16] For example, a class Car could be composed of and contain a class Engine. Therefore, a Car has an Engine. One aspect of composition is containment, which is the enclosure of component instances by the instance that has them. If an enclosing object contains component instances by value, the components and their enclosing object have a similar lifetime. If the components are contained by reference, they may not have a similar lifetime.[17] For example, in Objective-C 2.0:This Car class has an instance of NSString (a string object), Engine, and NSArray (an array object).Hierarchical[edit]Classes can be derived from one or more existing classes, thereby establishing a hierarchical relationship between the derived-from classes (base classes, parent classes or superclasses) and the derived class (child class or subclass) . The relationship of the derived class to the derived-from classes is commonly known as an is-a relationship.[18] For example, a class 'Button' could be derived from a class 'Control'. Therefore, a Button is a Control. Structural and behavioral members of the parent classes are inherited by the child class. Derived classes can define additional structural members (data fields) and behavioral members (methods) in addition to those that they inherit and are therefore specializations of their superclasses. Also, derived classes can override inherited methods if the language allows.Not all languages support multiple inheritance. For example, Java allows a class to implement multiple interfaces, but only inherit from one class.[19] If multiple inheritance is allowed, the hierarchy is a directed acyclic graph (or DAG for short), otherwise it is a tree. The hierarchy has classes as nodes and inheritance relationships as links. Classes in the same level are more likely to be associated than classes in different levels. The levels of this hierarchy are called layers or levels of abstraction.Example (Simplified Objective-C 2.0 code, from iPhone SDK):In this example, a UITableView is a UIScrollView is a UIView is a UIResponder is an NSObject.Definitions of subclass[edit]Conceptually, a superclass is a superset of its subclasses. For example, a common class hierarchy would involve GraphicObject as a superclass of Rectangle and Elipse, while Square would be a subclass of Rectangle. These are all subset relations in set theory as well, i.e., all squares are rectangles but not all rectangles are squares.A common conceptual error is to mistake a part of relation with a subclass. For example, a car and truck are both kinds of vehicles and it would be appropriate to model them as subclasses of a vehicle class. However, it would be an error to model the component parts of the car as subclass relations. For example, a car is composed of an engine and body, but it would not be appropriate to model engine or body as a subclass of car.In object-oriented modeling these kinds of relations are typically modeled as object properties. In this example the Car class would have a property called parts. parts would be typed to hold a collection of objects such as instances of Body, Engine, Tires,.... Object modeling languages such as UML include capabilities to model various aspects of part of and other kinds of relations. Data such as the cardinality of the objects, constraints on input and output values, etc. This information can be utilized by developer tools to generate additional code beside the basic data definitions for the objects. Things such as error checking on get and set methods.[20]One important question when modeling and implementing a system of object classes is whether a class can have one or more superclasses. In the real world with actual sets it would be rare to find sets that didn't intersect with more than one other set. However, while some systems such as Flavors and CLOS provide a capability for more than one parent to do so at run time introduces complexity that many in the object-oriented community consider antithetical to the goals of using object classes in the first place. Understanding which class will be responsible for handling a message can get complex when dealing with more than one superclass. If used carelessly this feature can introduce some of the same system complexity and ambiguity classes were designed to avoid.[21]Most modern object-oriented languages such as Smalltalk and Java require single inheritance at run time. For these languages, multiple inheritance may be useful for modeling but not for an implementation.However, semantic web application objects do have multiple superclasses. The volatility of the Internet requires this level of flexibility and the technology standards such as the Web Ontology Language (OWL) are designed to support it.A similar issue is whether or not the class hierarchy can be modified at run time. Languages such as Flavors, CLOS, and Smalltalk all support this feature as part of their meta-object protocols. Since classes are themselves first-class objects, it is possible to have them dynamically alter their structure by sending them the appropriate messages. Other languages that focus more on strong typing such as Java and C++ do not allow the class hierarchy to be modified at run time. Semantic web objects have the capability for run time changes to classes. The rational is similar to the justification for allowing multiple superclasses, that the Internet is so dynamic and flexible that dynamic changes to the hierarchy are required to manage this volatility.[22]Orthogonality of the class concept and inheritance[edit]Although class-based languages are commonly assumed to support inheritance, inheritance is not an intrinsic aspect of the concept of classes. Some languages, often referred to as object-based languages, support classes yet do not support inheritance. Examples of object-based languages include earlier versions of Visual Basic.Within object-oriented analysis[edit]In object-oriented analysis and in UML, an association between two classes represents a collaboration between the classes or their corresponding instances. Associations have direction; for example, a bi-directional association between two classes indicates that both of the classes are aware of their relationship.[23] Associations may be labeled according to their name or purpose.[24]An association role is given end of an association and describes the role of the corresponding class. For example, a subscriber role describes the way instances of the class Person participate in a subscribes-to association with the class Magazine. Also, a Magazine has the subscribed magazine role in the same association. Association role multiplicity describes how many instances correspond to each instance of the other class of the association. Common multiplicities are 0..1, 1..1, 1..* and 0..*, where the * specifies any number of instances.[23]Taxonomy of classes[edit]There are many categories of classes, some of which overlap.Abstract and concrete[edit]In a language that supports inheritance, an abstract class, or abstract base class (ABC), is a class that cannot be instantiated because it is either labeled as abstract or it simply specifies abstract methods (or virtual methods). An abstract class may provide implementations of some methods, and may also specify virtual methods via signatures that are to be implemented by direct or indirect descendants of the abstract class. Before a class derived from an abstract class can be instantiated, all abstract methods of its parent classes must be implemented by some class in the derivation chain.[25]Most object-oriented programming languages allow the programmer to specify which classes are considered abstract and will not allow these to be instantiated. For example, in Java, C# and PHP, the keyword abstract is used.[26][27] In C++, an abstract class is a class having at least one abstract method given by the appropriate syntax in that language (a pure virtual function in C++ parlance).[25]A class consisting of only virtual methods is called a Pure Abstract Base Class (or Pure ABC) in C++ and is also known as an interface by users of the language.[13] Other languages, notably Java and C#, support a variant of abstract classes called an interface via a keyword in the language. In these languages, multiple inheritance is not allowed, but a class can implement multiple interfaces. Such a class can only contain abstract publicly accessible methods.[19][28][29]A concrete class is a class that can be instantiated, as opposed to abstract classes, which cannot.Local and inner[edit]In some languages, classes can be declared in scopes other than the global scope. There are various types of such classes.An inner class is a class defined within another class. The relationship between an inner class and its containing class can also be treated as another type of class association. An inner class is typically neither associated with instances of the enclosing class nor instantiated along with its enclosing class. Depending on language, it may or may not be possible to refer to the class from outside the enclosing class. A related concept is inner types, also known as inner data type or nested type, which is a generalization of the concept of inner classes. C++ is an example of a language that supports both inner classes and inner types (via typedef declarations).[30][31]Another type is a local class, which is a class defined within a procedure or function. This limits references to the class name to within the scope where the class is declared. Depending on the semantic rules of the language, there may be additional restrictions on local classes compared to non-local ones. One common restriction is to disallow local class methods to access local variables of the enclosing function. For example, in C++, a local class may refer to static variables declared within its enclosing function, but may not access the function's automatic variables.[32]Metaclasses[edit]Metaclasses are classes whose instances are classes.[33] A metaclass describes a common structure of a collection of classes and can implement a design pattern or describe particular kinds of classes. Metaclasses are often used to describe frameworks.[34]In some languages, such as Python, Ruby or Smalltalk, a class is also an object; thus each class is an instance of a unique metaclass that is built into the language. [5] [35] [36] The Common Lisp Object System (CLOS) provides metaobject protocols (MOPs) to implement those classes and metaclasses. [37]Non-subclassable[edit]Non-subclassable classes allow programmers to design classes and hierarchies of classes where at some level in the hierarchy, further derivation is prohibited. (A stand-alone class may be also designated as non-subclassable, preventing the formation of any hierarchy). Contrast this to abstract classes, which imply, encourage, and require derivation in order to be used at all. A non-subclassable class is implicitly concrete.A non-subclassable class is created by declaring the class as sealed in C# or as final in Java or PHP.[38][39][40]For example, Java's String class is designated as final.[41]Non-subclassable classes may allow a compiler (in compiled languages) to perform optimizations that are not available for subclassable classes.[citation needed]Mixins[edit]Some languages have special support for mixins, though in any language with multiple inheritance a mixin is simply a class that does not represent an is-a-type-of relationship. Mixins are typically used to add the same methods to multiple classes; for example, a class UnicodeConversionMixin might provide a method called unicode_to_ascii when included in classes FileReader and WebPageScraper that do not share a common parent.Partial[edit]In languages supporting the feature, a partial class is a class whose definition may be split into multiple pieces, within a single source-code file or across multiple files. The pieces are merged at compile-time, making compiler output the same as for a non-partial class.The primary motivation for introduction of partial classes is to facilitate the implementation of code generators, such as visual designers. It is otherwise a challenge or compromise to develop code generators that can manage the generated code when it is interleaved within developer-written code. Using partial classes, a code generator can process a separate file or coarse-grained partial class within a file, and is thus alleviated from intricately interjecting generated code via extensive parsing, increasing compiler efficiency and eliminating the potential risk of corrupting developer code. In a simple implementation of partial classes, the compiler can perform a phase of precompilation where it unifies all the parts of a partial class. Then, compilation can proceed as usual.Other benefits and effects of the partial class feature include:\nEnables separation of a class's interface and implementation code in a unique way.\nEases navigation through large classes within an editor.\nEnables separation of concerns, in a way similar to aspect-oriented programming but without using any extra tools.\nEnables multiple developers to work on a single class concurrently without the need to merge individual code into one file at a later time.\nPartial classes have existed in Smalltalk under the name of Class Extensions for considerable time. With the arrival of the .NET framework 2, Microsoft introduced partial classes, supported in both C# 2.0 and Visual Basic 2005. WinRT also supports partial classes.Example in VB.NET[edit]This simple example, written in Visual Basic .NET, shows how parts of the same class are defined in two different files.\nfile1.vb\n\nfile2.vb\nWhen compiled, the result is the same as if the two files were written as one, like this:Example in Objective-C[edit]In Objective-C, partial classes, also known as categories, may even spread over multiple libraries and executables, like this example:In Foundation, header file NSData.h:In user-supplied library, a separate binary from Foundation framework, header file NSData+base64.h:And in an app, yet another separate binary file, source code file main.m:The dispatcher will find both methods called over the NSData instance and invoke both of them correctly.Uninstantiable[edit]Uninstantiable classes allow programmers to group together per-class fields and methods that are accessible at runtime without an instance of the class. Indeed, instantiation is prohibited for this kind of class.For example, in C#, a class marked static can not be instantiated, can only have static members (fields, methods, other), may not have instance constructors, and is sealed. [42]Unnamed[edit]An unnamed class or anonymous class is a class that is not bound to a name or identifier upon definition. This is analogous to named versus unnamed functions.Benefits[edit]The benefits of organizing software into object classes fall into three categories:[43]\nRapid development\nEase of maintenance\nReuse of code and designs\nObject classes facilitate rapid development because they lessen the semantic gap between the code and the users. System analysts can talk to both developers and users using essentially the same vocabulary, talking about accounts, customers, bills, etc. Object classes often facilitate rapid development because most object-oriented environments come with powerful debugging and testing tools. Instances of classes can be inspected at run time to verify that the system is performing as expected. Also, rather than get dumps of core memory, most object-oriented environments have interpreted debugging capabilities so that the developer can analyze exactly where in the program the error occurred and can see which methods were called to which arguments and with what arguments.[44]Object classes facilitate ease of maintenance via encapsulation. When developers need to change the behavior of an object they can localize the change to just that object and its component parts. This reduces the potential for unwanted side effects from maintenance enhancements.Software re-use is also a major benefit of using Object classes. Classes facilitate re-use via inheritance and interfaces. When a new behavior is required it can often be achieved by creating a new class and having that class inherit the default behaviors and data of its superclass and then tailor some aspect of the behavior or data accordingly. Re-use via interfaces (also known as methods) occurs when another object wants to invoke (rather than create a new kind of) some object class. This method for re-use removes many of the common errors that can make their way into software when one program re-uses code from another.[45]These benefits come with a cost of course. One of the most serious obstacles to using object classes has been performance. Interpreted environments that support languages such as Smalltalk and CLOS provided rapid development but the resulting code was not nearly as fast as what could be achieved in some procedural languages such as C. This has been partly addressed by the development of object-oriented languages that are not interpreted such as C++ and Java.[46] Also, due to Moore's law the processing power of computers has increased to the point where efficient code is not as critical for most systems as it was in the past.[citation needed]Still, no matter how well designed the language, there will always be an inevitable bit of required extra overhead to create a class rather than use procedural code and in some circumstances, especially where performance or memory are required to be optimal, that using object classes may not be the best approach. Also, getting the benefits of object classes requires that they be used appropriately and that requires training. Without the proper training developers may simply code procedural programs in an object-oriented environment and end up with the worst of both worlds.[47]Run-time representation[edit]As a data type, a class is usually considered as a compile-time construct. A language may also support prototype or factory metaobjects that represent run-time information about classes, or even represent metadata that provides access to reflection facilities and ability to manipulate data structure formats at run-time. Many languages distinguish this kind of run-time type information about classes from a class on the basis that the information is not needed at run-time. Some dynamic languages do not make strict distinctions between run-time and compile-time constructs, and therefore may not distinguish between metaobjects and classes.For example, if Human is a metaobject representing the class Person, then instances of class Person can be created by using the facilities of the Human metaobject.See also[edit]\nClass-based programming\nClass diagram (UML)\nList of object-oriented programming languages\nMixin\nObject-oriented programming\nPrototype-based programming\nTrait (computer programming)\nNotes[edit]References[edit]Further reading[edit]\nAbadi; Cardelli: A Theory of Objects\nISO/IEC 14882:2003 Programming Language C++, International standard\nClass Warfare: Classes vs. Prototypes, by Brian Foote\nMeyer, B.: Object-oriented software construction, 2nd edition, Prentice Hall, 1997, ISBN 0-13-629155-4\nRumbaugh et al.: Object-oriented modeling and design, Prentice Hall, 1991, ISBN 0-13-630054-5\nExternal links[edit]\nDias, Tiago (October 2006). Programming demo - .NET using Partial Types for better code. Hyper/Net. Youtube. \n", "subtitles": ["Class vs. type", "Design and implementation", "Inter-class relationships", "Taxonomy of classes", "Benefits", "Run-time representation", "See also", "Notes", "References", "Further reading", "External links"], "title": "Class (computer programming)"},
{"content": "In most computer programming languages, a while loop is a control flow statement that allows code to be executed repeatedly based on a given Boolean condition. The while loop can be thought of as a repeating if statement.Overview[edit]The while construct consists of a block of code and a condition/expression.[1] The condition/expression is evaluated, and if the condition/expression is true,[1] the code within the block is executed. This repeats until the condition/expression becomes false. Because the while loop checks the condition/expression before the block is executed, the control structure is often also known as a pre-test loop. Compare this with the do while loop, which tests the condition/expression after the loop has executed.For example, in the C programming language (as well as Java, C#,[2] Objective-C, and C++, which use the same syntax in this case), the code fragmentfirst checks whether x is less than 5, which it is, so then the {loop body} is entered, where the printf function is run and x is incremented by 1. After completing all the statements in the loop body, the condition, (x < 5), is checked again, and the loop is executed again, this process repeating until the variable x has the value 5.Note that it is possible, and in some cases desirable, for the condition to always evaluate to true, creating an infinite loop. When such a loop is created intentionally, there is usually another control structure (such as a break statement) that controls termination of the loop. For example:Equivalent constructs[edit]In the C programming language,is equivalent toorororThose last two are not recommended because the use of goto statements makes it hard for a programmer to understand the flow of control, and is generally regarded as a last resort.Also, in C and its descendants, a while loop is a for loop with no initialization or counting expressions, i.e.,Demonstrating while loops[edit]These while loops will calculate the factorial of the number 5:ActionScript 3[edit]Ada[edit]Microsoft Small Basic[edit]Visual Basic[edit]Bourne (Unix) shell[edit]\ninclude <stdio.h>\nint main() {\n int i=10;\n while (i==10);\n {\n printf(%d,i);\n i++;\n }\n}Fortran[edit]Java, C#, D[edit]The code for the loop is the same for Java, C# and D:For Java the result is printed as follows:The same in C#And finally in DJavaScript[edit]Lua[edit]MATLAB[edit]Mathematica[edit]Oberon, Oberon-2 (programming language), Oberon-07, or Component Pascal[edit]Maya Embedded Language[edit]Pascal[edit]Perl[edit]While loops are frequently used for reading data line by line (as defined by the $/ line separator) from open filehandles:PHP[edit]PL/I[edit]Python[edit]Non-terminating while loop:Racket[edit]In Racket, as in other Scheme implementations, a named-let is a popular way to implement loops:Using a macro system, implementing a while loop is a trivial exercise (commonly used to introduce macros):But note that an imperative programming style is often discouraged in Racket (as in Scheme).Ruby[edit]Smalltalk[edit]Contrary to other languages, in Smalltalk a while loop is not a language construct but defined in the class BlockClosure as a method with one parameter, the body as a closure, using self as the condition.Smalltalk also has a corresponding whileFalse: method.Swift[edit]Tcl[edit]VEX[edit]Windows PowerShell[edit]While programming language[edit]The While programming language[3] is a simple programming language constructed from assignments, sequential composition, conditionals and while statements, used in the theoretical analysis of imperative programming language semantics.[4][5]See also[edit]\nDo while loop\nFor loop\nForeach\nLOOP (programming language) \u2013 a programming language with the property that the functions it can compute are exactly the primitive recursive functions\nReferences[edit]", "subtitles": ["Overview", "Equivalent constructs", "Demonstrating ", " loops", "See also", "References"], "title": "While loop"},
{"content": "In computer science, an object can be a variable, a data structure, a function, or a method, and as such, is a location in memory having a value and referenced by an identifier.In the class-based object-oriented programming paradigm, object refers to a particular instance of a class where the object can be a combination of variables, functions, and data structures.In relational database management, an object can be a table or column, or an association between data and a database entity (such as relating a person's age to a specific person).[1]Object-based languages[edit]An important distinction in programming languages is the difference between an object-oriented language and an object-based language. A language is usually considered object-based if it includes the basic capabilities for an object: identity, properties, and attributes. A language is considered object-oriented if it is object-based and also has the capability of polymorphism and inheritance. Polymorphism refers to the ability to overload the name of a function with multiple behaviors based on which object(s) are passed to it. Conventional message passing discriminates only on the first object and considers that to be sending a message to that object. However, some OOP languages such as Flavors and the Common Lisp Object System (CLOS) enable discriminating on more than the first parameter of the function.[2] Inheritance is the ability to subclass an object class, to create a new class that is a subclass of an existing one and inherits all the data constraints and behaviors of its parents but also adds new and/or changes one or more of them.[3][4]Object-oriented programming[edit]Object-oriented programming is an approach to designing modular reusable software systems. The object-oriented approach is an evolution of good design practices that go back to the very beginning of computer programming. Object-orientation is simply the logical extension of older techniques such as structured programming and abstract data types. An object is an abstract data type with the addition of polymorphism and inheritance.Rather than structure programs as code and data, an object-oriented system integrates the two using the concept of an object. An object has state (data) and behavior (code). Objects can correspond to things found in the real world. So for example, a graphics program will have objects such as circle, square, menu. An online shopping system will have objects such as shopping cart, customer, product. The shopping system will support behaviors such as place order, make payment, and offer discount. The objects are designed as class hierarchies. So for example with the shopping system there might be high level classes such as electronics product, kitchen product, and book. There may be further refinements for example under electronic products: CD Player, DVD player, etc. These classes and subclasses correspond to sets and subsets in mathematical logic.[5][6]Specialized objects[edit]An important concept for objects is the design pattern. A design pattern provides a reusable template to address a common problem. The following object descriptions are examples of some of the most common design patterns for objects.[7]\nFunction object: an object with a single method (in C++, this method would be the function operator, operator()) that acts much like a function (like a C/C++ pointer to a function).\nImmutable object: an object set up with a fixed state at creation time and which does not change afterward.\nFirst-class object: an object that can be used without restriction.\nContainer object: an object that can contain other objects.\nFactory object: an object whose purpose is to create other objects.\nMetaobject: an object from which other objects can be created (compare with a class, which is not necessarily an object).\nPrototype object: a specialized metaobject from which other objects can be created by copying\nGod object: an object that knows or does too much (it is an example of an anti-pattern).\nSingleton object: an object that is the only instance of its class during the lifetime of the program.\nFilter object.\nDistributed objects[edit]The object-oriented approach is not just a programming model. It can be used equally well as an interface definition language for distributed systems. The objects in a distributed computing model tend to be larger grained, longer lasting, and more service-oriented than programming objects.A standard method to package distributed objects is via an Interface Definition Language (IDL). An IDL shields the client of all of the details of the distributed server object. Details such as which computer the object resides on, what programming language it uses, what operating system, and other platform specific issues. The IDL is also usually part of a distributed environment that provides services such as transactions and persistence to all objects in a uniform manner. Two of the most popular standards for distributed objects are the Object Management Group's CORBA standard and Microsoft's DCOM.[8]In addition to distributed objects, a number of other extensions to the basic concept of an object have been proposed to enable distributed computing:\nProtocol objects are components of a protocol stack that enclose network communication within an object-oriented interface.\nReplicated objects are groups of distributed objects (called replicas) that run a distributed multi-party protocol to achieve high consistency between their internal states, and that respond to requests in a coordinated way. Examples include fault-tolerant CORBA objects.\nLive distributed objects (or simply live objects)[9] generalize the replicated object concept to groups of replicas that might internally use any distributed protocol, perhaps resulting in only a weak consistency between their local states.\nSome of these extensions, such as distributed objects and protocol objects, are domain-specific terms for special types of ordinary objects used in a certain context (such as remote method invocation or protocol composition). Others, such as replicated objects and live distributed objects, are more non-standard, in that they abandon the usual case that an object resides in a single location at a time, and apply the concept to groups of entities (replicas) that might span across multiple locations, might have only weakly consistent state, and whose membership might dynamically change.The Semantic Web[edit]The Semantic Web is essentially a distributed objects framework. Two key technologies in the Semantic Web are the Web Ontology Language (OWL) and the Resource Description Framework (RDF). RDF provides the capability to define basic objects\u2014names, properties, attributes, relations\u2014that are accessible via the Internet. OWL adds a richer object model, based on set theory, that provides additional modeling capabilities such as multiple inheritance.OWL objects are not like standard large grained distributed objects accessed via an Interface Definition Language. Such an approach would not be appropriate for the Internet because the Internet is constantly evolving and standardization on one set of interfaces is difficult to achieve. OWL objects tend to be similar to the kind of objects used to define application domain models in programming languages such as Java and C++.However, there are important distinctions between OWL objects and traditional object-oriented programming objects. Where as traditional objects get compiled into static hierarchies usually with single inheritance, OWL objects are dynamic. An OWL object can change its structure at run time and can become an instance of new or different classes.Another critical difference is the way the model treats information that is currently not in the system. Programming objects and most database systems use the closed-world assumption. If a fact is not known to the system that fact is assumed to be false. Semantic Web objects use the open-world assumption, a statement is only considered false if there is actual relevant information that it is false, otherwise it is assumed to be unknown, neither true nor false.OWL objects are actually most like objects in artificial intelligence frame languages such as KL-ONE and Loom.The following table contrasts traditional objects from Object-Oriented programming languages such as Java or C++ with Semantic Web Objects:[10][11]See also[edit]\nObject lifetime\nObject copy\nDesign pattern (computer science)\nBusiness object (computer science)\nActor model\nReferences[edit]External links[edit]\nWhat Is an Object? from The Java Tutorials\nTHE COMPUTER OBJECTS LOOKING FOR THEIR SOCIAL AND ORGANIZATIONAL IMPLICATIONS. http://revistas.face.ufmg.br/index.php/farol/article/view/2709\n", "subtitles": ["Object-based languages", "Object-oriented programming", "Specialized objects", "Distributed objects", "The Semantic Web", "See also", "References", "External links"], "title": "Object (computer science)"},
{"content": "A method in object-oriented programming (OOP) is a procedure associated with a message and an object. An object is mostly made up of data and behavior, which form the interface that an object presents to the outside world. Data is represented as properties of the object and behavior as methods. For example, a Window object would have methods such as open and close, while its state (whether it is opened or closed) would be a property.In class-based programming, methods are defined in a class, and objects are instances of a given class. One of the most important capabilities that a method provides is method overriding. The same name (e.g., area) can be used for multiple different kinds of classes. This allows the sending objects to invoke behaviors and to delegate the implementation of those behaviors to the receiving object. A method in Java programming sets the behavior of a class object. For example, an object can send an area message to another object and the appropriate formula is invoked whether the receiving object is a rectangle, circle, triangle, etc.Methods also provide the interface that other classes use to access and modify the data properties of an object. This is known as encapsulation. Encapsulation and overriding are the two primary distinguishing features between methods and procedure calls.[1]Overriding and overloading[edit]Method overriding and overloading are two of the most significant ways that a method differs from a conventional procedure or function call. Overriding refers to a subclass redefining the implementation of a method of its superclass. For example, findArea may be a method defined on a shape class. The various subclasses: rectangle, circle, triangle, etc. would each define the appropriate formula to calculate their area. The idea is to look at objects as black boxes so that changes to the internals of the object can be made with minimal impact on the other objects that use it. This is known as encapsulation and is meant to make code easier to maintain and re-use.Method overloading, on the other hand, refers to differentiating the code used to handle a message based on the parameters of the method. If one views the receiving object as the first parameter in any method then overriding is just a special case of overloading where the selection is based only on the first argument.[2] The following simple Java example illustrates the difference:[3]Accessor, mutator and manager methods[edit]Accessor methods are used to read data values of an object. Mutator methods are used to modify the data of an object. Manager methods are used to initialize and destroy objects of a class, e.g. constructors and destructors.These methods provide an abstraction layer that facilitates encapsulation and modularity. For example, if a bank-account class provides a getBalance() accessor method to retrieve the current balance (rather than directly accessing the balance data fields), then later revisions of the same code can implement a more complex mechanism for balance retrieval (e.g., a database fetch), without the dependent code needing to be changed. The concepts of encapsulation and modularity are not unique to object-oriented programming. Indeed, in many ways the object-oriented approach is simply the logical extension of previous paradigms such as abstract data types and structured programming.[4]Constructors[edit]A constructor is a method that is called at the beginning of an object's lifetime to create and initialize the object, a process called construction (or instantiation). Initialization may include an acquisition of resources. Constructors may have parameters but usually, do not return values in most languages. See the following example in Java:Destructors[edit]A destructor is a method that is called automatically at the end of an object's lifetime, a process called destruction. Destruction in most languages does not allow destructor method arguments nor return values. Destruction can be implemented so as to perform cleanup chores and other tasks at object destruction.Finalizers[edit]In garbage-collected languages, such as Java, C#, and Python, destructors are known as finalizers. They have a similar purpose and function to destructors, but because of the differences between languages that utilize garbage-collection and languages with manual memory management, the sequence in which they are called is different.Abstract methods[edit]An abstract method is one with only a signature and no implementation body. It is often used to specify that a subclass must provide an implementation of the method. Abstract methods are used to specify interfaces in some computer languages.[5]Example[edit]The following Java code shows an abstract class that needs to be extended:The following subclass extends the main class:Class methods[edit]Class methods are methods that are called on a class rather than an instance. They are typically used as part of an object meta-model. I.e, for each class, defined an instance of the class object in the meta-model is created. Meta-model protocols allow classes to be created and deleted. In this sense, they provide the same functionality as constructors and destructors described above. But in some languages such as the Common Lisp Object System (CLOS) the meta-model allows the developer to dynamically alter the object model at run time: e.g., to create new classes, redefine the class hierarchy, modify properties, etc.Special methods[edit]Special methods are very language-specific and a language may support none, some, or all of the special methods defined here. A language's compiler may automatically generate default special methods or a programmer may be allowed to optionally define special methods. Most special methods cannot be directly called, but rather the compiler generates code to call them at appropriate times.Static methods[edit]Static methods are meant to be relevant to all the instances of a class rather than to any specific instance. They are similar to static variables in that sense. An example would be a static method to sum the values of all the variables of every instance of a class. For example, if there were a Product class it might have a static method to compute the average price of all products.In Java, a commonly used static method is:\nMath.max(double a, double b)\nThis static method has no owning object and does not run on an instance. It receives all information from its arguments.[6]A static method can be invoked even if no instances of the class exist yet. Static methods are called static because they are resolved at compile time based on the class they are called on and not dynamically as in the case with instance methods, which are resolved polymorphically based on the runtime type of the object.Copy-assignment operators[edit]Copy-assignment operators define actions to be performed by the compiler when a class object is assigned to a class object of the same type.Operator methods[edit]Operator methods define or redefine operator symbols and define the operations to be performed with the symbol and the associated method parameters. C++ Example:Member functions in C++[edit]Some procedural languages were extended with object-oriented capabilities to leverage the large skill sets and legacy code for those languages but still provide the benefits of object-oriented development. Perhaps the most well-known example is C++, an object-oriented extension of the C programming language. Due to the design requirements to add the object-oriented paradigm on to an existing procedural language, message passing in C++ has some unique capabilities and terminologies. For example, in C++ a method is known as a member function. C++ also has the concept of virtual functions which are member functions that can be overridden in derived classes and allow for dynamic dispatch.Virtual functions[edit]Virtual functions are the means by which a C++ class can achieve polymorphic behavior. Non-virtual member functions, or regular methods, are those that do not participate in polymorphism.C++ Example:See also[edit]\nProperty (programming)\nRemote method invocation\nSubroutine, also called subprogram, routine, procedure, or function\nNotes[edit]References[edit]", "subtitles": ["Overriding and overloading", "Accessor, mutator and manager methods", "Abstract methods", "Class methods", "Special methods", "Member functions in C++", "See also", "Notes", "References"], "title": "Method (computer programming)"},
{"content": "For each (or foreach) is a control flow statement for traversing items in a collection. Foreach is usually used in place of a standard for statement. Unlike other for loop constructs, however, foreach loops[1] usually maintain no explicit counter: they essentially say do this to everything in this set, rather than do this x times. This avoids potential off-by-one errors and makes code simpler to read. In object-oriented languages an iterator, even if implicit, is often used as the means of traversal.The foreach statement in some languages has some defined order, processing each item in the collection from the first to the last. The foreach statement in many other languages does not have any particular order, especially array programming languages, in order to support loop optimization in general and in particular to allow vector processing to process some or all of the items in the collection simultaneously.Syntax[edit]Syntax varies among languages. Most use the simple word for, roughly as follows:\nfor each item in collection:\n  do something to item\nLanguage support[edit]Programming languages which support foreach loops include ABC, ActionScript, Ada, C++11, C#, ColdFusion Markup Language (CFML), Cobra, D, Daplex (query language), ECMAScript, Erlang, Java (since 1.5, using the reserved word for for the for loop and the foreach loop), JavaScript, Lua, Objective-C (since 2.0), ParaSail, Perl, PHP, Python, REALbasic, Ruby, Scala, Smalltalk, Swift, Tcl, tcsh, Unix shells, Visual Basic .NET, and Windows PowerShell. Notable languages without foreach are C, and C++ pre-C++11.ActionScript[edit]ActionScript supports foreach loops by key/index and by value:Typical usage is as shown, but someArray could be any object, and someObject could be an array.Ada[edit]Ada supports foreach loops as part of the normal for loop. Say X is an array:This syntax is used on mostly arrays, but will also work with other types when a full iteration is needed.Ada 2012 has generalized loops to foreach loops on any kind of container (array, lists, maps...):C[edit]The language C does not have collections or a foreach construct. However, it has several standard data structures that can be used as collections, and foreach can be made easily with a macro.However, two obvious problems occur:\nThe macro is unhygienic: it declares a new variable in the existing scope which remains after the loop.\nOne foreach macro cannot be defined that works with different collection types (e.g., array and linked list) or that is extensible to user types.\nC string as a collection of charC int array as a collection of int (array size known at compile-time)Most general: string or array as collection (collection size known at run-time)\nNote: idxtype can be removed and typeof(col[0]) used in its place with GCC\nC#[edit]In C#, assuming that myArray is an array of integers:Language Integrated Query (LINQ) provides the following syntax, accepting a delegate or lambda expression:C++[edit]C++11 provides a foreach loop. The syntax is similar to that of Java:Currently, C++11 range-based for statements have been implemented in GNU Compiler Collection (GCC) (since version 4.6), Clang (since version 3.0) and Visual C++ 2012 (version 11 [2])The C++ STL also supports for_each[3], that applies each element to a function, which can be any predefined function or a lambda expression. While the direction of the range-based for is only from the beginning to the end, you can change the direction or range by altering the first two parameters.Qt, a C++ framework, offers a macro providing foreach loops[4] using the STL iterator interface:Boost, a set of free peer-reviewed portable C++ libraries also provides foreach loops:[5]C++/CLI[edit]The C++/CLI language proposes a construct similar to C#.Assuming that myArray is an array of integers:ColdFusion Markup Language (CFML)[edit]Script syntax[edit]Tag syntax[edit]CFML incorrectly identifies the value as index in this construct; the index variable does receive the actual value of the array element, not its index.Common Lisp[edit]Common Lisp provides foreach ability either with the dolist macro:or the powerful loop macro to iterate on more data typesand even with the mapcar function:D[edit]Dart[edit]Object Pascal, Delphi[edit]Foreach support was added in Delphi 2005, and uses an enumerator variable that must be declared in the var section.Eiffel[edit]The iteration (foreach) form of the Eiffel loop construct is introduced by the keyword across.In this example, every element of the structure my_list is printed:The local entity ic is an instance of the library class ITERATION_CURSOR. The cursor's feature item provides access to each structure element. Descendants of class ITERATION_CURSOR can be created to handle specialized iteration algorithms. The types of objects that can be iterated across (my_list in the example) are based on classes that inherit from the library class ITERABLE.The iteration form of the Eiffel loop can also be used as a boolean expression when the keyword loop is replaced by either all (effecting universal quantification) or some (effecting existential quantification).This iteration is a boolean expression which is true if all items in my_list have counts greater than three:The following is true if at least one item has a count greater than three:Go[edit]Go's foreach loop can be used to loop over an array, slice, string, map, or channel.Using the two-value form, we get the index/key (first element) and the value (second element):Using the one-value form, we get the index/key (first element):[6]Groovy[edit]Groovy supports for loops over collections like arrays, lists and ranges:Groovy also supports a C-style for loop with an array index:Collections in Groovy can also be iterated over using the each keyword and a closure. By default, the loop dummy is named itHaskell[edit]Haskell allows looping over lists with monadic actions using mapM_ and forM_ (mapM_ with its arguments flipped) from Control.Monad:It's also possible to generalize those functions to work on applicative functors rather than monads and any data structure that is traversable using traverse (for with its arguments flipped) and mapM (forM with its arguments flipped) from Data.Traversable.Haxe[edit]Java[edit]In Java, a foreach-construct was introduced in Java Development Kit (JDK) 1.5.0.[7]Official sources use several names for the construct. It is referred to as the Enhanced for Loop,[7] the For-Each Loop,[8] and the foreach statement.[9]JavaScript[edit]For unordered iteration over the keys in an Object, JavaScript features the for...in loop:To limit the iteration to the object's own properties, excluding those inherited through the prototype chain, it is sometimes useful to add a hasOwnProperty() test, if supported by the JavaScript engine (for WebKit/Safari, this means in version 3 or later).In ECMAScript 5 it is possible to use the keys method of the Object function to iterate over the own keys of an object more naturally. [10]In ECMAScript 5 it's also possible to use the forEach method of a native array.[11]Gecko\u2019s JavaScript engine also has a for each...in statement, which iterates over the values in the object, not the keys.[12]Also note that it is inadvisable to use either a for...in or for each...in statement on an Array object in JavaScript, due to the above issue of properties inherited from prototypes, and also because it only iterates over existent keys and is not guaranteed to iterate over the elements in any particular order.[13] A regular C-style for loop should be used instead. The EcmaScript 6 standard has for..of for index-less iteration over generators, arrays and more.Lua[14][edit]Iterate only through numerical index values:Iterate through all index values:Mathematica[edit]In Mathematica, Do will simply evaluate an expression for each element of a list, without returning any value.It is more common to use Table, which returns the result of each evaluation in a new list.MATLAB[edit]Mint[edit]For each loops are supported in Mint, possessing the following syntax:The for (;;) or while (true) infinite loop in Mint can be written using a for each loop and an infinitely long list.[15]Objective-C[edit]Foreach loops, called Fast enumeration, are supported starting in Objective-C 2.0. They can be used to iterate over any object that implements the NSFastEnumeration protocol, including NSArray, NSDictionary (iterates over keys), NSSet, etc.NSArrays can also broadcast a message to their members:Where blocks are available, an NSArray can automatically perform a block on every contained item:The type of collection being iterated will dictate the item returned with each iteration. For example:OCaml[edit]OCaml is a functional language. Thus, the equivalent of a foreach loop can be achieved as a library function over lists and arrays.For lists:or in short way:For arrays:or in short way:ParaSail[edit]The ParaSail parallel programming language supports several kinds of iterators, including a general for each iterator over a container:ParaSail also supports filters on iterators, and the ability to refer to both the key and the value of a map. Here is a forward iteration over the elements of My_Map selecting only elements where the keys are in My_Set:Pascal[edit]In Pascal, ISO standard 10206:1990 introduced iteration over set types, thus:Perl[edit]In Perl, foreach (which is equivalent to the shorter for) can be used to traverse elements of a list. The expression which denotes the collection to loop over is evaluated in list-context and each item of the resulting list is, in turn, aliased to the loop variable.List literal example:Array examples:Hash example:Direct modification of collection members:Perl 6[edit]In Perl 6, a distinct language from Perl 5, for must be used to traverse elements of a list. (foreach is no longer allowed.) The expression which denotes the collection to loop over is evaluated in list-context, but not flattened by default, and each item of the resulting list is, in turn, aliased to the loop variable(s).List literal example:Array examples:Hash example:ororDirect modification of collection members:PHP[edit]It is also possible to extract both keys and values using the alternate syntax:Direct modification of collection members:\nMore information\nPython[edit]Python's tuple assignment, fully available in its foreach loop, also makes it trivial to iterate on (key, value) pairs in associative arrays:As for ... in is the only kind of for loop in Python, the equivalent to the counter loop found in other languages is...... though using the enumerate function is considered more Pythonic:Racket[edit]or using the conventional Scheme for-each function:do-something-with is a one-argument function.Ruby[edit]orThis can also be used with a hash.Scala[edit]Scheme[edit]do-something-with is a one-argument function.Smalltalk[edit]Swift[edit]Swift uses the for...in construct to iterate over members of a collection.[16]The for...in loop is often used with the closed and half-open range constructs to iterate over the loop body a certain number of times.SystemVerilog[edit]SystemVerilog supports iteration over any vector or array type of any dimensionality using the foreach keyword.A trivial example iterates over an array of integers:A more complex example iterates over an associative array of arrays of integers:Tcl[edit]Tcl uses foreach to iterate over lists. It is possible to specify more than one iterator variable, in which case they are assigned sequential values from the list.It is also possible to iterate over more than one list simultaneously. In the following i assumes sequential values of the first list, j sequential values of the second list:Visual Basic .NET[edit]or without type inferenceWindows PowerShell[edit]From a pipelineExtensible Stylesheet Language (XSL)[edit][17]See also[edit]\nDo while loop\nFor loop\nWhile loop\nMap (higher-order function)\nReferences[edit]", "subtitles": ["Syntax", "Language support", "See also", "References"], "title": "Foreach loop"},
{"content": "In computer science, conditional statements, conditional expressions and conditional constructs are features of a programming language, which perform different computations or actions depending on whether a programmer-specified boolean condition evaluates to true or false. Apart from the case of branch predication, this is always achieved by selectively altering the control flow based on some condition.In imperative programming languages, the term conditional statement is usually used, whereas in functional programming, the terms conditional expression or conditional construct are preferred, because these terms all have distinct meanings.A conditional is sometimes colloquially referred to as an if-check, especially when perceived as a simple one and when its specific form is irrelevant or unknown.Although dynamic dispatch is not usually classified as a conditional construct, it is another way to select between alternatives at runtime.If\u2013then(\u2013else)[edit]The if\u2013then construct (sometimes called if\u2013then\u2013else) is common across many programming languages. Although the syntax varies from language to language, the basic structure (in pseudocode form) looks like this:In the example code above, the part represented by (boolean condition) constitutes a conditional expression, having intrinsic value (e.g., it may be substituted by either of the values True or False) but having no intrinsic meaning. In contrast, the combination of this expression, the If and Then surrounding it, and the consequent that follows afterward constitute a conditional statement, having intrinsic meaning (e.g., expressing a coherent logical rule) but no intrinsic value.When an interpreter finds an If, it expects a boolean condition \u2013 for example, x > 0, which means the variable x contains a number that is greater than zero \u2013 and evaluates that condition. If the condition is true, the statements following the then are executed. Otherwise, the execution continues in the following branch \u2013 either in the else block (which is usually optional), or if there is no else branch, then after the end If.After either branch has been executed, control returns to the point after the end If.In early programming languages, especially some dialects of BASIC in the 1980s home computers, an if\u2013then statement could only contain GOTO statements. This led to a hard-to-read style of programming known as spaghetti programming, with programs in this style called spaghetti code. As a result, structured programming, which allows (virtually) arbitrary statements to be put in statement blocks inside an if statement, gained in popularity, until it became the norm even in most BASIC programming circles. Such mechanisms and principles were based on the older but more advanced ALGOL family of languages, and ALGOL-like languages such as Pascal and Modula-2 influenced modern BASIC variants for many years. While it is possible while using only GOTO statements in if\u2013then statements to write programs that are not spaghetti code and are just as well structured and readable as programs written in a structured programming language, structured programming makes this easier and enforces it. Structured if\u2013then\u2013else statements like the example above are one of the key elements of structured programming, and they are present in most popular high-level programming languages such as C, Java, JavaScript and Visual Basic .A subtlety is that the optional else clause found in many languages means that the context-free grammar is ambiguous, since nested conditionals can be parsed in multiple ways. Specifically,\nif a then if b then s else s2\ncan be parsed as\nif a then (if b then s) else s2\nor\nif a then (if b then s else s2)\ndepending on whether the else is associated with the first if or second if. This is known as the dangling else problem, and is resolved in various ways, depending on the language.Else if[edit]By using else if, it is possible to combine several conditions. Only the statements following the first condition that is found to be true will be executed. All other statements will be skipped. The statements ofelseif, in Ada, is simply syntactic sugar for else followed by if. In Ada, the difference is that only one end if is needed, if one uses elseif instead of else followed by if. This is similar in Perl, which provides the keyword elsif to avoid the large number of braces that would be required by multiple if and else statements and also in Python, which uses the special keyword elif because structure is denoted by indentation rather than braces, so a repeated use of else and if would require increased indentation after every condition. Similarly, the earlier UNIX shells (later gathered up to the POSIX shell syntax[1]) use elif too, but giving the choice of delimiting with spaces, line breaks, or both.However, in many languages more directly descended from Algol, such as Algol68, Simula, Pascal, BCPL and C, this special syntax for the else if construct is not present, nor is it present in the many syntactical derivatives of C, such as Java, ECMA-script, PHP, and so on. This works because in these languages, any single statement (in this case if cond...) can follow a conditional without being enclosed in a block.This design choice has a slight cost in that code else if branch is, effectively, adding an extra nesting level, complicating the job for some compilers (or its implementors), which has to analyse and implement arbitrarily long else if chains recursively.If all terms in the sequence of conditionals are testing the value of a single expression (e.g., if x=0 ... else if x=1 ... else if x=2...), then an alternative is the switch statement, also called case-statement or select-statement. Conversely, in languages that do not have a switch statement, these can be produced by a sequence of else if statements.If\u2013then\u2013else expressions[edit]Many languages support if expressions, which are similar to if statements, but return a value as a result. Thus, they are true expressions (which evaluate to a value), not statements (which changes the program state or perform some kind of action).Algol family[edit]ALGOL 60 and some other members of the ALGOL family allow if\u2013then\u2013else as an expression:\n  myvariable := if x > 10 then 1 else 2\nLisp dialects[edit]In dialects of Lisp \u2013 Scheme, Racket and Common Lisp \u2013 the first of which was inspired to a great extent by ALGOL:Haskell[edit]In Haskell 98, there is only an if expression, no if statement, and the else part is compulsory, as every expression must have some value.[2] Logic that would be expressed with conditionals in other languages is usually expressed with pattern matching in recursive functions.Because Haskell is lazy, it is possible to write control structures, such as if, as ordinary expressions; the lazy evaluation means that an if function can evaluate only the condition and proper branch (where a strict language would evaluate all three). It can be written like this:[3]C-like languages[edit]C and C-like languages have a special ternary operator (?:) for conditional expressions with a function that may be described by a template like this:\ncondition ? evaluated-when-true : evaluated-when-false\nThis means that it can be inlined into expressions, unlike if-statements, in C-like languages:which can be compared to the Algol-family if\u2013then\u2013else expressions (and similar in Ruby and Scala, among others).To accomplish the same using an if-statement, this would take more than one line of code (under typical layout conventions):Some argue that the explicit if/then statement is easier to read and that it may compile to more efficient code than the ternary operator,[4] while others argue that concise expressions are easier to read than statements spread over several lines.In Small Basic[edit]First, when the user runs the program, a cursor appears waiting for the reader to type a number. If that number is greater than 10, the text My variable is named 'foo'. is displayed on the screen. If the number is smaller than 10, then the message My variable is named 'bar'. is printed on the screen.In Visual Basic[edit]In Visual Basic and some other languages, a function called IIf is provided, which can be used as a conditional expression. However, it does not behave like a true conditional expression, because both the true and false branches are always evaluated; it is just that the result of one of them is thrown away, while the result of the other is returned by the IIf function.Arithmetic if[edit]Up to Fortran 77, the language Fortran has an arithmetic if statement which is halfway between a computed IF and a case statement, based on the trichotomy x < 0, x = 0, x > 0. This was the earliest conditional statement in Fortran:[5]Where e is any numeric expression (not necessarily an integer); this is equivalent toBecause this arithmetic IF is equivalent to multiple GOTO statements that could jump to anywhere, it is considered to be an unstructured control statement, and should not be used if more structured statements can be used. In practice it has been observed that most arithmetic IF statements referenced the following statement with one or two of the labels.This was the only conditional control statement in the original implementation of Fortran on the IBM 704 computer. On that computer the test-and-branch op-code had three addresses for those three states. Other computers would have flag registers such as positive, zero, negative, even, overflow, carry, associated with the last arithmetic operations and would use instructions such as 'Branch if accumulator negative' then 'Branch if accumulator zero' or similar. Note that the expression is evaluated once only, and in cases such as integer arithmetic where overflow may occur, the overflow or carry flags would be considered also.Object-oriented implementation in Smalltalk[edit]In contrast to other languages, in Smalltalk the conditional statement is not a language construct but defined in the class Boolean as an abstract method that takes two parameters, both closures. Boolean has two subclasses, True and False, which both define the method, True executing the first closure only, False executing the second closure only.[6]JavaScript[edit]Two examples in JavaScript:Lambda Calculus[edit]In Lambda Calculus, the concept of an if-then-else conditional can be expressed using the expressions:\ntrue = \u03bbx. \u03bby. x\nfalse = \u03bbx. \u03bby. y\nifThenElse = (\u03bbc. \u03bbx. \u03bby. (c x y))\n\ntrue takes up to two arguments and once both are provided(see currying), it returns the first argument given.\nfalse takes up to two arguments and once both are provided(see currying), it returns the second argument given.\nifThenElse takes up to three arguments and once all are provided, it passes both second and third argument to the first argument(which is a function that given two arguments, and produces a result). We expect ifThenElse to only take true or false as an argument, both of which project the given two arguments to their preferred single argument, which is then returned.\nnote: if ifThenElse is passed two functions as the left and right conditionals; it is necessary to also pass an empty tuple () to the result of ifThenElse in order to actually call the chosen function, otherwise ifThenElse will just return the function object without getting called.In a system where numbers can be used without definition(like Lisp, Traditional paper math, so on), the above can be expressed as a single closure below:\n((\u03bbtrue. \u03bbfalse. \u03bbifThenElse.\n    (ifThenElse true 2 3)\n)(\u03bbx. \u03bby. x)(\u03bbx. \u03bby. y)(\u03bbc. \u03bbl. \u03bbr. c l r))\nHere, true, false, and ifThenElse are bound to their respective definitions which are passed to their scope at the end of their block.A working JavaScript analogy(using only functions of single variable for rigor) to this is:\nvar computationResult = ((_true => _false => _ifThenElse => \n    _ifThenElse(_true)(2)(3) \n)(x => y => x)(x => y => y)(c => x => y => c(x)(y)));\nThe code above with multivariable functions looks like this:\nvar computationResult = ((_true, _false, _ifThenElse) =>\n    _ifThenElse(_true, 2, 3)\n)((x, y) => x, (x, y) => y, (c, x, y) => c(x, y));\nanother version of the earlier example without a system where numbers are assumed is below.First example shows the first branch being taken, while second example shows the second branch being taken.\n((\u03bbtrue. \u03bbfalse. \u03bbifThenElse.\n    (ifThenElse true (\u03bbFirstBranch. FirstBranch) (\u03bbSecondBranch. SecondBranch))\n)(\u03bbx. \u03bby. x)(\u03bbx. \u03bby. y)(\u03bbc. \u03bbl. \u03bbr. c l r))\n\n((\u03bbtrue. \u03bbfalse. \u03bbifThenElse.\n    (ifThenElse false (\u03bbFirstBranch. FirstBranch) (\u03bbSecondBranch. SecondBranch))\n)(\u03bbx. \u03bby. x)(\u03bbx. \u03bby. y)(\u03bbc. \u03bbl. \u03bbr. c l r))\nSmalltalk uses a similar idea for its true and false representations, with True and False being singleton objects that respond to messages ifTrue/ifFalse differently.Haskell used to use this exact model for its Boolean type, but at the time of writing, most Haskell programs use syntactic sugar if a then b else c construct which unlike ifThenElse does not compose unlesseither wrapped in another function or re-implemented as shown in The Haskell section of this page.Case and switch statements[edit]Switch statements (in some languages, case statements or multiway branches) compare a given value with specified constants and take action according to the first constant to match. There is usually a provision for a default action ('else','otherwise') to be taken if no match succeeds. Switch statements can allow compiler optimizations, such as lookup tables. In dynamic languages, the cases may not be limited to constant expressions, and might extend to pattern matching, as in the shell script example on the right, where the '*)' implements the default case as a regular expression matching any string.Pattern matching[edit]Pattern matching may be seen as a more sophisticated alternative to both if\u2013then\u2013else, and case statements. It is available in many programming languages with functional programming features, such as Wolfram Language, ML and many others. Here is a simple example written in the OCaml language:The power of pattern matching is the ability to concisely match not only actions but also values to patterns of data. Here is an example written in Haskell which illustrates both of these features:This code defines a function map, which applies the first argument (a function) to each of the elements of the second argument (a list), and returns the resulting list. The two lines are the two definitions of the function for the two kinds of arguments possible in this case \u2013 one where the list is empty (just return an empty list) and the other case where the list is not empty.Pattern matching is not strictly speaking always a choice construct, because it is possible in Haskell to write only one alternative, which is guaranteed to always be matched \u2013 in this situation, it is not being used as a choice construct, but simply as a way to bind names to values. However, it is frequently used as a choice construct in the languages in which it is available.Hash-based conditionals[edit]In programming languages that have associative arrays or comparable data structures, such as Python, Perl, PHP or Objective-C, it is idiomatic to use them to implement conditional assignment.[7]In languages that have anonymous functions or that allow a programmer to assign a named function to a variable reference, conditional flow can be implemented by using a hash as a dispatch table.Predication[edit]An alternative to conditional branch instructions is predication. Predication is an architectural feature that enables instructions to be conditionally executed instead of modifying the control flow.Choice system cross reference[edit]This table refers to the most recent language specification of each language. For languages that do not have a specification, the latest officially released implementation is referred to.\n^ This refers to pattern matching as a distinct conditional construct in the programming language \u2013 as opposed to mere string pattern matching support, such as regular expression support.\n1 2 3 4 5 The often-encountered else if in the C family of languages, and in COBOL and Haskell, is not a language feature but a set of nested and independent if then else statements combined with a particular source code layout. However, this also means that a distinct else\u2013if construct is not really needed in these languages.\n1 2 In Haskell and F#, a separate constant choice construct is unneeded, because the same task can be done with pattern matching.\n^ In a Ruby case construct, regular expression matching is among the conditional flow-control alternatives available. For an example, see this Stack Overflow question.\n1 2 SQL has two similar constructs that fulfill both roles, both introduced in SQL-92. A searched CASE expression CASE WHEN cond1 THEN expr1 WHEN cond2 THEN expr2 [...] ELSE exprDflt END works like if ... else if ... else, whereas a simple CASE expression: CASE expr WHEN val1 THEN expr1 [...] ELSE exprDflt END works like a switch statement. For details and examples see Case (SQL).\n^ Arithmetic if is obsolescent in Fortran 90.\nSee also[edit]\nBranch (computer science)\nConditional compilation\nDynamic dispatch for another way to make execution choices\nMcCarthy Formalism for history and historical references\nNamed condition\nTest (Unix)\nYoda conditions\nConditional move\nReferences[edit]External links[edit]\nIF NOT (ActionScript 3.0) video\n", "subtitles": ["If\u2013then(\u2013else)", "Lambda Calculus", "Case and switch statements", "Pattern matching", "Hash-based conditionals", "Predication", "Choice system cross reference", "See also", "References", "External links"], "title": "Conditional (computer programming)"},
{"content": "The AI Memos are a series of influential memorandums and technical reports published by the MIT AI Lab, Massachusetts Institute of Technology, United States. They cover Artificial Intelligence, a field of computer science.Noteworthy memos in the series include:\nAI Memo 39, The New Compiler, describing the first implementation of a self-hosting compiler (for LISP 1.5)\nAI Memo 41, A Chess Playing Program, describing Kotok-McCarthy, the first computer program to play chess convincingly\nAI Memo 239 (1972), also known as HAKMEM, a compendium of hacks and algorithms\nSussman and Steele's Lambda Papers:\n\nAI Memo 349 (1975), Scheme: An Interpreter for Extended Lambda Calculus\nAI Memo 353 (1976), Lambda: The Ultimate Imperative\nAI Memo 379 (1976), Lambda: The Ultimate Declarative\nAI Memo 443 (1977), Debunking the 'Expensive Procedure Call' Myth, or, Procedure Call Implementations Considered Harmful, or, Lambda: The Ultimate GOTO\nAI Memo 453 (1978), The Art of the Interpreter of, the Modularity Complex (Parts Zero, One, and Two)\nAI Technical Report 474 (1978), RABBIT: A Compiler for SCHEME\nAI Memo 514 (1979), Design of LISP-based Processors, or SCHEME: A Dielectric LISP, or Finite Memories Considered Harmful, or LAMBDA: The Ultimate Opcode\n\n\nReferences[edit]\nMarvin Minsky (1983). Introduction to the COMTEX Microfiche Edition of the Early MIT Artificial Intelligence Memos. AI Magazine. 4 (1): 19\u201322. doi:10.1609/aimag.v4i1.384. \nExternal links[edit]\nAI Memos (1959\u20132004) collection at DSpace at MIT\nAI Series historical archive at the CSAIL Publications and Digital Archive\n", "subtitles": [], "title": "AI Memo"},
{"content": "CiteSeerx (originally called CiteSeer) is a public search engine and digital library for scientific and academic papers, primarily in the fields of computer and information science. Many[who?] consider it to be the first academic paper search engine and the first automated citation indexing system. CiteSeer holds a United States patent # 6289342, titled Autonomous citation indexing and literature browsing using citation context, granted on September 11, 2001. Stephen R. Lawrence, C. Lee Giles, Kurt D. Bollacker are the inventors of this patent assigned to NEC Laboratories America, Inc. This patent was filed on May 20, 1998, which has its roots (Priority) to January 05, 1998. A continuation patent was also granted to the same inventors and also assigned to NEC Labs on this invention i.e. US Patent # 6738780 granted on May 18, 2004 and was filed on May 16, 2001. CiteSeer is considered as a predecessor of academic search tools such as Google Scholar and Microsoft Academic Search.[citation needed] CiteSeer-like engines and archives usually only harvest documents from publicly available websites and do not crawl publisher websites. For this reason, authors whose documents are freely available are more likely to be represented in the index.CiteSeer's goal is to improve the dissemination and access of academic and scientific literature. As a non-profit service that can be freely used by anyone, it has been considered as part of the open access movement that is attempting to change academic and scientific publishing to allow greater access to scientific literature. CiteSeer freely provided Open Archives Initiative metadata of all indexed documents and links indexed documents when possible to other sources of metadata such as DBLP and the ACM Portal. To promote open data, CiteSeerx shares its data for non-commercial purposes under a Creative Commons license.[1]The name can be construed to have at least two explanations. As a pun, a 'sightseer' is a tourist who looks at the sights, so a 'cite seer' would be a researcher who looks at cited papers. Another is a 'seer' is a prophet and a 'cite seer' is a prophet of citations. CiteSeer changed its name to ResearchIndex at one point and then changed it back.History[edit]CiteSeer and CiteSeer.IST[edit]CiteSeer was created by researchers Lee Giles, Kurt Bollacker and Steve Lawrence in 1997 while they were at the NEC Research Institute (now NEC Labs), Princeton, New Jersey, USA. CiteSeer's goal was to actively crawl and harvest academic and scientific documents on the web and use autonomous citation indexing to permit querying by citation or by document, ranking them by citation impact. At one point, it was called ResearchIndex.CiteSeer became public in 1998 and had many new features unavailable in academic search engines at that time. These included:\nAutonomous Citation Indexing automatically created a citation index that can be used for literature search and evaluation.\nCitation statistics and related documents were computed for all articles cited in the database, not just the indexed articles.\nReference linking allowing browsing of the database using citation links.\nCitation context showed the context of citations to a given paper, allowing a researcher to quickly and easily see what other researchers have to say about an article of interest.\nRelated documents were shown using citation and word based measures and an active and continuously updated bibliography is shown for each document.\nAfter NEC, in 2004 it was hosted as CiteSeer.IST on the World Wide Web at the College of Information Sciences and Technology, The Pennsylvania State University, and had over 700,000 documents. For enhanced access, performance and research, similar versions of CiteSeer were supported at universities such as the Massachusetts Institute of Technology, University of Zu\u0308rich and the National University of Singapore. However, these versions of CiteSeer proved difficult to maintain and are no longer available. Because CiteSeer only indexes freely available papers on the web and does not have access to publisher metadata, it returns fewer citation counts than sites, such as Google Scholar, that have publisher metadata.CiteSeer had not been comprehensively updated since 2005 due to limitations in its architecture design. It had a representative sampling of research documents in computer and information science but was limited in coverage because it was limited to papers that are publicly available, usually at an author's homepage, or those submitted by an author. To overcome some of these limitations, a modular and open source architecture for CiteSeer was designed - CiteSeerx.CiteSeerx[edit]CiteSeerx replaced CiteSeer and all queries to CiteSeer were redirected. CiteSeerx[2] is a public search engine and digital library and repository for scientific and academic papers primarily with a focus on computer and information science.[2] However, recently CiteSeerx has been expanding into other scholarly domains such as economics, physics and others. Released in 2008, it was loosely based on the previous CiteSeer search engine and digital library and is built with a new open source infrastructure, SeerSuite, and new algorithms and their implementations. It was developed by researchers Dr. Isaac Councill and Dr. C. Lee Giles at the College of Information Sciences and Technology, Pennsylvania State University. It continues to support the goals outlined by CiteSeer to actively crawl and harvest academic and scientific documents on the public web and to use a citation inquery by citations and ranking of documents by the impact of citations. Currently, Lee Giles, Prasenjit Mitra, Susan Gauch, Min-Yen Kan, Pradeep Teregowda, Juan Pablo Ferna\u0301ndez Rami\u0301rez, Pucktada Treeratpituk, Jian Wu, Douglas Jordan, Steve Carman, Jack Carroll, Jim Jansen, and Shuyi Zheng are or have been actively involved in its development. Recently, a table search feature was introduced.[3] It has been funded by the National Science Foundation, NASA, and Microsoft Research.CiteSeerx continues to be rated as one of the world's top repositories and was rated number 1 in July 2010.[4] It currently has over 6 million documents with nearly 6 million unique authors and 120 million citations.CiteSeerx also shares its software, data, databases and metadata with other researchers, currently by Amazon S3 and by rsync.[5] Its new modular open source architecture and software (available previously on SourceForge but now on GitHub) is built on Apache Solr and other Apache and open source tools which allows it to be a testbed for new algorithms in document harvesting, ranking, indexing, and information extraction.Current features[edit]Automated information extraction[edit]CiteSeerx uses automated information extraction tools, usually built on machine learning methods such ParsCit, to extract scholarly document metadata such as title, authors, abstract, citations, etc. As such, there are sometime errors in authors and titles. Other academic search engines have similar errors.Focused crawling[edit]CiteSeerx crawls publicly available scholarly documents primarily from author webpages and other open resources, and does not have access to publisher metadata. As such citation counts in CiteSeerx are usually less than those in Google Scholar and Microsoft Academic Search who have access to publisher metadata.Usage[edit]CiteSeerx has nearly 1 million users worldwide based on unique IP addresses and has millions of hits daily. Annual downloads of document PDFs was nearly 200 million for 2015.Data[edit]CiteSeerx data is regularly shared under a Creative Commons BY-NC-SA License with researchers worldwide and has been and is used in many experiments and competitions.Other SeerSuite-based search engines[edit]The CiteSeer model had been extended to cover academic documents in business with SmealSearch and in e-business with eBizSearch. However, these were not maintained by their sponsors. An older version of both of these could be once found at BizSeer.IST but is no longer in service.Other Seer-like search and repository systems have been built for chemistry, ChemXSeer and for archaeology, ArchSeer. Another had been built for robots.txt file search, BotSeer. All of these are built on the open source tool SeerSuite, which uses the open source indexer Lucene.See also[edit]References[edit]Further reading[edit]\nGiles, C. Lee; Bollacker, Kurt D.; Lawrence, Steve (1998). CiteSeer: an automatic citation indexing system. Proceedings of the third ACM conference on Digital libraries: 89\u201398. CiteSeerX 10.1.1.30.6847 . doi:10.1145/276675.276685. ISBN 0-89791-965-3. \nExternal links[edit]\nOfficial website of CiteSeerx\nCiteSeerX on GitHub\nSeerSuite on SourceForge.net (historic)\n", "subtitles": ["History", "Current features", "Other SeerSuite-based search engines", "See also", "References", "Further reading", "External links"], "title": "CiteSeer"},
{"content": "\nStephen M. Omohundro (born 1959) is an American computer scientist[1] whose areas of research include Hamiltonian physics, dynamical systems, programming languages, machine learning, machine vision, and the social implications of artificial intelligence. His current work uses rational economics to develop safe and beneficial intelligent technologies for better collaborative modeling, understanding, innovation, and decision making.Education[edit]Omohundro earned degrees in physics and mathematics from Stanford University (Phi Beta Kappa)[2] and a Ph.D. in physics from the University of California, Berkeley.[3]Learning algorithms[edit]Omohundro started the Vision and Learning Group at the University of Illinois which produced 4 Masters and 2 Ph.D. theses. His work in learning algorithms included a number of efficient geometric algorithms,[4][5] the manifold learning task and various algorithms for accomplishing this task,[6] other related visual learning and modelling tasks,[7] the best-first model merging approach to machine learning[8] (including the learning of Hidden Markov Models and Stochastic Context-free Grammars),[9][10][11] and the Family Discovery Learning Algorithm, which discovers the dimension and structure of a parameterized family of stochastic models.[12]Self-improving artificial Intelligence and AI safety[edit]Omohundro started Self-Aware Systems in Palo Alto, California to research the technology and social implications of self-improving artificial intelligence. He is an advisor to the Machine Intelligence Research Institute on artificial intelligence. He argues that rational systems exhibit problematic natural drives that will need to be countered in order to build intelligent systems safely.[2][13] His papers, talks, and videos on AI safety have generated extensive interest.[1][14][15][16] He has given many talks on self-improving artificial intelligence, cooperative technology, AI safety, and connections with biological intelligence.Programming languages[edit]At Thinking Machines Corporation, Cliff Lasser and Steve Omohundro developed Star Lisp, the first programming language for the Connection Machine. Omohundro joined the International Computer Science Institute (ICSI) in Berkeley, California, where he led the development of the open source programming language Sather.[17][18] Sather is featured in O'Reilly's History of Programming Languages poster.[19]Physics and dynamical systems theory[edit]Omohundro's book Geometric Perturbation Theory in Physics[2][20] describes natural Hamiltonian symplectic structures for a wide range of physical models that arise from perturbation theory analyses.He showed that there exist smooth partial differential equations which stably perform universal computation by simulating arbitrary cellular automata.[21] The asymptotic behavior of these PDEs is therefore logically undecidable.With John David Crawford he showed that the orbits of three-dimensional period doubling systems can form an infinite number of topologically distinct torus knots and described the structure of their stable and unstable manifolds.[22]Mathematica and Apple tablet contest[edit]From 1986 to 1988, he was an Assistant Professor of Computer science at the University of Illinois at Urbana-Champaign and cofounded the Center for Complex Systems Research with Stephen Wolfram and Norman Packard. While at the University of Illinois, he worked with Stephen Wolfram and five others to create the symbolic mathematics program Mathematica.[2] He and Wolfram led a team of students that won an Apple Computer contest to design The Computer of the Year 2000. Their design entry Tablet was a touchscreen tablet with GPS and other features that finally appeared when the Apple iPad was introduced 22 years later.[23][24]Other contributions[edit]Subutai Ahmad and Steve Omohundro developed biologically realistic neural models of selective attention.[25][26][27][28] As a research scientist at the NEC Research Institute, Omohundro worked on machine learning and computer vision, and was a co-inventor of U.S. Patent 5,696,964, Multimedia Database Retrieval System Which Maintains a Posterior Probability Distribution that Each Item in the Database is a Target of a Search.[29][30][31][32]Pirate puzzle[edit]Omohundro developed an extension to the game theoretic pirate puzzle that was featured in Scientific American.[33]Outreach[edit]Omohundro has sat on the Machine Intelligence Research Institute board of advisors.[34] He has written extensively on artificial intelligence;[35] in addition, he has warned that an autonomous weapons arms race is already taking place because military and economic pressures are driving the rapid development of autonomous systems.[36][37]References[edit]External links[edit]\nOfficial website\nSelf-Aware Systems\nSteve Omohundro Interviews Playlist\n", "subtitles": ["Education", "Learning algorithms", "Self-improving artificial Intelligence and AI safety", "Programming languages", "Physics and dynamical systems theory", "Mathematica and Apple tablet contest", "Other contributions", "Outreach", "References", "External links"], "title": "Steve Omohundro"},
{"content": "In computer science, corecursion is a type of operation that is dual to recursion. Whereas recursion works analytically, starting on data further from a base case and breaking it down into smaller data and repeating until one reaches a base case, corecursion works synthetically, starting from a base case and building it up, iteratively producing data further removed from a base case. Put simply, corecursive algorithms use the data that they themselves produce, bit by bit, as they become available, and needed, to produce further bits of data. A similar but distinct concept is generative recursion which may lack a definite direction inherent in corecursion and recursion.Where recursion allows programs to operate on arbitrarily complex data, so long as they can be reduced to simple data (base cases), corecursion allows programs to produce arbitrarily complex and potentially infinite data structures, such as streams, so long as it can be produced from simple data (base cases) in a sequence of finite steps. Where recursion may not terminate, never reaching a base state, corecursion starts from a base state, and thus produces subsequent steps deterministically, though it may proceed indefinitely (and thus not terminate under strict evaluation), or it may consume more than it produces and thus become non-productive. Many functions that are traditionally analyzed as recursive can alternatively, and arguably more naturally, be interpreted as corecursive functions that are terminated at a given stage, for example recurrence relations such as the factorial.Corecursion can produce both finite and infinite data structures as results, and may employ self-referential data structures. Corecursion is often used in conjunction with lazy evaluation, to produce only a finite subset of a potentially infinite structure (rather than trying to produce an entire infinite structure at once). Corecursion is a particularly important concept in functional programming, where corecursion and codata allow total languages to work with infinite data structures.Examples[edit]Corecursion can be understood by contrast with recursion, which is more familiar. While corecursion is primarily of interest in functional programming, it can be illustrated using imperative programming, which is done below using the generator facility in Python. In these examples local variables are used, and assigned values imperatively (destructively), though these are not necessary in corecursion in pure functional programming. In pure functional programming, rather than assigning to local variables, these computed values form an invariable sequence, and prior values are accessed by self-reference (later values in the sequence reference earlier values in the sequence to be computed). The assignments simply express this in the imperative paradigm and explicitly specify where the computations happen, which serves to clarify the exposition.Factorial[edit]A classic example of recursion is computing the factorial, which is defined recursively as \n  \n    \n      \n        0\n        !\n        :=\n        1\n      \n    \n    {\\displaystyle 0!:=1}\n  \n and \n  \n    \n      \n        n\n        !\n        :=\n        n\n        \u00d7\n        (\n        n\n        \u2212\n        1\n        )\n        !\n      \n    \n    {\\displaystyle n!:=n\\times (n-1)!}\n  \nTo recursively compute its result on a given input, a recursive function calls (a copy of) itself with a different (smaller in some way) input and uses the result of this call to construct its result. The recursive call does the same, unless the base case has been reached. Thus a call stack develops in the process. For example, to compute fac(3), this recursively calls in turn fac(2), fac(1), fac(0) (winding up the stack), at which point recursion terminates with fac(0) = 1, and then the stack unwinds in reverse order and the results are calculated on the way back along the call stack to the initial call frame fac(3), where the final result is calculated as 3*2 =: 6 and finally returned. In this example a function returns a single value.This stack unwinding can be explicated, defining the factorial corecursively, as an iterator, where one starts with the case of \n  \n    \n      \n        1\n        =:\n        0\n        !\n      \n    \n    {\\displaystyle 1=:0!}\n  \n, then from this starting value constructs factorial values for increasing numbers 1, 2, 3... as in the above recursive definition with time arrow reversed, as it were, by reading it backwards as \n  \n    \n      \n        n\n        !\n        \u00d7\n        (\n        n\n        +\n        1\n        )\n        =:\n        (\n        n\n        +\n        1\n        )\n        !\n      \n    \n    {\\displaystyle n!\\times (n+1)=:(n+1)!}\n  \n. The corecursive algorithm thus defined produces a stream of all factorials. This may be concretely implemented as a generator. Symbolically, noting that computing next factorial value requires keeping track of both n and f (a previous factorial value), this can be represented as:\n\n  \n    \n      \n        n\n        ,\n        f\n        =\n        (\n        0\n        ,\n        1\n        )\n        :\n        (\n        n\n        +\n        1\n        ,\n        f\n        \u00d7\n        (\n        n\n        +\n        1\n        )\n        )\n      \n    \n    {\\displaystyle n,f=(0,1):(n+1,f\\times (n+1))}\n  \n\nor in Haskell,meaning, starting from \n  \n    \n      \n        n\n        ,\n        f\n        =\n        0\n        ,\n        1\n      \n    \n    {\\displaystyle n,f=0,1}\n  \n, on each step the next values are calculated as \n  \n    \n      \n        n\n        +\n        1\n        ,\n        f\n        \u00d7\n        (\n        n\n        +\n        1\n        )\n      \n    \n    {\\displaystyle n+1,f\\times (n+1)}\n  \n. This is mathematically equivalent and almost identical to the recursive definition, but the \n  \n    \n      \n        +\n        1\n      \n    \n    {\\displaystyle +1}\n  \n emphasizes that the factorial values are being built up, going forwards from the starting case, rather than being computed after first going backwards, down to the base case, with a \n  \n    \n      \n        \u2212\n        1\n      \n    \n    {\\displaystyle -1}\n  \n decrement. Note also that the direct output of the corecursive function does not simply contain the factorial \n  \n    \n      \n        n\n        !\n      \n    \n    {\\displaystyle n!}\n  \n values, but also includes for each value the auxiliary data of its index n in the sequence, so that any one specific result can be selected among them all, as and when needed.Note the connection with denotational semantics, where the denotations of recursive programs is built up corecursively in this way.In Python, a recursive factorial function can be defined as:[a]This could then be called for example as factorial(5) to compute 5!.A corresponding corecursive generator can be defined as:This generates an infinite stream of factorials in order; a finite portion of it can be produced by:This could then be called to produce the factorials up to 5! via:If we're only interested in a certain factorial, just the last value can be taken, or we can fuse the production and the access into one function,As can be readily seen here, this is practically equivalent (just by substituting return for the only yield there) to the accumulator argument technique for tail recursion, unwound into an explicit loop. Thus it can be said that the concept of corecursion is an explication of the embodiment of iterative computation processes by recursive definitions, where applicable.Fibonacci sequence[edit]In the same way, the Fibonacci sequence can be represented as:\n\n  \n    \n      \n        a\n        ,\n        b\n        =\n        (\n        0\n        ,\n        1\n        )\n        :\n        (\n        b\n        ,\n        a\n        +\n        b\n        )\n      \n    \n    {\\displaystyle a,b=(0,1):(b,a+b)}\n  \n\nNote that because the Fibonacci sequence is a recurrence relation of order 2, the corecursive relation must track two successive terms, with the \n  \n    \n      \n        (\n        b\n        ,\n        \u2212\n        )\n      \n    \n    {\\displaystyle (b,-)}\n  \n corresponding to shift forward by one step, and the \n  \n    \n      \n        (\n        \u2212\n        ,\n        a\n        +\n        b\n        )\n      \n    \n    {\\displaystyle (-,a+b)}\n  \n corresponding to computing the next term. This can then be implemented as follows (using parallel assignment):In Haskell,Tree traversal[edit]Tree traversal via a depth-first approach is a classic example of recursion. Dually, breadth-first traversal can very naturally be implemented via corecursion.Without using recursion or corecursion specifically, one may traverse a tree by starting at the root node, placing its child nodes in a data structure, then iterating by removing node after node from the data structure while placing each removed node's children back into that data structure.[b] If the data structure is a stack (LIFO), this yields depth-first traversal, and if the data structure is a queue (FIFO), this yields breadth-first traversal.Using recursion, a (post-order)[c] depth-first traversal can be implemented by starting at the root node and recursively traversing each child subtree in turn (the subtree based at each child node) \u2013 the second child subtree does not start processing until the first child subtree is finished. Once a leaf node is reached or the children of a branch node have been exhausted, the node itself is visited (e.g., the value of the node itself is outputted). In this case, the call stack (of the recursive functions) acts as the stack that is iterated over.Using corecursion, a breadth-first traversal can be implemented by starting at the root node, outputting its value,[d] then breadth-first traversing the subtrees \u2013 i.e., passing on the whole list of subtrees to the next step (not a single subtree, as in the recursive approach) \u2013 at the next step outputting the value of all of their root nodes, then passing on their child subtrees, etc.[e] In this case the generator function, indeed the output sequence itself, acts as the queue. As in the factorial example (above), where the auxiliary information of the index (which step one was at, n) was pushed forward, in addition to the actual output of n!, in this case the auxiliary information of the remaining subtrees is pushed forward, in addition to the actual output. Symbolically:\n\n  \n    \n      \n        v\n        ,\n        t\n        =\n        (\n        [\n        ]\n        ,\n        F\n        u\n        l\n        l\n        T\n        r\n        e\n        e\n        )\n        :\n        (\n        R\n        o\n        o\n        t\n        V\n        a\n        l\n        u\n        e\n        s\n        ,\n        C\n        h\n        i\n        l\n        d\n        T\n        r\n        e\n        e\n        s\n        )\n      \n    \n    {\\displaystyle v,t=([],FullTree):(RootValues,ChildTrees)}\n  \n\nmeaning that at each step, one outputs the list of values of root nodes, then proceeds to the child subtrees. Generating just the node values from this sequence simply requires discarding the auxiliary child tree data, then flattening the list of lists (values are initially grouped by level (depth); flattening (ungrouping) yields a flat linear list). In Haskell,These can be compared as follows. The recursive traversal handles a leaf node (at the bottom) as the base case (when there are no children, just output the value), and analyzes a tree into subtrees, traversing each in turn, eventually resulting in just leaf nodes \u2013 actual leaf nodes, and branch nodes whose children have already been dealt with (cut off below). By contrast, the corecursive traversal handles a root node (at the top) as the base case (given a node, first output the value), treats a tree as being synthesized of a root node and its children, then produces as auxiliary output a list of subtrees at each step, which are then the input for the next step \u2013 the child nodes of the original root are the root nodes at the next step, as their parents have already been dealt with (cut off above). Note also that in the recursive traversal there is a distinction between leaf nodes and branch nodes, while in the corecursive traversal there is no distinction, as each node is treated as the root node of the subtree it defines.Notably, given an infinite tree,[f] the corecursive breadth-first traversal will traverse all nodes, just as for a finite tree, while the recursive depth-first traversal will go down one branch and not traverse all nodes, and indeed if traversing post-order, as in this example (or in-order), it will visit no nodes at all, because it never reaches a leaf. This shows the usefulness of corecursion rather than recursion for dealing with infinite data structures.In Python, this can be implemented as follows.[g] The usual post-order depth-first traversal can be defined as:[h]This can then be called by df(t) to print the values of the nodes of the tree in post-order depth-first order.The breadth-first corecursive generator can be defined as:[i]This can then be called to print the values of the nodes of the tree in breadth-first order:Definition[edit]Initial data types can be defined as being the least fixpoint (up to isomorphism) of some type equation; the isomorphism is then given by an initial algebra. Dually, final (or terminal) data types can be defined as being the greatest fixpoint of a type equation; the isomorphism is then given by a final coalgebra.If the domain of discourse is the category of sets and total functions, then final data types may contain infinite, non-wellfounded values, whereas initial types do not.[1][2] On the other hand, if the domain of discourse is the category of complete partial orders and continuous functions, which corresponds roughly to the Haskell programming language, then final types coincide with initial types, and the corresponding final coalgebra and initial algebra form an isomorphism.[3]Corecursion is then a technique for recursively defining functions whose range (codomain) is a final data type, dual to the way that ordinary recursion recursively defines functions whose domain is an initial data type.[4]The discussion below provides several examples in Haskell that distinguish corecursion. Roughly speaking, if one were to port these definitions to the category of sets, they would still be corecursive. This informal usage is consistent with existing textbooks about Haskell.[5] Also note that the examples used in this article predate the attempts to define corecursion and explain what it is.Discussion[edit]The rule for primitive corecursion on codata is the dual to that for primitive recursion on data. Instead of descending on the argument by pattern-matching on its constructors (that were called up before, somewhere, so we receive a ready-made datum and get at its constituent sub-parts, i.e. fields), we ascend on the result by filling-in its destructors (or observers, that will be called afterwards, somewhere - so we're actually calling a constructor, creating another bit of the result to be observed later on). Thus corecursion creates (potentially infinite) codata, whereas ordinary recursion analyses (necessarily finite) data. Ordinary recursion might not be applicable to the codata because it might not terminate. Conversely, corecursion is not strictly necessary if the result type is data, because data must be finite.In Programming with streams in Coq: a case study: the Sieve of Eratosthenes[6] we findwhere primes are obtained by applying the primes operation to the stream (Enu 2). Following the above notation, the sequence of primes (with a throwaway 0 prefixed to it) and numbers streams being progressively sieved, can be represented as\n\n  \n    \n      \n        p\n        ,\n        s\n        =\n        (\n        0\n        ,\n        [\n        2..\n        ]\n        )\n        :\n        (\n        h\n        d\n        (\n        s\n        )\n        ,\n        s\n        i\n        e\n        v\n        e\n        (\n        h\n        d\n        (\n        s\n        )\n        ,\n        t\n        l\n        (\n        s\n        )\n        )\n        )\n      \n    \n    {\\displaystyle p,s=(0,[2..]):(hd(s),sieve(hd(s),tl(s)))}\n  \n\nor in Haskell,The authors discuss how the definition of sieve is not guaranteed always to be productive, and could become stuck e.g. if called with [5,10..] as the initial stream.Here is another example in Haskell. The following definition produces the list of Fibonacci numbers in linear time:This infinite list depends on lazy evaluation; elements are computed on an as-needed basis, and only finite prefixes are ever explicitly represented in memory. This feature allows algorithms on parts of codata to terminate; such techniques are an important part of Haskell programming.This can be done in Python as well:[7]The definition of zipWith can be inlined, leading to this:This example employs a self-referential data structure. Ordinary recursion makes use of self-referential functions, but does not accommodate self-referential data. However, this is not essential to the Fibonacci example. It can be rewritten as follows:This employs only self-referential function to construct the result. If it were used with strict list constructor it would be an example of runaway recursion, but with non-strict list constructor this guarded recursion gradually produces an indefinitely defined list.Corecursion need not produce an infinite object; a corecursive queue[8] is a particularly good example of this phenomenon. The following definition produces a breadth-first traversal of a binary tree in linear time:This definition takes an initial tree and produces a list of subtrees. This list serves dual purpose as both the queue and the result (gen len p produces its output len notches after its input back-pointer, p, along the queue). It is finite if and only if the initial tree is finite. The length of the queue must be explicitly tracked in order to ensure termination; this can safely be elided if this definition is applied only to infinite trees.Another particularly good example gives a solution to the problem of breadth-first labeling.[9] The function label visits every node in a binary tree in a breadth first fashion, and replaces each label with an integer, each subsequent integer is bigger than the last by one. This solution employs a self-referential data structure, and the binary tree can be finite or infinite.An apomorphism (such as an anamorphism, such as unfold) is a form of corecursion in the same way that a paramorphism (such as a catamorphism, such as fold) is a form of recursion.The Coq proof assistant supports corecursion and coinduction using the CoFixpoint command.History[edit]Corecursion, referred to as circular programming, dates at least to (Bird 1984), who credits John Hughes and Philip Wadler; more general forms were developed in (Allison 1989). The original motivations included producing more efficient algorithms (allowing 1 pass over data in some cases, instead of requiring multiple passes) and implementing classical data structures, such as doubly linked lists and queues, in functional languages.See also[edit]\nBisimulation\nCoinduction\nRecursion\nAnamorphism\nNotes[edit]References[edit]", "subtitles": ["Examples", "Definition", "Discussion", "History", "See also", "Notes", "References"], "title": "Corecursion"},
{"content": "Sather is an object-oriented programming language. It originated circa 1990 at the International Computer Science Institute (ICSI) at the University of California, Berkeley, developed by an international team led by Steve Omohundro. It supports garbage collection and generics by subtypes.Originally, it was based on Eiffel, but it has diverged, and now includes several functional programming features. It is probably best to view it as an object-oriented language, with many ideas borrowed from Eiffel.Even the name is inspired by Eiffel; the Sather Tower is a recognizable landmark at Berkeley, named after Jane Krom Sather, the widow of Peder Sather, who donated large sums to the foundation of the university.Sather also takes inspiration from other programming languages and paradigms: iterators, design by contract, abstract classes, multiple inheritance, anonymous functions, operator overloading, contravariant type system.The original Berkeley implementation (last stable version 1.1 was released in 1995, no longer maintained[1]) has been adopted by the Free Software Foundation therefore becoming GNU Sather. Last stable GNU version (1.2.3) was released in July 2007[2] and the software is currently not maintained. There were several other variants: Sather-K from the University of Karlsruhe;[3][4] Sather-W from the University of Waikato[5] (implementation of Sather version 1.3); Peter Naulls' port of ICSI Sather 1.1 to RISC OS;[6] and pSather,[7][8] a parallel version of ICSI Sather addressing non-uniform memory access multiprocessor architectures but presenting a shared memory model to the programmer.The former ICSI Sather compiler (now GNU Sather) is implemented as a compiler to C, i.e., the compiler does not output object or machine code, but takes Sather source code and generates C source code as an intermediate language. Optimizing is left to the C compiler.The GNU Sather compiler, written in Sather itself, is dual licensed under the GNU GPL & LGPL.Hello World[edit]A few remarks:\nClass names are ALL CAPS; this is not only a convention but is enforced by the compiler.\nThe method called main is the entry point for execution. It may belong to any class, but if this is different from MAIN, it must be specified as a compiler option.\n# is the constructor symbol, calling method create of the corresponding class; here it is used for instantiating the OUT class, which is actually stdout.\nThe + operator has been overloaded here to stand for stream append.\nOperators such as + are syntactic sugar for conventionally named method calls: a + b stands for a.plus(b). The usual arithmetic precedence conventions are used to resolve the calling order of methods in complex formulae.\nThe program layout allows for pre- and post-conditions (not shown here), showing Sather's Eiffel lineage.\nExample of iterators[edit]This program prints numbers from 1 to 10.The loop ... end construct is the preferred means of defining loops (although while and repeat-until are also available). Within the construct, one or more iterators may be used. Iterator names always end with an exclamation mark (this convention is enforced by the compiler). upto! is a method of the integer class INT accepting one once argument, meaning its value will not change as the iterator yields. upto! could be implemented in the INT class like this:Type information for variables is denoted by a postfix syntax variable:CLASS. The type can often be inferred and thus the typing information is optional, like in anInteger::=1. SAME is a convenience pseudo-class referring to the current class.References[edit]External links[edit]\nSather homepage\nGNU Sather\n", "subtitles": ["Hello World", "Example of iterators", "References", "External links"], "title": "Sather"},
{"content": "Barbara Liskov (born November 7, 1939 as Barbara Jane Huberman) is an American computer scientist[2] who is an Institute Professor at the Massachusetts Institute of Technology and Ford Professor of Engineering in its School of Engineering's electrical engineering and computer science department.[3] She was one of the first women to be granted a doctorate in computer science in the United States and is a Turing Award winner who developed the Liskov substitution principle.Early life and education[edit]Liskov was born November 7, 1939 in Los Angeles, California,[4] the eldest of Jane (ne\u0301e Dickhoff) and Moses Huberman's four children.[5] She earned her BA in mathematics with a minor in physics at the University of California, Berkeley in 1961. In her classes she had one other female classmate, the rest were male. After she graduated she applied to graduate mathematics programs at Berkeley and Princeton. At the time Princeton was not accepting female students in mathematics.[6] She was accepted at Berkeley but instead of studying she moved to Boston and began working at Mitre Corporation. It was there that she became interested in computers and programming. She worked at Mitre for one year before taking a programming job at Harvard where she worked on language translation.[6]She then decided to go back to school and applied again to Berkeley, but also to Stanford and Harvard. In 1968 she became one of the first women in the United States to be awarded a Ph.D from a computer science department when she was awarded her degree from Stanford University.[7][8] At Stanford she worked with John McCarthy and was supported to work in artificial intelligence.[6] The topic of her Ph.D. thesis was a computer program to play chess endgames.[9]Career[edit]After graduating from Stanford, Liskov returned to Mitre to work as research staff.[citation needed]Liskov has led many significant projects, including the Venus operating system, a small, low-cost and interactive timesharing system; the design and implementation of CLU; Argus, the first high-level language to support implementation of distributed programs and to demonstrate the technique of promise pipelining; and Thor, an object-oriented database system. With Jeannette Wing, she developed a particular definition of subtyping, commonly known as the Liskov substitution principle. She leads the Programming Methodology Group at MIT, with a current research focus in Byzantine fault tolerance and distributed computing.[3]Recognition and awards[edit]Liskov is a member of the National Academy of Engineering, the National Academy of Sciences and a fellow of the American Academy of Arts and Sciences and of the Association for Computing Machinery (ACM). In 2002, she was recognized as one of the top women faculty members at MIT, and among the top 50 faculty members in the sciences in the U.S.[10]In 2004, Barbara Liskov won the John von Neumann Medal for fundamental contributions to programming languages, programming methodology, and distributed systems.[11] On 19 November 2005, Barbara Liskov and Donald E. Knuth were awarded ETH Honorary Doctorates.[12] Liskov and Knuth were also featured in the ETH Zurich Distinguished Colloquium Series.[13]Liskov received the 2008 Turing Award from the ACM, in March 2009,[14] for her work in the design of programming languages and software methodology that led to the development of object-oriented programming.[15] Specifically, Liskov developed two programming languages, CLU[16] in the 1970s and Argus[17] in the 1980s.[15] The ACM cited her contributions to the practical and theoretical foundations of programming language and system design, especially related to data abstraction, fault tolerance, and distributed computing.[18] In 2012 she was inducted into the National Inventors Hall of Fame.[19]Barbara Liskov is the author of three books and over one hundred technical papers.Personal life[edit]In 1970, she married Nathan Liskov.[6] Their son, Moses Liskov, was born in 1975.See also[edit]\nList of pioneers in computer science\nWomen in computing\nReferences[edit]External links[edit]\nProf. Liskov's home page\nProgramming Methodology Group\nTuring Award press release\nTom Van Vleck, Barbara Liskov, A.M. Turing Award Winner\nNational Public Radio Science Friday interview with Barbara Liskov, originally aired on 13 Mar 2009\n\nCelebrating Women of Distinction, Barbara Liskov, Turing Award interview by, Stephen Ibaraki\nBarbara Liskov: An Interview Conducted by William Aspray, IEEE History Center, August 6, 1991. GHN: IEEE Global History Network. Retrieved 2013-11-29. \nJohn V. Guttag, Barbara Liskov, The Electron and The Bit: EECS at MIT, 1902\u20132002, Chapter VII: Pioneering Women in EECS, pp. 225\u2013239, 2003, Department of Electrical Engineering and Computer Science, MIT\nBarbara Liskov named Institute Professor, MIT News, July 1, 2008\nDepartment News: Barbara Liskov named Institute Professor, EECS Newsletter, Fall 2008\nNatasha Plotkin, Barbara Liskov named Institute Professor, The Tech (MIT), 128,29, July 9, 2008\nRobert Weisman, Top prize in computing goes to MIT professor, The Boston Globe, March 10, 2009\nErica Naone, Driven to Abstraction, MIT Technology Review, December 21, 2009\nBarbara Liskov at the Chess programming wiki\n", "subtitles": ["Early life and education", "Career", "Recognition and awards", "Personal life", "See also", "References", "External links"], "title": "Barbara Liskov"},
{"content": "In functional programming, an iteratee is a composable abstraction for incrementally processing sequentially presented chunks of input data in a purely functional fashion. With iteratees, it is possible to lazily transform how a resource will emit data, for example, by converting each chunk of the input to uppercase as they are retrieved or by limiting the data to only the five first chunks without loading the whole input data into memory. Iteratees are also responsible for opening and closing resources, providing predictable resource management.On each step, an iteratee is presented with one of three possible types of values: the next chunk of data, a value to indicate no data is available, or a value to indicate the iteration process has finished. It may return one of three possible types of values, to indicate to the caller what should be done next: one that means stop (and contains the final return value), one that means continue (and specifies how to continue), and one that means signal an error. The latter types of values in effect represent the possible states of an iteratee. An iteratee would typically start in the continue state.Iteratees are used in Haskell and Scala (in the Play Framework[1] and in Scalaz), and are also available for F#.[2] Various slightly different implementations of iteratees exist. For example, in the Play framework, they involve Futures so that asynchronous processing can be performed.Because iteratees are called by other code which feeds them with data, they are an example of inversion of control. However, unlike many other examples of inversion of control such as SAX XML parsing, the iteratee retains a limited amount of control over the process. It cannot reverse back and look at previous data (unless it stores that data internally), but it can stop the process cleanly without throwing an exception (using exceptions as a means of control flow, rather than to signal an exceptional event, is often frowned upon by programmers[3]).Commonly associated abstractions[edit]The following abstractions are not strictly speaking necessary to work with iteratees, but they do make it more convenient.Enumerators[edit]An Enumerator (not to be confused with Java's Enumeration interface) is a convenient abstraction for feeding data into an iteratee from an arbitrary data source. Typically the enumerator will take care of any necessary resource cleanup associated with the data source. Because the enumerator knows exactly when the iteratee has finished reading data, it will do the resource cleanup (such as closing a file) at exactly the right time \u2013 neither too early nor too late. However, it can do this without needing to know about, or being co-located to, the implementation of the iteratee \u2013 so enumerators and iteratees form an example of separation of concerns.Enumeratees[edit]An Enumeratee is a convenient abstraction for transforming the output of either an enumerator or iteratee, and feeding that output to an iteratee. For example, a map enumeratee would map a function over each input chunk.[4]Motivations[edit]Iteratees were created due to problems with existing purely functional solutions to the problem of making input/output composable yet correct. Lazy I/O in Haskell allowed pure functions to operate on data on disk as if it were in memory, without explicitly doing I/O at all after opening the file - a kind of memory-mapped file feature - but because it was impossible in general (due to the Halting problem) for the runtime to know whether the file or other resource was still needed, excessive numbers of files could be left open unnecessarily, resulting in file descriptor exhaustion at the operating system level. Traditional C-style I/O, on the other hand, was too low-level and required the developer to be concerned with low-level details such as the current position in the file, which hindered composability. Iteratees and enumerators combine the high-level functional programming benefits of lazy I/O, with the ability to control resources and low-level details where necessary afforded by C-style I/O.[5]Examples[edit]Uses[edit]Iteratees are used in the Play framework to push data out to long-running Comet and WebSocket connections to web browsers.Iteratees may also be used to perform incremental parsing (that is, parsing that does not read all the data into memory at once), for example of JSON.[6]It is important to note, however, that iteratees are a very general abstraction and can be used for arbitrary kinds of sequential information processing (or mixed sequential/random-access processing) - and need not involve any I/O at all. This makes it easy to repurpose an iteratee to work on an in-memory dataset instead of data flowing in from the network.History[edit]In a sense, a distant predecessor of the notion of an enumerator pushing data into a chain of one or more iteratees, was the pipeline concept in operating systems. However, unlike a typical pipeline, iteratees are not separate processes (and hence do not have the overhead of IPC) - or even separate threads, although they can perform work in a similar manner to a chain of worker threads sending messages to each other. This means that iteratees are more lightweight than processes or threads - unlike the situations with separate processes or threads, no extra stacks are needed.Iteratees and enumerators were invented by Oleg Kiselyov for use in Haskell.[5] Later, they were introduced into Scalaz (in version 5.0; enumeratees were absent and were introduced in Scalaz 7) and into Play Framework 2.0.Formal semantics[edit]Iteratees have been formally modelled as free monads, allowing equational laws to be validated, and employed to optimise programs using iteratees.[5]Alternatives[edit]\nIterators may be used instead of iteratees in Scala, but they are imperative, so are not a purely functional solution.\nIn Haskell, two alternative abstractions known as Conduits and Pipes have been developed. (These Pipes are not operating system level pipes, so like iteratees they do not require the use of system calls). Conduits in particular are associated with substantially richer libraries of primitives and combinators than iteratees; conduit adapters for incremental functionalities such as parsing HTML, XML, generalised parsing, making HTTP requests and processing the responses, exist, making conduits more suitable than iteratees for industrial software development in Haskell, out of the box.\nThere is also a high-level abstraction named machines. In Scala there is a package called FS2: Functional Streams for Scala, whose ancestry can be traced back to machines via several ports, renames and refactors.\nIn Haskell, the package safe-lazy-io exists. It provides a simpler solution to some of the same problems, which essentially involves being strict enough to pull all data that is required, or might be required, through a pipeline which takes care of cleaning up the resources on completion.\nReferences[edit]Further reading[edit]\nJohn W. Lato (12 May 2010). Iteratee: Teaching an Old Fold New Tricks. Issue #16 of The Monad Reader. Retrieved 29 June 2013.  This relates to Haskell.\nExternal links[edit]\nScala tutorials\n\nPlay 2.0\n\nUnderstanding Play 2 iteratees for normal humans\nIteratees for imperative programmers\n\n\nScalaz\n\nScalaz tutorial: Enumeration-based I/O with iteratees\n\n\n\n\nHaskell tutorials\n\nStanford lecture notes\n\n\nFurther information\n\nOleg Kiselyov's Iteratees and Enumerators page\n\n\n", "subtitles": ["Commonly associated abstractions", "Motivations", "Examples", "Uses", "History", "Formal semantics", "Alternatives", "References", "Further reading", "External links"], "title": "Iteratee"},
{"content": "XL stands for eXtensible Language. It is the first and so far the only computer programming language designed to support concept programming.[1]XL features programmer-reconfigurable syntax and semantics. Compiler plug-ins can be used to add new features to the language. A base set of plug-ins implements a relatively standard imperative language. Programmers can write their own plug-ins to implement application-specific notations, such as symbolic differentiation, which can then be used as readily as built-in language features.Language[edit]XL is defined at four different levels:\nXL0 defines how an input text is transformed into a parse tree.\nXL1 defines a base language with features comparable to C++.\nXL2 defines the standard library, which includes common data types and operators.\nXLR defines a dynamic runtime for XL based on XL0.\nXL has no primitive types nor keywords. All useful operators and data types, like integers or addition, are defined in the standard library (XL2). XL1 is portable between different execution environments. There is no such guarantee for XL2: if a particular CPU does not implement floating-point multiplication, the corresponding operator definition may be missing from the standard library, and using a floating-point multiply may result in a compile-time error.The Hello World program in XL looks like the following:\n use XL.TEXT_IO\n WriteLn Hello World\nAn alternative form in a style more suitable for large-scale programs would be:\n import IO = XL.TEXT_IO\n IO.WriteLn Hello World\nA recursive implementation of factorial in XLR looks like the following:\n 0! -> 1\n N! -> N * (N-1)!\nSyntax[edit]Syntax is defined at the XL0 level. The XL0 phase of the compiler can be configured using a syntax description file, where properties like the text representation and precedence of operators are defined. A basic syntax file defines common mathematical notations, like + for addition, with the usually accepted order of operations.The parse tree consists of 7 node types, 4 leaf node types (integer, real, text and symbol) and 3 internal node types (infix, prefix and block).\ninteger nodes represent an integer literal, such as 2. The # sign can be used to specify a base other than 10, as in (2#1001). A separating underscore can be used to improve readability, as in 1_000_000.\nreal nodes represent non-integral numbers, such as 2.5. Based-notations and separators can be used, as for integer nodes, for example 16#F.FFF#E-10 is a valid real literal.\ntext nodes represent textual contents. They are normally surrounded by simple or double quotes, like Hello or 'a', but the syntax file can be used to add other separators, including for multi-line textual contents.\nsymbol nodes represent names or operators. Names are sequence of alphanumeric characters beginning with a letter, like Hello. XL0 preserves case, but XL1 ignores case and underscores, so that JohnDoe and john_doe are the same name. Operators are sequences of non-alphanumeric characters, like * or =/=.\ninfix nodes represent two nodes related by an infix symbol, like A+1 or 2 and 3. Infix nodes are in particular used to separate lines, with an infix new-line symbol.\nprefix nodes represent two consecutive nodes, like Write Hello. It is also used for postfix notations, like 3! or Open?.\nblock nodes represent a node surrounded by grouping symbols, like (A), [Index]. Indentation is internally represented by a block node.\nWith the default syntax file, the following is valid XL0, irrespective of any semantics.\nA = B + Hello\nIt parses as:\ninfix(=,\n      symbol(A),\n      infix(+,\n            symbol(B), text(Hello)))\nSemantics of XL1[edit]The XL1 phase is defined as a sequence of operations on the XL0 parse tree. These operations are provided by various compiler plug-ins, that are triggered based on the shape of the parse tree.Special constructs, translate and translation, are provided by a plug-in designed to facilitate the writing of other plug-ins. The quote construct generates a parse tree. Here is how these notations can be used to implement a plug-in called ZeroRemoval that eliminates superfluous additions and multiplications by zero.\ntranslation ZeroRemoval\n  when\n    'X' + 0\n  then\n    return X\n  when\n    'X' * 0\n  then\n    return parse_tree(0)\nA plug-in can be invoked on a whole file from the command line, or more locally in the source code using the pragma notation, as follows:\nX := {Differentiate} d(sin(omega * T) * exp(-T/T0)) / dT\nThe XL1 phase contains a large set of plug-ins, notably XLSemantics, that provide common abstractions like subroutine, data type and variable declaration and definition, as well as basic structured programming statements, like conditionals or loops.Type system[edit]XL1 type checking is static, with generic programming abilities that are beyond those of languages like Ada or C++. Types like arrays or pointers, which are primitive in languages like C++, are declared in the library in XL. For instance, a one-dimensional array type could be defined as follows:\ngeneric [Item : type; Size : integer] type array\nA validated generic type is a generic type where a condition indicates how the type can be used. Such types need not have generic parameters. For instance, one can declare that a type is ordered if it has a less-than operator as follows:\n// A type is ordered if it has a less-than relationship\ngeneric type ordered if\n  A, B : ordered\n  Test : boolean := A < B\nIt is then possible to declare a function that is implicitly generic because the type ordered itself is generic.\n// Generic function for the minimum of one item\nfunction Min(X : ordered) return ordered is\n  ... compute Y of type ordered ... \n  return Y\nThis also applies to generic types that have parameters, such as array. A function computing the sum of the elements in any array can be written as follows:\nfunction Sum(A : array) return array.Item is\n  for I in 0..array.Size-1 loop\n    result += A[I]\nType-safe variable argument lists[edit]Functions can be overloaded. A function can be declared to use a variable number of arguments by using ... in the parameter list (historically, the keyword other was used for that purpose). In such a function, ... can be used to pass the variable number of arguments to another subroutine, a feature now called Variadic templates:\n// Generic function for the minimum of N item\nfunction Min(X : ordered; ...) return ordered is\n  result := Min(...)\n  if X < result then\n    result := X\nWhen such a function is called, the compiler recursively instantiates functions to match the parameter list:\n// Examples of use of the Min just declared\nX : real := Min(1.3, 2.56, 7.21)\nY : integer := Min(1, 3, 6, 7, 1, 2)\nExpression reduction: operator overloading[edit]Operators can be defined using the written form of function declarations. Below is the code that would declare the addition of integers:\nfunction Add(X, Y: integer) return integer written X+Y\nSuch written forms can have more than two parameters. For instance, a matrix linear transform can be written as:\nfunction Linear(A, B, C : matrix) return matrix written A+B*C\nA written form can use constants, and such a form is more specialized than a form without constants. For example:\nfunction Equal(A, B : matrix) return boolean written A=B\nfunction IsNull(A : matrix) return boolean written A=0\nfunction IsUnity(A : matrix) return boolean written A=1\nThe mechanism is used to implement all basic operators. An expression is progressively reduced to function calls using written forms. For that reason, the mechanism is referred to as expression reduction rather than operator overloading.Iterators[edit]XL iterators allow programmers to implement both generators and iterators.\nimport IO = XL.UI.CONSOLE\n\niterator IntegerIterator (var out Counter : integer; Low, High : integer) written Counter in Low..High is\n    Counter := Low\n    while Counter <= High loop\n        yield\n        Counter += 1\n\n// Note that I needs not be declared, because declared 'var out' in the iterator\n// An implicit declaration of I as an integer is therefore made here\nfor I in 1..5 loop\n    IO.WriteLn I=, I\nDevelopment status and history[edit]XL is the result of a long language design work that began around 1992. The language was designed and implemented primarily by Christophe de Dinechin.Historically, the XL compiler was written in C++. It had achieved a point where most of the features described above worked correctly, but writing plug-ins was a nightmare, because C++ itself is not extensible, so implementing translate-like statements was impossible. The parse tree was more complicated, with dozens of node types, because it was designed for cross-language support. Moka was a Java-to-Java extensible compiler using the same infrastructure.Abandoning the cross-language objectives and complex parse-tree structure, a complete rewrite of the compiler was started in 2003. The parse tree was vastly simplified down to the seven XL0 nodes types now in use. This new compiler bootstrapped in 2004, and all new development is now written in XL. However, this new compiler still has somewhat incomplete XL1 support, although its abilities already exceed C++ in a few areas.Ancestry[edit]XL1 was inspired by a large number of other languages. In alphabetical order:\nAda inspired some of large-scale program support, exception handling, tasking, and supportability aspects.\nBASIC the more modern variants that dispense of line numbers and support structured programming, showed how simple the syntax of a programming language could be.\nC was used as the standard to expect in terms of runtime and machine-level support. XL will not require a virtual machine to run.\nC++ and the standard template library demonstrated the need for good support of generic types, including implicit instantiation of generics (which Ada lacks).\nFortran's continued performance lead over C and C++ for numerical-intensive applications helped identify which language constructs would prevent useful optimizations.\nJava demonstrated the importance of a large, portable support library. Java containers also showed the limitations of an approach not based on generic programming. Interfacing with Java code remains an interesting challenge for XL.\nLisp extensibility was considered as a key factor in its survival and relevance to this day. Lisp was the first language to normalize object-oriented features, despite having been designed years before object-oriented ideas were invented.\nProlog demonstrated that alternative programming models are sometimes useful and highly productive. Every effort was made to ensure that a Prolog-style plug-in could be written for XL.\nVisual Basic showed how the parse tree representation can be dissociated from its visual presentation. Few people edit VB Forms textually. It is expected that XL edit-time plug-ins will one day provide similar abilities, by directly manipulating the parse tree.\nSemantics[edit]XLR is a dynamic language, originally intended as a back-end for the XL1 compiler, hence the name, which stands for XL runtime. It shares the basic XL0 syntax with XL1, but its behavior is much closer to a functional language, whereas XL1 is intended to look mostly like an imperative language. XLR has practically only one built-in operator, ->, which denotes a rewrite. The notation on the left of the rewrite is transformed into the notation on the right of the rewrite.This mechanism is used to implement standard notations:\n if true then TrueBody else FalseBody -> TrueBody\n if false then TrueBody else FalseBody -> FalseBody\nThe XL Programming Language uses a programming approach focusing on how concepts, that live in the programmer's mind, translate into representations that are found in the code space.Pseudo-metrics[edit]Concept programming uses pseudo-metrics to evaluate the quality of code. They are called pseudo-metrics because they relate the concept space and the code space, with a clear understanding that the concept space cannot be formalized strictly enough for a real metric to be defined. Concept programming pseudo-metrics include:\nSyntactic noise measures discrepancies between the concept and the syntax used to represent it. For instance, the semi-colon at the end of statements in C can be considered as syntactic noise, because it has no equivalent in the concept space.\nSemantic noise measures discrepancies between the expected meaning or behavior of the concept and its actual meaning or behavior in the code. For instance, the fact that integer data types overflow (when mathematical integers do not) is a form of semantic noise.\nBandwidth measures how much of the concept space a given code construct can represent. For instance, the overloaded addition operator in C has higher bandwidth than the Add instruction in assembly language, because the C operator can represent addition on floating-point numbers and not just integer numbers.\nSignal/noise ratio measures what fraction of the code space is used for representing actual concepts, as opposed to implementation information.\nRule of equivalence, equivalence breakdown[edit]The rule of equivalence is verified when the code behavior matches the original concept. This equivalence may break down in many cases. Integer overflow breaks the equivalence between the mathematical integer concept and the computerized approximation of the concept.Many ways to break the equivalence have been given specific names, because they are very common:\nA domain error is a condition where code executes outside of the domain of equivalence, which is the domain where the concept and the implementation match. An integer overflow is an example of domain error.\nA concept cast (also concept recast or concept recasting) is a rewrite of a concept as a different concept because the original concept cannot be represented by the tools. In C, using pointers for output arguments because C doesn't support output arguments explicitly is an example of concept cast.\nA priority inversion is a form of syntactic or semantic noise introduced by some language-enforced general rule. It is called a priority inversion because the language takes precedence over the concept. In Smalltalk, everything is an object, and that rule leads to the undesirable consequence that an expression like 2+3*5 doesn't obey the usual order of operations (Smalltalk interprets this as sending the message * to the number resulting from 2+3, which yields result 25 instead of 17).\nMethodology[edit]To write code, concept programming recommends the following steps:\nIdentify and define the relevant concepts in the concept space.\nIdentify traditional notations for the concepts, or invent usable notations.\nIdentify a combination of programming constructs that allows the concepts to be represented comfortably in code - That includes finding a code notation that matches the notation identified in the previous step as closely as possible.\nWrite code that preserves, as much as possible, the expected behavior and semantics of the relevant aspects of the original concept.\nMany programming tools often lack in notational abilities, thus concept programming sometimes requires the use of preprocessors, domain-specific languages, or metaprogramming techniques.Languages[edit]XL is the only programming language known to date to be explicitly created for concept programming, but concept programming can be done in nearly any language, with varying degrees of success. Lisp and Forth (and their derivatives) are examples of pre-existing languages which lend themselves well to concept programming.[citation needed]Similar works[edit]There are projects that exploit similar ideas to create code with higher level of abstraction. Among them are:\nIntentional Programming\nLanguage-oriented programming\nLiterate programming\nModel-driven architecture\nReferences[edit]External links[edit]\nOfficial website\nThe historical development site\nCoverage on XL and Concept programming at The Register\nSlides presenting XL and Concept Programming\n", "subtitles": ["Language", "Syntax", "Semantics of XL1", "Development status and history", "Semantics", "Pseudo-metrics", "Rule of equivalence, equivalence breakdown", "Methodology", "Languages", "Similar works", "References", "External links"], "title": "XL (programming language)"},
{"content": "Prentice Hall is a major educational publisher owned by Pearson plc. Prentice Hall publishes print and digital content for the 6\u201312 and higher-education market. Prentice Hall distributes its technical titles through the Safari Books Online e-reference service.History[edit]On October 13, 1913, law professor Charles Gerstenberg and his student Richard Ettinger founded Prentice Hall. Gerstenberg and Ettinger took their mothers' maiden names\u2014Prentice and Hall\u2014to name their new company.[1]Prentice Hall was acquired by Gulf+Western in 1984, and became part of that company's publishing division Simon & Schuster. Publication of trade books ended in 1991[2]. Simon & Schuster's educational division, including Prentice Hall, was sold to Pearson by G+W successor Viacom in 1998.Notable titles[edit]Prentice Hall is the publisher of Magruder's American Government as well as Biology by Ken Miller and Joe Levine. Their artificial intelligence series includes Artificial Intelligence: A Modern Approach by Stuart J. Russell and Peter Norvig and ANSI Common Lisp by Paul Graham. They also published the well-known computer programming book The C Programming Language by Brian Kernighan and Dennis Ritchie and Operating Systems: Design and Implementation by Andrew S. Tanenbaum. Other titles include Dennis Nolan's Big Pig (1976), Monster Bubbles: A Counting Book (1976), Alphabrutes (1977), Wizard McBean and his Flying Machine (1977), Witch Bazooza (1979), Llama Beans (1979, with author Charles Keller), and The Joy of Chickens (1981).In personal computer history[edit]A Prentice Hall subsidiary, Reston Publishing, was in the foreground of technical-book publishing when microcomputers were first becoming available. It was still unclear who would be buying and using personal computers, and the scarcity of useful software and instruction created a publishing market niche whose target audience yet had to be defined. In the spirit of the pioneers who made PCs possible, Reston Publishing's editors addressed non-technical users with the reassuring, and mildly experimental, Computer Anatomy for Beginners by Marlin Ouverson of People's Computer Company. They followed with a collection of books that was generally by and for programmers, building a stalwart list of titles relied on by many in the first generation of microcomputers users.See also[edit]\ncis-test PLC\nPrentice Hall International Series in Computer Science\nReferences[edit]External links[edit]\nPrentice Hall website\nPrentice Hall School website\nPrentice Hall Higher Education website\nPrentice Hall Professional Technical Reference website\n", "subtitles": ["History", "Notable titles", "In \"personal computer\" history", "See also", "References", "External links"], "title": "Prentice Hall"},
{"content": "JSP Model 2 is a complex design pattern used in the design of Java Web applications which separates the display of content from the logic used to obtain and manipulate the content. Since Model 2 drives a separation between logic and display, it is usually associated with the model\u2013view\u2013controller (MVC) paradigm. While the exact form of the MVC Model was never specified by the Model 2 design, a number of publications recommend a formalized layer to contain MVC Model code. The Java BluePrints, for example, originally recommended using EJBs to encapsulate the MVC Model.In a Model 2 application, requests from the client browser are passed to the controller. The controller performs any logic necessary to obtain the correct content for display. It then places the content in the request (commonly in the form of a JavaBean or POJO) and decides which view it will pass the request to. The view then renders the content passed by the controller.Model 2 is recommended for medium- and large-sized applications.History[edit]In 1998, Sun Microsystems published a pre-release of the JavaServer Pages specification, version 0.92.[1] In this specification, Sun laid out two methods by which JSP pages could be used. The first model (referred to as model 1 due to its ordering in the document) was a simplistic model whereby JSP pages were standalone, disjointed entities. Logic could be contained within the page itself, and navigation between pages was typically achieved by way of hyperlinks. This fit with the then-common usage of template technology.ColdFusion and Active Server Pages are examples of contemporary technologies that also implemented this model.The second model referred to by the document (model 2 in the ordering) was an improved method that combined servlet technology with JSP technology. The specific difference listed was that a servlet would intercept the request, place the content to render into a request attribute (typically represented by a JavaBean), then call a JSP to render the content in the desired output format. This model differed from the previous model in the fact that JSP technology was used as a pure template engine. All of the logic was separated out into a servlet, leaving the JSP with the sole responsibility of rendering the output for the content provided.In December 1999, JavaWorld published an article by Govind Seshadri entitled Understanding JavaServer Pages Model 2 architecture.[2] In this article, Govind accomplished two major milestones in the use of the term Model 2. The first milestone was to formalize the term Model 2 as an architectural pattern rather than one of two possible options. The second milestone was the claim that Model 2 provided an MVC architecture for web-based software.[3]Govind believed that because Model 2 architecture separated the logic out of the JSP and placed it in a servlet, the two pieces could be seen as the View and the Controller (respectively) in an MVC architecture. The Model part of the MVC architecture was left open by Govind, with a suggestion that nearly any data-structure could meet the requirements. The specific example used in the article was a Vector list stored in the user's session.In March 2000, the Apache Struts project was released. This project formalized the division between View and Controller and claimed implementation of the Model 2 pattern.[3] Once again, the implementation of the Model was left undefined with the expectation that software developers would fill in an appropriate solution. Database interaction via JDBC and EJBs were options suggested on the Struts homepage. More recently, Hibernate, iBatis, and Object Relational Bridge were listed as more modern options that could be used for a model.[4]Since the release of Struts, a number of competing frameworks have appeared. Many of these frameworks also claim to implement Model 2 and MVC. In result, the two terms have become synonymous in the minds of developers. This has led to the use of the term MVC Model 2 or MVC2 for short.Misconceptions[edit]A common misconception is that a formalized MVC pattern is required to achieve a Model 2 implementation. However, the Java BluePrints specifically warn against this interpretation:[5]\nThe literature on Web-tier technology in the J2EE platform frequently uses the terms Model 1 and Model 2 without explanation. This terminology stems from early drafts of the JSP specification, which described two basic usage patterns for JSP pages. While the terms have disappeared from the specification document, they remain in common use. Model 1 and Model 2 simply refer to the absence or presence (respectively) of a controller servlet that dispatches requests from the client tier and selects views.\nFurthermore, the term MVC2 has led many to a mistaken belief that Model 2 represents a next-generation MVC pattern. In fact, MVC2 is simply a shortening of the term MVC Model 2.[6]The confusion over the term MVC2 has led to additional confusion over Model 1 code, resulting in common usage of the nonexistent term MVC1.See also[edit]\nApache Struts is an open-source framework for implementing web-applications based on a Model 2 architecture.\nReferences[edit]External links[edit]\nUnderstanding JavaServer Pages Model 2 architecture by Govind Seshadri (JavaWorld)\nA History of MVC, Including Model 2\nASP.NET Presentation Patterns - In this article Dino Esposito discusses how Model2 is also used in ASP.NET MVC.\n", "subtitles": ["History", "Misconceptions", "See also", "References", "External links"], "title": "JSP model 2 architecture"},
{"content": "In software engineering, inversion of control (IoC) is a design principle in which custom-written portions of a computer program receive the flow of control from a generic framework. A software architecture with this design inverts control as compared to traditional procedural programming: in traditional programming, the custom code that expresses the purpose of the program calls into reusable libraries to take care of generic tasks, but with inversion of control, it is the framework that calls into the custom, or task-specific, code.Inversion of control is used to increase modularity of the program and make it extensible,[1] and has applications in object-oriented programming and other programming paradigms. The term was used by Michael Mattsson in a thesis[2], taken from there[3] by Stefano Mazzocchi and popularized by him in 1999 in a now-defunct Apache Software Foundation project Avalon, then further popularized in 2004 by Robert C. Martin and Martin Fowler.The term is related to, but different from, the dependency inversion principle, which concerns itself with decoupling dependencies between high-level and low-level layers through shared abstractions. The general concept is also related to event-driven programming in that it is often implemented using IoC, so that the custom code is commonly only concerned with the handling of events, whereas the event loop and dispatch of events/messages is handled by the framework or the runtime environment.Overview[edit]As an example, with traditional programming, the main function of an application might make function calls into a menu library to display a list of available commands and query the user to select one.[4] The library thus would return the chosen option as the value of the function call, and the main function uses this value to execute the associated command. This style was common in text based interfaces. For example, an email client may show a screen with commands to load new mails, answer the current mail, start a new mail, etc., and the program execution would block until the user presses a key to select a command.With inversion of control, on the other hand, the program would be written using a software framework that knows common behavioral and graphical elements, such as windowing systems, menus, controlling the mouse, and so on. The custom code fills in the blanks for the framework, such as supplying a table of menu items and registering a code subroutine for each item, but it is the framework that monitors the user's actions and invokes the subroutine when a menu item is selected. In the mail client example, the framework could follow both the keyboard and mouse inputs and call the command invoked by the user by either means, and at the same time monitor the network interface to find out if new messages arrive and refresh the screen when some network activity is detected. The same framework could be used as the skeleton for a spreadsheet program or a text editor. Conversely, the framework knows nothing about Web browsers, spreadsheets or text editors; implementing their functionality takes custom code.Inversion of control carries the strong connotation that the reusable code and the problem-specific code are developed independently even though they operate together in an application. Software frameworks, callbacks, schedulers, event loops, dependency injection, and the template method are examples of design patterns that follow the inversion of control principle, although the term is most commonly used in the context of object-oriented programming.Inversion of control serves the following design purposes:\nTo decouple the execution of a task from implementation.\nTo focus a module on the task it is designed for.\nTo free modules from assumptions about how other systems do what they do and instead rely on contracts.\nTo prevent side effects when replacing a module.\nInversion of control is sometimes facetiously referred to as the Hollywood Principle: Don't call us, we'll call you.Background[edit]Inversion of control is not a new term in computer science. Martin Fowler traces the etymology of the phrase back to 1988.[5] Dependency injection is a specific type of IoC.[4] A service locator such as the Java Naming and Directory Interface (JNDI) is similar. In an article by Loek Bergman,[6] it is presented as an architectural principle.In an article by Robert C. Martin,[7] the dependency inversion principle and abstraction by layering come together. His reason to use the term inversion is in comparison with traditional software development methods. He describes the uncoupling of services by the abstraction of layers when he is talking about dependency inversion. The principle is used to find out where system borders are in the design of the abstraction layers.Description[edit]In traditional programming, the flow of the business logic is determined by objects that are statically bound to one another. With inversion of control, the flow depends on the object graph that is built up during program execution. Such a dynamic flow is made possible by object interactions that are defined through abstractions. This run-time binding is achieved by mechanisms such as dependency injection or a service locator. In IoC, the code could also be linked statically during compilation, but finding the code to execute by reading its description from external configuration instead of with a direct reference in the code itself.In dependency injection, a dependent object or module is coupled to the object it needs at run time. Which particular object will satisfy the dependency during program execution typically cannot be known at compile time using static analysis. While described in terms of object interaction here, the principle can apply to other programming methodologies besides object-oriented programming.In order for the running program to bind objects to one another, the objects must possess compatible interfaces. For example, class A may delegate behavior to interface I which is implemented by class B; the program instantiates A and B, and then injects B into A.Implementation techniques[edit]In object-oriented programming, there are several basic techniques to implement inversion of control. These are:\nUsing a service locator pattern\nUsing dependency injection, for example\n\nConstructor injection\nParameter injection\nSetter injection\nInterface injection\n\n\nUsing a contextualized lookup\nUsing template method design pattern\nUsing strategy design pattern\nIn an original article by Martin Fowler,[8] the first three different techniques are discussed. In a description about inversion of control types,[9] the last one is mentioned. Often the contextualized lookup will be accomplished using a service locator.More important than the applied technique, however, is the optimization of the purposes.Examples[edit]Most frameworks such as .NET or Enterprise Java display this pattern:This basic outline in Java gives an example of code following the IoC methodology. It is important, however, that in the ServerFacade a lot of assumptions are made about the data returned by the data access object (DAO).Although all these assumptions might be valid at some time, they couple the implementation of the ServerFacade to the DAO implementation. Designing the application in the manner of inversion of control would hand over the control completely to the DAO object. The code would then becomeThe example shows that the way the method respondToRequest is constructed determines if IoC is used. It is the way that parameters are used that define IoC. This resembles the message-passing style that some object-oriented programming languages use.See also[edit]References[edit]External links[edit]\nInversion of Control explanation and implementation example\n", "subtitles": ["Overview", "Background", "Description", "Implementation techniques", "Examples", "See also", "References", "External links"], "title": "Inversion of control"},
{"content": "A data transfer object (DTO[1][2]) is an object that carries data between processes. The motivation for its use is that communication between processes is usually done resorting to remote interfaces (e.g., web services), where each call is an expensive operation.[2] Because the majority of the cost of each call is related to the round-trip time between the client and the server, one way of reducing the number of calls is to use an object (the DTO) that aggregates the data that would have been transferred by the several calls, but that is served by one call only.[2]The difference between data transfer objects and business objects or data access objects is that a DTO does not have any behavior except for storage, retrieval, serialization and deserialization of its own data (mutators, accessors, parsers and serializers). In other words, DTOs are simple objects that should not contain any business logic but may contain serialization and deserialization mechanisms for transferring data over the wire.[1]This pattern is often incorrectly used outside of remote interfaces. This has triggered a response from its author[3] where he reiterates that the whole purpose of DTOs is to shift data in expensive remote calls.Terminology[edit]A value object is not a DTO. The two terms have been conflated by Java developers in the past.[2]References[edit]External links[edit]\nSummary from Fowler's book\nData Transfer Object - Microsoft MSDN Library\nGeDA - generic dto assembler is an open source Java framework for enterprise level solutions\nLocal DTO\n", "subtitles": [], "title": "Data transfer object"},
{"content": "The Portland Pattern Repository (PPR) is a repository for computer programming design patterns. It was accompanied by a companion website, WikiWikiWeb, which was the world's first wiki. The repository has an emphasis on Extreme Programming, and it is hosted by Cunningham & Cunningham (C2) of Portland, Oregon.[1] The PPR's motto is People, Projects & Patterns.History[edit]On 17 September 1987, programmer Ward Cunningham then with Tektronix and Apple Computer's Kent Beck co-published the paper Using Pattern Languages for Object-Oriented Programs[2] This paper, about programming patterns was inspired by Christopher Alexander's architectural concept of patterns[2] It was written for the 1987 OOPSLA programming conference organized by the Association for Computing Machinery Cunningham and Beck's idea became popular among programmers, because it helped them exchange programming ideas in a format that is easy to understand. Cunningham & Cunningham, the programming consultancy that would eventually host the PPR on its Internet domain, was incorporated in Salem, Oregon on 1 November 1991, and is named after Ward and his wife, Karen R. Cunningham, a mathematician, school teacher, and school director. Cunningham & Cunningham registered their Internet domain, c2.com, on 23 October 1994. Ward created the Portland Pattern Repository on c2.com as a means to help object-oriented programmers publish their computer programming patterns by submitting them to him. Some of those programmers attended the OOPSLA and PLoP conferences about object-oriented programming, and posted their ideas on the PPR. The PPR is accompanied, on c2.com, by the first ever wiki\u2014a collection of reader-modifiable Web pages\u2014which is called WikiWikiWeb.[3]See also[edit]\nMerge User Email(s)\nUser API\nDesign pattern\nHistory of wikis\nSoftware design pattern\nWikiWikiWeb\nString\nReferences[edit]External links[edit]\nOfficial website\nOOPSLA\n", "subtitles": ["History", "See also", "References", "External links"], "title": "Portland Pattern Repository"},
{"content": "In computer science, the syntax of a computer language is the set of rules that defines the combinations of symbols that are considered to be a correctly structured document or fragment in that language. This applies both to programming languages, where the document represents source code, and markup languages, where the document represents data. The syntax of a language defines its surface form.[1] Text-based computer languages are based on sequences of characters, while visual programming languages are based on the spatial layout and connections between symbols (which may be textual or graphical). Documents that are syntactically invalid are said to have a syntax error.Syntax \u2013 the form \u2013 is contrasted with semantics \u2013 the meaning. In processing computer languages, semantic processing generally comes after syntactic processing, but in some cases semantic processing is necessary for complete syntactic analysis, and these are done together or concurrently. In a compiler, the syntactic analysis comprises the frontend, while semantic analysis comprises the backend (and middle end, if this phase is distinguished).Levels of syntax[edit]Computer language syntax is generally distinguished into three levels:\nWords \u2013 the lexical level, determining how characters form tokens;\nPhrases \u2013 the grammar level, narrowly speaking, determining how tokens form phrases;\nContext \u2013 determining what objects or variables names refer to, if types are valid, etc.\nDistinguishing in this way yields modularity, allowing each level to be described and processed separately, and often independently. First a lexer turns the linear sequence of characters into a linear sequence of tokens; this is known as lexical analysis or lexing. Second the parser turns the linear sequence of tokens into a hierarchical syntax tree; this is known as parsing narrowly speaking. Thirdly the contextual analysis resolves names and checks types. This modularity is sometimes possible, but in many real-world languages an earlier step depends on a later step \u2013 for example, the lexer hack in C is because tokenization depends on context. Even in these cases, syntactical analysis is often seen as approximating this ideal model.The parsing stage itself can be divided into two parts: the parse tree or concrete syntax tree which is determined by the grammar, but is generally far too detailed for practical use, and the abstract syntax tree (AST), which simplifies this into a usable form. The AST and contextual analysis steps can be considered a form of semantic analysis, as they are adding meaning and interpretation to the syntax, or alternatively as informal, manual implementations of syntactical rules that would be difficult or awkward to describe or implement formally.The levels generally correspond to levels in the Chomsky hierarchy. Words are in a regular language, specified in the lexical grammar, which is a Type-3 grammar, generally given as regular expressions. Phrases are in a context-free language (CFL), generally a deterministic context-free language (DCFL), specified in a phrase structure grammar, which is a Type-2 grammar, generally given as production rules in Backus\u2013Naur form (BNF). Phrase grammars are often specified in much more constrained grammars than full context-free grammars, in order to make them easier to parse; while the LR parser can parse any DCFL in linear time, the simple LALR parser and even simpler LL parser are more efficient, but can only parse grammars whose production rules are constrained. In principle, contextual structure can be described by a context-sensitive grammar, and automatically analyzed by means such as attribute grammars, though in general this step is done manually, via name resolution rules and type checking, and implemented via a symbol table which stores names and types for each scope.Tools have been written that automatically generate a lexer from a lexical specification written in regular expressions and a parser from the phrase grammar written in BNF: this allows one to use declarative programming, rather than need to have procedural or functional programming. A notable example is the lex-yacc pair. These automatically produce a concrete syntax tree; the parser writer must then manually write code describing how this is converted to an abstract syntax tree. Contextual analysis is also generally implemented manually. Despite the existence of these automatic tools, parsing is often implemented manually, for various reasons \u2013 perhaps the phrase structure is not context-free, or an alternative implementation improves performance or error-reporting, or allows the grammar to be changed more easily. Parsers are often written in functional languages, such as Haskell, or in scripting languages, such as Python or Perl, or in C or C++.Examples of errors[edit]As an example, (add 1 1) is a syntactically valid Lisp program (assuming the 'add' function exists, else name resolution fails), adding 1 and 1. However, the following are invalid:\n(_ 1 1)    lexical error: '_' is not valid\n(add 1 1   parsing error: missing closing ')'\nNote that the lexer is unable to identify the first error \u2013 all it knows is that, after producing the token LEFT_PAREN, '(' the remainder of the program is invalid, since no word rule begins with '_'. The second error is detected at the parsing stage: The parser has identified the list production rule due to the '(' token (as the only match), and thus can give an error message; in general it may be ambiguous.Type errors and undeclared variable errors are sometimes considered to be syntax errors when they are detected at compile-time (which is usually the case when compiling strongly-typed languages), though it is common to classify these kinds of error as semantic errors instead.[2][3][4]As an example, the Python code\n'a' + 1\ncontains a type error because it adds a string literal to an integer literal. Type errors of this kind can be detected at compile-time: They can be detected during parsing (phrase analysis) if the compiler uses separate rules that allow integerLiteral + integerLiteral but not stringLiteral + integerLiteral, though it is more likely that the compiler will use a parsing rule that allows all expressions of the form LiteralOrIdentifier + LiteralOrIdentifier and then the error will be detected during contextual analysis (when type checking occurs). In some cases this validation is not done by the compiler, and these errors are only detected at runtime.In a dynamically typed language, where type can only be determined at runtime, many type errors can only be detected at runtime. For example, the Python code\na + b\nis syntactically valid at the phrase level, but the correctness of the types of a and b can only be determined at runtime, as variables do not have types in Python, only values do. Whereas there is disagreement about whether a type error detected by the compiler should be called a syntax error (rather than a static semantic error), type errors which can only be detected at program execution time are always regarded as semantic rather than syntax errors.Syntax definition[edit]The syntax of textual programming languages is usually defined using a combination of regular expressions (for lexical structure) and Backus\u2013Naur form (for grammatical structure) to inductively specify syntactic categories (nonterminals) and terminal symbols. Syntactic categories are defined by rules called productions, which specify the values that belong to a particular syntactic category.[1] Terminal symbols are the concrete characters or strings of characters (for example keywords such as define, if, let, or void) from which syntactically valid programs are constructed.A language can have different equivalent grammars, such as equivalent regular expressions (at the lexical levels), or different phrase rules which generate the same language. Using a broader category of grammars, such as LR grammars, can allow shorter or simpler grammars compared with more restricted categories, such as LL grammar, which may require longer grammars with more rules. Different but equivalent phrase grammars yield different parse trees, though the underlying language (set of valid documents) is the same.Example: Lisp S-expressions[edit]Below is a simple grammar, defined using the notation of regular expressions and Extended Backus\u2013Naur form. It describes the syntax of S-expressions, a data syntax of the programming language Lisp, which defines productions for the syntactic categories expression, atom, number, symbol, and list:This grammar specifies the following:\nan expression is either an atom or a list;\nan atom is either a number or a symbol;\na number is an unbroken sequence of one or more decimal digits, optionally preceded by a plus or minus sign;\na symbol is a letter followed by zero or more of any characters (excluding whitespace); and\na list is a matched pair of parentheses, with zero or more expressions inside it.\nHere the decimal digits, upper- and lower-case characters, and parentheses are terminal symbols.The following are examples of well-formed token sequences in this grammar: '12345', '()', '(a b c232 (1))'Complex grammars[edit]The grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The phrase grammar of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars,[5] though the overall syntax is context-sensitive (due to variable declarations and nested scopes), hence Type-1. However, there are exceptions, and for some languages the phrase grammar is Type-0 (Turing-complete).In some languages like Perl and Lisp the specification (or implementation) of the language allows constructs that execute during the parsing phase. Furthermore, these languages have constructs that allow the programmer to alter the behavior of the parser. This combination effectively blurs the distinction between parsing and execution, and makes syntax analysis an undecidable problem in these languages, meaning that the parsing phase may not finish. For example, in Perl it is possible to execute code during parsing using a BEGIN statement, and Perl function prototypes may alter the syntactic interpretation, and possibly even the syntactic validity of the remaining code.[6] Colloquially this is referred to as only Perl can parse Perl (because code must be executed during parsing, and can modify the grammar), or more strongly even Perl cannot parse Perl (because it is undecidable). Similarly, Lisp macros introduced by the defmacro syntax also execute during parsing, meaning that a Lisp compiler must have an entire Lisp run-time system present. In contrast, C macros are merely string replacements, and do not require code execution.[7][8]Syntax versus semantics[edit]The syntax of a language describes the form of a valid program, but does not provide any information about the meaning of the program or the results of executing that program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.Using natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:\nColorless green ideas sleep furiously. is grammatically well formed but has no generally accepted meaning.\nJohn is a married bachelor. is grammatically well formed but expresses a meaning that cannot be true.\nThe following C language fragment is syntactically correct, but performs an operation that is not semantically defined (because p is a null pointer, the operations p->real and p->im have no meaning):As a simpler example,is syntactically valid, but not semantically defined, as it uses an uninitialized variable. Even though compilers for some programming languages (e.g., Java and C#) would detect uninitialized variable errors of this kind, they should be regarded as semantic errors rather than syntax errors.[4][9]See also[edit]To quickly compare syntax of various programming languages, take a look at the list of Hello, World! program examples:\nProlog syntax and semantics\nPerl syntax\nPHP syntax and semantics\nC syntax\nC++ syntax\nJava syntax\nJavaScript syntax\nPython syntax and semantics\nLua syntax\nHaskell syntax\nReferences[edit]External links[edit]\nVarious syntactic constructs used in computer programming languages\n", "subtitles": ["Levels of syntax", "Syntax definition", "Syntax versus semantics", "See also", "References", "External links"], "title": "Syntax (programming languages)"},
{"content": "Microsoft Dynamics AX is one of Microsoft's enterprise resource planning software products. It is part of the Microsoft Dynamics family.History[edit]Microsoft Dynamics AX was originally developed as a collaboration between IBM and Danish Damgaard Data as IBM Axapta. Axapta was initially released in March 1998 in the Danish and U.S. markets. IBM returned all rights in the product to Damgaard Data shortly after the release of Version 1.5. Damgaard Data merged with Navision Software A/S in 2000 to form NavisionDamgaard, later named Navision A/S. Microsoft acquired the combined company in July 2002.[4]In September 2011, Microsoft released version AX 2012.[5] It was made available and supported in more than 30 countries and 25 languages.The newest version, released in February 2016,[6] dropped the nomenclature of year and version and was simply called AX, although was widely known as AX7. This update was a major revision with a completely new UI delivered through a browser-based HTML5 client, and initially only available as a cloud-hosted application. This version lasted only a few months, though, as Dynamics AX was rebranded Microsoft Dynamics 365 for Operations in October 2016, and once more as Dynamics 365 for Finance and Operations in July 2017. An additional version is available focusing on Retail branded as Dynamics 365 for Retail. This has a slightly different licensing price than Dynamics 365 for Finance and Operations.Development Centers[edit]MDCC or Microsoft Development Center Copenhagen was once the primary development center for Dynamics AX.[7] MDCC is now located in Kongens Lyngby and also houses Microsoft Dynamics NAV and several other Microsoft Dynamics family products. Microsoft Denmark is also found in the same building. Microsoft employs about 900 people of around 40 different nationalities in Denmark. In addition to MDCC, Microsoft carries out AX development in Bellevue, Washington, Fargo, North Dakota, USA; Moscow, Russia; Shanghai, China; and Pakistan.Features (modules)[edit]Microsoft Dynamics AX contains 19 core modules:[8]Traditional core (since Axapta 2.5)[edit]\nGeneral Ledger \u2013 ledger, sales tax, currency, and fixed assets features\nBank Management \u2013 receives and pays cash\nCustomer Relationship Management (CRM) \u2013 business relations contact and maintenance (customers, vendors, and leads)\nAccounts Receivable \u2013 order entry, shipping, and invoicing\nAccounts Payable \u2013 purchase orders, goods received into inventory\nInventory Management \u2013 inventory management and valuation[9]\nMaster Planning (resources) \u2013 purchase and production planning\nProduction \u2013 bills of materials, manufacturing tracking\nProduct Builder \u2013 product mode creation and maintenance\nHuman Resources \u2013 employee information\nProject Accounting \u2013 projects creation and tracking (primarily from an accounting perspective)\nBasic \u2013 data configuration\nAdministration Module \u2013 system configuration\nProcurement and Sourcing\nSales and Marketing\nAX 2012 R3\nCall Center - employees take orders over the phone and are able to create sales orders\nGeneral Ledger - the ability to transfer opening balances in balance sheet accounts to a new fiscal year\nInventory and Warehouse Management - compare item prices, enhanced posting routine and a new Inventory aging report\nMaster Planning - estimate future demand and create demand forecasts based on transaction history\nProcurement and Sourcing - create your own solicitation request for RFQs, and more\nProduction Control - a new option to automate material reservations\nProject Management and Accounting - new on-account billing rules and fee transactions that modify invoice proposal sales prices\nPublic Sector - now able to publish a request for quotation (RFQ) to the Vendor portal and now have the ability to view details of closed RFQs\nRetail - commerce Data Exchange, updated retail server, new retail hardware station, and more\nSales and Marketing - register serial numbers during sales processes when preparing the packing slip or the sales order invoice\nTransportation Management - plan transportation for inbound and outbound shipments, configure rating structures and view driver check-in and check-out history\nTrade Allowance Management - define merchandising events, manage trade fund budgets, process customer payments (including deductions, and more\nWarehouse Management - configure inbound and outbound intelligent workflows, use scanners/mobile devices to optimize precision in the picking and put-away processes, and more\nFor the full list of AX 2012 R3 features, click hereExtended core[edit]The following modules are part of the core of AX 2009 (AX 5.0) and available on a per-license basis in AX 4.0:\nShop Floor Control\nCost Accounting\nBalanced Scorecards\nService Management\nExpense Management\nPayroll Management[10]\nEnvironmental Management[11]\nExternal components[edit]Several external components are also available:\nEnterprise Portal for Dynamics AX (built on Sharepoint Services)\nMicrosoft SQL Reporting Services integration\nMicrosoft SQL Analysis services (KPIs)\nProject Server Integration\nWorkFlow\nApplication Integration Framework (Webservices + Biztalk adapter)\nA .Net Business Connector for third-party software (A COM adapter is also available)\nMicrosoft Dynamics Mobile 1.5 development tools\nMicrosoft Project Client\nMicrosoft Excel\nMicrosoft Word\nOffice 365\nArchitecture[edit]The Microsoft Dynamics AX software is composed of four major components:\nThe Database Server, a database that stores the Microsoft Dynamics AX data\nThe File Server, a folder containing the Microsoft Dynamics AX application files (in AX2012 application files are stored in the database)\nThe Application Object Server(s) (AOS), a service that controls all aspects of Microsoft Dynamics AX's operation\nThe Client(s), the actual user interface into Microsoft Dynamics AX\nMorphX and X++[edit]Custom AX development and modification is done with its own IDE, MorphX, which resides in the same client application that a normal day-to-day user would access, thus allowing development to take place on any instance of the client. Since the Dynamics AX 2012 version, development can also be performed in Microsoft Visual Studio 2010 through a Visual Studio plugin.MorphX is an integrated development environment in Microsoft Dynamics AX that developers use to graphically design data types, base enumerations, tables, queries, forms, menus and reports. In addition to application object future versions of AX, it provides access to application code by launching the X++ code editor.MorphX uses referencing to link objects, so changes in\u2014for example\u2014datatypes of field names automatically updates everyplace that uses those field names (such as forms or reports). Furthermore, changes made through MorphX show in the application immediately after compilation.Microsoft Dynamics AX also offers support for version control systems (VCS) integrated with the IDE, which facilitates development collaboration. Another tool converts table structures and class structures to Visio diagrams. Actual implementation limits the practical use of both these features.X++ itself is the programming language behind MorphX, and belongs to the curly brackets and .-operator class of programming languages (like C# or Java). It is an object-oriented, class-based, single dispatch language. X++ is derived from C++ (both lack the finally keyword for example) with added garbage collection and language-integrated SQL queries.Code samples[edit]X++ integrates SQL queries into standard Java-style code. The following three examples produce the same result, though the first has generally better performance. Samples 2 and 3 hint at an object-like behavior from table buffers.Sample #1Sample #2Sample #3Future[edit]On its Partner Source web site, Microsoft publishes a Statement of Direction for Dynamics AX that describes future development plans. It states that future versions of AX will include increased vertical market functionality, cloud computing, and HTML 5.Presence on the Internet[edit]One of the most notable sources of information about Axapta (prior to the Microsoft purchase) was technet.navision.com, a proprietary web-based newsgroup, which grew to a considerable number of members and posts before the Microsoft purchase in 2002.After Microsoft incorporated Axapta into their Business Solution suite, they transferred the newsgroup's content to the Microsoft Business Solutions newsgroup.[12] The oldest Axapta Technet post that can be found today dates to August 2000.[13] During the Axapta 3.0 era, this newsgroup in conjunction with secured official Microsoft websites (Partnersource for Microsoft Partners and Axapta resellers and Customersource for licensed Axapta customers) accounted for most of the official documentation sources on Axapta. During this time, freely accessible documentation remained scarce. Following Microsoft's release of Dynamics AX 4.0, Axapta's presence on the World Wide Web greatly improved through heightened interest from professional blogs as well as a continually improving presence on MSDN. Though MSDN contained mostly placeholders immediately following the release, it now contains more detailed information\u2014from a complete SDK, to white papers and code samples.Community[edit]The AX community consists primarily of employees of Dynamics Partners, end-users, and MS MVPs (Microsoft Most Valuable Professional).There are number of organizations dedicated to augmenting information provided by Microsoft.\nThe Dynamics AX User Group (AXUG) is a community for users of the software\nThe Dynamics User Group (DUG) is an online community for users, partners, and freelancers\nMibuso (Mibuso) is an online community for users, partners, and freelancers\nAdditionally, Microsoft hosts a forum for the extended community at https://community.dynamics.com/.Events[edit]AXUG SummitAXUG Summit is held each fall and is an independent, user-led conference.Extreme Conferences Is the leading conference for the Dynamics 365 Partner Community which now includes Dynamics AX, including an Executive Forum.Personalization and Predictive Analytics[edit]At the National Retail Federation (NRF) Conference 2016 in New York, Microsoft unveiled its partnership with Infinite Analytics, a Cambridge, MA based Predictive Analytics & Personalization company. With this partnership, Microsoft now offers predictive analytics based personalization for retail in its Microsoft Dynamics AX platform.[14]References[edit]External links[edit]\nMicrosoft Dynamics AX Official Website\n", "subtitles": ["History", "Features (modules)", "Architecture", "MorphX and X++", "Presence on the Internet", "Community", "Events", "Personalization and Predictive Analytics", "References", "External links"], "title": "Microsoft Dynamics AX"},
{"content": "The Hillside Group is an educational nonprofit organization founded in August 1993[1] to help software developers analyze and document common development and design problems as software design patterns. The Hillside Group supports the patterns community through sponsorship of the Pattern Languages of Programs conferences.[2]History[edit]In August 1993, Kent Beck and Grady Booch sponsored a mountain retreat in Colorado where a group converged on foundations for software patterns. Ward Cunningham, Ralph Johnson, Ken Auer, Hal Hildebrand, Grady Booch, Kent Beck and Jim Coplien struggled with Alexander's ideas and our own experiences to forge a marriage of objects and patterns. The Group agreed that we were ready to build on Erich Gamma's foundation work studying object-oriented patterns, to use patterns in a generative way in the sense that Christopher Alexander uses patterns for urban planning and building architecture. We then used the term generative to mean creational to distinguish them from Gamma patterns that captured observations. The Group was meeting on the side of a hill when all this occurred, hence the name.[3]Since then, the Hillside Group has been incorporated as an educational non-profit. It currently sponsors and helps run various PLoP (Pattern Languages of Programming) conferences[4] such as GuruPLoP, PLoP, EuroPlop, ChiliPlop, GuruPLoP, Asian PLoP, Scrum PLoP, Viking PLoP and Sugarloaf PLoP. Following are a list of historical PLoP conferences sponsored by The Hillside Group: ParaPLoP, KoalaPLoP, Mensore PLoP, ParaPLoP, Meta PLoP and UP97) The Hillside Group has also been responsible for getting the Pattern Languages Of Program Design series of books put together and published.[5]Activities[edit]The Hillside Group sponsors the Pattern Languages of Programs conferences in various countries, including the U.S., Brazil, Norway, Germany, Australia, and Japan. The Hillside Group assisted in publishing the Pattern Languages of Program Design book series until 2006.[6][7][8] Since 2006, The Hillside Group has published patterns and conference proceedings through the Association for Computing Machinery (ACM) Digital Library.[9]Patterns Library[edit]The Hillside Patterns Library contains a comprehensive archive of patterns developed by the community, either directly or indirectly through the PLoP conferences.[10]Conferences[edit]The Hillside Group sponsors the conferences listed.[11] The conferences focus on writing patterns, workshops, and invited talks related to pattern development. Most of the conferences are held annually and encourage attendees to submit papers pre-conference for inclusion in the writer's workshops. The papers undergo a shepherding process, where they are analyzed and evolved before conference attendance.\nPLoP: Pattern Languages of Programs\nChiliPLoP: Southwestern Conference on Pattern Languages of Programs [1]\nEuroPLoP: European Conference on Pattern Languages of Programs [2]\nAsianPLoP: Japanese Conference on Pattern Languages of Programs [3]\nSugarLoafPLoP: Latin American Conference on Pattern Languages of Programming [4]\nVikingPLoP: Nordic Conference on Pattern Languages of Programs [5]\nScrumPLoP: Conference on Pattern Languages of Scrum [6]\nEduPLoP: Educational Patterns Writing Workshop [7]\nThe Hillside Group Board[edit]The President of The Hillside Group for 2010\u20132014 is Joseph Yoder of The Refactory, Inc.The Hillside Group is led by a Board consisting of the President, Vice-President, Chief Operating Officer, Treasurer, two Directors, Secretary, two Editors in Chief and four Members.Current Board[edit]Founding members[edit]\nWard Cunningham\nRalph Johnson\nKen Auer\nHal Hildebrand\nGrady Booch\nKent Beck\nJim Coplien\nReferences[edit]External links[edit]\nThe Hillside Group official website\nThe Hillside Group European website\nList of PLoP Conferences\nLNCS Transactions on Pattern Languages of Programming\nACM Digital Library\n", "subtitles": ["History", "Activities", "Patterns Library", "Conferences", "The Hillside Group Board", "Current Board", "Founding members", "References", "External links"], "title": "The Hillside Group"},
{"content": "The Association for the Advancement of Artificial Intelligence (AAAI) is an international, nonprofit, scientific society devoted to promote research in, and responsible use of, artificial intelligence. AAAI also aims to increase public understanding of artificial intelligence (AI), improve the teaching and training of AI practitioners, and provide guidance for research planners and funders concerning the importance and potential of current AI developments and future directions.[1]History[edit]The organization was founded in 1979 under the name American Association for Artificial Intelligence and changed its name in 2007 to Association for the Advancement of Artificial Intelligence. It has in excess of 4,000 members worldwide. In its early history, the organization was presided over by notable figures in computer science such as Allen Newell, Edward Feigenbaum, Marvin Minsky and John McCarthy. The current president is Subbarao Kambhampati, and the president elect is Yolanda Gil.[2]Activities[edit]The AAAI provides many services to the Artificial Intelligence community. The AAAI sponsors many conferences and symposia each year as well as providing support to 14 journals in the field of artificial intelligence. AAAI produces a quarterly publication, AI Magazine, which seeks to publish significant new research and literature across the entire field of artificial intelligence and to help members to keep abreast of research outside their immediate specialties. The magazine has been published continuously since 1980.AAAI organises the AAAI Conference on Artificial Intelligence,[3] which is considered to be one of the top conferences in the field of artificial intelligence.[4][5]ACM-AAAI Allen Newell Award[edit]The ACM-AAAI Allen Newell Award is presented to an individual selected for career contributions that have breadth within computer science, or that bridge computer science and other disciplines. This endowed award is accompanied by a prize of $10,000, and is supported by the Association for the Advancement of Artificial Intelligence (AAAI), Association for Computing Machinery (ACM), and by individual contributions.[6]Past recipients:[7]\nJitendra Malik (2016)\nEric Horvitz (2015)\nJon Kleinberg (2014)\nMoshe Tennenholtz and Yoav Shoham (2012)\nStephanie Forrest (2011)\nTakeo Kanade (2010)\nMichael I. Jordan (2009)\nBarbara J. Grosz and Joseph Halpern (2008)\nLeonidas Guibas (2007)\nKaren Spa\u0308rck Jones (2006)\nJack Minker (2005)\nRichard P. Gabriel (2004)\nDavid Haussler and Judea Pearl (2003)\nPeter Chen (2002)\nRuzena Bajcsy (2001)\nLotfi A. Zadeh (2000)\nNancy Leveson (1999)\nSaul Amarel (1998)\nCarver Mead (1997)\nJoshua Lederberg (1995)\nFred Brooks (1994)\nSee also[edit]\nFellows of the American Association for Artificial Intelligence\nGlossary of artificial intelligence\nReferences[edit]External links[edit]\nAAAI.org, AAAI official website\nAmerican Association for Artificial Intelligence on Facebook\n", "subtitles": ["History", "Activities", "See also", "References", "External links"], "title": "Association for the Advancement of Artificial Intelligence"},
{"content": "In computer science, conditional statements, conditional expressions and conditional constructs are features of a programming language, which perform different computations or actions depending on whether a programmer-specified boolean condition evaluates to true or false. Apart from the case of branch predication, this is always achieved by selectively altering the control flow based on some condition.In imperative programming languages, the term conditional statement is usually used, whereas in functional programming, the terms conditional expression or conditional construct are preferred, because these terms all have distinct meanings.A conditional is sometimes colloquially referred to as an if-check, especially when perceived as a simple one and when its specific form is irrelevant or unknown.Although dynamic dispatch is not usually classified as a conditional construct, it is another way to select between alternatives at runtime.If\u2013then(\u2013else)[edit]The if\u2013then construct (sometimes called if\u2013then\u2013else) is common across many programming languages. Although the syntax varies from language to language, the basic structure (in pseudocode form) looks like this:In the example code above, the part represented by (boolean condition) constitutes a conditional expression, having intrinsic value (e.g., it may be substituted by either of the values True or False) but having no intrinsic meaning. In contrast, the combination of this expression, the If and Then surrounding it, and the consequent that follows afterward constitute a conditional statement, having intrinsic meaning (e.g., expressing a coherent logical rule) but no intrinsic value.When an interpreter finds an If, it expects a boolean condition \u2013 for example, x > 0, which means the variable x contains a number that is greater than zero \u2013 and evaluates that condition. If the condition is true, the statements following the then are executed. Otherwise, the execution continues in the following branch \u2013 either in the else block (which is usually optional), or if there is no else branch, then after the end If.After either branch has been executed, control returns to the point after the end If.In early programming languages, especially some dialects of BASIC in the 1980s home computers, an if\u2013then statement could only contain GOTO statements. This led to a hard-to-read style of programming known as spaghetti programming, with programs in this style called spaghetti code. As a result, structured programming, which allows (virtually) arbitrary statements to be put in statement blocks inside an if statement, gained in popularity, until it became the norm even in most BASIC programming circles. Such mechanisms and principles were based on the older but more advanced ALGOL family of languages, and ALGOL-like languages such as Pascal and Modula-2 influenced modern BASIC variants for many years. While it is possible while using only GOTO statements in if\u2013then statements to write programs that are not spaghetti code and are just as well structured and readable as programs written in a structured programming language, structured programming makes this easier and enforces it. Structured if\u2013then\u2013else statements like the example above are one of the key elements of structured programming, and they are present in most popular high-level programming languages such as C, Java, JavaScript and Visual Basic .A subtlety is that the optional else clause found in many languages means that the context-free grammar is ambiguous, since nested conditionals can be parsed in multiple ways. Specifically,\nif a then if b then s else s2\ncan be parsed as\nif a then (if b then s) else s2\nor\nif a then (if b then s else s2)\ndepending on whether the else is associated with the first if or second if. This is known as the dangling else problem, and is resolved in various ways, depending on the language.Else if[edit]By using else if, it is possible to combine several conditions. Only the statements following the first condition that is found to be true will be executed. All other statements will be skipped. The statements ofelseif, in Ada, is simply syntactic sugar for else followed by if. In Ada, the difference is that only one end if is needed, if one uses elseif instead of else followed by if. This is similar in Perl, which provides the keyword elsif to avoid the large number of braces that would be required by multiple if and else statements and also in Python, which uses the special keyword elif because structure is denoted by indentation rather than braces, so a repeated use of else and if would require increased indentation after every condition. Similarly, the earlier UNIX shells (later gathered up to the POSIX shell syntax[1]) use elif too, but giving the choice of delimiting with spaces, line breaks, or both.However, in many languages more directly descended from Algol, such as Algol68, Simula, Pascal, BCPL and C, this special syntax for the else if construct is not present, nor is it present in the many syntactical derivatives of C, such as Java, ECMA-script, PHP, and so on. This works because in these languages, any single statement (in this case if cond...) can follow a conditional without being enclosed in a block.This design choice has a slight cost in that code else if branch is, effectively, adding an extra nesting level, complicating the job for some compilers (or its implementors), which has to analyse and implement arbitrarily long else if chains recursively.If all terms in the sequence of conditionals are testing the value of a single expression (e.g., if x=0 ... else if x=1 ... else if x=2...), then an alternative is the switch statement, also called case-statement or select-statement. Conversely, in languages that do not have a switch statement, these can be produced by a sequence of else if statements.If\u2013then\u2013else expressions[edit]Many languages support if expressions, which are similar to if statements, but return a value as a result. Thus, they are true expressions (which evaluate to a value), not statements (which changes the program state or perform some kind of action).Algol family[edit]ALGOL 60 and some other members of the ALGOL family allow if\u2013then\u2013else as an expression:\n  myvariable := if x > 10 then 1 else 2\nLisp dialects[edit]In dialects of Lisp \u2013 Scheme, Racket and Common Lisp \u2013 the first of which was inspired to a great extent by ALGOL:Haskell[edit]In Haskell 98, there is only an if expression, no if statement, and the else part is compulsory, as every expression must have some value.[2] Logic that would be expressed with conditionals in other languages is usually expressed with pattern matching in recursive functions.Because Haskell is lazy, it is possible to write control structures, such as if, as ordinary expressions; the lazy evaluation means that an if function can evaluate only the condition and proper branch (where a strict language would evaluate all three). It can be written like this:[3]C-like languages[edit]C and C-like languages have a special ternary operator (?:) for conditional expressions with a function that may be described by a template like this:\ncondition ? evaluated-when-true : evaluated-when-false\nThis means that it can be inlined into expressions, unlike if-statements, in C-like languages:which can be compared to the Algol-family if\u2013then\u2013else expressions (and similar in Ruby and Scala, among others).To accomplish the same using an if-statement, this would take more than one line of code (under typical layout conventions):Some argue that the explicit if/then statement is easier to read and that it may compile to more efficient code than the ternary operator,[4] while others argue that concise expressions are easier to read than statements spread over several lines.In Small Basic[edit]First, when the user runs the program, a cursor appears waiting for the reader to type a number. If that number is greater than 10, the text My variable is named 'foo'. is displayed on the screen. If the number is smaller than 10, then the message My variable is named 'bar'. is printed on the screen.In Visual Basic[edit]In Visual Basic and some other languages, a function called IIf is provided, which can be used as a conditional expression. However, it does not behave like a true conditional expression, because both the true and false branches are always evaluated; it is just that the result of one of them is thrown away, while the result of the other is returned by the IIf function.Arithmetic if[edit]Up to Fortran 77, the language Fortran has an arithmetic if statement which is halfway between a computed IF and a case statement, based on the trichotomy x < 0, x = 0, x > 0. This was the earliest conditional statement in Fortran:[5]Where e is any numeric expression (not necessarily an integer); this is equivalent toBecause this arithmetic IF is equivalent to multiple GOTO statements that could jump to anywhere, it is considered to be an unstructured control statement, and should not be used if more structured statements can be used. In practice it has been observed that most arithmetic IF statements referenced the following statement with one or two of the labels.This was the only conditional control statement in the original implementation of Fortran on the IBM 704 computer. On that computer the test-and-branch op-code had three addresses for those three states. Other computers would have flag registers such as positive, zero, negative, even, overflow, carry, associated with the last arithmetic operations and would use instructions such as 'Branch if accumulator negative' then 'Branch if accumulator zero' or similar. Note that the expression is evaluated once only, and in cases such as integer arithmetic where overflow may occur, the overflow or carry flags would be considered also.Object-oriented implementation in Smalltalk[edit]In contrast to other languages, in Smalltalk the conditional statement is not a language construct but defined in the class Boolean as an abstract method that takes two parameters, both closures. Boolean has two subclasses, True and False, which both define the method, True executing the first closure only, False executing the second closure only.[6]JavaScript[edit]Two examples in JavaScript:Lambda Calculus[edit]In Lambda Calculus, the concept of an if-then-else conditional can be expressed using the expressions:\ntrue = \u03bbx. \u03bby. x\nfalse = \u03bbx. \u03bby. y\nifThenElse = (\u03bbc. \u03bbx. \u03bby. (c x y))\n\ntrue takes up to two arguments and once both are provided(see currying), it returns the first argument given.\nfalse takes up to two arguments and once both are provided(see currying), it returns the second argument given.\nifThenElse takes up to three arguments and once all are provided, it passes both second and third argument to the first argument(which is a function that given two arguments, and produces a result). We expect ifThenElse to only take true or false as an argument, both of which project the given two arguments to their preferred single argument, which is then returned.\nnote: if ifThenElse is passed two functions as the left and right conditionals; it is necessary to also pass an empty tuple () to the result of ifThenElse in order to actually call the chosen function, otherwise ifThenElse will just return the function object without getting called.In a system where numbers can be used without definition(like Lisp, Traditional paper math, so on), the above can be expressed as a single closure below:\n((\u03bbtrue. \u03bbfalse. \u03bbifThenElse.\n    (ifThenElse true 2 3)\n)(\u03bbx. \u03bby. x)(\u03bbx. \u03bby. y)(\u03bbc. \u03bbl. \u03bbr. c l r))\nHere, true, false, and ifThenElse are bound to their respective definitions which are passed to their scope at the end of their block.A working JavaScript analogy(using only functions of single variable for rigor) to this is:\nvar computationResult = ((_true => _false => _ifThenElse => \n    _ifThenElse(_true)(2)(3) \n)(x => y => x)(x => y => y)(c => x => y => c(x)(y)));\nThe code above with multivariable functions looks like this:\nvar computationResult = ((_true, _false, _ifThenElse) =>\n    _ifThenElse(_true, 2, 3)\n)((x, y) => x, (x, y) => y, (c, x, y) => c(x, y));\nanother version of the earlier example without a system where numbers are assumed is below.First example shows the first branch being taken, while second example shows the second branch being taken.\n((\u03bbtrue. \u03bbfalse. \u03bbifThenElse.\n    (ifThenElse true (\u03bbFirstBranch. FirstBranch) (\u03bbSecondBranch. SecondBranch))\n)(\u03bbx. \u03bby. x)(\u03bbx. \u03bby. y)(\u03bbc. \u03bbl. \u03bbr. c l r))\n\n((\u03bbtrue. \u03bbfalse. \u03bbifThenElse.\n    (ifThenElse false (\u03bbFirstBranch. FirstBranch) (\u03bbSecondBranch. SecondBranch))\n)(\u03bbx. \u03bby. x)(\u03bbx. \u03bby. y)(\u03bbc. \u03bbl. \u03bbr. c l r))\nSmalltalk uses a similar idea for its true and false representations, with True and False being singleton objects that respond to messages ifTrue/ifFalse differently.Haskell used to use this exact model for its Boolean type, but at the time of writing, most Haskell programs use syntactic sugar if a then b else c construct which unlike ifThenElse does not compose unlesseither wrapped in another function or re-implemented as shown in The Haskell section of this page.Case and switch statements[edit]Switch statements (in some languages, case statements or multiway branches) compare a given value with specified constants and take action according to the first constant to match. There is usually a provision for a default action ('else','otherwise') to be taken if no match succeeds. Switch statements can allow compiler optimizations, such as lookup tables. In dynamic languages, the cases may not be limited to constant expressions, and might extend to pattern matching, as in the shell script example on the right, where the '*)' implements the default case as a regular expression matching any string.Pattern matching[edit]Pattern matching may be seen as a more sophisticated alternative to both if\u2013then\u2013else, and case statements. It is available in many programming languages with functional programming features, such as Wolfram Language, ML and many others. Here is a simple example written in the OCaml language:The power of pattern matching is the ability to concisely match not only actions but also values to patterns of data. Here is an example written in Haskell which illustrates both of these features:This code defines a function map, which applies the first argument (a function) to each of the elements of the second argument (a list), and returns the resulting list. The two lines are the two definitions of the function for the two kinds of arguments possible in this case \u2013 one where the list is empty (just return an empty list) and the other case where the list is not empty.Pattern matching is not strictly speaking always a choice construct, because it is possible in Haskell to write only one alternative, which is guaranteed to always be matched \u2013 in this situation, it is not being used as a choice construct, but simply as a way to bind names to values. However, it is frequently used as a choice construct in the languages in which it is available.Hash-based conditionals[edit]In programming languages that have associative arrays or comparable data structures, such as Python, Perl, PHP or Objective-C, it is idiomatic to use them to implement conditional assignment.[7]In languages that have anonymous functions or that allow a programmer to assign a named function to a variable reference, conditional flow can be implemented by using a hash as a dispatch table.Predication[edit]An alternative to conditional branch instructions is predication. Predication is an architectural feature that enables instructions to be conditionally executed instead of modifying the control flow.Choice system cross reference[edit]This table refers to the most recent language specification of each language. For languages that do not have a specification, the latest officially released implementation is referred to.\n^ This refers to pattern matching as a distinct conditional construct in the programming language \u2013 as opposed to mere string pattern matching support, such as regular expression support.\n1 2 3 4 5 The often-encountered else if in the C family of languages, and in COBOL and Haskell, is not a language feature but a set of nested and independent if then else statements combined with a particular source code layout. However, this also means that a distinct else\u2013if construct is not really needed in these languages.\n1 2 In Haskell and F#, a separate constant choice construct is unneeded, because the same task can be done with pattern matching.\n^ In a Ruby case construct, regular expression matching is among the conditional flow-control alternatives available. For an example, see this Stack Overflow question.\n1 2 SQL has two similar constructs that fulfill both roles, both introduced in SQL-92. A searched CASE expression CASE WHEN cond1 THEN expr1 WHEN cond2 THEN expr2 [...] ELSE exprDflt END works like if ... else if ... else, whereas a simple CASE expression: CASE expr WHEN val1 THEN expr1 [...] ELSE exprDflt END works like a switch statement. For details and examples see Case (SQL).\n^ Arithmetic if is obsolescent in Fortran 90.\nSee also[edit]\nBranch (computer science)\nConditional compilation\nDynamic dispatch for another way to make execution choices\nMcCarthy Formalism for history and historical references\nNamed condition\nTest (Unix)\nYoda conditions\nConditional move\nReferences[edit]External links[edit]\nIF NOT (ActionScript 3.0) video\n", "subtitles": ["If\u2013then(\u2013else)", "Lambda Calculus", "Case and switch statements", "Pattern matching", "Hash-based conditionals", "Predication", "Choice system cross reference", "See also", "References", "External links"], "title": "Conditional (computer programming)"},
{"content": "In computer science, predication is an architectural feature that provides an alternative to conditional branch instructions. Predication works by executing instructions from both paths of the branch and only permitting those instructions from the taken path to modify architectural state.[1] The instructions from the taken path are permitted to modify architectural state because they have been associated (predicated) with a predicate, a Boolean value used by the instruction to control whether the instruction is allowed to modify the architectural state or not.Overview[edit]Most computer programs contain conditional code, which will be executed only under specific conditions depending on factors that cannot be determined beforehand, for example depending on user input. As the majority of processors simply execute the next instruction in a sequence, the traditional solution is to insert branch instructions that allow a program to conditionally branch to a different section of code, thus changing the next step in the sequence. This was sufficient until designers began improving performance by implementing instruction pipelining, a method which is slowed down by branches. For a more thorough description of the problems which arose, and a popular solution, see branch predictor.Luckily, one of the more common patterns of code that normally relies on branching has a more elegant solution. Consider the following pseudocode:[1]\nif condition\n    do this\nelse\n    do that\nOn a system that uses conditional branching, this might translate to machine instructions looking similar to:[1]\nbranch if condition to label 1\n   do that\n  branch to label 2\n label 1:\n   do this\n label 2:\n  ...\nWith predication, all possible branch paths are coded inline, but some instructions execute while others do not. The basic idea is that each instruction is associated with a predicate (the word here used similarly to its usage in predicate logic) and that the instruction will only be executed if the predicate is true. The machine code for the above example using predication might look something like this:[1]\n(condition) do this\n(not condition) do that\nNote that beside eliminating branches, less code is needed in total, provided the architecture provides predicated instructions. While this does not guarantee faster execution in general, it will if the do this and do that blocks of code are short enough.Predication's simplest form is partial predication, where the architecture has conditional move or conditional select instructions. Conditional move instructions write the contents of one register over another only if the predicate's value is true, whereas conditional select instructions choose which of two registers has its contents written to a third based on the predicate's value. A more generalized and capable form is full predication. Full predication has a set of predicate registers for storing predicates (which allows multiple nested or sequential branches to be simultaneously eliminated) and most instructions in the architecture have a register specifier field to specify which predicate register supplies the predicate.[2]Advantages[edit]The main purpose of predication is to avoid jumps over very small sections of program code, increasing the effectiveness of pipelined execution and avoiding problems with the cache. It also has a number of more subtle benefits:\nFunctions that are traditionally computed using simple arithmetic and bitwise operations may be quicker to compute using predicated instructions.\nPredicated instructions with different predicates can be mixed with each other and with unconditional code, allowing better instruction scheduling and so even better performance.\nElimination of unnecessary branch instructions can make the execution of necessary branches, such as those that make up loops, faster by lessening the load on branch prediction mechanisms.\nElimination of the cost of a branch misprediction which can be high on deeply pipelined architectures.\nDisadvantages[edit]Predication's primary drawback is in increased encoding space. In typical implementations, every instruction reserves a bitfield for the predicate specifying under what conditions that instruction should have an effect. When available memory is limited, as on embedded devices, this space cost can be prohibitive. However, some architectures such as Thumb-2 are able to avoid this issue (see below). Other detriments are the following:[3]\nPredication complicates the hardware by adding levels of logic to critical paths and potentially degrades clock speed.\nA predicated block includes cycles for all operations, so shorter paths may take longer and be penalized.\nPredication is most effective when paths are balanced or when the longest path is the most frequently executed,[3] but determining such a path is very difficult at compile time, even in the presence of profiling information.History[edit]Predicated instructions were popular in European computer designs of the 1950s, including the Mailu\u0308fterl (1955), the Zuse Z22 (1955), the ZEBRA (1958), and the Electrologica X1 (1958). The IBM ACS-1 design of 1967 allocated a skip bit in its instruction formats, and the CDC Flexible Processor in 1976 allocated three conditional execution bits in its microinstruction formats.Hewlett-Packard's PA-RISC architecture (1986) had a feature called nullification, which allowed most instructions to be predicated by the previous instruction. IBM's POWER architecture (1990) featured conditional move instructions. POWER's successor, PowerPC (1993), dropped these instructions. Digital Equipment Corporation's Alpha architecture (1992) also featured conditional move instructions. MIPS gained conditional move instructions in 1994 with the MIPS IV version; and SPARC was extended in Version 9 (1994) with conditional move instructions for both integer and floating-point registers.In the Hewlett-Packard/Intel IA-64 architecture, most instructions are predicated. The predicates are stored in 64 special-purpose predicate registers; and one of the predicate registers is always true so that unpredicated instructions are simply instructions predicated with the value true. The use of predication is essential in IA-64's implementation of software pipelining because it avoids the need for writing separated code for prologs and epilogs.[clarification needed]In the x86 architecture, a family of conditional move instructions (CMOV and FCMOV) were added to the architecture by the Intel Pentium Pro (1995) processor. The CMOV instructions copied the contents of the source register to the destination register depending on a predicate supplied by the value of the flag register.In the ARM architecture, the original 32-bit instruction set provides a feature called conditional execution that allows most instructions to be predicated by one of 13 predicates that are based on some combination of the four condition codes set by the previous instruction. ARM's Thumb instruction set (1994) dropped conditional execution to reduce the size of instructions so they could fit in 16 bits, but its successor, Thumb-2 (2003) overcame this problem by using a special instruction which has no effect other than to supply predicates for the following four instructions. The 64-bit instruction set introduced in ARMv8-A (2011) replaced conditional execution with conditional selection instructions.See also[edit]References[edit]Further reading[edit]\nClements, Alan (2013). Computer Organization & Architecture: Themes and Variations. Cengage Learning. pp. 532\u2013539. ISBN 1-285-41542-6. \n", "subtitles": ["Overview", "Advantages", "Disadvantages", "History", "See also", "References", "Further reading"], "title": "Predication (computer architecture)"},
{"content": "In programming jargon, Yoda conditions (also called Yoda notation) is a programming style where the two parts of an expression are reversed from the typical order in a conditional statement. A Yoda condition places the constant portion of the expression on the left side of the conditional statement. The name for this programming style is derived from the Star Wars character named Yoda, who spoke English in a non-standard syntax.Yoda conditions are part of the WordPress [1] and Symfony coding standards.[2]Example[edit]Usually a conditional statement would be written as:Yoda conditions describe the same expression, but reversed:The constant is written to the left of the comparison operator, and the variable whose value is being checked against the constant is written to the right. This order is comparable to the non-standard speaking style of Yoda, which is roughly object\u2013subject\u2013verb[3] (e.g., \u201cWhen nine hundred years old you reach, look as good you will not.[4][5]).Advantage[edit]Placing the constant value in the expression does not change the behavior of the program (unless the values evaluate to false\u2014see below). In programming languages that use a single equals sign (=) for assignment and not for comparison, a possible mistake is to assign a value unintentionally instead of writing a conditional statement.Using Yoda conditions:Since 42 is a constant and can not be changed, this error will be caught by the compiler.It can also solve some types of unsafe null behavior.With Yoda conditions:Criticism[edit]Critics of Yoda conditions see the lack of readability as a disadvantage that outweighs the benefits described above. Some programming languages as Python and Swift do not allow variable assignments within conditionals, by defining assignments to not return a value, in which case this error is impossible to make.[6] Many compilers produce a warning for code such as if (myNumber = 42) (e.g., the GCC -Wall option warns suggest parentheses around assignment used as truth value), which alerts the programmer to the likely mistake. In JavaScript, linters such as ESLint can warn on assignment inside a conditional.[7]The advantage of avoiding null behavior can also be considered a disadvantage, as null pointer errors can be hidden and only appear much later in the program.Another disadvantage appears in C++ when comparing non-basic types as the == is an operator and there may not be a suitable overloaded operator function defined. Example: a CComBSTR compare against a string literal, written as if (LHello == cbstrMessage), does not map to an overload function.[8]References[edit]External links[edit]\nunited-coders.com: What are Yoda Conditions? Examples in Java\nNew programming jargon Mentions Yoda Conditions in a list of new programming jargon\nCoding in Style Probable origin of the term\nYoda Conditions in Java Potential pitfalls of the technique\n", "subtitles": ["Example", "Advantage", "Criticism", "References", "External links"], "title": "Yoda conditions"},
{"content": "The history of the Scheme programming language begins with the development of earlier members of the Lisp family of languages during the second half of the twentieth century, the process of design and development during which language designers Guy L. Steele and Gerald Jay Sussman released an influential series of MIT AI Memos known as the Lambda Papers (1975\u20131980), the growth in popularity of the language, and the era of standardization (1990 onwards). Much of the history of Scheme has been documented by the developers themselves.[1]Prehistory[edit]The development of Scheme was heavily influenced by two predecessors that were quite different from one another: Lisp provided its general semantics and syntax, and ALGOL provided its lexical scope and block structure. Scheme is a dialect of Lisp but Lisp has evolved; the Lisp dialects from which Scheme evolved\u2014although they were in the mainstream at the time\u2014are quite different from any modern Lisp.Lisp[edit]Lisp was invented by John McCarthy in 1958 while he was at the Massachusetts Institute of Technology (MIT). McCarthy published its design in a paper in Communications of the ACM in 1960, entitled Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I[2] (Part II was never published). He showed that with a few simple operators and a notation for functions, one can build a Turing-complete language for algorithms.The use of S-expressions which characterize the syntax of Lisp was initially intended to be an interim measure pending the development of a language employing what McCarthy called M-expressions. As an example, the M-expression car[cons[A,B]] is equivalent to the S-expression (car (cons A B)). S-expressions proved popular, however, and the many attempts to implement M-expressions failed to catch on.The first implementation of Lisp was on an IBM 704 by Steve Russell, who read McCarthy's paper and coded the eval function he described in machine code. The familiar (but puzzling to newcomers) names CAR and CDR used in Lisp to describe the head element of a list and its tail, evolved from two IBM 704 assembly language commands: Contents of Address Register and Contents of Decrement Register, each of which returned the contents of a 15-bit register corresponding to segments of a 36-bit IBM 704 instruction word.The first complete Lisp compiler, written in Lisp, was implemented in 1962 by Tim Hart and Mike Levin at MIT.[3] This compiler introduced the Lisp model of incremental compilation, in which compiled and interpreted functions can intermix freely.The two variants of Lisp most significant in the development of Scheme were both developed at MIT: LISP 1.5[4] developed by McCarthy and others, and MACLISP[5] \u2013 developed for MIT's Project MAC, a direct descendant of LISP 1.5. which ran on the PDP-10 and Multics systems.Since its inception, Lisp was closely connected with the artificial intelligence research community, especially on PDP-10[6] systems.ALGOL[edit]ALGOL 58, originally to be called IAL for International Algorithmic Language, was developed jointly by a committee of European and American computer scientists in a meeting in 1958 at ETH Zurich. ALGOL 60, a later revision developed at the ALGOL 60 meeting in Paris and now commonly known as ALGOL, became the standard for the publication of algorithms and had a profound effect on future language development, despite the language's lack of commercial success and its limitations. C. A. R. Hoare has remarked: Here is a language so far ahead of its time that it was not only an improvement on its predecessors but also on nearly all its successors.[7]ALGOL introduced the use of block structure and lexical scope. It was also notorious for its difficult call by name default parameter passing mechanism, which was defined so as to require textual substitution of the expression representing the actual parameter in place of the formal parameter during execution of a procedure or function, causing it to be re-evaluated each time it is referenced during execution. ALGOL implementors developed a mechanism they called a thunk, which captured the context of the actual parameter, enabling it to be evaluated during execution of the procedure or function.Carl Hewitt, the Actor model, and the birth of Scheme[edit]In 1971 Sussman, Drew McDermott, and Eugene Charniak had developed a system called Micro-Planner which was a partial and somewhat unsatisfactory implementation of Carl Hewitt's ambitious Planner project. Sussman and Hewitt worked together along with others on Muddle (later MDL), an extended Lisp which formed a component of Hewitt's project. Drew McDermott, and Sussman in 1972 developed the Lisp-based language Conniver, which revised the use of automatic backtracking in Planner which they thought was unproductive. Hewitt was dubious that the hairy control structure in Conniver was a solution to the problems with Planner. Pat Hayes remarked: Their [Sussman and McDermott] solution, to give the user access to the implementation primitives of Planner, is however, something of a retrograde step (what are Conniver's semantics?)[8]In November 1972, Hewitt and his students invented the Actor model of computation as a solution to the problems with Planner.[9] A partial implementation of Actors was developed called Planner-73 (later called PLASMA). Steele, then a graduate student at MIT, had been following these developments, and he and Sussman decided to implement a version of the Actor model in their own tiny Lisp developed on top of MacLisp, in order to understand the model better. Using this basis they then began to develop mechanisms for creating actors and sending messages.[10]PLASMA's use of lexical scope was similar to the lambda calculus. Sussman and Steele decided to try to model Actors in the lambda calculus. They called their modeling system Schemer, eventually changing it to Scheme to fit the six-character limit on the ITS file system on their DEC PDP-10. They soon concluded Actors were essentially closures that never return but instead invoke a continuation, and thus they decided that the closure and the Actor were, for the purposes of their investigation, essentially identical concepts. They eliminated what they regarded as redundant code and, at that point, discovered that they had written a very small and capable dialect of Lisp. Hewitt remained critical of the hairy control structure in Scheme[11] and considered primitives (e.g., START!PROCESS, STOP!PROCESS and EVALUATE!UNINTERRUPTIBLY) used in the Scheme implementation to be a backward step.25 years later, in 1998, Sussman and Steele reflected that the minimalism of Scheme was not a conscious design goal, but rather the unintended outcome of the design process. We were actually trying to build something complicated and discovered, serendipitously, that we had accidentally designed something that met all our goals but was much simpler than we had intended... we realized that the lambda calculus\u2014a small, simple formalism\u2014could serve as the core of a powerful and expressive programming language. [10]On the other hand, Hewitt remained critical of the lambda calculus as a foundation for computation writing The actual situation is that the \u03bb-calculus is capable of expressing some kinds of sequential and parallel control structures but, in general, not the concurrency expressed in the Actor model. On the other hand, the Actor model is capable of expressing everything in the \u03bb-calculus and more. He has also been critical of aspects of Scheme that derive from the lambda calculus such as reliance on continuation functions and the lack of exceptions.[12]The Lambda Papers[edit]Between 1975 and 1980 Sussman and Steele worked on developing their ideas about using the lambda calculus, continuations and other advanced programming concepts such as optimization of tail recursion, and published them in a series of AI Memos which have become known collectively as the Lambda Papers.[13]List of papers[edit]\n1975: Scheme: An Interpreter for Extended Lambda Calculus\n1976: Lambda: The Ultimate Imperative\n1976: Lambda: The Ultimate Declarative\n1977: Debunking the 'Expensive Procedure Call' Myth, or, Procedure Call Implementations Considered Harmful, or, Lambda: The Ultimate GOTO\n1978: The Art of the Interpreter or, the Modularity Complex (Parts Zero, One, and Two)\n1978: RABBIT: A Compiler for SCHEME\n1979: Design of LISP-based Processors, or SCHEME: A Dialect of LISP, or Finite Memories Considered Harmful, or LAMBDA: The Ultimate Opcode\n1980: Compiler Optimization Based on Viewing LAMBDA as RENAME + GOTO\n1980: Design of a Lisp-based Processor\nInfluence[edit]Scheme was the first dialect of Lisp to choose lexical scope. It was also one of the first programming languages after Reynold's Definitional Language [14] to support first-class continuations. It had a large impact on the effort that led to the development of its sister-language, Common Lisp, to which Guy Steele was a contributor.[15]Standardization[edit]The Scheme language is standardized in the official IEEE standard,[16] and a de facto standard called the Revisedn Report on the Algorithmic Language Scheme (RnRS). The most widely implemented standard is R5RS (1998),[17] and a new standard, R6RS,[18] was ratified in 2007.[19]References[edit]", "subtitles": ["Prehistory", "Carl Hewitt, the Actor model, and the birth of Scheme", "The Lambda Papers", "Influence", "Standardization", "References"], "title": "History of the Scheme programming language"},
{"content": "Guy Lewis Steele Jr. (/sti\u02d0l/; born October 2, 1954) is an American computer scientist who has played an important role in designing and documenting several computer programming languages.Biography[edit]Steele was born in Missouri and graduated from the Boston Latin School in 1972. He received a BA in applied mathematics from Harvard (1975) and an MS and Ph.D. from MIT in Computer Science (1977, 1980). He then worked as an assistant professor of computer science at Carnegie Mellon University and a compiler implementer at Tartan Laboratories. Then he joined the supercomputer company Thinking Machines, where he helped define and promote a parallel version of Lisp called *Lisp (Star Lisp) and a parallel version of C called C*.In 1994, Steele joined Sun Microsystems and was invited by Bill Joy to become a member of the Java team after the language had been designed, since he had a track record of writing good specifications for existing languages.[citation needed] He was named a Sun Fellow in 2003. Steele joined Oracle in 2010 when Oracle acquired Sun Microsystems.Works[edit]While at MIT, Steele published more than two dozen papers with Gerald Jay Sussman on the subject of the Lisp language and its implementation (the Lambda Papers). One of their most notable contributions was the design of the programming language Scheme.Steele also designed the original command set of Emacs and was the first to port TeX (from WAITS to ITS). He has published papers on other subjects, including compilers, parallel processing, and constraint languages. One song he composed has been published in Communications of the Association for Computing Machinery (CACM) (The Telnet Song, April 1984, a parody of the behavior of a series of PDP-10 TELNET implementations written by Mark Crispin).Steele has served on accredited standards committees ECMA TC39 (ECMAScript, for which he was editor of the first edition), X3J11 (the C language), and X3J3 (Fortran) and is currently chairman of X3J13 (Common Lisp). He was also a member of the IEEE working group that produced the IEEE Standard for the Scheme Programming Language, IEEE Std 1178-1990. He represented Sun Microsystems in the High Performance Fortran Forum, which produced the High Performance Fortran specification in May, 1993.In addition to specifications of the Java programming language, Steele's work at Sun Microsystems has included research in parallel algorithms, implementation strategies, and architectural and software support. In 2005, Steele began leading a team of researchers at Sun developing a new programming language named Fortress, a high-performance language designed to obsolete Fortran.Books[edit]In 1982, Steele edited The Hacker's Dictionary (Harper&Row, 1983; ISBN 0-06-091082-8), which was a print version of the Jargon File.Steele and Samuel P. Harbison wrote C: A Reference Manual, (Prentice-Hall, 1984; ISBN 0-13-110016-5), to provide a precise description of the C programming language, which Tartan Laboratories was trying to implement on a wide range of systems. Both authors participated in the ANSI C standardization process; several revisions of the book were issued to reflect the new standard.On 16 March 1984, Steele published Common Lisp the Language (Digital Press; ISBN 0-932376-41-X; 465 pages). This first edition was the original specification of Common Lisp (CLtL1) and served as the basis for the ANSI standard. Steele released a greatly expanded second edition in 1990, (Digital Press; ISBN 1-55558-041-6; 1029 pages) which documented a near-final version of the ANSI standard.[1]Steele, along with Charles H. Koelbel, David B. Loveman, Robert S. Schreiber, and Mary E. Zosel wrote The High Performance Fortran Handbook (MIT Press, 1994; ISBN 0-262-11185-3).Steele also coauthored all three editions of The Java Language Specification (Addison-Wesley, third ed. 2005; ISBN 0-321-24678-0) with James Gosling, Bill Joy, and Gilad Bracha.Awards[edit]Steele received the ACM Grace Murray Hopper Award in 1988. He was named an ACM Fellow in 1994, a member of the National Academy of Engineering of the United States of America in 2001 and a Fellow of the American Academy of Arts and Sciences in 2002. He received the Dr. Dobb's Excellence in Programming Award in 2005.[2]Other activities[edit]Steele is a Modern Western square dancer and caller from Mainstream up through C3A, a member of Tech Squares,[3] and a member of Callerlab.Under the pseudonym Great Quux,[4] which was an old student nickname at the Boston Latin School and MIT, he has published light verse and Crunchly cartoons; a few of the latter appeared in The New Hacker's Dictionary. He has also used the initialism GLS /\u02c8\u0261l\u026as/.In 1989, Steele solved the game Teeko via computer, showing what must occur if both players play wisely; he found that neither player can force a win. Steele also showed that the Advanced Teeko variant is a win for Black (again, assuming perfect play), as is one other variant, but the other fourteen variants are draws.[5]References[edit]External links[edit]\nWorks by Guy L. Steele at Project Gutenberg\nWorks by or about Guy L. Steele Jr. at Internet Archive\nSun/Oracle biographical page for Steele\nTelnet Song\nPoems (mostly parodies) from Guy Steele's student days\nA podcast interview with Guy Steele on Software Engineering Radio\nGrowing a Language, Keynote at the 1998 ACM OOPSLA Conference (text)\nGuy Steele: Dan Friedman--Cool Ideas (Dan Friedman's 60th Birthday)\n", "subtitles": ["Biography", "Works", "Awards", "Other activities", "References", "External links"], "title": "Guy L. Steele Jr."},
{"content": "Gerald Jay Sussman (born February 8, 1947) is the Panasonic Professor of Electrical Engineering at the Massachusetts Institute of Technology (MIT). He received his S.B. and Ph.D. degrees in mathematics from MIT in 1968 and 1973 respectively. He has been involved in artificial intelligence research at MIT since 1964. His research has centered on understanding the problem-solving strategies used by scientists and engineers, with the goals of automating parts of the process and formalizing it to provide more effective methods of science and engineering education. Sussman has also worked in computer languages, in computer architecture and in VLSI design. [1]Education[edit]Sussman attended the Massachusetts Institute of Technology as an undergraduate and received his S.B. in mathematics in 1968. He continued his studies at MIT and obtained a Ph.D. in 1973, also in mathematics. His doctoral thesis was titled A Computational Model of Skill Acquisition focusing on artificial intelligence and machine learning, using a computational performance model called HACKER.[2]Academic work[edit]Sussman is a coauthor (with Hal Abelson and his wife Julie Sussman) of the introductory computer science textbook Structure and Interpretation of Computer Programs. It was used at MIT for several decades, and has been translated into several languages.Sussman's contributions to artificial intelligence include problem solving by debugging almost-right plans, propagation of constraints applied to electrical circuit analysis and synthesis, dependency-based explanation and dependency-based backtracking, and various language structures for expressing problem-solving strategies. Sussman and his former student, Guy L. Steele Jr., invented the Scheme programming language in 1975.Sussman saw that artificial intelligence ideas can be applied to computer-aided design. Sussman developed, with his graduate students, sophisticated computer-aided design tools for VLSI. Steele made the first Scheme chips in 1978. These ideas and the AI-based CAD technology to support them were further developed in the Scheme chips of 1979 and 1981. The technique and experience developed were then used to design other special-purpose computers. Sussman was the principal designer of the Digital Orrery, a machine designed to do high-precision integrations for orbital mechanics experiments. The Orrery was designed and built by a few people in a few months, using AI-based simulation and compilation tools.Using the Digital Orrery, Sussman has worked with Jack Wisdom to discover numerical evidence for chaotic motions in the outer planets. The Digital Orrery is now retired at the Smithsonian Institution in Washington, DC. Sussman was also the lead designer of the Supercomputer Toolkit, another multiprocessor computer optimized for evolving systems of ordinary differential equations. The Supercomputer Toolkit was used by Sussman and Wisdom to confirm and extend the discoveries made with the Digital Orrery to include the entire planetary system.Sussman has pioneered the use of computational descriptions to communicate methodological ideas in teaching subjects in Electrical Circuits and in Signals and Systems. Over the past decade Sussman and Wisdom have developed a subject that uses computational techniques to communicate a deeper understanding of advanced classical mechanics. In Computer Science: Reflections on the Field, Reflections from the Field, he writes ...computational algorithms are used to express the methods used in the analysis of dynamical phenomena. Expressing the methods in a computer language forces them to be unambiguous and computationally effective. Students are expected to read the programs and to extend them and to write new ones. The task of formulating a method as a computer-executable program and debugging that program is a powerful exercise in the learning process. Also, once formalized procedurally, a mathematical idea becomes a tool that can be used directly to compute results. Sussman and Wisdom, with Meinhard Mayer, have produced a textbook, Structure and Interpretation of Classical Mechanics, to capture these new ideas.Sussman and Abelson have also been a part of the Free Software Movement, including releasing MIT/GNU Scheme as free software[3] and serving on the Board of Directors of the Free Software Foundation.[4]Awards and organizations[edit]For his contributions to computer-science education, Sussman received the ACM's Karl Karlstrom Outstanding Educator Award in 1990, and the Amar G. Bose award for teaching in 1991.Sussman, Hal Abelson, and Richard Stallman are the only founding directors still active on the board of directors of the Free Software Foundation (FSF).Sussman is a fellow of the Institute of Electrical and Electronics Engineers (IEEE), a member of the National Academy of Engineering (NAE), a fellow of the Association for the Advancement of Artificial Intelligence (AAAI), a fellow of the Association for Computing Machinery (ACM), a fellow of the American Association for the Advancement of Science (AAAS), a fellow of the New York Academy of Sciences (NYAS), and a fellow of the American Academy of Arts and Sciences. He is also a bonded locksmith, a life member of the American Watchmakers-Clockmakers Institute (AWI), a member of the Massachusetts Watchmakers-Clockmakers Association (MWCA), a member of the Amateur Telescope Makers of Boston (ATMOB), and a member of the American Radio Relay League (ARRL).Personal life[edit]Gerald Sussman is married to computer programmer, Julie Sussman.[5] Julie is an MIT graduate and has also studied many languages including French, Russian, German, Chinese, Japanese, Norwegian, Swedish, Dutch, Hebrew, and Serbo-Croatian. She has written books on software and a book on everyday Chinese characters.[6]See also[edit]\nMarvin Minsky\nSeymour Papert\nTerry Winograd\nMDL programming language\nSussman Anomaly\nExternal links[edit]\nVideo of Flexible Systems The Power of Generic Operations talk for LispNYC, January 2016\nVideo clip of Sussman speaking at the International Conference on Complex Systems, hosted by the New England Complex Systems Institute (NECSI)\nSussman's homepage\nGerald Sussman at the Mathematics Genealogy Project\nVideo of The Legacy of Computer Science talk for ArsDigita University, 2001\nWorks by or about Gerald Jay Sussman in libraries (WorldCat catalog)\nVideo of his keynote talk at the Strange Loop conference: We Really Don't Know How To Compute!, Sept 19, 2011\nThese twenty video lectures by Hal Abelson and Gerald Jay Sussman are a complete presentation of the MIT's SICP course, given in July 1986.\nReferences[edit]", "subtitles": ["Education", "Academic work", "Awards and organizations", "Personal life", "See also", "External links", "References"], "title": "Gerald Jay Sussman"},
{"content": "Marvin Lee Minsky (August 9, 1927 \u2013 January 24, 2016) was an American cognitive scientist concerned largely with research of artificial intelligence (AI), co-founder of the Massachusetts Institute of Technology's AI laboratory, and author of several texts concerning AI and philosophy.[12][13][14][15]Biography[edit]Marvin Lee Minsky was born in New York City, to an eye surgeon father, Henry, and to a mother, Fannie, who was an activist of Zionist affairs.[15][16] His family was Jewish. He attended the Ethical Culture Fieldston School and the Bronx High School of Science. He later attended Phillips Academy in Andover, Massachusetts. He then served in the US Navy from 1944 to 1945. He received a B.A. in mathematics from Harvard University (1950) and a Ph.D. in mathematics from Princeton University (1954).[17][18]He was on the MIT faculty from 1958 to his death. He joined the staff at MIT Lincoln Laboratory in 1958, and a year later he and John McCarthy initiated what is known now as the MIT Computer Science and Artificial Intelligence Laboratory.[19][20] He was the Toshiba Professor of Media Arts and Sciences, and professor of electrical engineering and computer science.Contributions in computer science[edit]Minsky's inventions include the first head-mounted graphical display (1963)[21] and the confocal microscope[2][22] (1957, a predecessor to today's widely used confocal laser scanning microscope). He developed, with Seymour Papert, the first Logo turtle. Minsky also built, in 1951, the first randomly wired neural network learning machine, SNARC.Minsky wrote the book Perceptrons (with Seymour Papert), which became the foundational work in the analysis of artificial neural networks. This book is the center of a controversy in the history of AI, as some claim it to have had great importance in discouraging research of neural networks in the 1970s, and contributing to the so-called AI winter.[23] He also founded several other famous AI models. His book A framework for representing knowledge created a new paradigm in programming. While his Perceptrons is now more a historical than practical book, the theory of frames is in wide use.[24] Minsky has also written on the possibility that extraterrestrial life may think like humans, permitting communication.[25]In the early 1970s, at the MIT Artificial Intelligence Lab, Minsky and Papert started developing what came to be known as the Society of Mind theory. The theory attempts to explain how what we call intelligence could be a product of the interaction of non-intelligent parts. Minsky says that the biggest source of ideas about the theory came from his work in trying to create a machine that uses a robotic arm, a video camera, and a computer to build with children's blocks. In 1986, Minsky published The Society of Mind, a comprehensive book on the theory which, unlike most of his previously published work, was written for the general public.In November 2006, Minsky published The Emotion Machine, a book that critiques many popular theories of how human minds work and suggests alternative theories, often replacing simple ideas with more complex ones. Recent drafts of the book are freely available from his webpage.[26]Role in popular culture[edit]Minsky was an adviser[27] on Stanley Kubrick's movie 2001: A Space Odyssey; one of the movie's characters, Victor Kaminski, was named in Minsky's honor[28]. Minsky himself is explicitly mentioned in Arthur C. Clarke's derivative novel of the same name, where he is portrayed as achieving a crucial break-through in artificial intelligence in the then-future 1980s, paving the way for HAL 9000 in the early 21st century:\nIn the 1980s, Minsky and Good had shown how neural networks could be generated automatically\u2014self replicated\u2014in accordance with any arbitrary learning program. Artificial brains could be grown by a process strikingly analogous to the development of a human brain. In any given case, the precise details would never be known, and even if they were, they would be millions of times too complex for human understanding.[29]\nPersonal life[edit]In 1952, Minsky married pediatrician Gloria Rudisch; together they had three children.[30] Minsky was a talented improvisational pianist[31] who published musings on the relations between music and psychology.Opinions[edit]Minsky was an atheist[32] and a signatory to the Scientists' Open Letter on Cryonics.[33] He was a critic of the Loebner Prize for conversational robots.[34][35]Minsky believed that there is no fundamental difference between humans and machines, and that humans are machines whose intelligence emerges from the interplay of the many unintelligent but semi-autonomous agents that comprise the brain.[36] He has stated that somewhere down the line, some computers will become more intelligent than most people, but that it's very hard to predict how fast progress will be.[37] He has cautioned that an artificial superintelligence designed to solve an innocuous mathematical problem might decide to assume control of Earth's resources to build supercomputers to help achieve its goal,[38] but believed that such negative scenarios are hard to take seriously because he was confident AI would go through a lot of testing before being deployed.[39]Death[edit]Minsky died of a cerebral hemorrhage at the age of 88.[40] Minsky was a member of Alcor's Scientific Advisory Board,[41] and is believed to have been cryonically preserved by Alcor,[42] presumably as 'Patient 144', whose cooling procedures began on January 27, 2016.[43]Bibliography (selected)[edit]\n1967 \u2013 Computation: Finite and Infinite Machines, Prentice-Hall\n1986 \u2013 The Society of Mind\n2006 \u2013 The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind\nAwards and affiliations[edit]Minsky won the Turing Award (the greatest distinction in computer science)[36] in 1969, the Japan Prize in 1990, the IJCAI Award for Research Excellence for 1991, and the Benjamin Franklin Medal from the Franklin Institute for 2001.[44] In 2006, he was inducted as a Fellow of the Computer History Museum for co-founding the field of artificial intelligence, creating early neural networks and robots, and developing theories of human and machine cognition.[45] In 2011, Minsky was inducted into IEEE Intelligent Systems' AI Hall of Fame for the significant contributions to the field of AI and intelligent systems.[46][47] In 2014, Minsky won the Dan David Prize for Artificial Intelligence, the Digital Mind.[48] He was also awarded with the 2013 BBVA Foundation Frontiers of Knowledge Award in the Information and Communication Technologies category.[49]Minsky was affiliated with the following organizations:\nUnited States National Academy of Engineering[21]\nUnited States National Academy of Sciences[21]\nExtropy Institute's Council of Advisors[50]\nAlcor Life Extension Foundation's Scientific Advisory Board[41]\nkynamatrix Research Network's Board of Directors[51]\nSee also[edit]\nList of pioneers in computer science\nReferences[edit]External links[edit]\nOral history interview with Marvin Minsky at Charles Babbage Institute, University of Minnesota, Minneapolis. Minsky describes artificial intelligence (AI) research at the Massachusetts Institute of Technology (MIT). Topics include: the work of John McCarthy; changes in the MIT research laboratories with the advent of Project MAC; research in the areas of expert systems, graphics, word processing, and time-sharing; variations in the Advanced Research Projects Agency (ARPA) attitude toward AI.\nOral history interview with Terry Winograd at Charles Babbage Institute, University of Minnesota, Minneapolis. Winograd describes his work in computer science, linguistics, and artificial intelligence at the Massachusetts Institute of Technology (MIT), discussing the work of Marvin Minsky and others.\nScientist on the Set: An Interview with Marvin Minsky\nMarvin Minsky Playlist Appearance on WMBR's Dinnertime Sampler radio show November 26, 2003\nConsciousness Is A Big Suitcase: A talk with Marvin Minsky\nVideo of Minsky speaking at the International Conference on Complex Systems, hosted by the New England Complex Systems Institute (NECSI)\nThe Emotion Universe: Video with Marvin Minsky\nMarvin Minsky's thoughts on the Fermi Paradox at the Transvisions 2007 conference\nHealth, population and the human mind: Marvin Minsky talk at the TED conference\nThe Society of Mind on MIT OpenCourseWare\nMarvin Minsky tells his life story at Web of Stories (video)\n", "subtitles": ["Biography", "Contributions in computer science", "Role in popular culture", "Personal life", "Bibliography (selected)", "Awards and affiliations", "See also", "References", "External links"], "title": "Marvin Minsky"},
{"content": "Model-driven architecture (MDA\u00ae) is a software design approach for the development of software systems. It provides a set of guidelines for the structuring of specifications, which are expressed as models. Model-driven architecture is a kind of domain engineering, and supports model-driven engineering of software systems. It was launched by the Object Management Group (OMG) in 2001.[1]Overview[edit]The model-driven architecture approach defines system functionality using a platform-independent model (PIM) using an appropriate domain-specific language (DSL).[citation needed]Then, given a platform model corresponding to CORBA, .NET, the Web, etc., the PIM is translated to one or more platform-specific models (PSMs) that computers can run. This requires mappings and transformations and should be modeled too.The PSM may use different DSLs or a general purpose language.[citation needed]. Automated tools generally perform this translation.The OMG organization provides rough specifications rather than implementations, often as answers to Requests for Proposals (RFPs). Implementations come from private companies or open source groups.MDA principles can also apply to other areas such as business process modeling (BPM) where the PIM is translated to either automated or manual processes[citation needed].Related standards[edit]The MDA model is related to multiple standards, including the Unified Modeling Language (UML), the Meta-Object Facility (MOF), XML Metadata Interchange (XMI), Enterprise Distributed Object Computing (EDOC), the Software Process Engineering Metamodel (SPEM), and the Common Warehouse Metamodel (CWM). Note that the term \u201carchitecture\u201d in Model-driven architecture does not refer to the architecture of the system being modeled, but rather to the architecture of the various standards and model forms that serve as the technology basis for MDA.Executable UML was the UML profile used when MDA was born. Now, the OMG is promoting fUML, instead. (The action language for fUML is ALF.)Trademark[edit]The Object Management Group holds registered trademarks on the term Model Driven Architecture\u00ae and its acronym MDA\u00ae, as well as trademarks for terms such as: Model Based Application DevelopmentTM, Model Driven Application DevelopmentTM, Model Based Application DevelopmentTM, Model Based ProgrammingTM, Model Driven SystemsTM and others.[2] The main acronym that has not yet been deposited by OMG until now is Model-driven engineering (MDE). As a consequence, the research community uses MDE to refer to general model engineering ideas, without committing to strict OMG standards.[citation needed]Model-driven architecture topics[edit]MDA approach[edit]OMG focuses Model-driven architecture on forward engineering, i.e. producing code from abstract, human-elaborated modelling diagrams (e.g. class diagrams)[citation needed]. OMG's ADTF (Analysis and Design Task Force) group leads this effort. With some humour, the group chose ADM (MDA backwards) to name the study of reverse engineering. ADM decodes to Architecture-Driven Modernization. The objective of ADM is to produce standards for model-based reverse engineering of legacy systems.[3] Knowledge Discovery Metamodel (KDM) is the furthest along of these efforts, and describes information systems in terms of various assets (programs, specifications, data, test files, database schemas, etc.).One of the main aims of the MDA is to separate design from architecture[citation needed]. As the concepts and technologies used to realize designs and the concepts and technologies used to realize architectures have changed at their own pace, decoupling them allows system developers to choose from the best and most fitting in both domains. The design addresses the functional (use case) requirements while architecture provides the infrastructure through which non-functional requirements like scalability, reliability and performance are realized. MDA envisages that the platform independent model (PIM), which represents a conceptual design realizing the functional requirements, will survive changes in realization technologies and software architectures.Of particular importance to model-driven architecture is the notion of model transformation. A specific standard language for model transformation has been defined by OMG called QVT.MDA tools[edit]The OMG organization provides rough specifications rather than implementations, often as answers to Requests for Proposals (RFPs). The OMG documents the overall process in a document called the MDA Guide.Basically, an MDA tool is a tool used to develop, interpret, compare, align, measure, verify, transform, etc. models or metamodels.[4] In the following section model is interpreted as meaning any kind of model (e.g. a UML model) or metamodel (e.g. the CWM metamodel). In any MDA approach we have essentially two kinds of models: initial models are created manually by human agents while derived models are created automatically by programs. For example, an analyst may create a UML initial model from its observation of some loose business situation while a Java model may be automatically derived from this UML model by a Model transformation operation.An MDA tool may be one or more of the following types[citation needed]:\nCreation Tool\nA tool used to elicit initial models and/or edit derived models.\nAnalysis Tool\nA tool used to check models for completeness, inconsistencies, or error and warning conditions. Also used to calculate metrics for the model.\nTransformation Tool\nA tool used to transform models into other models or into code and documentation.\nComposition Tool\nA tool used to compose (i.e. to merge according to a given composition semantics) several source models, preferably conforming to the same metamodel.\nTest Tool\nA tool used to test models as described in Model-based testing.\nSimulation Tool\nA tool used to simulate the execution of a system represented by a given model. This is related to the subject of model execution.\nMetadata Management Tool\nA tool intended to handle the general relations between different models, including the metadata on each model (e.g. author, date of creation or modification, method of creation (which tool? which transformation? etc.)) and the mutual relations between these models (i.e. one metamodel is a version of another one, one model has been derived from another one by a transformation, etc.)\nReverse Engineering Tool\nA tool intended to transform particular legacy or information artifact portfolios into full-fledged models.\nSome tools perform more than one of the functions listed above. For example, some creation tools may also have transformation and test capabilities. There are other tools that are solely for creation, solely for graphical presentation, solely for transformation, etc.One of the characteristics of MDA tools is that they mainly take models (e.g. MOF models or metamodels) as input and generate models as output[citation needed]. In some cases however the parameters may be taken outside the MDA space like in model to text or text to model transformation tools.Implementations of the OMG specifications come from private companies or open source groups. One important source of implementations for OMG specifications is the Eclipse Foundation (EF). Many implementations of OMG modeling standards may be found in the Eclipse Modeling Framework (EMF) or Graphical Modeling Framework (GMF), the Eclipse foundation is also developing other tools of various profiles as GMT. Eclipse's compliance to OMG specifications is often not strict. This is true for example for OMG's EMOF standard, which Eclipse approximates with its ECORE implementation. More examples may be found in the M2M project implementing the QVT standard or in the M2T project implementing the MOF2Text standard.One should be careful not to confuse the List of MDA Tools and the List of UML tools, the former being much broader. This distinction can be made more general by distinguishing 'variable metamodel tools' and 'fixed metamodel tools'. A UML CASE tool is typically a 'fixed metamodel tool' since it has been hard-wired to work only with a given version of the UML metamodel (e.g. UML 2.1). On the contrary, other tools have internal generic capabilities allowing them to adapt to arbitrary metamodels or to a particular kind of metamodels.Usually MDA tools focus rudimentary architecture specification, although in some cases the tools are architecture-independent (or platform independent).Simple examples of architecture specifications include:\nSelecting one of a number of supported reference architectures like Java EE or Microsoft .NET,\nSpecifying the architecture at a finer level including the choice of presentation layer technology, business logic layer technology, persistence technology and persistence mapping technology (e.g. object-relational mapper).\nMetadata: information about data.\nMDA concerns[edit]Some key concepts that underpin the MDA approach (launched in 2001) were first elucidated by the Shlaer-Mellor method during the late 1980s. Indeed, a key absent technical standard of the MDA approach (that of an action language syntax for Executable UML) has been bridged by some vendors by adapting the original Shlaer-Mellor Action Language (modified for UML)[citation needed]. However, during this period the MDA approach has not gained mainstream industry acceptance; with the Gartner Group still identifying MDA as an on the rise technology in its 2006 Hype Cycle,[5] and Forrester Research declaring MDA to be D.O.A. in 2006.[6] Potential concerns that have been raised with the OMG MDA approach include:\nIncomplete Standards: The MDA approach is underpinned by a variety of technical standards, some of which are yet to be specified (e.g. an action semantic language for xtUML), or are yet to be implemented in a standard manner (e.g. a QVT transformation engine or a PIM with a virtual execution environment).[7][8]\nVendor Lock-in: Although MDA was conceived as an approach for achieving (technical) platform independence, current MDA vendors have been reluctant to engineer their MDA toolsets to be interoperable. Such an outcome could result in vendor lock-in for those pursuing an MDA approach.[citation needed]\nIdealistic: MDA is conceived as a forward engineering approach in which models that incorporate Action Language programming are transformed into implementation artifacts (e.g. executable code, database schema) in one direction via a fully or partially automated generation step. This aligns with OMG's vision that MDA should allow modelling of a problem domain's full complexity in UML (and related standards) with subsequent transformation to a complete (executable) application.[9] This approach does, however, imply that changes to implementation artifacts (e.g. database schema tuning) are not supported . This constitutes a problem in situations where such post-transformation adapting of implementation artifacts is seen to be necessary. Evidence that the full MDA approach may be too idealistic for some real world deployments has been seen in the rise of so-called pragmatic MDA.[10] Pragmatic MDA blends the literal standards from OMG's MDA with more traditional model driven mechanisms such as round-trip engineering that provides support for adapting implementation artifacts.\nSpecialised Skillsets: Practitioners of MDA based software engineering are (as with other toolsets) required to have a high level of expertise in their field. Current expert MDA practitioners (often referred to as Modeller/Architects) are scarce relative to the availability of traditional developers.[11]\nOMG Track Record: The OMG consortium who sponsor the MDA approach (and own the MDA trademark) also introduced and sponsored the CORBA standard which itself failed to materialise as a widely utilised standard.[12]\nUncertain Value Proposition (UVP): As discussed, the vision of MDA allows for the specification of a system as an abstract model, which may be realized as a concrete implementation (program) for a particular computing platform (e.g. .NET). Thus an application that has been successfully developed via a pure MDA approach could theoretically be ported to a newer release .NET platform (or even a Java platform) in a deterministic manner \u2013 although significant questions remain as to real-world practicalities during translation (such as user interface implementation). Whether this capability represents a significant value proposition remains a question for particular adopters. Regardless, adopters of MDA who are seeking value via an alternative to programming should be very careful when assessing this approach. The complexity of any given problem domain will always remain, and the programming of business logic needs to be undertaken in MDA as with any other approach. The difference with MDA is that the programming language used (e.g. xtUML) is more abstract (than, say, Java or C#) and exists interwoven with traditional UML artifacts (e.g. class diagrams). Whether programming in a language that is more abstract than mainstream 3GL languages will result in systems of better quality, cheaper cost or faster delivery, is a question that has yet to be adequately answered.\nMDA was recognized as a possible way to bring various independently developed standardized solutions together. For the simulation community, it was recommended as a business and industry based alternative to yet another US DoD mandated standard.[13]\nConferences[edit]Among the various conferences on this topic we may mention ECMDA, the European Conference on MDA and also MoDELS, former firmed as <<UML>> conference series (till 2004), the Italian Forum on MDA in collaboration with the OMG. There are also several conferences and workshops (at OOPSLA, ECOOP mainly) focusing on more specific aspects of MDA like model transformation, model composition, and generation.Code generation controversy[edit]Code generation means that the user abstractly models solutions, which are connoted by some model data, and then an automated tool derives from the models parts or all of the source code for the software system. In some tools, the user can provide a skeleton of the program source code, in the form of a source code template where predefined tokens are then replaced with program source code parts during the code generation process.An often cited criticism is that the UML diagrams just lack the detail which is needed to contain the same information as is covered with the program source. Some developers even claim that the Code is the design.[14][15]See also[edit]References[edit]Further reading[edit]\nKevin Lano. Model-Driven Software Development With UML and Java. CENGAGE Learning, ISBN 978-1-84480-952-3\nDavid S. Frankel. Model Driven Architecture: Applying MDA to Enterprise Computing. John Wiley & Sons, ISBN 0-471-31920-1\nMeghan Kiffer The MDA Journal: Model Driven Architecture Straight From The Masters. ISBN 0-929652-25-8\nAnneke Kleppe (2003). MDA Explained, The Model Driven Architecture: Practice and Promise. Addison-Wesley. ISBN 0-321-19442-X\nStephen J. Mellor (2004). MDA Distilled, Principles of Model Driven Architecture. Addison-Wesley Professional. ISBN 0-201-78891-8\nChris Raistrick. Model Driven Architecture With Executable UML. Cambridge University Press, ISBN 0-521-53771-1\nMarco Brambilla, Jordi Cabot, Manuel Wimmer, Model Driven Software Engineering in Practice, foreword by Richard Soley (OMG Chairman), Morgan & Claypool, USA, 2012, Synthesis Lectures on Software Engineering #1. 182 pages. ISBN 9781608458820 (paperback), ISBN 9781608458837 (ebook). http://www.mdse-book.com\nStanley J. Sewall. Executive Justification for MDA\nSoylu A., De Causmaecker Patrick. Merging model driven and ontology driven system development approaches pervasive computing perspective, in Proc 24th Intl Symposium on Computer and Information Sciences. 2009, pp 730\u2013735.\nExternal links[edit]\nOMG's MDA Web site\nModel-Driven Software Development Course, B. Tekinerdogan, Bilkent University\n", "subtitles": ["Overview", "Model-driven architecture topics", "Conferences", "Code generation controversy", "See also", "References", "Further reading", "External links"], "title": "Model-driven architecture"},
{"content": "Language-oriented programming (LOP) is a style of computer programming in which, rather than solving problems in general-purpose programming languages, the programmer creates one or more domain-specific languages for the problem first, and solves the problem in those languages. This concept is described in detail in the paper by Martin Ward entitled Language Oriented Programming,[1] published in Software - Concepts and Tools, Vol.15, No.4, pp 147-161, 1994.[2]Concept[edit]The concept of language-oriented programming takes the approach to capture requirements in the user's terms, and then to try to create an implementation language as isomorphic as possible to the user's descriptions, so that the mapping between requirements and implementation is as direct as possible. A measure of the closeness of this isomorphism is the redundancy of the language, defined as the number of editing operations needed to implement a stand-alone change in requirements. It is not assumed a-priori what is the best language for implementing the new language. Rather, the developer can choose among options created by analysis of the information flows \u2014 what information is acquired, what its structure is, when it is acquired, from whom, and what is done with it.[3]See also[edit]\nGrammar-oriented programming\nDialecting\nDomain-specific language\nExtensible programming\nHomoiconicity\nReferences[edit]External links[edit]\nLanguage Oriented Programming Martin Ward's original paper that coined the term.\nLanguage Oriented Programming: The Next Programming Paradigm Sergey Dmitriev's paper that further explored the topic.\nLanguage Workbenches: The Killer-App for Domain Specific Languages? Martin Fowler's article describing both the concept and tools that support it.\nA Programmable Programming Language By Matthias Felleisen, Robert Bruce Findler, Matthew Flatt, Shriram Krishnamurthi, Eli Barzilay, Jay McCarthy, Sam Tobin-Hochstadt, Communications of the ACM, Vol. 61 No. 3, Pages 62-71.\n", "subtitles": ["Concept", "See also", "References", "External links"], "title": "Language-oriented programming"},
{"content": "A domain-specific language (DSL) is a computer language specialized to a particular application domain. This is in contrast to a general-purpose language (GPL), which is broadly applicable across domains. There is a wide variety of DSLs, ranging from widely used languages for common domains, such as HTML for web pages, down to languages used by only one or a few pieces of software, such as Emacs Lisp for GNU Emacs and XEmacs. DSLs can be further subdivided by the kind of language, and include domain-specific markup languages, domain-specific modeling languages (more generally, specification languages), and domain-specific programming languages. Special-purpose computer languages have always existed in the computer age, but the term domain-specific language has become more popular due to the rise of domain-specific modeling. Simpler DSLs, particularly ones used by a single application, are sometimes informally called mini-languages.The line between general-purpose languages and domain-specific languages is not always sharp, as a language may have specialized features for a particular domain but be applicable more broadly, or conversely may in principle be capable of broad application but in practice used primarily for a specific domain. For example, Perl was originally developed as a text-processing and glue language, for the same domain as AWK and shell scripts, but was mostly used as a general-purpose programming language later on. By contrast, PostScript is a Turing complete language, and in principle can be used for any task, but in practice is narrowly used as a page description language.Use[edit]The design and use of appropriate DSLs is a key part of domain engineering, by using a language suitable to the domain at hand \u2013 this may consist of using an existing DSL or GPL, or developing a new DSL. Language-oriented programming considers the creation of special-purpose languages for expressing problems as standard part of the problem solving process. Creating a domain-specific language (with software to support it), rather than reusing an existing language, can be worthwhile if the language allows a particular type of problem or solution to be expressed more clearly than an existing language would allow and the type of problem in question reappears sufficiently often. Pragmatically, a DSL may be specialized to a particular problem domain, a particular problem representation technique, a particular solution technique, or other aspect of a domain.Overview[edit]A domain-specific language is created specifically to solve problems in a particular domain and is not intended to be able to solve problems outside it (although that may be technically possible). In contrast, general-purpose languages are created to solve problems in many domains. The domain can also be a business area. Some examples of business areas include:\ndomain-specific language for life insurance policies developed internally in large insurance enterprise\ndomain-specific language for combat simulation\ndomain-specific language for salary calculation\ndomain-specific language for billing\nA domain-specific language is somewhere between a tiny programming language and a scripting language, and is often used in a way analogous to a programming library. The boundaries between these concepts are quite blurry, much like the boundary between scripting languages and general-purpose languages.In design and implementation[edit]Domain-specific languages are languages (or often, declared syntaxes or grammars) with very specific goals in design and implementation. A domain-specific language can be one of a visual diagramming language, such as those created by the Generic Eclipse Modeling System, programmatic abstractions, such as the Eclipse Modeling Framework, or textual languages. For instance, the command line utility grep has a regular expression syntax which matches patterns in lines of text. The sed utility defines a syntax for matching and replacing regular expressions. Often, these tiny languages can be used together inside a shell to perform more complex programming tasks.The line between domain-specific languages and scripting languages is somewhat blurred, but domain-specific languages often lack low-level functions for filesystem access, interprocess control, and other functions that characterize full-featured programming languages, scripting or otherwise. Many domain-specific languages do not compile to byte-code or executable code, but to various kinds of media objects: GraphViz exports to PostScript, GIF, JPEG, etc., where Csound compiles to audio files, and a ray-tracing domain- specific language like POV compiles to graphics files. A computer language like SQL presents an interesting case: it can be deemed a domain-specific language because it is specific to a specific domain (in SQL's case, accessing and managing relational databases), and is often called from another application, but SQL has more keywords and functions than many scripting languages, and is often thought of as a language in its own right, perhaps because of the prevalence of database manipulation in programming and the amount of mastery required to be an expert in the language.Further blurring this line, many domain-specific languages have exposed APIs, and can be accessed from other programming languages without breaking the flow of execution or calling a separate process, and can thus operate as programming libraries.Programming tools[edit]Some domain-specific languages expand over time to include full-featured programming tools, which further complicates the question of whether a language is domain-specific or not. A good example is the functional language XSLT, specifically designed for transforming one XML graph into another, which has been extended since its inception to allow (particularly in its 2.0 version) for various forms of filesystem interaction, string and date manipulation, and data typing.In model-driven engineering, many examples of domain-specific languages may be found like OCL, a language for decorating models with assertions or QVT, a domain-specific transformation language. However languages like UML are typically general purpose modeling languages.To summarize, an analogy might be useful: a Very Little Language is like a knife, which can be used in thousands of different ways, from cutting food to cutting down trees. A domain-specific language is like an electric drill: it is a powerful tool with a wide variety of uses, but a specific context, namely, putting holes in things. A General Purpose Language is a complete workbench, with a variety of tools intended for performing a variety of tasks. Domain-specific languages should be used by programmers who, looking at their current workbench, realize they need a better drill, and find that a particular domain-specific language provides exactly that.Domain-specific language topics[edit]Usage patterns[edit]There are several usage patterns for domain-specific languages:[1][2]\nprocessing with standalone tools, invoked via direct user operation, often on the command line or from a Makefile (e.g., grep for regular expression matching, sed, lex, yacc, the GraphViz tool set, etc.)\ndomain-specific languages which are implemented using programming language macro systems, and which are converted or expanded into a host general purpose language at compile-time or read-time\nembedded (or internal) domain-specific languages, implemented as libraries which exploit the syntax of their host general purpose language or a subset thereof, while adding domain-specific language elements (data types, routines, methods, macros etc.). (e.g. Embedded SQL, LINQ)\ndomain-specific languages which are called (at runtime) from programs written in general purpose languages like C or Perl, to perform a specific function, often returning the results of operation to the host programming language for further processing; generally, an interpreter or virtual machine for the domain-specific language is embedded into the host application (e.g. format strings, a regular expression engine)\ndomain-specific languages which are embedded into user applications (e.g., macro languages within spreadsheets) and which are (1) used to execute code that is written by users of the application, (2) dynamically generated by the application, or (3) both.\nMany domain-specific languages can be used in more than one way.[citation needed] DSL code embedded in a host language may have special syntax support, such as regexes in sed, AWK, Perl or JavaScript, or may be passed as strings.Design goals[edit]Adopting a domain-specific language approach to software engineering involves both risks and opportunities. The well-designed domain-specific language manages to find the proper balance between these.Domain-specific languages have important design goals that contrast with those of general-purpose languages:\ndomain-specific languages are less comprehensive.\ndomain-specific languages are much more expressive in their domain.\ndomain-specific languages should exhibit minimal redundancy.\nIdioms[edit]In programming, idioms are methods imposed by programmers to handle common development tasks, e.g.:\nEnsure data is saved before the window is closed.\nEdit code whenever command-line parameters change because they affect program behavior.\nGeneral purpose programming languages rarely support such idioms, but domain-specific languages can describe them, e.g.:\nA script can automatically save data.\nA domain-specific language can parameterize command line input.\nExamples[edit]Examples of domain-specific languages include HTML, Logo for pencil-like drawing, Verilog and VHDL hardware description languages, MATLAB and GNU Octave for matrix programming, Mathematica, Maple and Maxima for symbolic mathematics, Specification and Description Language for reactive and distributed systems, spreadsheet formulas and macros, SQL for relational database queries, YACC grammars for creating parsers, regular expressions for specifying lexers, the Generic Eclipse Modeling System for creating diagramming languages, Csound for sound and music synthesis, and the input languages of GraphViz and GrGen, software packages used for graph layout and graph rewriting.Game Maker Language[edit]The GML scripting language used by GameMaker: Studio is a domain-specific language targeted at novice programmers to easily be able to learn programming. While the language serves as a blend of multiple languages including Delphi, C++, and BASIC, there is a lack of structures, data types, and other features of a full-fledged programming language. Many of the built-in functions are sandboxed for the purpose of easy portability. The language primarily serves to make it easy for anyone to pick up the language and develop a game.Unix shell scripts[edit]Unix shell scripts give a good example of a domain-specific language for data[3] organization. They can manipulate data in files or user input in many different ways. Domain abstractions and notations include streams (such as stdin and stdout) and operations on streams (such as redirection and pipe). These abstractions combine to make a robust language to describe the flow and organization of data.The language consists of a simple interface (a script) for running and controlling processes that perform small tasks. These tasks represent the idioms of organizing data into a desired format such as tables, graphs, charts, etc.These tasks consist of simple control-flow and string manipulation mechanisms that cover a lot of common usages like searching and replacing string in files, or counting occurrences of strings (frequency counting).Even though Unix scripting languages are Turing complete, they differ from general purpose languages.[clarification needed]In practice, scripting languages are used to weave together small Unix tools such as grep, ls, sort or wc.ColdFusion Markup Language[edit]ColdFusion's associated scripting language is another example of a domain-specific language for data-driven websites. This scripting language is used to weave together languages and services such as Java, .NET, C++, SMS, email, email servers, http, ftp, exchange, directory services, and file systems for use in websites.The ColdFusion Markup Language (CFML) includes a set of tags that can be used in ColdFusion pages to interact with data sources, manipulate data, and display output. CFML tag syntax is similar to HTML element syntax.Erlang OTP[edit]The Erlang Open Telecom Platform was originally designed for use inside Ericsson as a domain-specific language. The language itself offers a platform of libraries to create finite state machines, generic servers and event managers that quickly allow an engineer to deploy applications, or support libraries, that have been shown in industry benchmarks to outperform other languages intended for a mixed set of domains, such as C and C++. The language is now officially open source and can be downloaded from their website.FilterMeister[edit]FilterMeister is a programming environment, with a programming language that is based on C, for the specific purpose of creating Photoshop-compatible image processing filter plug-ins; FilterMeister runs as a Photoshop plug-in itself and it can load and execute scripts or compile and export them as independent plug-ins. Although the FilterMeister language reproduces a significant portion of the C language and function library, it contains only those features which can be used within the context of Photoshop plug-ins and adds a number of specific features only useful in this specific domain.MediaWiki templates[edit]The Template feature of MediaWiki is an embedded domain-specific language whose fundamental purpose is to support the creation of page templates and the transclusion (inclusion by reference) of MediaWiki pages into other MediaWiki pages.Software engineering uses[edit]There has been much interest in domain-specific languages to improve the productivity and quality of software engineering. Domain-specific language could possibly provide a robust set of tools for efficient software engineering. Such tools are beginning to make their way into development of critical software systems.The Software Cost Reduction Toolkit[4] is an example of this. The toolkit is a suite of utilities including a specification editor to create a requirements specification, a dependency graph browser to display variable dependencies, a consistency checker to catch missing cases in well-formed formulas in the specification, a model checker and a theorem prover to check program properties against the specification, and an invariant generator that automatically constructs invariants based on the requirements.A newer development is language-oriented programming, an integrated software engineering methodology based mainly on creating, optimizing, and using domain-specific languages.Metacompilers[edit]Complementing language-oriented programming, as well as all other forms of domain-specific languages, are the class of compiler writing tools called metacompilers. A metacompiler is not only useful for generating parsers and code generators for domain-specific languages, but a metacompiler itself compiles a domain-specific metalanguage specifically designed for the domain of metaprogramming.Besides parsing domain-specific languages, metacompilers are useful for generating a wide range of software engineering and analysis tools. The meta-compiler methodology is often found in program transformation systems.Metacompilers that played a significant role in both computer science and the computer industry include Meta-II[5] and its descendent TreeMeta.[6]Unreal Engine before version 4 and other games[edit]Unreal and Unreal Tournament unveiled a language called UnrealScript. This allowed for rapid development of modifications compared to the competitor Quake (using the Id Tech 2 engine). The Id Tech engine used standard C code meaning C had to be learned and properly applied, while UnrealScript was optimized for ease of use and efficiency. Similarly, the development of more recent games introduced their own specific languages, one more common example is Lua for scripting.Rules Engines for Policy Automation[edit]Various Business Rules Engines have been developed for automating policy and business rules used in both government and private industry. ILOG, Oracle Policy Automation, DTRules, Drools and others provide support for DSLs aimed to support various problem domains. DTRules goes so far as to define an interface for the use of multiple DSLs within a Rule Set.The purpose of Business Rules Engines is to define a representation of business logic in as human readable fashion as possible. This allows both subject matter experts and developers to work with and understand the same representation of the business logic. Most Rules Engines provide both an approach to simplifying the control structures for business logic (for example, using Declarative Rules or Decision Tables) coupled with alternatives to programming syntax in favor of DSLs.Statistical modelling languages[edit]Statistical modellers have developed domain-specific languages such as Bugs, Jags, and Stan. These languages provide a syntax for describing a Bayesian model, and generate a method for solving it using simulation.Generate model and services to multiple programming Languages[edit]Generate object handling and services based on a Interface Description Language for a domain-specific language such as JavaScript for web applications, HTML for documentation, C++ for high performance code, etc. This is done by cross language frameworks such as Apache Thrift or Google Protocol Buffers.Gherkin[edit]Gherkin is a language designed to define test cases to check the behaviour of software, without specifying how that behaviour is implemented. It is meant to be read and used by non-technical users using a natural language syntax and a line-oriented design. The tests defined with Gherkin must then be implemented in a general programming language. Then, the steps in a Gherkin program acts as a syntax for method invocation accessible to non-developers.Other examples[edit]Other prominent examples of domain-specific languages include:\nTest DSL\nEmacs Lisp\nGame Description Language\nOpenGL Shading Language\nGradle\nAdvantages and disadvantages[edit]Some of the advantages:[1][2]\nDomain-specific languages allow solutions to be expressed in the idiom and at the level of abstraction of the problem domain. The idea is that domain experts themselves may understand, validate, modify, and often even develop domain-specific language programs. However, this is seldom the case.[7]\nDomain-specific languages allow validation at the domain level. As long as the language constructs are safe any sentence written with them can be considered safe.[citation needed]\nDomain-specific languages can help to shift the development of business information systems from traditional software developers to the typically larger group of domain-experts who (despite having less technical expertise) have deeper knowledge of the domain.[8]\nDomain-specific languages are easier to learn, given their limited scope.\nSome of the disadvantages:\nCost of learning a new language vs. its limited applicability\nCost of designing, implementing, and maintaining a domain-specific language as well as the tools required to develop with it (IDE)\nFinding, setting, and maintaining proper scope.\nDifficulty of balancing trade-offs between domain-specificity and general-purpose programming language constructs.\nPotential loss of processor efficiency compared with hand-coded software.\nProliferation of similar non-standard domain-specific languages, for example, a DSL used within one insurance company versus a DSL used within another insurance company.[9]\nNon-technical domain experts can find it hard to write or modify DSL programs by themselves.[7]\nIncreased difficulty of integrating the DSL with other components of the IT system (as compared to integrating with a general-purpose language).\nLow supply of experts in a particular DSL tends to raise labor costs.\nHarder to find code examples.\nTools for designing domain-specific languages[edit]\nJetBrains MPS is a tool for designing domain-specific languages. It uses projectional editing which allows overcoming the limits of language parsers, and building DSL editors, such as ones with tables and diagrams. It implements language-oriented programming. MPS combines an environment for language definition, a language workbench, and an Integrated Development Environment (IDE) for such languages.[10]\n\nXtext is an open-source software framework for developing programming languages and domain-specific languages (DSLs). Unlike standard parser generators, Xtext generates not only a parser, but also a class model for the abstract syntax tree. In addition, it provides a fully featured, customizable Eclipse-based IDE.[11]\nSee also[edit]\nArchitecture description language\nDomain-specific entertainment language\nMetalinguistic abstraction\nProgramming domain\nReferences[edit]Further reading[edit]\nDunlavey, Building Better Applications: a Theory of Efficient Software Development International Thomson Publishing ISBN 0-442-01740-5, 1994.\nConstance Heitmeyer. Using the SCR Toolset to Specify Software Requirements. Proceedings, Second IEEE Workshop on Industrial Strength Formal Specification Techniques, Boca Raton, FL, Oct. 19, 1998.\nMarjan Mernik, Jan Heering, and Anthony M. Sloane. When and how to develop domain-specific languages. ACM Computing Surveys, 37(4):316\u2013344, 2005. doi:10.1145/1118890.1118892\nDiomidis Spinellis. Notable design patterns for domain specific languages. Journal of Systems and Software, 56(1):91\u201399, February 2001. doi:10.1016/S0164-1212(00)00089-3\nTerence Parr. The Definitive ANTLR Reference: Building Domain-Specific Languages. ISBN 978-0-9787392-5-6\nJames Larus. Spending Moore's Dividend. ISSN 0001-0782. Communications of the ACM. Volume 52, Issue 5 (May 2009).\nWerner Schuster (June 15, 2007). What's a Ruby DSL and what isn't?. C4Media. Retrieved 2009-09-08. \nMartin Fowler. Domain Specific Languages. ISBN 978-0-321-71294-3\nMarco Brambilla, Jordi Cabot, Manuel Wimmer, Model Driven Software Engineering in Practice, foreword by Richard Soley (OMG Chairman), Morgan & Claypool, USA, 2012, Synthesis Lectures on Software Engineering #1. 182 pages. ISBN paperback: 9781608458820, ISBN 9781608458837. http://www.mdse-book.com\nExternal links[edit]\nMinilanguages, The Art of Unix Programming, by Eric S. Raymond\nMartin Fowler on domain-specific languages and Language Workbenches. Also in a video presentation\nDomain-Specific Languages: An Annotated Bibliography\nOne Day Compilers: Building a small domain-specific language using OCaml\nUsenix Association: Conference on Domain-Specific Languages (DSL '97) and 2nd Conference on Domain-Specific Languages (DSL '99)\nInternal Domain-Specific Languages\nThe complete guide to (external) Domain Specific Languages\njEQN example of internal Domain-Specific Language for the Modeling and Simulation of Extended Queueing Networks.\n\nArticles\n\nExternal DSLs with Eclipse technology\nBuilding Domain-Specific Languages over a Language Framework. CiteSeerX 10.1.1.50.4685 . \nUsing Acceleo with GMF : Generating presentations from a MindMap DSL modeler\nUML vs. Domain-Specific Languages\nSagar Sen; et al. Meta-model Pruning. CiteSeerX 10.1.1.156.6008 . \n", "subtitles": ["Use", "Overview", "Domain-specific language topics", "Examples", "Advantages and disadvantages", "Tools for designing domain-specific languages", "See also", "References", "Further reading", "External links"], "title": "Domain-specific language"},
{"content": "Communication noise refers to influences on effective communication that influence the interpretation of conversations. While often looked over, communication noise can have a profound impact both on our perception of interactions with others and our analysis of our own communication proficiency.Forms of communication noise include psychological noise, physical noise, physiological and semantic noise. All these forms of noise subtly, yet greatly influence our communication with others and are vitally important to anyone\u2019s skills as a competent communicator.Psychological noise[edit]Psychological noise results from preconceived notions we bring to conversations, such as racial stereotypes, reputations, biases, and assumptions. When we come into a conversation with ideas about what the other person is going to say and why, we can easily become blinded to their original message. Most of the time psychological noise is impossible to free ourselves from, and we must simply strive to recognize that it exists and take those distractions into account when we converse with others.Environmental Noise[edit]Environmental noise is the summary of noise pollution from outside, caused by transport, industrial and recreational activities.Physical noise[edit]Physical noise is any external or environmental stimulus that distracts us from receiving the intended message sent by a communicator (Rothwell 11). Examples of physical noise include: others talking in the background, background music, a startling noise and acknowledging someone outside of the conversation.Semantic noise[edit]This is noise caused by the sender. i.e., the encoder. This type of noise occurs when grammar or technical language is used that the receiver (the decoder) cannot understand, or cannot understand it clearly. It occurs when the sender of the message uses a word or a phrase that we don't know the meaning of, or which we use in a different way from the speakers. This is usually due to the result that the encoder had failed to practice audience analysis at first. The type of audience is the one that determine the jargon one will use.References[edit]\nRothwell,Dan J. In the Company of Others: An Introduction to Communication. New York: McGraw Hill, 2004\n", "subtitles": ["Psychological noise", "Environmental Noise", "Physical noise", "Semantic noise", "References"], "title": "Communication noise"},
{"content": "XL stands for eXtensible Language. It is the first and so far the only computer programming language designed to support concept programming.[1]XL features programmer-reconfigurable syntax and semantics. Compiler plug-ins can be used to add new features to the language. A base set of plug-ins implements a relatively standard imperative language. Programmers can write their own plug-ins to implement application-specific notations, such as symbolic differentiation, which can then be used as readily as built-in language features.Language[edit]XL is defined at four different levels:\nXL0 defines how an input text is transformed into a parse tree.\nXL1 defines a base language with features comparable to C++.\nXL2 defines the standard library, which includes common data types and operators.\nXLR defines a dynamic runtime for XL based on XL0.\nXL has no primitive types nor keywords. All useful operators and data types, like integers or addition, are defined in the standard library (XL2). XL1 is portable between different execution environments. There is no such guarantee for XL2: if a particular CPU does not implement floating-point multiplication, the corresponding operator definition may be missing from the standard library, and using a floating-point multiply may result in a compile-time error.The Hello World program in XL looks like the following:\n use XL.TEXT_IO\n WriteLn Hello World\nAn alternative form in a style more suitable for large-scale programs would be:\n import IO = XL.TEXT_IO\n IO.WriteLn Hello World\nA recursive implementation of factorial in XLR looks like the following:\n 0! -> 1\n N! -> N * (N-1)!\nSyntax[edit]Syntax is defined at the XL0 level. The XL0 phase of the compiler can be configured using a syntax description file, where properties like the text representation and precedence of operators are defined. A basic syntax file defines common mathematical notations, like + for addition, with the usually accepted order of operations.The parse tree consists of 7 node types, 4 leaf node types (integer, real, text and symbol) and 3 internal node types (infix, prefix and block).\ninteger nodes represent an integer literal, such as 2. The # sign can be used to specify a base other than 10, as in (2#1001). A separating underscore can be used to improve readability, as in 1_000_000.\nreal nodes represent non-integral numbers, such as 2.5. Based-notations and separators can be used, as for integer nodes, for example 16#F.FFF#E-10 is a valid real literal.\ntext nodes represent textual contents. They are normally surrounded by simple or double quotes, like Hello or 'a', but the syntax file can be used to add other separators, including for multi-line textual contents.\nsymbol nodes represent names or operators. Names are sequence of alphanumeric characters beginning with a letter, like Hello. XL0 preserves case, but XL1 ignores case and underscores, so that JohnDoe and john_doe are the same name. Operators are sequences of non-alphanumeric characters, like * or =/=.\ninfix nodes represent two nodes related by an infix symbol, like A+1 or 2 and 3. Infix nodes are in particular used to separate lines, with an infix new-line symbol.\nprefix nodes represent two consecutive nodes, like Write Hello. It is also used for postfix notations, like 3! or Open?.\nblock nodes represent a node surrounded by grouping symbols, like (A), [Index]. Indentation is internally represented by a block node.\nWith the default syntax file, the following is valid XL0, irrespective of any semantics.\nA = B + Hello\nIt parses as:\ninfix(=,\n      symbol(A),\n      infix(+,\n            symbol(B), text(Hello)))\nSemantics of XL1[edit]The XL1 phase is defined as a sequence of operations on the XL0 parse tree. These operations are provided by various compiler plug-ins, that are triggered based on the shape of the parse tree.Special constructs, translate and translation, are provided by a plug-in designed to facilitate the writing of other plug-ins. The quote construct generates a parse tree. Here is how these notations can be used to implement a plug-in called ZeroRemoval that eliminates superfluous additions and multiplications by zero.\ntranslation ZeroRemoval\n  when\n    'X' + 0\n  then\n    return X\n  when\n    'X' * 0\n  then\n    return parse_tree(0)\nA plug-in can be invoked on a whole file from the command line, or more locally in the source code using the pragma notation, as follows:\nX := {Differentiate} d(sin(omega * T) * exp(-T/T0)) / dT\nThe XL1 phase contains a large set of plug-ins, notably XLSemantics, that provide common abstractions like subroutine, data type and variable declaration and definition, as well as basic structured programming statements, like conditionals or loops.Type system[edit]XL1 type checking is static, with generic programming abilities that are beyond those of languages like Ada or C++. Types like arrays or pointers, which are primitive in languages like C++, are declared in the library in XL. For instance, a one-dimensional array type could be defined as follows:\ngeneric [Item : type; Size : integer] type array\nA validated generic type is a generic type where a condition indicates how the type can be used. Such types need not have generic parameters. For instance, one can declare that a type is ordered if it has a less-than operator as follows:\n// A type is ordered if it has a less-than relationship\ngeneric type ordered if\n  A, B : ordered\n  Test : boolean := A < B\nIt is then possible to declare a function that is implicitly generic because the type ordered itself is generic.\n// Generic function for the minimum of one item\nfunction Min(X : ordered) return ordered is\n  ... compute Y of type ordered ... \n  return Y\nThis also applies to generic types that have parameters, such as array. A function computing the sum of the elements in any array can be written as follows:\nfunction Sum(A : array) return array.Item is\n  for I in 0..array.Size-1 loop\n    result += A[I]\nType-safe variable argument lists[edit]Functions can be overloaded. A function can be declared to use a variable number of arguments by using ... in the parameter list (historically, the keyword other was used for that purpose). In such a function, ... can be used to pass the variable number of arguments to another subroutine, a feature now called Variadic templates:\n// Generic function for the minimum of N item\nfunction Min(X : ordered; ...) return ordered is\n  result := Min(...)\n  if X < result then\n    result := X\nWhen such a function is called, the compiler recursively instantiates functions to match the parameter list:\n// Examples of use of the Min just declared\nX : real := Min(1.3, 2.56, 7.21)\nY : integer := Min(1, 3, 6, 7, 1, 2)\nExpression reduction: operator overloading[edit]Operators can be defined using the written form of function declarations. Below is the code that would declare the addition of integers:\nfunction Add(X, Y: integer) return integer written X+Y\nSuch written forms can have more than two parameters. For instance, a matrix linear transform can be written as:\nfunction Linear(A, B, C : matrix) return matrix written A+B*C\nA written form can use constants, and such a form is more specialized than a form without constants. For example:\nfunction Equal(A, B : matrix) return boolean written A=B\nfunction IsNull(A : matrix) return boolean written A=0\nfunction IsUnity(A : matrix) return boolean written A=1\nThe mechanism is used to implement all basic operators. An expression is progressively reduced to function calls using written forms. For that reason, the mechanism is referred to as expression reduction rather than operator overloading.Iterators[edit]XL iterators allow programmers to implement both generators and iterators.\nimport IO = XL.UI.CONSOLE\n\niterator IntegerIterator (var out Counter : integer; Low, High : integer) written Counter in Low..High is\n    Counter := Low\n    while Counter <= High loop\n        yield\n        Counter += 1\n\n// Note that I needs not be declared, because declared 'var out' in the iterator\n// An implicit declaration of I as an integer is therefore made here\nfor I in 1..5 loop\n    IO.WriteLn I=, I\nDevelopment status and history[edit]XL is the result of a long language design work that began around 1992. The language was designed and implemented primarily by Christophe de Dinechin.Historically, the XL compiler was written in C++. It had achieved a point where most of the features described above worked correctly, but writing plug-ins was a nightmare, because C++ itself is not extensible, so implementing translate-like statements was impossible. The parse tree was more complicated, with dozens of node types, because it was designed for cross-language support. Moka was a Java-to-Java extensible compiler using the same infrastructure.Abandoning the cross-language objectives and complex parse-tree structure, a complete rewrite of the compiler was started in 2003. The parse tree was vastly simplified down to the seven XL0 nodes types now in use. This new compiler bootstrapped in 2004, and all new development is now written in XL. However, this new compiler still has somewhat incomplete XL1 support, although its abilities already exceed C++ in a few areas.Ancestry[edit]XL1 was inspired by a large number of other languages. In alphabetical order:\nAda inspired some of large-scale program support, exception handling, tasking, and supportability aspects.\nBASIC the more modern variants that dispense of line numbers and support structured programming, showed how simple the syntax of a programming language could be.\nC was used as the standard to expect in terms of runtime and machine-level support. XL will not require a virtual machine to run.\nC++ and the standard template library demonstrated the need for good support of generic types, including implicit instantiation of generics (which Ada lacks).\nFortran's continued performance lead over C and C++ for numerical-intensive applications helped identify which language constructs would prevent useful optimizations.\nJava demonstrated the importance of a large, portable support library. Java containers also showed the limitations of an approach not based on generic programming. Interfacing with Java code remains an interesting challenge for XL.\nLisp extensibility was considered as a key factor in its survival and relevance to this day. Lisp was the first language to normalize object-oriented features, despite having been designed years before object-oriented ideas were invented.\nProlog demonstrated that alternative programming models are sometimes useful and highly productive. Every effort was made to ensure that a Prolog-style plug-in could be written for XL.\nVisual Basic showed how the parse tree representation can be dissociated from its visual presentation. Few people edit VB Forms textually. It is expected that XL edit-time plug-ins will one day provide similar abilities, by directly manipulating the parse tree.\nSemantics[edit]XLR is a dynamic language, originally intended as a back-end for the XL1 compiler, hence the name, which stands for XL runtime. It shares the basic XL0 syntax with XL1, but its behavior is much closer to a functional language, whereas XL1 is intended to look mostly like an imperative language. XLR has practically only one built-in operator, ->, which denotes a rewrite. The notation on the left of the rewrite is transformed into the notation on the right of the rewrite.This mechanism is used to implement standard notations:\n if true then TrueBody else FalseBody -> TrueBody\n if false then TrueBody else FalseBody -> FalseBody\nThe XL Programming Language uses a programming approach focusing on how concepts, that live in the programmer's mind, translate into representations that are found in the code space.Pseudo-metrics[edit]Concept programming uses pseudo-metrics to evaluate the quality of code. They are called pseudo-metrics because they relate the concept space and the code space, with a clear understanding that the concept space cannot be formalized strictly enough for a real metric to be defined. Concept programming pseudo-metrics include:\nSyntactic noise measures discrepancies between the concept and the syntax used to represent it. For instance, the semi-colon at the end of statements in C can be considered as syntactic noise, because it has no equivalent in the concept space.\nSemantic noise measures discrepancies between the expected meaning or behavior of the concept and its actual meaning or behavior in the code. For instance, the fact that integer data types overflow (when mathematical integers do not) is a form of semantic noise.\nBandwidth measures how much of the concept space a given code construct can represent. For instance, the overloaded addition operator in C has higher bandwidth than the Add instruction in assembly language, because the C operator can represent addition on floating-point numbers and not just integer numbers.\nSignal/noise ratio measures what fraction of the code space is used for representing actual concepts, as opposed to implementation information.\nRule of equivalence, equivalence breakdown[edit]The rule of equivalence is verified when the code behavior matches the original concept. This equivalence may break down in many cases. Integer overflow breaks the equivalence between the mathematical integer concept and the computerized approximation of the concept.Many ways to break the equivalence have been given specific names, because they are very common:\nA domain error is a condition where code executes outside of the domain of equivalence, which is the domain where the concept and the implementation match. An integer overflow is an example of domain error.\nA concept cast (also concept recast or concept recasting) is a rewrite of a concept as a different concept because the original concept cannot be represented by the tools. In C, using pointers for output arguments because C doesn't support output arguments explicitly is an example of concept cast.\nA priority inversion is a form of syntactic or semantic noise introduced by some language-enforced general rule. It is called a priority inversion because the language takes precedence over the concept. In Smalltalk, everything is an object, and that rule leads to the undesirable consequence that an expression like 2+3*5 doesn't obey the usual order of operations (Smalltalk interprets this as sending the message * to the number resulting from 2+3, which yields result 25 instead of 17).\nMethodology[edit]To write code, concept programming recommends the following steps:\nIdentify and define the relevant concepts in the concept space.\nIdentify traditional notations for the concepts, or invent usable notations.\nIdentify a combination of programming constructs that allows the concepts to be represented comfortably in code - That includes finding a code notation that matches the notation identified in the previous step as closely as possible.\nWrite code that preserves, as much as possible, the expected behavior and semantics of the relevant aspects of the original concept.\nMany programming tools often lack in notational abilities, thus concept programming sometimes requires the use of preprocessors, domain-specific languages, or metaprogramming techniques.Languages[edit]XL is the only programming language known to date to be explicitly created for concept programming, but concept programming can be done in nearly any language, with varying degrees of success. Lisp and Forth (and their derivatives) are examples of pre-existing languages which lend themselves well to concept programming.[citation needed]Similar works[edit]There are projects that exploit similar ideas to create code with higher level of abstraction. Among them are:\nIntentional Programming\nLanguage-oriented programming\nLiterate programming\nModel-driven architecture\nReferences[edit]External links[edit]\nOfficial website\nThe historical development site\nCoverage on XL and Concept programming at The Register\nSlides presenting XL and Concept Programming\n", "subtitles": ["Language", "Syntax", "Semantics of XL1", "Development status and history", "Semantics", "Pseudo-metrics", "Rule of equivalence, equivalence breakdown", "Methodology", "Languages", "Similar works", "References", "External links"], "title": "XL (programming language)"},
{"content": "Literate programming is a programming paradigm introduced by Donald Knuth in which a program is given as an explanation of the program logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which a compilable source code can be generated.[1]The literate programming paradigm, as conceived by Knuth, represents a move away from writing programs in the manner and order imposed by the computer, and instead enables programmers to develop programs in the order demanded by the logic and flow of their thoughts.[2] Literate programs are written as an uninterrupted exposition of logic in an ordinary human language, much like the text of an essay, in which macros are included to hide abstractions and traditional source code.Literate programming (LP) tools are used to obtain two representations from a literate source file: one suitable for further compilation or execution by a computer, the tangled code, and another for viewing as formatted documentation, which is said to be woven from the literate source.[3] While the first generation of literate programming tools were computer language-specific, the later ones are language-agnostic and exist above the programming languages.History and philosophy[edit]Literate programming was first introduced by Donald E. Knuth. The main intention behind this approach was to treat program as a literature understandable to human beings. This approach was implemented at Stanford university as a part of research on algorithms and digital typography. This implementation was further called as \u201cWEB\u201d by Donald Knuth since he believed that it was one of the few three-letter words of English that hadn\u2019t already been applied to computer. However, it correctly resembles the complicated nature of software delicately pieced together from simple materials.[1]Concept[edit]Literate programming is writing out the program logic in a human language with included (separated by a primitive markup) code snippets and macros. Macros in a literate source file are simply title-like or explanatory phrases in a human language that describe human abstractions created while solving the programming problem, and hiding chunks of code or lower-level macros. These macros are similar to the algorithms in pseudocode typically used in teaching computer science. These arbitrary explanatory phrases become precise new operators, created on the fly by the programmer, forming a meta-language on top of the underlying programming language.A preprocessor is used to substitute arbitrary hierarchies, or rather interconnected 'webs' of macros,[4] to produce the compilable source code with one command (tangle), and documentation with another (weave). The preprocessor also provides an ability to write out the content of the macros and to add to already created macros in any place in the text of the literate program source file, thereby disposing of the need to keep in mind the restrictions imposed by traditional programming languages or to interrupt the flow of thought.Advantages[edit]According to Knuth,[5][6] literate programming provides higher-quality programs, since it forces programmers to explicitly state the thoughts behind the program, making poorly thought-out design decisions more obvious. Knuth also claims that literate programming provides a first-rate documentation system, which is not an add-on, but is grown naturally in the process of exposition of one's thoughts during a program's creation.[7] The resulting documentation allows the author to restart his own thought processes at any later time, and allows other programmers to understand the construction of the program more easily. This differs from traditional documentation, in which a programmer is presented with source code that follows a compiler-imposed order, and must decipher the thought process behind the program from the code and its associated comments. The meta-language capabilities of literate programming are also claimed to facilitate thinking, giving a higher bird's eye view of the code and increasing the number of concepts the mind can successfully retain and process. Applicability of the concept to programming on a large scale, that of commercial-grade programs, is proven by an edition of TeX code as a literate program.[5]Contrast with documentation generation[edit]Literate programming is very often misunderstood[8] to refer only to formatted documentation produced from a common file with both source code and comments \u2013 which is properly called documentation generation \u2013 or to voluminous commentaries included with code. This is backwards: well-documented code or documentation extracted from code follows the structure of the code, with documentation embedded in the code; in literate programming code is embedded in documentation, with the code following the structure of the documentation.This misconception has led to claims that comment-extraction tools, such as the Perl Plain Old Documentation or Java Javadoc systems, are literate programming tools. However, because these tools do not implement the web of abstract concepts hiding behind the system of natural-language macros, or provide an ability to change the order of the source code from a machine-imposed sequence to one convenient to the human mind, they cannot properly be called literate programming tools in the sense intended by Knuth.[8][9]Workflow[edit]Implementing literate programming consists of two steps:\nWeaving: Generating comprehensive document about program and its maintenance.\nTangling: Generating machine executable code\nWeaving and Tangling are done on the same source so that they are consistent with each other.Example[edit]A classic example of literate programming is the literate implementation of the standard Unix wc word counting program. Knuth presented a CWEB version of this example in Chapter 12 of his Literate Programming book. The same example was later rewritten for the noweb literate programming tool.[10] This example provides a good illustration of the basic elements of literate programming.Creation of macros[edit]The following snippet of the wc literate program[10] shows how arbitrary descriptive phrases in a natural language are used in a literate program to create macros, which act as new operators in the literate programming language, and hide chunks of code or other macros. The mark-up notation consists of double angle brackets (<<...>>) that indicate macros, the @ symbol which indicates the end of the code section in a noweb file. The <<*>> symbol stands for the root, topmost node the literate programming tool will start expanding the web of macros from. Actually, writing out the expanded source code can be done from any section or subsection (i.e. a piece of code designated as <<name of the chunk>>=, with the equal sign), so one literate program file can contain several files with machine source code.The unraveling of the chunks can be done in any place in the literate program text file, not necessarily in the order they are sequenced in the enclosing chunk, but as is demanded by the logic reflected in the explanatory text that envelops the whole program.Program as a web\u2014macros are not just section names[edit]Macros are not the same as section names in standard documentation. Literate programming macros can hide any chunk of code behind themselves, and be used inside any low-level machine language operators, often inside logical operators such as if, while or case. This is illustrated by the following snippet of the wc literate program.[10]In fact, macros can stand for any arbitrary chunk of code or other macros, and are thus more general than top-down or bottom-up chunking, or than subsectioning. Knuth says that when he realized this, he began to think of a program as a web of various parts.[1]Order of human logic, not that of the compiler[edit]In a noweb literate program besides the free order of their exposition, the chunks behind macros, once introduced with <<...>>=, can be grown later in any place in the file by simply writing <<name of the chunk>>= and adding more content to it, as the following snippet illustrates (plus is added by the document formatter for readability, and is not in the code).[10]Record of the train of thought[edit]The documentation for a literate program is produced as part of writing the program. Instead of comments provided as side notes to source code a literate program contains the explanation of concepts on each level, with lower level concepts deferred to their appropriate place, which allows for better communication of thought. The snippets of the literate wc above show how an explanation of the program and its source code are interwoven. Such exposition of ideas creates the flow of thought that is like a literary work. Knuth wrote a novel which explains the code of the interactive fiction game Colossal Cave Adventure.[11]Tools[edit]The first published literate programming environment was WEB, introduced by Donald Knuth in 1981 for his TeX typesetting system; it uses Pascal as its underlying programming language and TeX for typesetting of the documentation. The complete commented TeX source code was published in Knuth's TeX: The program, volume B of his 5-volume Computers and Typesetting. Knuth had privately used a literate programming system called DOC as early as 1979. He was inspired by the ideas of Pierre-Arnoul de Marneffe.[12] The free CWEB, written by Knuth and Silvio Levy, is WEB adapted for C and C++, runs on most operating systems and can produce TeX and PDF documentation.There are various other implementations of the literate programming concept:\nAxiom, which is evolved from scratchpad, a computer algebra system developed by IBM. It is now being developed by Tim Daly, one of the developers of scratchpad, Axiom is totally written as a literate program.\nnoweb is independent of the programming language of the source code. It is well known for its simplicity, given the need of using only two text markup conventions and two tool invocations, and it allows for text formatting in HTML rather than going through the TeX system.\nLiterate is a modern literate programming system. Like noweb, it works with any programming language, but it produces pretty-printed and syntax-highlighted HTML, and it tries to retain all the advantages of CWEB, including output formatted like CWEB. Other notable advantages compared with older tools include being based on Markdown and generating well-formatted tangled code. https://github.com/zyedidia/Literate.\nFunnelWeb is another LP tool that can produce HTML documentation output. It has more complicated markup (with @ escaping any FunnelWeb command), but has many more flexible options. Like noweb, it is independent of the programming language of the source code. http://www.ross.net/funnelweb/\nNuweb can translate a single LP source into any number of code files in any mix of languages together with documentation in LaTeX. It does it in a single invocation; it does not have separate weave and tangle commands. It does not have the extensibility of noweb, but it can use the listings package of LaTeX to provide pretty-printing and the hyperref package to provide hyperlinks in PDF output. It also has extensive indexing and cross-referencing facilities including cross-references from the generated code back to the documentation, both as automatically generated comments and as strings that the code can use to report its behaviour. Vimes is a type-checker for Z notation which shows the use of nuweb in a practical application. Around 15,000 lines of nuweb source are translated into nearly 15,000 lines of C/C++ code and over 460 pages of documentation. http://nuweb.sourceforge.net/\nMolly is an LP tool written in Perl, which aims to modernize and scale it with folding HTML and virtual views on code. It uses noweb markup for the literate source files. https://github.com/unixtechie/Literate-Molly.\nCodnar is an inverse literate programming tool available as a Ruby Gem. Instead of the machine-readable source code being extracted out of the literate documentation sources, the literate documentation is extracted out of the normal machine-readable source code files. This allows these source code files to be edited and maintained as usual. The approach is similar to that used by popular API documentation tools, such as JavaDoc. Such tools, however, generate API reference documentation, while Codnar generates a linear narrative describing the code, similar to that created by classical LP tools. Codnar can co-exist with API documentation tools, allowing both a reference manual and a linear narrative to be generated from the same set of source code files. https://github.com/orenbenkiki/codnar\nThe Leo text editor is an outlining editor which supports optional noweb and CWEB markup. The author of Leo mixes two different approaches: first, Leo is an outlining editor, which helps with management of large texts; second, Leo incorporates some of the ideas of literate programming, which in its pure form (i.e., the way it is used by Knuth Web tool or tools like noweb) is possible only with some degree of inventiveness and the use of the editor in a way not exactly envisioned by its author (in modified @root nodes). However, this and other extensions (@file nodes) make outline programming and text management successful and easy and in some ways similar to literate programming.[13]\nThe Haskell programming language has native support for semi-literate programming. The compiler/interpreter supports two file name extensions: .hs and .lhs; the latter stands for literate Haskell.\n\nThe literate scripts can be full LaTeX source text, at the same time it can be compiled, with no changes, because the interpreter only compile the text in a code environment, for example\n\n\n\n% here text describing the function:\n\\begin{code}\nfact 0 = 1\nfact (n+1) = (n+1) * fact n\n\\end{code}\nhere more text\n\n\nThe code can be also marked in the Richard Bird style, starting each line with a greater than symbol and a space, preceding and ending the piece of code with blank lines.\n\nThe LaTeX listings package provides a lstlisting environment which can be used to embellish the source code. It can be used to define a code environment to use within Haskell to print the symbols something like:\n\n\n\n\n\newenvironment{code}{\\lstlistings[language=Haskell]}{\\endlstlistings}\n\n\\begin{code}\ncomp :: (beta -> gamma) -> (alpha -> beta) -> (alpha -> gamma)\n(g `comp` f) x = g(f x)\n\\end{code}\n\n\ncan be configured to yield something like this:\n\n\n  \n    \n      \n        \n          \n            \n              \n              \n                c\n                o\n                m\n                p\n                ::\n                (\n                \u03b2\n                \u2192\n                \u03b3\n                )\n                \u2192\n                (\n                \u03b1\n                \u2192\n                \u03b2\n                )\n                \u2192\n                (\n                \u03b1\n                \u2192\n                \u03b3\n                )\n              \n            \n            \n              \n              \n                \n                (\n                g\n                comp\n                \u2061\n                f\n                )\n                x\n                =\n                g\n                (\n                f\n                x\n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}&comp::(\\beta \\to \\gamma )\\to (\\alpha \\to \\beta )\\to (\\alpha \\to \\gamma )\\\\&(g\\operatorname {comp} f)x=g(fx)\\end{aligned}}}\n  \n\n\n\nAlthough the package does not provide means to organize chunks of code, one can split the LaTeX source code in different files. See listings manual for an overview.\n\nThe Web 68 Literate Programming system uses Algol 68 as the underlying programming language, although there is nothing in the pre-processor 'tang' to force the use of that language.[14]\nEmacs org-mode for literate programming through Babel,[15] which allows embedding blocks of source code from multiple programming languages[16] within a single text document. Blocks of code can share data with each other, display images inline, or be parsed into pure source code using the noweb reference syntax.[17]\nCoffeeScript supports a literate mode, which enables programs to be compiled from a source document written in Markdown with indented blocks of code.[18]\nWolfram Language, formerly known as Mathematica, is written in notebooks which combine text with code.[19]\nSwift (programming language), created by Apple Inc. can be edited in Playgrounds which provide an interactive programming environment that evaluates each statement and displays live results as the code is edited. Playgrounds also allow the user to add Markup language along with the code that provide headers, inline formatting and images.[20]\nJupyter Notebook, formerly IPython Notebook - works in the format of notebooks, which combine headings, text (including LaTeX), plots, etc. with the written code.\nJulia (programming language) supports the iJulia mode of development which was inspired by iPython.\nAgda (programming language) supports a limited form of literate programming out of the box.[21]\nEve programming language programs are primarily prose[22]. Eve combines variants of Datalog and Markdown with a live graphical development environment.\nSimilar to Jupyter Notebooks, R Notebooks are a method of literate programming that allows for direct interaction with R (only) while producing a reproducible document with publication-quality output.\nSee also[edit]\nSweave and Knitr \u2013 examples of use of the noweb-like Literate Programming tool inside the R language for creation of dynamic statistical reports\nSelf-documenting code \u2013 source code that can be easily understood without documentation\nReferences[edit]Further reading[edit]", "subtitles": ["History and philosophy", "Concept", "Workflow", "Example", "Tools", "See also", "References", "Further reading"], "title": "Literate programming"},
{"content": "In computer science, syntactic noise is syntax within a programming language that makes the programming language more difficult to read and understand for humans. It fills the language with excessive clutter that makes it a hassle to write code. Syntactic noise is considered to be the opposite of syntactic sugar, which is syntax that makes a programming language more readable and enjoyable for the programmer.", "subtitles": [], "title": "Syntactic noise"},
{"content": "In computer programming, Intentional Programming is a programming paradigm developed by Charles Simonyi that encodes in software source code the precise intention which programmers (or users) have in mind when conceiving their work. By using the appropriate level of abstraction at which the programmer is thinking, creating and maintaining computer programs become easier. By separating the concerns for intentions and how they are being operated upon, the software becomes more modular and allows for more reusable software code.Intentional Programming was developed by former Microsoft chief architect Charles Simonyi, who led a team in Microsoft Research, which developed the paradigm and built an integrated development environment (IDE) called IP (for Intentional Programming) that demonstrated the paradigm. Microsoft decided not to productize the Intentional Programming paradigm, as in the early 2000s Microsoft was rolling out C# and .NET to counter Java adoption.[1] Charles Simonyi decided, with approval of Microsoft, to take his idea out from Microsoft and commercialize it himself. He founded the company Intentional Software to pursue this. Microsoft licensed the Intentional Programming patents Simonyi had acquired while at Microsoft, but no source code, to Intentional Software.An overview of Intentional Programming as it was developed at Microsoft Research is given in Chapter 11 of the book Generative Programming: Methods, Tools, and Applications.[2]Development cycle[edit]As envisioned by Simonyi, developing a new application via the Intentional Programming paradigm proceeds as follows. A programmer builds a WYSIWYG-like environment supporting the schema and notation of business knowledge for a given problem domain (such as productivity applications or life insurance). Users then use this environment to capture their intentions, which are recorded at high level of abstraction. The environment can operate on these intentions and assist the user to create semantically richer documents that can be processed and executed, similar to a spreadsheet. The recorded knowledge is executed by an evaluator or is compiled to generate the final program. Successive changes are done at the WYSIWYG level only. As opposed to word processors, spreadsheets or presentation software, an Intentional environment has more support for structure and semantics of the intentions to be expressed, and can create interactive documents that capture more richly what the user is trying to accomplish. A special case is when the content is program code, and the environment becomes an intelligent IDE.[3]Separating source code storage and presentation[edit]Key to the benefits of Intentional Programming is that domain code which capture the intentions are not stored in source code text files, but in a tree-based storage (could be binary or XML). Tight integration of the environment with the storage format brings some of the nicer features of database normalization to source code. Redundancy is eliminated by giving each definition a unique identity, and storing the name of variables and operators in exactly one place. This makes it easier to intrinsically distinguish declarations from references, and the environment can show them differently.Whitespace in a program is also not stored as part of the source code, and each programmer working on a project can choose an indentation display of the source. More radical visualizations include showing statement lists as nested boxes, editing conditional expressions as logic gates, or re-rendering names in Chinese.The system uses a normalized language for popular languages like C++ and Java, while letting users of the environment mix and match these with ideas from Eiffel and other languages. Often mentioned in the same context as language-oriented programming via domain-specific languages, and aspect-oriented programming, IP purports to provide some breakthroughs in generative programming. These techniques allow developers to extend the language environment to capture domain-specific constructs without investing in writing a full compiler and editor for any new languages.Programming Example[edit]A Java program that writes out the numbers from 1 to 10, using a curly bracket syntax, might look like this:The code above contains a common construct of most programming languages, the bounded loop, in this case represented by the for construct. The code, when compiled, linked and run, will loop 10 times, incrementing the value of i each time after printing it out.But this code does not capture the intentions of the programmer, namely to print the numbers 1 to 10. In this simple case, a programmer asked to maintain the code could likely figure out what it is intended to do, but it is not always so easy. Loops that extend across many lines, or pages, can become very difficult to understand, notably if the original programmer uses unclear labels. Traditionally the only way to indicate the intention of the code was to add source code comments, but often comments are not added, or are unclear, or drift out of sync with the source code they originally described.In intentional programming systems the above loop could be represented, at some level, as something as obvious as print the numbers 1 to 10. The system would then use the intentions to generate source code, likely something very similar to the code above. The key difference is that the intentional programming systems maintain the semantic level, which the source code lacks, and which can dramatically ease readability in larger programs.Although most languages contain mechanisms for capturing certain kinds of abstraction, IP, like the Lisp family of languages, allows for the addition of entirely new mechanisms. Thus, if a developer started with a language like C, they would be able to extend the language with features such as those in C++ without waiting for the compiler developers to add them. By analogy, many more powerful expression mechanisms could be used by programmers than mere classes and procedures.Identity[edit]IP focuses on the concept of identity. Since most programming languages represent the source code as plain text, objects are defined by names, and their uniqueness has to be inferred by the compiler. For example, the same symbolic name may be used to name different variables, procedures, or even types. In code that spans several pages \u2013 or, for globally visible names, multiple files \u2013 it can become very difficult to tell what symbol refers to what actual object. If a name is changed, the code where it is used must carefully be examined.By contrast, in an IP system, all definitions not only assign symbolic names, but also unique private identifiers to objects. This means that in the IP development environment, every reference to a variable or procedure is not just a name \u2013 it is a link to the original entity.The major advantage of this is that if an entity is renamed, all of the references to it in the program remain valid (known as referential integrity). This also means that if the same name is used for unique definitions in different namespaces (such as .to_string()), references with the same name but different identity will not be renamed, as sometimes happens with search/replace in current editors. This feature also makes it easy to have multi-language versions of the program; it can have a set of English-language names for all the definitions as well as a set of Japanese-language names which can be swapped in at will.Having a unique identity for every defined object in the program also makes it easy to perform automated refactoring tasks, as well as simplifying code check-ins in versioning systems. For example, in many current code collaboration systems (e.g. CVS), when two programmers commit changes that conflict (i.e. if one programmer renames a function while another changes one of the lines in that function), the versioning system will think that one programmer created a new function while another modified an old function. In an IP versioning system, it will know that one programmer merely changed a name while another changed the code.Levels of detail[edit]IP systems also offer several levels of detail, allowing the programmer to zoom in or out. In the example above, the programmer could zoom out to get a level that would say something like:\n<<print the numbers 1 to 10>>\nThus IP systems are self-documenting to a large degree, allowing the programmer to keep a good high-level picture of the program as a whole.Similar works[edit]There are projects that exploit similar ideas to create code with higher level of abstraction. Among them are:\nConcept programming\nLanguage-oriented programming (LOP)\n\nDomain-specific language (DSL)\n\n\nProgram transformation\nSemantic-oriented programming (SOP)\nLiterate programming\nModel-driven architecture (MDA)\nSoftware factory\nMetaprogramming\nLisp (programming language)\nSee also[edit]\nAutomatic programming\nObject database\nProgramming by demonstration\nArtefaktur\nSemantic resolution tree\nStructure editor\nReferences[edit]External links[edit]\nIntentional Software - Charles Simonyi's company\nThe Death Of Computer Languages, The Birth of Intentional Programming, a technical report by Charles Simonyi (1995)\nIntentional Programming - Innovation in the Legacy Age, a talk by Charles Simonyi (1996)\nEdge.org interview with Charles Simonyi (interviewer: John Brockman)\nLanguage Workbenches: The Killer-App for Domain Specific Languages? - Martin Fowler's article on the general class of tools that Intentional Programming is an example of.\nAnything You Can Do, I Can Do Meta Tuesday, January 9, 2007, Scott Rosenberg, Technology Review\nAwaiting the Day When Everyone Writes Software, The New York Times, 28 January 2007\nIs programming a form of encryption?, by Charles Simonyi (2005)\nAppropriate Levels of Abstraction, by Charles Simonyi (2005)\nThe information contents of programs, by Charles Simonyi (2005)\nFeature X Considered Harmful, by Charles Simonyi (2005)\nNotations and Programming Languages, by Charles Simonyi (2005)\nPersonal Observations from a Developer, by Mark Edel (2005)\nMicrosoft Research's educational video introducing their Intentional Programming system (ASF format, circa 1998, 20 megabytes)\n", "subtitles": ["Development cycle", "Separating source code storage and presentation", "Programming Example", "Similar works", "See also", "References", "External links"], "title": "Intentional programming"},
{"content": "CfMD stands for Certified for Microsoft Dynamics.[1][2]The program recognizes the third-party developed solutions that meet Microsoft's highest standards for Dynamics implementations.If a solution is CfMD certified, it means:\nThe product is developed only by a certified and reputable Software Vendor\nThe product is designed for a unique business and industry need\nThe product abides the governmental policies and regulations\nThe product is tested for seamless integration with Microsoft Dynamics\nThe product has been used and recommended by other companies\nThe product is of low-risk to use, fast to implement, and simple in maintenance\nThere are 6 key requirements to earn Certified for Microsoft Dynamics and gain access to the CfMD Logo\nSoftware Solution Test (SST) via 3 tracks 1) Tested in Lab 2) ISV Self Test 3) Application Services Track\nSoftware Escrow \u2013 confirm that you have offered Software Escrow under your license terms\nDemonstrate your Support Capability - an online resource for your solution with specific support information, SLA and product roadmap\nProvide existing Customer Evidences - Supply customer references or evidence from Microsoft and your resellers related to 10 customers using the current or 1 previous major Microsoft Dynamics version\nEstablish an ERP/CRM competency with the Microsoft Partner Network\nEstablish a Microsoft Dynamics application profile on Pinpoint\nFor more information see http://microsites.lionbridge.com/veritestcertification/SitePages/microsoft-dynamics.aspxReferences[edit]", "subtitles": [], "title": "Certified for Microsoft Dynamics"},
{"content": "Microsoft Dynamics C5 is a business software from Microsoft.[1]The product is part of the Microsoft Dynamics family, and intended to assist with finance, supply chain, project management, analytics for small and medium-sized businesses. Microsoft Dynamics partners may have full access to the business logic source code, and it has a reputation as being easy to use and customize.[citation needed]More than 85,000 licenses have been sold through a partner eco-system since 1995. In 2013 Microsoft released the third generation of C5 fully cloud-enabled.History[edit]C5 originates from the Damgaard Data Concorde C4 DOS-based business solution. C5 was launched in 1995 replacing C4. At the time of the release it was sold under the name Concorde C5 in Denmark and Arctos abroad.The logic source code was named eXtended Application Language (XAL) and borrowed from a larger product called Microsoft Dynamics XAL, also originally a Concorde product from Damgaard, which was withdrawn from the market because it shared the same market segment as Microsoft Dynamics NAV formerly known as Navision. XAL, and to some extent C5, offered database and OS options for a number of non-Microsoft products like Oracle, DB2 and Linux. The name eXtended Application Language was chosen due to the fact that it was an enhancement of the logic source code used in products like Navision.In connection with Microsoft XAL's retirement from the market the product was changed from targeting only small businesses to target medium-sized businesses too, so customers running on the discontinued Microsoft XAL could convert their product easily to C5, NAV or AX.Microsoft Dynamics C5 was sold almost entirely in Denmark because Microsoft consider the competition among solutions sold to smaller companies to be strong.[citation needed]In 2013, it was time to change again. Starting with the release of Dynamics C5 2014 the new generation of C5 shares the same platform and roadmap as Dynamics NAV. All capabilities of Dynamics NAV, except a by licensing reduced set of application features, are available in the new generation of Dynamics C5.[citation needed]Looking at the legacy C5 still serves a no. of medium-sized business Microsoft today offers a license migration path from the legacy C5 to Dynamics NAV. Further Dynamics partners offers migration packages enabling legacy C5 customers to migrate to either the new C5 or NAV. The C5 2012 version will be available for resale until January 5, 2017.[citation needed]Features[edit]The C5 application comes installed with all modules. The customer can unlock a module by purchasing a license key. Like with all Dynamics products only Dynamics partners are allowed to re-sell the license keys.The first version of C5 was sold in 1995. Today you have supported versions and unsupported versions. In January 2010 Microsoft changed their trade agreements so customers no longer can expand the unsupported versions with more database capacity or users.Supported versions:Microsoft Dynamics C5 2012 (until January 9, 2019), Microsoft Dynamics C5 2014, Microsoft Dynamics C5 2015 and Microsoft Dynamics C5 2016.References[edit]External links[edit]\nMicrosoft Dynamics C5 Official Site\n", "subtitles": ["History", "Features", "References", "External links"], "title": "Microsoft Dynamics C5"},
{"content": "Microsoft Dynamics SL is one of Microsoft\u2019s enterprise resource planning software products for project-driven small- and medium-sized enterprises. It is part of the Microsoft Dynamics product family.Microsoft Dynamics SL has project-based ERP with a connection to Microsoft Office Project Server, a member of the Microsoft Office family. This business management system provides project-, service-, and distribution-driven businesses with project management and project accounting functionality to help organizations manage projects .[citation needed] The functionality includes finance, project accounting, manufacturing, field services, supply chain management, analytics, and electronic commerce.Project-based ERP Industry Features[edit]Microsoft Dynamics SL supports budgeting and cost forecasting, time and expense entry, complex allocations, unlimited billing formats, change order control, contract administration, local and Web-based project analysis, employee utilization/realization, proactive alerts, and workflow.Microsoft Dynamics SL provides government contractors with functionality to assist with Defense Contract Audit Agency (DCAA) audit requirements.[citation needed]In the construction industry, Microsoft Dynamics SL provides general contractors and residential homebuilders with project management, job cost, materials management, service call entry, receiving, billing, and sales capabilities to allow the management of complex job sites while lowering costs, reducing project delays, and improving customer service.[citation needed]Microsoft Dynamics SL provides distribution-focused organizations with inventory, receiving, billing, and sales solutions. The functionality is designed to help organizations reduce distribution costs and inventory, and streamline processes while improving customer service.[citation needed]History[edit]Based in Findlay, Ohio, Solomon's roots go back more than 35 years, when co-founders Gary Harpst, Jack Ridge and Vernon Strong started TLB, Inc. in 1980. TLB, Inc. stands for The Lord's Business. TLB was named to remind the founders why the business was started: to conduct the business according to biblical principles. TLB was later renamed Solomon Software, and then Microsoft Dynamics SL, [1]In April 1999, Solomon Software refocused the product on an all Microsoft technology strategy: Microsoft SQL Server as the database technology; Visual Basic as the software language; and Visual Basic for Applications (VBA) as the customization language.Solomon was acquired by Great Plains Software in June 2000. Great Plains was subsequently acquired by Microsoft Corporation in May 2001.The newest[when?] version is Microsoft Dynamics SL 9.0 (now Dynamics SL 2015[2]), which extends the reach of business information with Microsoft SQL Server business intelligence technology to improve collaboration, reporting, and analysis.[citation needed]Competitors[edit]\nAcumatica\nAgresso and Coda Financials from Unit4\nSage Group\nNetSuite\nIntacct\nFinesse from ESS\nReferences[edit]External links[edit]\nMicrosoft Dynamics SL official website\nMicrosoft Dynamics SL Customer Stories\nMicrosoft Dynamics Users Group SL\nMicrosoft Dynamics Solution Finder\n", "subtitles": ["Project-based ERP Industry Features", "History", "Competitors", "References", "External links"], "title": "Microsoft Dynamics SL"},
{"content": "Microsoft Dynamics GP is a mid-market business accounting software or ERP software package marketed in North and South America, UK and Ireland, the Middle East, Singapore, Australia and New Zealand. It is used in many additional countries with partner supported localizations. It uses either Microsoft SQL Server 2005, 2008, 2012, 2014 or 2016 to store data. It is one of four accounting packages acquired by Microsoft that now share the Microsoft Dynamics Business Solutions brand. Dynamics GP is written in a language called Dexterity.The Dynamics GP product was originally developed by Great Plains Software, an independent company located in Fargo, North Dakota, which was run by Doug Burgum. Dynamics Release 1.0 was released in February 1993.[1] It was one of the first accounting packages in the USA that was designed and written to be multi-user and to run under Windows as 32-bit software.[2] In late 2000, Microsoft announced the purchase of Great Plains Software.[3] This acquisition was completed in April 2001.Versions[edit]Dynamics GP 2018 was released by Microsoft on December 1 2017. [4]Dynamics GP 2016 R2 was released by Microsoft on December 1, 2016.[5]Dynamics GP 2016 was released by Microsoft on May 1, 2016.[6]Dynamics GP 2015 R2 was released by Microsoft on May 29, 2015.[7]Dynamics GP 2015 (Version 14) was released by Microsoft on Dec. 1, 2014.[8]Dynamics GP 2013 (Version 12) was released by Microsoft on Dec. 19, 2012.[9] For the first time the software had evolved from a pure client-server application to a web-enabled application.[10] The full client will continue to provide a 'rich' content, since it is the only way to cover all the modules and third-party products properly in the application. The web-enabled client only covered the basic modules (Financial & Distribution in Phase 1, HR & Payroll added in Phase 2, Project Accounting in Phase 3, Customer support (Sales ?) in Phase 4 and finally Manufacturing in Phase 5). The various modules were added over the course of the development between the initial release date and the release date of Dynamics GP 2015 in December 2014.Dynamics GP 2010R2 was released in April 2011.[11]Dynamics GP 2010 was released in April 2010;[12]Microsoft Dynamics GP 10.0 was released in June 2007.Prior versions were named Microsoft Great Plains and Microsoft Dynamics. Previous versions were compatible with Microsoft SQL Server, Pervasive PSQL, Btrieve, and earlier versions also used C-tree, although after the buyout all new versions switched entirely to Microsoft SQL Server databases.Previous versions of Microsoft Dynamics GP were available in two editions:\nStandard: Up to 10 simultaneous users, and 500 payroll employees for each defined company.\nProfessional: Unlimited users, additional user-level security options, consolidation tools, automatic purchase order generation, and more reporting/analysis options. In addition, Professional Edition includes additional manufacturing and field service modules.\nDynamics GP Release dates and Version Numbers (incomplete) [1][13]\nMYTU = Mid Year Tax Update\nYETU = Year End Tax Update\nYEU2 = 2nd Year End Tax Update\nMacros[edit]Great Plains was one of the first accounting packages with capability to record and play back macros. Macros are saved in .MAC files in the Dexterity programming language. The .MAC files are editable text files. Macro files are very different from the VBA files found in the Microsoft Office products. Dynamics GP macros cannot make decisions, but merely play back keystrokes recorded by a user. Microsoft Dynamics can also have VBA functionality attached to forms and reports to carry out decisions.Modules[edit]Microsoft Dynamics GP is organized in Series, each of which contains several modules. The typical Series are Financial, Sales, Purchasing, Inventory, Project, Payroll, Manufacturing, Company and System. The last two contain all the necessary modules to configure various company-wide and system-wide options. Each Series involves a full cycle of transactions for that particular Series, for example, the Sales Series implements the Quote to Cash process. In addition to the typical out-of-the-box modules, Microsoft's community of Independent Software Vendors (ISV) has developed a number of add-ons and verticals, all generally referred to as Third Party applications, which complement or enhance the existing functionality of the application. Some of these are also written in Dexterity, and so look and function in the same way as Dynamics GP standard modules.Analytics[edit]Management Reporter for Microsoft Dynamics ERP: a corporate performance management solution for the Microsoft Dynamics ERP systems allows easy creation and consolidation of financial statements using a building block approach with Rows, Columns, Trees and Report Definitions and the familiar user interface used by Microsoft Office applications.Microsoft Forecaster: extracts real-time data from General Ledger to create and manage accurate budgets and plans which can be shared across the management team via a Web-based interface. Easy to learn: has the look and feel of a spreadsheet.Microsoft SQL Server Reporting Services(SSRS): offers customizable reports for Financial, Sales, Purchasing and Manufacturing. Reports are run from Internet Explorer and can be rich with charts and graphs for sharing across the organization or with designated suppliers or contractors. SSRS is often used to produce dashboard type charts for executive management.SmartList Builder: easy to use, yet powerful query tool to output data (no matter where records reside) based on virtually any specified criteria into a user-friendly format for screen view, for print or for saving in Excel or Word (auto-formatted). Combine and link data from up to 32 separate tables, including third-party dictionaries. Many common data-analysis functions are available in pre-configured SmartList objects that can be downloaded from Microsoft.Crystal Reports is widely used in building and designing reports with Microsoft Dynamics GP.Customization Tools[edit]Customization: comprehensive customization tools to enable .NET developers to create real-time, transactional connections between Microsoft Dynamics GP and other applications and expansion potential for new features and functionality.Integration: integrate and incorporate data with a high degree of safety, flexibility and speed from any source, even those not based on Microsoft platforms. Uses a mix of proprietary Microsoft technologies, such as Microsoft BizTalk Server, Component Object Model (COM), the Microsoft .NET Framework, and Microsoft Message Queuing (MSMQ); as well as industry-standard technologies such as Web services and XML.Earlier versions of Great Plains were written in and dependent upon the Dexterity programming language.Supply Chain Management[edit]Advanced Distribution: A tool intended to streamline the distribution cycle, gain rapid access to accurate information (view inventory levels for specific items at a glance and get a snap-shot view of the supply chain cycle via Distribution SmartLists), reduce input errors and automate information-sharing through a configurable workflow, allowing the user to define up to 6 stages in the order-to-invoice cycle.Advanced Picking: offers the capability to issue consolidated (bulk) picking lists across numerous orders for common items; it can meet multi-site needs. It adapts to warehouse layouts by tailoring picking routines. This module requires Advanced Distribution to run.Available to Promise: maintain up-to-date information concerning stock availability, current and future, so that accurate commitments are made to customers.Demand Planner: combines planning and forecasting functionality with an intuitive, easy-to-learn user interface to anticipate future demand and gain deep, multi-dimensional visibility into customer buying patterns. Excel Collaboration Plug-in allows for forecast information to be shared and for synchronization of demand management across organization.Inventory Management: provides access to detailed inventory information from a central location, has easy to use stock analysis tools and flexible reporting capabilities, improves picking efficiency with multi-bin tracking and enables the creation of personalized pricing schemes to meet customer demands. Blends well with other GP modules, such as Sales Order Processing, Invoicing and General Ledger to streamline inventory and sales processes.Order Management (for Business Portal): around-the-clock, security-enhanced access via an out-of-the-box, business-to-business portal which allows salespeople and customers to view, place and edit orders online, saving time and increasing accuracy of orders.Purchase Order Processing: enter purchase transactions earlier in the cycle to better manage costs and improve efficiency. Complete purchasing audit control with comprehensive selection of reports to track and analyze purchase activity (full historical and performance reporting). Option to print or e-mail purchase order documents. Other features include Auto-Receive, Auto-Invoice, VAT tracking, facility to handle price and quantity variances, approvals option, commitment reporting. Integrates smoothly with Payables Management, General Ledger, Sales Order Processing and Inventory.Requisition Management (for Business Portal): enter and approve requisitions online and automatically transfer orders to new or existing purchase orders in Dynamics GP Purchase Order Processing. Reduces paperwork, repetitive data entry and errors. Approval processes can be fully customized. Channel information to the right people through roles-based access.Sales Order Processing: manages the whole sales process from A-Z: quote to order to invoice, and with pinpoint accuracy. Enter quotes, orders, back orders, invoices and returns from one central location without data re-entry to increase office productivity. Invoices are auto-generated. Customer Priority Ranking feature to quickly identify top customers, and distinguish prospects from customers. Customizable data entry, sales documents and sales process to accommodate an organization\u2019s unique business needs. Has seamless integration with Inventory, Receivables Management and eCommerce modules.Foundation[edit]Analysis Cubes: for Microsoft Office Excel is a core component of the GP financial system which leverages the power of SQL Server. It helps define and extract key data and features the Excel Pivot Table Generator to allow the user to \u201cslice and dice\u201d information, business portal KPIs and a tool to share and increase transparency of financial information via the Business Portal to improve Sarbanes-Oxley compliance.Business Portal: A web-based information dissemination system where access is defined by user roles. Professional users can have full remote access data entry capability. A security-enhanced extranet deployment provides trusted customers and suppliers with access to selected data with the ability to customize their own pages.Electronic Document Delivery (for Business Portal): enables scheduled e-mail delivery, according to defined rules, of electronic documents, such as Invoices, Credit Notes, Debit Notes, Finance Charges and Returns in various formats.Key Performance Indicators (for Business Portal): roles-based to define and deliver personalized views of key business information via Web-based portal.Process Server: integrated with Dynamics GP to reduce the burden on client computers by moving heavy background tasks to process servers to eliminate costly slow-downs and delays.Report Writer: tool to build reports from scratch or to use one of the hundreds of templates available in the system and customize for specific individuals or groups to achieve consistency in presentation across the entire organization. Flexible scheduling options available to publish reports at any time: immediately, on a recurring basis or selectively in a variety of file formats including HTML and PDF. Reports can be shared across the organization by posting them online for viewing via a Web browser with role-based security options.System Manager: a tool to customize Dynamics GP to set up processes and role-based home pages or dashboards specific to business and employee needs. Creates queries against data or accesses more than 100 modifiable SmartList queries, exportable to Excel or Word. Streamline process set-up to provide audit information and maintain user accountability.Extensible Web Services: uses Microsoft technologies, such as SQL Server, Visual Studio and .Net, as well as industry standards, such as Web Services and XML, to increase real-time data sharing and integrate business processes throughout the organization. The Web Services layer works with the Business Services layer to provide security, policy validations, defaulting, and exception management for consumers of the Web service. These two tiers interact with Business Logic and Persistence layer within eConnect to provide scalable and reliable integration solutions.Security Management: manages user security quickly and effectively to protect the Dynamics GP system. Different security types can be assigned to fields through Dynamics GP using a single Explorer-style interface and security errors can be identified and fixed quickly using the interactive dialogs to help eliminate the need to change login user and minimize IT administration.Financial Management[edit]Analytical Accounting: Analytical Accounting is a tool that helps you to analyze, interpret, and create reports based on your company\u2019s chart of accounts. Using Analytical Accounting, you can better assess your company\u2019s accounts. You can also store information which cannot be computed in monetary terms such as labour hours. You can enter detailed analysis information without resorting to segmental accounting. You can create budgets using analysis dimensions and compare your actual figures with budgeted figures.Bank Reconciliation: customizable summary and detailed views of bank account balances and all transactions: cash, check and credit card. Tools available to sort and mark transactions to improve reconciliation capabilities.Cash Flow Management: calendar-based interface to view and manage cash inflows and outflows to improve day-to-day financial planning. Big picture and full drill-down options available.Collections Management: customizable interface enabling the user to enter and view all collections in one central point. Allows to target and follow up on overdue customers with automatic delivery and tracking of collection letters, e-mails, statements and invoices.eBanking: an aid to reduce administration costs and manual input error as well as improve productivity and cash management in a security-enhanced environment. Routine accounting tasks are moved online and bank transactions are electronically enabled and reconciled. Transactions are applied to accounts when they occur rather than days or weeks later, such as BACS payments or payment collections via Direct Debits or credit cards. Special feature verifies that sort codes and bank account numbers entered for suppliers and customers make sense.eExpense Automated Expense Management: enables employees to create and submit expense reports via the Web at any time and from any location; features electronic receipt imaging.Encumbrance Management: encumbrance accounting module specifically designed for Not for Profit and Public Sector organizations to ensure that actual expenditures and related commitments do not exceed available funds.Fixed Asset Management: create, define and manage an unlimited number of assets. Features standard fields and up to 15 user-defined fields with graphical user interface. Numerous depreciation methods available to automate depreciation routines. Integration into General Ledger to post depreciation journals and into Payables Management to pull in purchase information to fixed assets. Location IDs to aid inventory management: matching actual with recorded location. Information-sharing enabled with standard and custom reports.General Ledger: automates key accounting tasks to improve accuracy (includes automatic correction of posting errors) and streamlines budget planning and financial decision-making with reports and enquiry tools (features Excel wizard interface). Features up to 66 alphanumeric character codes, up to 10 segments and user-defined fields with 50 character descriptions.Grant Management: tracks grants, demonstrates accountability and compliance and also assists with future funding applications. As grant transactions are entered, the Analytical Accounting module will automatically validate them against the budget.Multi-currency Management: designed for multinational operations to more easily manage financial statistics and accounting operations involving multiple currencies and dealing with changing exchange rates.Payables Management: control expenditure, control payments (check and BACS runs) with flexible selection criteria and track supplier documents and information. Features include unlimited addresses/contacts per supplier, discounts, min/max payments, holds, returns, debit/credit notes, auto-allocation, performance and history reports.Receivables Management: tracks customer-related documents and information, controls cash, generates simple invoices as well as creates, prints and e-mails statements. Produces sophisticated debtor related reports at any point in time and performance reports including turnover, gross profit and payment days. Other features are flexible credit limits, unlimited address/contacts per customer,[citation needed] min/max payments and ability to handle insufficient funds, interest charges, debit/credit notes, returns, write-offs and auto-allocation.Field Service[edit]Field Service Management: nine powerful elements within a single user interface to manage engineer service calls, preventive maintenance, contract administration. Data can be entered remotely. PDA and CRM integration. Web-based tools allow customers to resolve service issues themselves. Applies standard and customized reports. Many of the Field Service Management elements perform invoicing through the Sales Order Processing module.Human Resource Management[edit]Human Resources: A module to build comprehensive records of employees to include attendance tracking, run \u201cwhat if\u201d scenarios with salary adjustment projections, access to numerous standard and customizable templates to streamline the recruitment process, standardize the process for performance reviews, facilitate information-sharing with seamless integration to GP payroll and general ledger applications.HRM Self Service Suite: personalized, secure portals to review expenses, pay and benefits, personal profiles, attendance records, recruitment, promotion and training opportunities, enter holiday requests as well as share selected data across the organization. Reduces administration costs and eliminates need for paper.Manufacturing[edit]Job Costing: captures and consolidates in one location all job costings as they occur to give manufacturers a comprehensive view of production profitability.Materials Requirements Planning (MRP): for greater accuracy and control in matching material flows and production to current projected demand. MRP is a key resource planning instrument to help reduce stock outages, drive down inventory costs and streamline the production process. Views can be in time format and with full drill-downs to source any MRP quantity.Manufacturing Bill of Materials: ensure materials are where they should be, when they are needed. Gain tighter control of costs, locations and routings of materials, components and assemblies to maximize production efficiency and lower inventory costs. Features intuitive, graphical \u201ctree views\u201d of Bill of Materials for entry and inquiry.Engineering Change Management: provides the means to collect, organize, validate and authorize process and component changes before they are released to the shop floor to ensure that they are strategically sound before they become orders.Manufacturing Order Processing: tracks detailed production costs; manages work orders, routings, material requirements planning (MRP), work center definitions, work in progress (WIP), outsourced operations and production costings. Facility to \u201cmass change\u201d the status of multiple manufacturing orders at one time.Quality Assurance: a tool to design and refine processes to test the quality of incoming raw materials to meet your manufacturing process. Flexible reporting to provide suppliers and customers with customized information on quality assurance testing and processes both quickly and accurately.Sales Forecasting: allows you to create forecasts for a range of items or salespeople and to combine these forecasts into a master forecast. Integrates with Materials Requirements Planning module so that material requirements plans reflect existing sales forecasts and current sales orders. Create statistical forecasting and interactive simulation scenarios with integration into Demand Planner module.Project Accounting[edit]Project Accounting: connects project activities with company financials and timelines so that projects get completed on time and within budget. Tracks unlimited contracts and projects. Has web-based time and expense entry, fixed or variable pricing, comprehensive revenue recognition methods, profitability and WIP reporting, budgets and forecasts, flexible categories.Project Time & Expense (for Business Portal -discontinued in 2014 - new mobile capabilities promised at the Atlanta Convergence show in March 2015- ): facility to capture, review and approve project time and expense data/reports via the Web for prompt, accurate customer invoicing and efficient reimbursement for out-of-pocket employee expenses. Helps reduce paperwork and increases operational efficiency.Community[edit]The GP community consists of professionals, typically employees of Dynamics Partners, End-users and MS MVP's (Microsoft Most Valuable Professional).The Dynamics GP User Group (GPUG) is the largest, user-led community for companies using the software.Events[edit]GPUG SummitGPUG Summit is held each fall and is an independent, user-led conferenceGPUG AmplifyGPUG Amplify is robust event for Dynamics GP users, designed to improve attendee skills around reporting, leadership, and industry best practices.reIMAGINEreIMAGINE is the only conference dedicated to the technical learning and educational opportunities of Microsoft Dynamics GP Partners.Enhancement[edit]Microsoft Dynamics GP 2013 is enhanced with a web client.The web client is powered by Silverlight technology.[14]\nMicrosoft Dynamics GP 2016 updates the web client to HTML5, removing the Silverlight dependency and allowing cross-platform and mobile access.[15]Microsoft Dynamics GP 2018 had updates to Workflow (V4.0), Document Attach, Power Suite (PowerApps and Power BI) and core Finance & HR community.[16]Criticism[edit]Microsoft Dynamics GP does not integrate with Microsoft Active Directory, which precludes single sign-on in deployments where Active Directory could otherwise be used to authenticate Dynamics GP users, and necessitates maintenance of separate SQL Server user accounts specifically for Dynamics GP.[17] This has been overcome by some users with third party modules, such as Config AD.[18]Competitors[edit]\nAcumatica\nAgresso and Coda Financials from Unit4\nIntacct\nNetSuite\nSage Group\nSAP Business One\nEclipse ERP\nNotes[edit]External links[edit]\nMicrosoft Dynamics GP Official Website\nMicrosoft Dynamics GP Official Blog - run by the Microsoft Dynamics GP Product Management & Marketing team\nMicrosoft Dynamics GP Blog run by David Musgrave and the Microsoft GP Developer Support Team\n", "subtitles": ["Versions", "Macros", "Modules", "Community", "Events", "Enhancement", "Criticism", "Competitors", "Notes", "External links"], "title": "Microsoft Dynamics GP"},
{"content": "Microsoft Dynamics CRM is a customer relationship management software package developed by Microsoft. The product focuses mainly on Sales, Marketing, and Service (help desk) sectors, but Microsoft has been marketing Dynamics CRM as an CRM platform and has been encouraging partners to use its proprietary (.NET based) framework to customize it. It is part of the Microsoft Dynamics family of business applications.Dynamics CRM is a server-client application, which, like Microsoft SharePoint, is primarily an IIS-based web application which also supports extensive web services interfaces. Clients access Dynamics CRM either by using a browser or by a thick client plug-in to Microsoft Outlook. Besides Internet Explorer the Chrome and Firefox browsers are fully supported since Microsoft Dynamics CRM 2011 Update Rollup 12.[2]The current version is Dynamics 365. The name and licencing changed with the update from Dynamics 2016. Note Microsoft Dynamics CRM has over 40,000 customers.[3][4]History[edit]\nMicrosoft CRM 1.0 launched in January 2003.\nMicrosoft CRM 1.2 was released December 8, 2003.[5] Microsoft CRM 1.2 was not widely adopted by industry.[citation needed]\nMicrosoft Dynamics CRM 3.0\n\nThe second version was rebranded as Microsoft Dynamics 3.0 (version 2.0 was skipped entirely) to signify its inclusion within the Dynamics product family and was released December 5, 2005.[6] Notable updates over version 1.2 are the ease of creating customizations to CRM, the switch from using Crystal Reports to Microsoft SQL Reporting Services, and the ability to run on Windows Vista and Outlook 2007.\nSignificant additions released later by Microsoft also allowed Dynamics CRM 3.0 to be accessed by various mobile devices and integration with Siebel Systems.\nThis was the first version that saw reasonable take up by customers.\n\nMicrosoft Dynamics CRM 4.0\n\nDynamics CRM 4.0 (a.k.a. Titan) introduced in December 2007 (RTM build number 4.0.7333.3 Microsoft CRM build numbers from version 4.0 to version 8..*). It features multi-tenancy, improved reporting security, data importing, direct mail merging and support for newer technologies such as Windows 2008 [7] and SQL 2008 (Update Rollup 4).[8]\nDynamics CRM 4.0 also implements CRM Online, a hosted solution that is offered directly by Microsoft. The multi-tenancy option also allows ISVs to offer hosted solutions to end customers as well.\nDynamics CRM 4.0 is the first version of the product which has seen significant takeup in the market and passed the 1 million user mark in July 2009.[9]\n\nMicrosoft Dynamics CRM 2011\n\nDynamics CRM 2011 was released to open Beta in February 2010\nIt then went into Release Candidate stage in December 2010\nThe product was then released in February 2011 (build number 5.0.9688.583)\n\nMicrosoft Dynamics CRM 2013\n\nDynamics CRM 2013 was released to a closed beta group on 28th of July 2013.\nDynamics CRM 2013 Online went live for new signups in October 2013.\nDynamics CRM 2013 was released in November 2013 (build number 6.0.0000.0809).\n\nMicrosoft Dynamics CRM 2015\n\nDynamics CRM 2015 was announced in September 2014 (RTM build number 7.0.0.3543).[10]\n\nMicrosoft Dynamics CRM 2016\n\nMicrosoft Dynamics CRM 2016 was officially released on November 30, 2015.[10]\nVersions for CRM 2016 was 8.0, 8.1 and 8.2. With version 8.2 the name, Microsoft Dynamics CRM 2016,was changed to Dynamics 365\n\nMicrosoft Dynamics 365\n\nThe lasted update called the July update came in October 2017 and was called Dynamics 365, with version number 9.0\nsee Dynamics_365\nMicrosoft Dynamics CRM 4.0.0[edit]Versions[edit]- Workgroup EditionThis edition is only allowed 5 CALs maximum,it is not possible to add more CALs. If more CALs are needed, an upgrade to Professional or Enterprise should be done. Also all the server roles are installed on 1 machine and cannot be separated. You can only create 1 organization in this version and the use of external connectors is not allowed. This version is ideal for small organizations that can use it with the SQL Server Workgroup Edition and on a Windows Small Business Server.- Professional EditionThe Professional Edition has the same functionality as the Workgroup Edition except there is no limit on the CALs. If the installation profile calls for supporting either multiple organizations or servers, the Enterprise Edition is required.- Enterprise EditionHas the same functionality as the Professional Edition but without limits. This version is to be used when multiple divisions should be accessing CRM from one platform.- Service Provider EditionThis edition is actually an Enterprise Edition that is configured to accept Internal user requests from AD and external user requests through IFD (Internet Facing Deployment). This version is mostly implemented by Microsoft Partners that offer Hosted CRM functionality, when letting external users connect to this CRM version through the Internet..Licensing[edit]Microsoft Dynamics CRM offers two types of licenses: Server license and Client Access License (CAL). Each deployment should have at least one server license and one CAL. CAL is also known as a user license.There are two types of Client CAL:- Named User CAL: This is tied with the user name i.e. the user can access MSCRM from any computer.- Device CAL: This is tied with the Device (i.e., CRM can be accessed from only one device). This model is useful in environments such as Call Centers.Read Only LicensesNew in Microsoft Dynamics CRM 4.0 are readonly licenses. Users that do not have to have write permissions can be assigned Read Only licenses. These licenses are cheaper because they do not allow any write operations on the records. If later a user should be able to perform a write operation, a step-up license can be bought to upgrade the Read-Only license to a Full Client Access License.Full Use Licenses Full Use Licenses are licenses where the client (user / device) has read, write and update permissions.External Connector LicensesWhenever an application (windows or web) reads or writes data from/in Microsoft Dynamics CRM, an external connector license is required. External Connector licenses are only valid when bought for a Professional or Enterprise edition. It is not allowed to use them with a Workgroup Edition.These also come in three forms:- External Connector: Is a combination of the Limited External Connector (that provides Read Only functionality) and the Full Use Additive External Connector (that provides Write Only functionality)- Limited External Connector: Provides Read Only functionality for the external application. This license can be upgraded to an 'External Connector License' when the Full Use Additive External Connector is bought.- Full Use Additive External Connector: Provides the Write functionality to a Limited External Connector license.Dynamics CRM version 4.0 adds a number of new features, including support for duplicate data detection and other enhancements. Perhaps most importantly, CRM 4.0 provides true multi-tenancy, which will allow the creation of multiple organizations on a single server. CRM 4.0 was released with the following improvements:\nMore powerful and easier to configure Reporting and BI (now based on SSRS instead of Crystal)\nMore powerful data import tools, de-duplication capability now included\nEnhanced entity relationships \u2013 many to many, self-referential\nImproved programmability \u2013 enhanced Web Services, unified event model, plug-ins to replace callouts\nLight enquiry user license now available \u2013 potentially reducing the costs associated with rolling out across larger organizations\nMulti Tenancy \u2013 One server can host more than one business organization\nMulti Currency\nMulti Lingual\nMicrosoft Office Communicator / Windows Live Messenger presence integration support\ncloud computing with Microsoft Online Services\nUpdates[edit]Microsoft publishes updates for Microsoft Dynamics CRM (called Rollups) every two months. At the time of writing, CRM 4.0 Rollup 21 is available. For CRM 2011, rollup 18 is available. For CRM 2013, rollup 3 is available which was introduced after an SP1 releases.Accelerators for Microsoft Dynamics CRM[edit]In order to maximize the integration with other products and to enable basic templating, Microsoft released the Accelerators, a set of basic vertical solution templates that can be used to extend Microsoft Dynamics CRM in a few directions. These accelerators could be downloaded (for free) from the CodePlex website and adapted by the organization itself. This was eventually retired Feb 28, 2013.End of life[edit]Mainstream Support for Microsoft Dynamics 4.0 ended on April 9th, 2013. [11], [12]Extended support for Microsoft Dynamics 4.0 will end on April 10, 2018. [13], [14]Microsoft Dynamics CRM 2011[edit]Microsoft Dynamics CRM 2011 is available as a cloud offering or an on-premises installation by a partner/customer. As in CRM 4 these versions can be highly customized using advanced extensions. New feature set includes \u2013 Visualizations, Dashboards, Document Management, Grid Filters, Dialogs, Recurring Appointments, Custom Activities, Goal Management, Fetch based Reports, MAPI based Outlook clients, FLS, etc.\nNative integration with SharePoint 2010\nAbility to create a query behind a look-up\nPlacing of a grid with child records on the parent record\nAuto filter sorting capability like in Microsoft Office Excel\nMicrosoft Office Ribbon interface replaces menus\nOData endpoints\nLINQ programming API in the SDK\nWCF services\nGlobal Optionset which can be used for other entities\nCustomization can be packaged as solutions\nCRM Online supports plugins in sandboxed mode\nMultiple forms per entity\nDashboard designer\nYammer integration\nLync integration\nThe Microsoft Dynamics CRM 2011 RTW/RTM is available since January and mid February 2011 respectively. 41 languages are supported.Microsoft Dynamics CRM 2013[edit]Microsoft Dynamics CRM 2013 is available as a cloud offering, on-premises or a hybrid of cloud and on-premises installation by a partner/Customer.\nNavigation drops down from the top of the screen. The old navigation pane is gone\nYou can hover over the Microsoft Dynamics CRM logo to access different work areas\nClicking on a work area will bring you to the record types you work with most often\nTo get to other info related to the record you're viewing, all you have to do is click the arrow next to the name of the record\nYou can edit info inline rather than having to flip to a different screen\nYou can add notes to each record\nLookup lists and inline editing help keep data current\nNo longer have to click save. Records are saved automatically\nCRM 2013 applications for Windows Phone, iPhone, Android, & Windows 8\n5 \u2013 200 GB of storage\nProcess-driven user experience\nContractual privacy protections via European Model Clauses\nMicrosoft Dynamics CRM 2015[edit]On Sept. 16, 2014, Microsoft announced that Microsoft Dynamics CRM 2015, as well as updates to its Microsoft Dynamics CRM Online and Microsoft Dynamics Marketing services, will be generally available in the fourth quarter of 2014. Microsoft also released a preview guide with details.\nOn Nov 30, 2014 Microsoft announced the general availability of Microsoft Dynamics CRM 2015 and the 2015 Update of Microsoft Dynamics Marketing.[15]\nOn Jan 6, 2015, Microsoft announced the availability of a CRM Cloud service specifically for US Government that is designed for FedRAMP compliance.[16]Microsoft Dynamics CRM 2016[edit]Microsoft Dynamics CRM 2016 was officially released on November 30, 2015. In the official press release Microsoft calls this \u201cThe most comprehensive upgrade ever for Dynamics CRM\u201d and says it \u201cincludes advancements in intelligence, mobility and service, with significant productivity enhancements\u201d.[17] In June 2016 was developed a special application which sends scanned info from business cards into MS Dynamics CRM named Business Card Reader for MS Dynamics and Call Tracker application in 2017.Microsoft Dynamics 365[edit]\nMicrosoft Dynamics was officially released on November 1,2016.[18] The product is presented as a revolution, combining Microsoft business products (CRM & ERP Dynamics AX)\nThe offer is divided in several applications:\nDynamics 365 for Sales (CRM)\nDynamics 365 for Customer Service (CRM)\nDynamics 365 for Marketing (CRM)\nDynamics 365 for Field Service (CRM)\nDynamics 365 for Project Service Automation (CRM)\nDynamics 365 for Operations (ERP)\nDynamics 365 for Financials (ERP)\n\nThe strategy is to let the customers choose the module they need.\nMicrosoft proposes a general offer, called Dynamics 365 Plan, a Customer Engagement Plan for CRM applications and a unified operations Plan for ERP applications.\n\nThe lasted update called the July update came in October 2017 and was called Dynamics 365, with version number 9.0\nFor more information: Dynamics 365\nMicrosoft SharePoint integration[edit]Since the 2011 version, it is possible to store and manage documents in the context of Dynamics CRM records on a server that is running Microsoft SharePoint. This feature allows to use the advanced SharePoint framework for the content management infrastructure inside Dynamics CRM. With the SharePoint integration, it is also possible to share documents for external users with granted permission but no access to Dynamics CRM account.[19]See also[edit]\nMicrosoft Dynamics\nDynamics 365\nMSSolve[edit]MS Solve is one of the core Incident Management Systems within Microsoft used by their agents to solve the technical issues that arise out of their products. MS CRM is being leveraged to create the DB tables and columns along with security roles management which is replaced by Clarify of amdocs.MIMOS[edit]Microsoft uses a tool called MIMOS \u2013 Microsoft Incident Management Operations System \u2013 to manage Operational requests originating from Microsoft Partners and Customers. MIMOS was co-developed by arvato and Microsoft in support of a multi-year Business Process Outsourcing initiative called FADA. MIMOS is internally developed using Dynamics CRM and Metastorm BPM (also a .NET-based product). MIMOS is used in Microsoft Regional Operations Centers worldwide, and replaced Siebel from Oracle as part of Microsoft's 2011 Siebel-free initiative. MIMOS is an example of using CRM as an XRM platform. MIMOS is being replaced by COSMIC an CRM Online based tool.Community[edit]The CRM community consists of professionals, typically employees of Dynamics Partners, End-users and MS MVPs (Microsoft Most Valuable Professional).The Dynamics CRM User Group (CRMUG) is the largest, user-led community for companies using the software.eXtremeCRM (http://www.extremecrm.com) is the premier event focused exclusively on Microsoft Dynamics 365 and dedicated to advancing best practices and strategies for Microsoft Dynamics CRM organizations.Events[edit]CRMUG SummitCRMUG Summit is held each fall and is an independent, for profit conferenceeXtremeCRM eventThere are two separate eXtremeCRM events held each year, one in Europe and the other in the United States.[20]References[edit]External links[edit]\nMicrosoft Dynamics CRM 2011 System Requirements\nMicrosoft Dynamics CRM Official Website\nCRM 4.0 SDK\nCRM Team Blog\nMicrosoft Dynamics CRM 4.0 for Government\nMicrosoft Dynamics CRM for Education\n[2]\n[3]\n[4]\nKew Gardens Selects Gateway Integrated Microsoft CRM Solution\nOfficial Website\nDynamics CRM Knowledgebase and Ticket System\n", "subtitles": ["History", "Microsoft Dynamics CRM 4.0.0", "Microsoft Dynamics CRM 2011", "Microsoft Dynamics CRM 2013", "Microsoft Dynamics CRM 2015", "Microsoft Dynamics CRM 2016", "Microsoft Dynamics 365", "Microsoft SharePoint integration", "See also", "Community", "Events", "References", "External links"], "title": "Microsoft Dynamics CRM"},
{"content": "XBRL (eXtensible Business Reporting Language) is a freely available and global standard for exchanging business information. XBRL allows the expression of semantic meaning commonly required in business reporting. The language is XML-based and uses the XML syntax and related XML technologies such as XML Schema, XLink, XPath, and Namespaces. One use of XBRL is to define and exchange financial information, such as a financial statement. The XBRL Specification is developed and published by XBRL International, Inc. (XII).XBRL is a standards-based way to communicate and exchange business information between business systems. These communications are defined by metadata set out in taxonomies, which capture the definition of individual reporting concepts as well as the relationships between concepts and other semantic meaning. Information being communicated or exchanged is provided within an XBRL instance.Early users of XBRL included regulators such as the U.S. Federal Deposit Insurance Corporation[2] and the Committee of European Banking Supervisors (CEBS).[3] Common functions in many countries that make use of XBRL include regulators of stock exchanges and securities, banking regulators, business registrars, revenue reporting and tax-filing agencies, and national statistical agencies.A wiki repository of XBRL projects is available to be freely explored and updated.[4] Within the last ten years, the Securities and Exchange Commission (SEC) in the United States, the United Kingdom's HM Revenue and Customs (HMRC), and Companies House, Singapore had begun to require companies to use it, and other regulators were following suit.[5] Development of the SEC's initial US GAAP Taxonomy was led by XBRL US and was accepted and deployed for use by public companies in 2008 in phases, with the largest filers going first: foreign companies which use International Financial Reporting Standards (IFRS) are expected to submit their financial returns to the SEC using XBRL once the IFRS taxonomy has been accepted by the SEC. In the UK in 2011, both HMRC and Companies House accepted XBRL in the iXBRL format. XBRL was adopted by the Ministry of Corporate Affairs (MCA) of India for filing financial and costing information with the Central Government.[6]Specification[edit]The current version of XBRL is 2.1, with errata corrections.[7] A conformance suite is available to test processors of XBRL documents.XBRL document structure[edit]In typical usage, XBRL consists of an XBRL instance, containing primarily the business facts being reported, and a collection of taxonomies (called a Discoverable Taxonomy Set (DTS)), which define metadata about these facts, such as what the facts mean and how they relate to one another. XBRL uses XML Schema, XLink, and XPointer standards.XBRL Instance[edit]The XBRL instance begins with the <xbrl> root element. There may be more than one XBRL instance embedded in a larger XML document. The XBRL instance itself holds the following information:\nBusiness Facts \u2013 facts can be divided into two categories\n\nItems are facts holding a single value. They are represented by a single XML element with the value as its content.\nTuples are facts holding multiple values. They are represented by a single XML element containing nested Items or Tuples.\n\n\nIn the design of XBRL, all Item facts must be assigned a context.\nContexts define the entity, e.g., company or individual, to which the fact applies, the period of time the fact is relevant, and an optional scenario. Date and time information appearing in the period element must conform to ISO 8601. Scenarios provide further contextual information about the facts, such as whether the business values reported are actual, projected, or budgeted.\nUnits define the units used by numeric or fractional facts within the document, such as USD, shares. XBRL allows more complex units to be defined if necessary. Facts of a monetary nature must use a unit from the ISO 4217 namespace.\nFootnotes use XLink to associate one or more facts with some content.\nReferences to XBRL taxonomies, typically through schema references. It is also possible to link directly to a linkbase.\nThis is an example of a fictitious Dutch company's International Financial Reporting Standards (IFRS) statement instance file :XBRL Taxonomy[edit]An XBRL Taxonomy is a collection of taxonomy schemas and linkbases. A taxonomy schema is an XML schema document (file). Linkbases are XML documents (file) which follow the XLink specification. The schema must ultimately extend the XBRL instance schema document and typically extend other published XBRL schemas on the xbrl.org website.\nTaxonomy schemas define Item and Tuple concepts using <xsd:element> elements. Concepts provide names for the fact and indicate whether or not it is a tuple or an item, the data type (such as monetary, numeric, fractional, or textual), and potentially more metadata. Items and Tuples can be regarded as implementations of concepts, or specific instances of a concept. A good analogy for those familiar with object oriented programming would be that Concepts are the classes and Items and Tuples are Object instances of those classes. This is the source of the use of the XBRL instance terminology. In addition to defining concepts, taxonomy schemas reference linkbase documents. Tuples instances are 1..n relationships with their parents; their metadata is simply the collection of their attributes.\nLinkbases are a collection of Links, which themselves are a collection of locators, arcs, and potentially resources. Locators are elements that essentially reference a concept and provide an arbitrary label for it. In turn, arcs are elements indicating that a concept links to another concept by referencing the labels defined by the locators. Some arcs link concepts to other concepts. Other arcs link concepts to resources, the most common of which are human-readable labels for the concepts. The XBRL 2.1 specification defines five different kinds of linkbases.\n\nLabel Linkbase\nReference Linkbase\nCalculation Linkbase\nDefinition Linkbase\nPresentation Linkbase\n\n\nLabel Linkbase[edit]This linkbase provides human readable strings for concepts. Using the label linkbase, multiple languages can be supported, as well as multiple strings within each language.XBRL aims to become a worldwide standard for electronic business reporting. This requires taxonomies to present business data in many different languages. Therefore, it is important to be able to create an element that is assigned with labels for different languages. There may also be different labels for different purposes. All labels are stored and linked to the elements in a label linkbase. Elements defined in a schema are built to convey accounting meaning to computers. In order to make it easier for computers to process their names, they have to obey some rules. For example, the use of spaces is not allowed so 'Cash and Cash Equivalents' would be named 'CashAndCashEquivalents' . Additionally, big taxonomies such as IFRS obey specific rules of naming and labelling to ensure consistency within the schema. For example, there could be a list of words that are excluded from the names, e.g., :and:, of ..., or words that appear only in a particular order (i.e., 'Net' or 'Total' at the end of the label after a comma). In the label linkbase, elements are connected to human readable labels using concept-label arcrole. As mentioned above, elements can be assigned to labels in different languages. An example that describes definitions of labels of the IFRS element AssetsTotal in English, German and Polish is provided below.To distinguish between languages, XBRL uses the XML attribute lang. Taxonomy creators may also define different labels for one element. One of the ideas of XBRL is that the information about the period and currency for which the element is reported is not contained within an element definition but is described by a context in instance documents. In financial reporting on the other hand, many terms express the date for which they are being reported, for instance Property, Plant and Equipment at the beginning of year and Property, Plant and Equipment at the end of year. XBRL allows the creation of different labels depending on the context in which an element will be used.The example above shows how three different labels are assigned to one element by applying different role attributes on labels.Reference Linkbase[edit]This linkbase associates concepts with citations of some body of authoritative literature.Financial concepts appearing on business reports more often than not stem from regulatory documents issued by authorities. For example, the IFRS Taxonomy describes financial reports prepared based on IFRSs (Bound Volume).[8] Elements defined by this taxonomy refer to the specific terms and concepts explained in the standards. For this reason, a taxonomy is often provided with a reference linkbase that presents relationships between elements and external regulations or standards (the other solution is to enclose documentation in label linkbase). This helps instance creators and users understand the intended meaning of each element and provides support for its inclusion in the taxonomy. The reference layer does not contain the full text of the regulations. Instead, it points to source documents by identifying their name and indicating the relevant paragraphs and clauses. This connection is created using concept-reference arcrole. There are several types of references that could be provided for each element.The example above indicates references for Cash Flow from (Used in) Operations. First, it provides a reference to a document which explains how and where the element should be presented in terms of its placement and labeling. In IAS 7, paragraph 14 we read that the concept Cash Flows from Operating Activities exists and what it is derived from. Second, the measurement reference provides explanations about what determines the value of the element and how it should be calculated. This description can be found in IAS 7 paragraph 18.a. XBRL also allows an element to be assigned other types of references containing examples, commentaries, etc.Calculation Linkbase[edit]This linkbase associates concepts with other concepts so that values appearing in an instance document may be checked for consistency.The idea of the calculation linkbase is to improve the quality of an XBRL report. It contains definitions of basic validation rules, which apply to all instance documents referring to a particular taxonomy. A hierarchical calculation linkbase sorts all monetary elements in this way so that lower level elements sum up to or are subtracted from one another so that the upper level concept is the result of these operations.The sign of the relationship depends on the weight attribute that is assigned to the arc connecting two elements. An example is provided below.The example shows that there are defined two calculation arcs providing details concerning relations between Gross profit, Revenue and Cost of Sales. In Income Statements, Gross profit is the difference between the other two. Therefore, we assign weight attribute value to 1 on the arc connecting Gross profit and Revenue and -1 between Gross profit and Cost of Sales. The reason why there is a difference between calculation and presentation linkbases, is that the total element that stands for the summation of all others usually appears at the bottom in the financial statements whereas in the calculation linkbase it must be placed as the top concept.\nPresentation    Calculation \nAssets (Presentation)                        Assets, Total       \n        Assets, Non-Current                     Assets, Non-Current     +1\n        Assets, Current                         Assets, Current         +1\n        Assets, Total                            \nThere are two major rules concerning calculation relations in XBRL. Firstly, we cannot carry out operations on elements that have different values of the periodType attribute. This is often called the cross-context rule and relates to defining some elements as For period (duration) and others as As of date (instant). For example, concepts that appear on the Balance Sheet are instant: which means that their value is presented for a specified day, while elements in the Income Statement or Statement of Cash Flows are duration: because they represent actions that took place over a period of time. The problem emerges for example in the Statement of Changes in Equity or Movements in Property, Plant and Equipment where instant elements mix with duration. The solution to this problem is a formula linkbase that will provide taxonomy creators with many more functions than just simple addition or subtraction. Secondly, the double entry accounting rule requires XBRL taxonomy creators to define the credit/debit nature of monetary elements appearing in the Balance Sheets and Income Statements. This rule does not only disallow the addition of elements with opposite balance attributes\u2014they must be subtracted\u2014it also defines whether the numerical value contained within an element should be positive or negative.Definition Linkbase[edit]This linkbase associates concepts with other concepts using a variety of arc roles to express relations such as is-a, whole-part, etc. Arc roles can be created by those who create XBRL taxonomies or commonly used arc roles can be added to the XBRL Link Role Registry (LRR).The definition linkbase provides taxonomy creators with the opportunity to define different kinds of relations between elements. There are four standard types of relationships supported by the definition linkbase.The first one is referred to as general-special. It distinguishes between concepts that have more generic or more specific meaning. For example, ZIP code is the US representation of Postal Code which is used worldwide. Therefore, to indicate that connection, taxonomy creators define Postal Code as a general term to which there is more specialised concept ZIP code.Second available relation type is essence-alias. By using it, taxonomy creators are able to indicate that two concepts have similar meaning. For example, some airlines may want to use the term Planes to describe their main component of their PPE while other would prefer Aircraft. To state that meaning of these two is the same and that they can be used interchangeably, taxonomy creators may connect them using essence-alias arcrole.The third standard type of relation is called requires-element. As its name indicates, taxonomy builders use it to force instance creators to enter the value of one element, if they provide the content of another. For instance, a regulator may want to require disclosures on a particular component of Assets if it appears on the Balance Sheet. In order to achieve that, the definition linkbase defines requires-element relationship between them (for example, Property, Plant and Equipment, Net and Property, Plant and Equipment Disclosures).The fourth relation is similar-tuples. It resembles essence-alias relation but is applied for tuples. It connects two tuples that are equivalents in terms of definition (documentation from label linkbase or reference in reference linkbase) but are diverse from XML perspective i.e., do not have identical content models, for example contain different elements. One of the reasons that this type of relation was introduced is the prohibition of schema redefinition which prevents changes in a tuple's content model.Presentation Linkbase[edit]This linkbase associates concepts with other concepts so that the resulting relations can guide the creation of a user interface, rendering, or visualisation.Business reports are in general prepared in the form of tables or statements or other structures. The presentation linkbase stores information about relationships between elements in order to properly organize the taxonomy content. This allows the elements to be arranged in a structure that is appropriate to represent the hierarchical relationships in particular business data. These groupings can be performed in many ways. For example, a typical Balance Sheet contains Assets, Equity and Liabilities. Assets consist of Current Assets and Non-current Assets. Current Assets are split in Inventories, Receivables and so on. The presentation linkbase, using parent-child relations organizes elements in this way and helps users find concepts they are interested in. The main drawback of a tree-like (hierarchical) structure in a presentation linkbase is that it only allows the presentation of flat lists of elements, while financial statements also contain more sophisticated reports such as Changes in Equity or Movements in Property, Plant and Equipment . The XBRL Consortium is currently working on rendering solutions that would provide for the automatic creation of such reports.This is the taxonomy schema of the above shown instance file:XBRL's Global Ledger Framework (XBRL GL) is the only set of taxonomies that is developed and recommended by XBRL International.XBRL modules[edit]XBRL International has issued and reissued a stability pledge in relation to the core XBRL 2.1 specification. In addition to the core XBRL 2.1 specification, work continues on the development of XBRL modules that define new, compatible functionality.\nXBRL Dimensions \u2013 This module has achieved Recommendation status in 2005. A new edition of the Dimensions 1.0 Specification with errata corrections was issued on 7 September 2009. The Dimension 1.0 Specification is an optional extension to the XBRL 2.1 Specification that enriches the rules and procedures for constructing dimensional taxonomies and instance documents. It supports the use of XBRL taxonomy linkbases to define additional, structured contextual information for business facts. Each piece of contextual information is referred to as a dimension. The base XBRL specification essentially defines three dimensions: reporting period, reporting entity (i.e.; a company or a division thereof), and a loosely defined reporting scenario, originally intended to distinguish between actual vs. projected facts. Taxonomies using XBRL Dimensions can define new dimensions, specify the valid values (domains) for dimensions, designate which dimensions apply to which business concepts through mechanisms called hypercubes, and relate other taxonomy metadata (labels, presentation information, etc.) to dimensions.\nXBRL Formula \u2013 This module achieved Recommendation status 22 June 2009. The Formula Specification 1.0 supports the creation of expressions (using XPath) that can be applied to XBRL instances to validate its information or to calculate new XBRL facts in a new instance. To see how formula components interrelate, click Interactive diagram of related Formula specifications\nInline XBRL (or iXBRL) \u2013 This module achieved Recommendation status 20 April 2010. The Inline XBRL Specification defines how XBRL metadata can be embedded within well-formed HTML or XHTML documents, so that data and associated rendering information can be encapsulated within a single document.\nXBRL Versioning \u2013 This module achieved Recommendation status 27 February 2013. This specification enables creation of Versioning Report which can be used by the authors of XBRL taxonomies to provide documentation of the changes between two taxonomies. Many large taxonomies (such as the IFRS taxonomy) change every year.\nXBRL Table Linkbase \u2013 This module allows taxonomy authors to define tabular reporting templates. The Table Linkbase can be used for presentation of XBRL data, and also for data entry, by allowing software to present a template for completion by the user. The Table Linkbase is well-suited to handling large, highly-dimensional reporting templates such as those used for Solvency II reporting to EIOPA, and COREP and FINREP reporting to the EBA.\nExtensibility[edit]Besides the creation of additional modules, XBRL International supports several methods for continuing expansion of shared XBRL functionality.\nLink Role Registry \u2013 This registry, hosted at xbrl.org, collects link roles and arc roles to promote reuse across taxonomies.\nFunctions Registry \u2013 This registry collects XPath functions for reuse in formula linkbases.\nTransformation Rules Registry \u2013 This registry collects common transforms used to convert human-readable data in Inline XBRL documents (e.g. 1st January 2016) into the formats required by XBRL (2016-01-01).\niXBRL[edit]iXBRL (Inline XBRL) is a development of XBRL in which the XBRL metadata are embedded in an HTML document, e.g., a published report and accounts.[9] It requires the HTML document to be well-formed[10] but does not otherwise specify the required XML format. Typically, iXBRL is implemented within HTML documents, which are displayed or printed by web browsers without revealing the XBRL metadata inside the document. The specification does, however, provide a normative schema which requires that any schema-valid iXBRL document should be in XHTML format.[10]Most iXBRL financial reports are produced in one of two ways:\nThe system which creates the report formats it directly in iXBRL. In the UK, where all companies are required to file in iXBRL, the main commercial accounting packages all provide iXBRL export of financial reports.\nThe financial report is produced as a Microsoft Word or Microsoft Excel document, and a Tagging Program is used to add the XBRL concept metadata and to export the document as Inline XBRL.\nWith large and complex financial statements, a single iXBRL file may be too large for a web browser to handle. This happens more often when, as in the UK, the company report, which may contain many graphics, is combined with the accounts in a single iXBRL document. The iXBRL specification allows for a set of iXBRL documents to be treated as a single iXBRL document set.[11]The word processing package which has been enhanced for iXBRL most widely is Microsoft Word. This allows round-tripping between its own format for the precise layout of documents and HTML through the use of non-standard extensions to HTML. The iXBRL tags are typically held as comments within the document.In the UK, HM Revenue and Customs requires businesses to submit their report and accounts and tax computations in iXBRL format when making their Corporation Tax return. Businesses and their agents can use HMRC's Online Filing software[12] to prepare their report and accounts and tax computations in iXBRL format or they can prepare the iXBRL files themselves and submit them to HMRC.HMRC's Online Filing software is an example of a program which generates iXBRL from source data. This uses a series of forms in which the key data (which will appear in XBRL tags) are entered in data entry fields. Additional data (the rest of the report and accounts) are entered in text boxes. The program generates the iXBRL report and accounts in a standard sequence of sections and a standard format. All other formatting of material is lost. While the resulting report and accounts meets HMRC's requirements, it is not an attractive document to view or read.iXBRL is mandated for corporate filings by government agencies in Japan, Denmark and the United Kingdom. In the United Kingdom, Companies House also accepts iXBRL. Although iXBRL is not mandated by Companies House, it makes up the majority of the filings received each year.Since June 2016 the SEC started allowing firms to file using inline XBRL in the required HTML filings. It's believed that the SEC plans to switch to iXBRL in 2020[13][14]History[edit]XBRL's beginning, in 1998,[15] can be traced to the initial efforts of one person, Charles Hoffman, a Certified Public Accountant from Tacoma, Washington. The American Institute of Certified Public Accountants (AICPA) was also instrumental in pulling together what eventually became XBRL International.[16]The specification went through several versions prior to XBRL v2.1 which was published in 2003.\n1.0 \u2013 Published in July 2000,[17] this version was based on DTDs. It expressed the difference between data exchange in instance documents and metadata exchange in taxonomy documents. Taxonomies were expressed as XML Schema files, but these were not used for instance validation.\n2.0 \u2013 This version introduced use of XML Schema substitution groups as a way of allowing schema validation of instances.[when?] Concept relations were broken out into separate XLink-based linkbases. Context data in the instance was collected into a separate element.\n2.1 \u2013 Published December 31, 2003,[17] this version tightened the definition of terms significantly, allowing for the introduction of a conformance suite.\nXBRL v2.1 has remained stable since publication, and has been updated only for errata corrections. The standard has evolved significantly through the development of additional XBRL modules. Details of all versions of the specification and associated modules can be found on the XBRL Specification Subsite.Lack of accuracy[edit]In April 2009 a study of the North Carolina State University Department of Accounting College of Management evaluated the accuracy of XBRL filings for 22 companies participating in the SEC's voluntary filing program in 2006.[18] Results of a comparison of XBRL filings to Forms 10-K revealed multiple errors in signage, amounts, labeling, and classification. The study considers that these errors are serious, since XBRL data are computer-readable and users will not visually recognize the errors, especially when using XBRL analysis software.A different conclusion was reached by Du et al., 2013 [19] who argued that companies are going through a learning curve and are steadily improving.In December 2017, Charlie Hoffman, the father of XBRL, states that there is a 10.2% chance that an XBRL-based public company financial report has errors in its primary financial statements. Hoffman predicts that per the current number of errors and the pace errors are being corrected, within about five years the information quality of XBRL-based public company financial reports will be very good.[20]Impact of XBRL[edit]An evaluation by Debreceny, Roger S., et al. 2005, of the impact of Financial Reporting in XBRL on the SEC's EDGAR System [21]A tool for converting the consolidated balance sheet, income statement, and statement of cash flows into XBRL\u2010tagged format.[22]Corporate governance is significantly and positively associated with a firm's decision to be an early and voluntary filer of financial information in XBRL format. Premuroso and Bhattacharya, 2008 [23]See also[edit]\nXBRL assurance\nReferences[edit]External links[edit]\nOfficial website\nThe XBRL Specification subsite - information for developers, with direct access to specifications, conformance suites and FAQ\nXBRL US official website - the US jurisdiction of XBRL International, the national consortium for standardized business reporting, creator of the initial XBRL US GAAP Taxonomy, under contract with the U.S. Securities and Exchange Commission.\nCurry, E.; Harth, A.; O'Riain, S. (2009). Challenges Ahead for Converging Financial Data. Proceedings of the XBRL/W3C Workshop on Improving Access to Financial Data on the Web. \nUnited Kingdom companies accounts search, full access to all Inline XBRL accounts filed at Companies House in the UK\nXBRL Link Role Registry (LRR)\nXBRLS: how a simpler XBRL can make a better XBRL\nWhite paper on the use of XBRL (PDF). (ACT-IAC) American Council for Technology and Industry Advisory Council. February 2007. \nHolland, L.E.F. (2004). XML Flattened: The lessons to be learnt from XBRL (PDF). \n", "subtitles": ["Specification", "XBRL document structure", "XBRL modules", "Extensibility", "iXBRL", "History", "Lack of accuracy", "Impact of XBRL", "See also", "References", "External links"], "title": "XBRL"},
{"content": "Neil Harrison is a British musician and dramatist. He was a founder-member of The Beatles tribute band, The Bootleg Beatles, in which he played John Lennon. He was replaced by Adam Hastings in 2011. He went to the University of Sheffield and was a flat mate with Brodie Pevans.The Bootleg Beatles[edit]In 1979, aged 28, Harrison had joined the cast of the West End musical Beatlemania.[2] In March 1980, after the musical's last West End show, Harrison formed The Bootleg Beatles with fellow cast members Andre Barreau and David Catlin-Birch. The band invested their dwindling finances in two guitars - an Epiphone and a Gretsch - as well as two Vox amplifiers, four black polo-necks and a wig.[3]On 26 March 2011 at a gig in St Albans, Neil Harrison \u2013 otherwise known as 'Bootleg John' \u2013 shocked the audience after coming to the stage to perform 'Imagine' as an encore by announcing that he was leaving the group 'to bring the average age down a bit'. He sang Imagine after shouts of support and thanks from the crowd and was presented with a bouquet of flowers and a further gift from the band. The Bootlegs then performed Back in the U.S.S.R. followed rather fittingly by the medley of songs from the Abbey Road album that culminates with The End. The band left the stage to a standing ovation and further shouts of thanks to Neil.Meet the Beatles[edit]Harrison has stated that he has met two original Beatles, on three different occasions.His first experience was in 1968, when he and some friends sang Christmas carols outside Paul McCartney's father's house on the Wirral.The second meeting was in 1996 at David Gilmour's 50th birthday party. Gilmour booked both the Bootleg Beatles and the Australian Pink Floyd Show as he'd always wanted to have the Beatles support Pink Floyd.[citation needed] George Harrison was in the audience and quipped you probably know the chords better than I do and Where's the Bootleg Brian Epstein? 'Cos he's got all the money!.[2]The third meeting was at the Party at the Palace for the Golden Jubilee of Elizabeth II in 2002, where McCartney headlined.Other works[edit]Outside the Bootleg Beatles, Harrison released an album in 1974 on Deram Records called All Dressed Up and Nowhere To Go. The album sounds very similar to The Beatles' works.He also wrote several songs for Lulu's album Don't Take Love For Granted, including the title track and I Could Never Miss You (More Than I Do), which was released as a single in 1981 and also included on her 1981 self-titled album Lulu. He has released another solo album entitled Richmond Hill. He sang an acoustic version of Stawberry Fields Forever for the 2013 Spanish movie Living is Easy with Eyes Closed.References[edit]", "subtitles": ["The Bootleg Beatles", "Meet the Beatles", "Other works", "References"], "title": "Neil Harrison"},
{"content": "Richard P. Gabriel (born 1949) is an American computer scientist who is known for his work related to the Lisp programming language (and especially Common Lisp) in computing. His best known work was a 1990 essay \u201cLisp: Good News, Bad News, How to Win Big\u201d, which incorporated the phrase Worse is Better,[1] and his set of Lisp benchmarks (the Gabriel Benchmarks), published in 1985 as Performance and evaluation of Lisp systems, which became a standard way of benchmarking Lisp implementations.Biography[edit]He was born in 1949, in the town of Merrimac in northeastern Massachusetts to two dairy farmers. He studied at Northeastern University, where he earned a B. A. in Mathematics (1967\u20131972). Currently he resides in Redwood City, California with his wife, Jo. He has a son named Joseph, and a daughter named Mariko, a Doctor of Physical Therapy in Los Altos, California.Studying[edit]Subsequently, he pursued graduate studies in mathematics at MIT, from 1972\u201373; he was tapped by Patrick Winston to become a permanent member of the AI Lab at MIT, but funding difficulties made it impossible to retain him. Gabriel tried to start up, with Dave Waltz, an AI Lab at the University of Illinois, but after two years the lab fell through due to general apathy.[citation needed] Gabriel did in this time period manage to earn an MS in Mathematics however (1973\u20131975).Because of some of his mathematical work, Gabriel was then admitted to Stanford University; during that period (1975\u20131981), he served as a Teaching Assistant to John McCarthy, the founder of Lisp; he ported Maclisp from its native ITS to WAITS; he earned a PhD. in Computer Science (on the topic of natural language generation); and he and his wife Kathy had a son. Around this time period, he became a spokesperson for the League for Programming Freedom.Postdoc[edit]After he earned a PhD, he continued to work on AI projects for McCarthy, although his thesis advisor was Terry Winograd. He eventually began working for Lawrence Livermore National Labs, where he recruited a number of the researchers and programmers for a company he founded in 1984 (and would leave in 1992), and would survive until 1994, Lucid, Incorporated.Gabriel was at various times the President and Chairman of Lucid Inc. The product the company shipped was an integrated Lisp IDE for Sun Microsystems\u2019 RISC hardware architecture. This sidestepped the principal failure of Lisp machines by, in essence, rewriting the Lisp machine IDE for use on a more cost-effective and less moribund architecture. During this time period, Gabriel married his second wife, and had a daughter; he later divorced his second wife in 1993.Eventually Lucid's focus shifted (during the AI Winter) to an IDE for C++. A core component of the IDE was Richard Stallman\u2019s version of Emacs, GNU Emacs. GNU Emacs was not up to Lucid\u2019s needs, however, and several Lucid programmers were assigned to help develop GNU Emacs. Friction arose between the programmers and Stallman over how to handle GUI issues, and Lucid forked; thus they were primarily responsible for the birth of what would come to be called XEmacs. One of his hires was another notable programmer, Jamie W. Zawinski.Own business and open source[edit]After Gabriel left Lucid, Inc. for good, he became a Vice President of Development for ParcPlace Systems (1994\u20131995), and then a consultant, for, among others, Aspen Smallworks, before joining Sun Microsystems. As a Distinguished Engineer at Sun,[2] Gabriel was an influential contributor to the evolution of the open source software strategy,[3] culminating in publication of the book Innovation Happens Elsewhere.[4] In 2007, he joined IBM Research as a Distinguished Engineer.ACM[edit]Gabriel is the recipient of Association for Computing Machinery's 1998 Fellows Award[5] and the 2004 Allen Newell Award. The citation reads: \u201cFor innovations not only on fundamental issues in programming languages and software design but also on the interaction between computer science and other disciplines, notably architecture and poetry.\u201d[citation needed]He was the conference chair of the 2007 OOPSLA.Trivia[edit]In 1998 he received his MFA in Poetry from Warren Wilson College. He has published poems in some literary journals. His chapbook, Drive On, was published by Hollyridge Press in 2005.[citation needed]Works[edit]\nGabriel, Richard P. (May 1985). Performance and Evaluation of Lisp Systems (PDF). Cambridge, Mass: MIT Press; Computer Systems Series. ISBN 9780262070935. LCCN 85-15161. \nGabriel, Richard P. (1996). Patterns of Software: Tales from the Software Community (PDF). Oxford University Press. ISBN 0-19-512123-6. \nGabriel, Richard P. (2002). Writers' Workshops & the Work of Making Things: Patterns, Poetry... (PDF). Addison-Wesley. ISBN 0-201-72183-X. \nGabriel, Richard P. (2005). Drive On. Hollyridge Press. ISBN 978-0-9752573-8-8. \nReferences[edit]\nGoldman, Ron (2005). Innovation Happens Elsewhere: Open Source as Business Strategy. Morgan Kaufmann. ISBN 1-55860-889-3. \nExternal links[edit]\nOfficial website\nThe ACM Newell Award announcement\nRichard Gabriel interview on Lisp\n", "subtitles": ["Biography", "Works", "References", "External links"], "title": "Richard P. Gabriel"},
{"content": "Defective by Design is an anti-DRM initiative by the Free Software Foundation. DRM technology, known as digital rights management technology by its supporters, restricts users' ability to freely use their purchased movies, music, literature, software, and hardware in ways they are accustomed to with ordinary non-restricted media (such as books and audio compact discs). As a result, DRM has been described as digital restrictions management or digital restrictions mechanisms by opponents.[2][3][4][5][6]The philosophy of the initiative is that DRM is designed to be deliberately defective, to restrict the use of the product. This, they claim, cripples the future of digital freedom. The group aims to target Big Media, unhelpful manufacturers, and DRM distributors and to bring public awareness of the issue and increase participation in the initiative. It represents one of the first efforts of the Free Software Foundation to find common cause with mainstream social activists, and to encourage free software advocates to become socially involved. As of late 2006, the campaign was claiming over 12,000 registered members.[citation needed]View on the impact of DRM[edit]DRM is used to encrypt various multimedia products (including audio, video, and console games) and is intended to restrict the uses of a product to those the rightsholders intend. Examples of DRM functionality include: limiting or prohibiting duplication of media to hopefully prevent copyright infringement or lawful archiving, sharing, of media and encrypting or blocking access to a system's input or output to prevent consumers from using non-licensed products, such as a competitor's hardware or media.[citation needed] DRM can prevent users from duplicating a CD or a DVD, prevent someone watching a DVD from skipping an advertisement, or create problems with interoperability between competing products. Although tech-savvy users are often able to find a way around DRM, this can be difficult and may require use of the analog hole. For others DRM might prevent them from using media in legal ways.[7]In addition to restricting copying of DRM-restricted media, DRM can allow a computer to systematically disobey its owner.[8]History[edit]Defective By Design is a joint effort by the Free Software Foundation and CivicActions, a company that develops online advocacy campaigns. The chief organizers are Gregory Heller of CivicActions, Peter T. Brown, executive director of the Free Software Foundation, and Henry Poole, a CivicActions member who is also a director of the Free Software Foundation.The campaign was launched in May 2006, with an anti-DRM protest at WinHEC. The protest featured Free Software Foundation (FSF) members in yellow hazmat suits handing out pamphlets explaining that Microsoft products are \u2013 in the words of the key slogan for the campaign \u2013 'defective by design' because of the DRM technologies included in them.[9]Since then, the campaign has launched a number of actions with varying degrees of success. The campaign claims that its phone-in campaign against the Recording Industry Association of America[10] and related organizations around the world resulted in thousands of calls from people questioning the industry's position on DRM. On the other hand, efforts to meet with Bono of U2, a prominent supporter of Apple's DRM-regulated iTunes, have so far met with no success. However, four major record labels dropped their pending lawsuits and joined with Apple and Microsoft to eliminate Digital Rights Management from music sales. But in 2016, the day was celebrated on May, 3rd[11]DefectiveByDesign.org proclaimed October 3, 2006 to be a Day Against DRM, and organized several events outside key Apple stores in the US and the UK.[12] Again hazmat suits were worn by protesters and leaflets were handed out to the public explaining Apple's use of DRM in their iTunes music store and on their iPod media players.[13]On January 30, 2007, the campaign organized along with the BadVista campaign at the Times Square. Protesters in hazmat suits then handed literature to attendants about the dangers of Windows Vista's Digital Rights Management and Trusted Computing features, as well as handed over CDs with free software for users to install an alternative to Windows Vista.[14]Tagging campaign[edit]The Defective by Design site encourages users to use the tagging feature of Amazon.com, Slashdot and on other sites that allow tagging, to mark certain products with the 'defectivebydesign' tag.[15] Items targeted include DVD players, DRM-restricted DVD titles, HD DVD and Blu-ray Disc titles, Windows XP and higher, the Zune, and the iPod.See also[edit]\nBroadcast Protection Discussion Group\nFree Software Foundation anti-Windows campaigns\nHardware restrictions\nTrusted Computing\nReferences[edit]External links[edit]\nOfficial website\nStallman, Richard (Nov 18, 2016). Can you trust your computer?. Essay. \n", "subtitles": ["View on the impact of DRM", "History", "Tagging campaign", "See also", "References", "External links"], "title": "Defective by Design"},
{"content": "Nagarjuna G. (Nagarjuna Gadiraju) works in the Homi Bhabha Centre for Science Education, Tata Institute of Fundamental Research in Mumbai, India. His major research interests include Science Education, Cognitive Science, History and Philosophy of Science and Structure and Dynamics of Knowledge. As an activist he focuses on promoting free knowledge and free software and serves as the chairperson of Free Software Foundation of India.Biography[edit]Nagarjuna was born in 1960 at Nagarjuna Sagar, in Andhra Pradesh, India.Education[edit]Nagarjuna did M.Sc. in Biology and M.A. in Philosophy from Mumbai and Ph.D. in Philosophy of Science from IIT Kanpur.Work[edit]Some of his areas of interest are semantic web, knowledge organization, AI, philosophy of science, biological roots of knowledge and modelling complex systems with specific interest in cognitive development. He is the author of a specification and implementation of a distributed knowledge base called GNOWSYS.[1] He is an architect of gnowledge.org, a community portal, which was launched on 2 February 2007. He contributed as a core developer and architect of SELF Platform. He is currently guiding four research scholars in the area of science education at HBCSE, TIFR.Free Software Foundation[edit]Nagarjuna is an active member of the Free Software Foundation in India. He is one of the speakers for the FSF.[2] He is a founding member, current chairperson and the member of the board of directors for the Free Software Foundation of India.[3]History and Philosophy of Science[edit]Nagarjuna has interest in History and Philosophy of Science. He has created an illustrated exhibition on History of Science at Homi Bhabha Centre for Science Education.[4] He also teaches graduate courses in History and Philosophy of Science at Homi Bhabha Centre for science Education and Centre for Excellence in Basic Sciences.[5]References[edit]External links[edit]\nOfficial Page:\nGnowledge Portal:\nPersonal Blog:\n", "subtitles": ["Biography", "Education", "Work", "References", "External links"], "title": "Nagarjuna G."},
{"content": "Dr. Ricardo Adolfo Galli Granada, also known as gallir, is a doctor of computer science at the University of the Balearic Islands, where he teaches operating system design. He is a speaker for the Free Software Foundation and a free software activist.Projects[edit]As a university project, he created a system that allows controlling of the airship parking at the Son Sant Joan Airport in Palma de Mallorca, Balearic Islands, Spain.In December 2005, he programmed Mene\u0301ame, a clone of the well-known Digg Web site, which serves to promote stories published on blogs. He then released the source code of Meneame, which the source code of the open source digg clone Pligg CMS is based on.He programmed cpudyn, a daemon that can be used to underclock portable computers to reduce their power consumption.He programmed wp-cache, a WordPress plugin for the purpose of caching pages to make one's blog faster and more responsive.In 2001, he was nominated for a Hispalinux prize.[1] He has published over 200 technical articles in BULMA, a Catalan Linux user Web site.[2]References[edit]External links[edit]\nRicardo Galli, de software libre \u2014 Galli's old blog (in Spanish)\nmene\u0301ame.net \u2014 Collaborative news site, launched by Galli\n", "subtitles": [], "title": "Ricardo Galli"},
{"content": "The GNU/Linux naming controversy is a dispute between members of the free software community and open-source software community over whether to refer to computer operating systems that use a combination of GNU software and the Linux kernel as GNU/Linux or Linux.GNU/Linux is a term promoted by the Free Software Foundation (FSF) and its founder Richard Stallman.[1] They argue that GNU was a longstanding project begun in 1984 to develop a free operating system, and that when the Linux kernel was independently created in 1991, it merely provided a substantial missing piece.[1] Several distributions employ the FSF-endorsed name, such as Debian,[2] Trisquel[3] and Parabola GNU/Linux-libre.[4]Proponents of the term Linux argue that it is far more commonly used by the public and media,[5][6] and that it serves as a generic term for systems that combine that kernel with software from multiple other sources.History[edit]In 1983, Richard Stallman, founder of the Free Software Foundation, set forth plans of a complete Unix-like operating system, called GNU, composed entirely of free software. In September of that year, Stallman published a manifesto in Dr. Dobb's Journal detailing his new project publicly, outlining his vision of free software.[7][8] Software development work began in January 1984. By 1991, the GNU mid-level portions of the operating system were almost complete, and the upper level could be supplied by the X Window System, but the lower level (kernel, device drivers, system-level utilities and daemons) was still mostly lacking. The GNU kernel was called GNU Hurd. The Hurd followed an ambitious design which proved unexpectedly difficult to implement and has only been marginally usable.Independently, in 1991, Linus Torvalds released the first version of the Linux kernel. Early Linux developers ported GNU code, including the GNU C Compiler, to the kernel. The free software community adopted the use of the Linux kernel as the missing kernel for the GNU operating system. This work filled the remaining gaps in providing a completely free operating system.Over the next few years, several suggestions arose for naming operating systems using the Linux kernel and GNU components. In 1992, the Yggdrasil Linux distribution adopted the name Linux/GNU/X. In Usenet and mailing-list discussions, one can find usages of GNU/Linux as early as 1992[9] and of GNU+Linux as early as 1993.[10] The Debian project, which was at one time sponsored by the Free Software Foundation, switched to calling its product Debian GNU/Linux in early 1994;[6][11][12][13] This change followed a request by Richard Stallman (who initially proposed LiGNUx, but suggested GNU/Linux instead after hearing complaints about the awkwardness of the former term).[14] GNU's June 1994 Bulletin describes Linux as a free Unix system for 386 machines (with many of the utilities and libraries from GNU),[15] but the January 1995 Bulletin switched to the term GNU/Linux instead.[16]Stallman's and the FSF's efforts to include GNU in the name started around 1994, but were reportedly mostly via private communications (such as the above-mentioned request to Debian) until 1996.[17][18] In May 1996, Stallman released Emacs 19.31 with the Autoconf system target linux changed to lignux (shortly thereafter changed to linux-gnu in emacs 19.32),[19][20] and included an essay Linux and the GNU system[21] suggesting that people use the terms Linux-based GNU system (or GNU/Linux system or Lignux for short). He later used GNU/Linux exclusively, and the essay was superseded by Stallman's 1997 essay, Linux and the GNU project.[1]Composition of operating systems[edit]Modern free software and Open-source software systems are composed of software by many different authors, including the Linux kernel developers, the GNU project, and other vendors such as those behind the X Window System. Desktop- and server-based distributions use GNU components such as the GNU C Library (glibc), GNU Core Utilities (Coreutils), and bash.In a 2002 analysis of the source code for Red Hat Linux 7.1, a typical Linux distribution, the total size of the packages from the GNU project was found to be much larger than the Linux kernel.[22] Later, a 2011 analysis of Ubuntu's Natty release (a popular Linux distribution) main repository found that 8% to 13% of it consisted of GNU components (the range depending on whether GNOME is considered part of GNU), while 9% is taken by the Linux kernel.[23] Determining exactly what constitutes the operating system per se is a matter of continuing debate.On the other hand, some embedded systems, such as handheld devices and smartphones (like Google's Android), residential gateways (routers), and Voice over IP devices, are engineered with space efficiency in mind and use a Linux kernel with few or no components of GNU. A system running \u03bcClinux is likely to substitute uClibc for glibc and BusyBox for Coreutils. Google's Linux-based Android operating system does not use any GNU components or libraries, replacing glibc with Google's own BSD-based Bionic C library. The FSF agrees that GNU/Linux is not an appropriate name for these systems.[24][25][26]There are also systems that use a GNU userspace and/or C library on top of a non-Linux kernel, for example Debian GNU/Hurd (GNU userland on the GNU kernel)[27] or Debian GNU/kFreeBSD (which uses the GNU coreutils and C library with the kernel from FreeBSD).[28]Opinions supporting GNU/Linux[edit]The FSF justifies the name GNU/Linux primarily on the grounds that the GNU project was specifically developing a complete system, of which they argue that the Linux kernel filled one of the final gaps;[29] the large number of GNU components and GNU source code used in such systems is a secondary argument:\nSo if you were going to pick a name for the system based on who wrote the programs in the system, the most appropriate single choice would be GNU. But we don't think that is the right way to consider the question. The GNU Project was not, is not, a project to develop specific software packages. [...] Many people have made major contributions to the free software in the system, and they all deserve credit. But the reason it is an integrated system\u2014and not just a collection of useful programs\u2014is because the GNU Project set out to make it one. We made a list of the programs needed to make a complete free system, and we systematically wrote, or found people to write, everything on the list.\n\u2014 Richard Stallman[29]\nIn addition, the FSF also argues that GNU/Linux recognizes the role that our idealism played in building our community, and helps the public recognize the practical importance of these ideals,[24] in contrast to the focus on technical advantage rather than freedom of the Linux kernel developers.[30][31] In the case of the Linux kernel, notable and recurring examples of this focus on technical advantage over freedom come from the long-time inclusion in the Linux kernel of many non-free firmware files and other files with non-free license terms.[1]The ordinary understanding of operating system includes both the kernel\u2014the specific subsystem that directly interfaces with the hardware\u2014and the userland software that is employed by the user and by application software to control the computer. Moreover, both the name GNU and the name Linux are intentionally related to the name Unix, and Unix has always conceptually included the C library and userland tools as well as the kernel.[24] In the 1991 release notes for versions 0.01 to 0.11 of the Linux kernel (which was not released under the GNU General Public License until version 0.12[32]), Torvalds wrote, Sadly, a kernel by itself gets you nowhere [...] Most of the tools used with linux are GNU software.[33] Torvalds also wrote during the 1992 Tanenbaum-Torvalds debate that, As has been noted (not only by me), the linux kernel is a miniscule part of a complete system.[34][35] Tanenbaum had criticized Torvalds for developing Linux as a monolithic kernel, which he considered obsolete and inferior to microkernels such as Mach.[36] He believed that Linux would be rejected in favor of the GNU HURD microkernel, which had stalled in development for years.[37]The use of the word Linux to refer to the kernel, the operating system, and entire distributions, often leads to confusion about the distinctions among the three. Many GNU packages are a key part of almost every Linux distribution, particularly the GNU toolchain, which is present in all distros (unless Android is included). Media sources sometimes make erroneous statements as well, such as claiming that the entire Linux operating system (rather than simply the kernel) was written by Torvalds in 1991;[38] or that Torvalds directs the development of other components such as graphical interfaces or the GNU tools.[citation needed]\nToday tens of millions of users are using an operating system that was developed so they could have freedom\u2014but they don't know this, because they think the system is Linux and that it was developed by a student 'just for fun'.\n\u2014 Richard Stallman[39]\nBecause of this confusion, legal threats and public relations campaigns apparently directed against the kernel, such as those launched by the SCO Group or the Alexis de Tocqueville Institution (AdTI), have been misinterpreted by many commentators who assume that the whole operating system is being targeted. SCO and the AdTI have even been accused of deliberately exploiting this confusion.[40][41][42]Regarding suggestions that renaming efforts stem from egotism or personal pique, Stallman has responded that his interest is not in giving credit to himself but to the GNU Project: Some people think that it's because I want my ego to be fed. Of course, I'm not asking you to call it 'Stallmanix'.[43] Stallman has admitted to irritation, although he believes it to be justified in response to seeing an idealistic project stymied and made ineffective, because people don't usually give it the credit for what it has done, concluding If you're an idealist like me, that can ruin your whole decade.[44]In response to another common argument (see below), the FSF acknowledges that many people have contributed to the system and that a short name cannot credit all of them, but argues that this cannot justify calling the system Linux:\nSince a long name such as GNU/X11/Apache/Linux/TeX/Perl/Python/FreeCiv becomes absurd, at some point you will have to set a threshold and omit the names of the many other secondary contributions. There is no one obvious right place to set the threshold, so wherever you set it, we won't argue against it ... But one name that cannot result from concerns of fairness and giving credit, not for any possible threshold level, is Linux. It can't be fair to give all the credit to one secondary contribution (Linux) while omitting the principal contribution (GNU).\n\u2014 GNU/Linux FAQ by Richard Stallman[24]\nIn continuing to speak on the subject, in 2010, Stallman stated that naming is not simply a matter of giving equal mention to the GNU Project. Because the system is more widely referred as Linux people tend to think it's all Linux, that it was all started by Mr. Torvalds in 1991, and they think it all comes from his vision of life, and that's the really bad problem.[45]Opinions supporting Linux[edit]Linux is by far the more widespread name.[5][6]Eric S. Raymond writes (in the Linux entry of the Jargon File):\nSome people object that the name Linux should be used to refer only to the kernel, not the entire operating system. This claim is a proxy for an underlying territorial dispute; people who insist on the term GNU/Linux want the FSF to get most of the credit for Linux because [Stallman] and friends wrote many of its user-level tools. Neither this theory nor the term GNU/Linux has gained more than minority acceptance.\nWhen Linus Torvalds was asked in the documentary Revolution OS whether the name GNU/Linux was justified, he replied:\nWell, I think it's justified, but it's justified if you actually make a GNU distribution of Linux ... the same way that I think that Red Hat Linux is fine, or SuSE Linux or Debian Linux, because if you actually make your own distribution of Linux, you get to name the thing, but calling Linux in general GNU Linux I think is just ridiculous.[46][47]\nAn earlier comment by Torvalds on the naming controversy was:\nUmm, this discussion has gone on quite long enough, thank you very much. It doesn't really matter what people call Linux, as long as credit is given where credit is due (on both sides). Personally, I'll very much continue to call it Linux, ...\nThe GNU people tried calling it GNU/Linux, and that's ok. It's certainly no worse a name than Linux Pro or Red Hat Linux or Slackware Linux ...\nLignux is just a punny name\u2014I think Linux/GNU or GNU/Linux is a bit more professional ...[48]\nThe name GNU/Linux, particularly when using Stallman's preferred pronunciation (see below), has been criticized for its perceived clumsiness and verbosity,[49][50] a factor that Torvalds has cited as the downfall of operating systems such as 386BSD.[51]The Linux Journal speculated that Stallman's advocacy of the combined name stems from frustration that Linus got the glory for what [Stallman] wanted to do.[52]Others have suggested that, regardless of the merits, Stallman's persistence in what sometimes seems a lost cause makes him and GNU look bad. For example, Larry McVoy (author of BitKeeper, once used to manage Linux kernel development) opined that claiming credit only makes one look foolish and greedy.[53]Many users and vendors who prefer the name Linux, such as Jim Gettys, one of the original developers of the X Window System, point to the inclusion of non-GNU, non-kernel tools, such as KDE, LibreOffice, and Firefox, in end-user operating systems based on the Linux kernel:\nThere are lots of people on this bus; I don't hear a clamor of support that GNU is more essential than many of the other components; can't take a wheel away, and end up with a functional vehicle, or an engine, or the seats. I recommend you be happy we have a bus.[54]\nPronunciation[edit]Although GNU/Linux /\u0261\u0259\u02c8nu\u02d0 sl\u00e6\u0283 \u02c8l\u026an\u0259ks/ is often pronounced without the slash, Stallman recommends explicitly saying the word slash or plus in order to avoid the mistaken suggestion that the Linux kernel itself is a GNU package,[55] as is the case with GNU Linux-libre.See also[edit]\nAlternative terms for free software\nGNU variants\nList of GNU packages\nHistory of free software\nReferences[edit]External links[edit]\nWhy GNU/Linux? (or What's in a name?), by Richard Stallman\nGNU Users Who Have Never Heard of GNU, also by Richard Stallman\nGNU/Linux FAQ by Richard Stallman\nThe Say Lignux Campaign, by Richard Stallman, 2013\nDavid A. Wheeler on why he mostly says GNU/Linux\nStallman explaining the relationship of GNU and Linux, Zagreb, 2006\nWho wrote Linux?, by Josh Mehlman, ZDNet Australia, 7 July 2004\n", "subtitles": ["History", "Composition of operating systems", "Opinions supporting \"GNU/Linux\"", "Opinions supporting \"Linux\"", "Pronunciation", "See also", "References", "External links"], "title": "GNU/Linux naming controversy"},
{"content": "Robert Bob Chassell was one of the founding directors of Free Software Foundation (FSF) in 1985. While on the Board of Directors, Chassell was also the treasurer for FSF.[2] He left the FSF to become a full-time speaker on free software topics. Bob was born on 22 August 1946, in Bennington, VT. He was diagnosed with Progressive Supranuclear Palsy (PSP) in 2010, and died as a result on 30 June 2017.Chassell has authored several books including:\nChassell, Robert J. (2003). Software Freedom: An Introduction. Boston: GNUpress. ISBN 1-882114-95-7. \nChassell, Robert J. (2004). An introduction to Programming in Emacs Lisp. Boston: GNUpress. ISBN 1-882114-56-6. \nReferences[edit]External links[edit]\nA 30 minute audio interview with Robert\nAn online copy of Software Freedom: An Introduction\nAn online copy of An Introduction to Programming in Emacs Lisp\nTribute to Robert J. Chassell on Bradley M. Kuhn's Personal Blog\nTribute to Robert J. Chassell on the Software Freedom Conservancy Website\nRobert J. Chassell's writings are at Richard M. Stallman's personal website\n", "subtitles": [], "title": "Robert J. Chassell"},
{"content": "Free Software Foundation anti-Windows campaigns are the events targeted against a line of Microsoft Windows operating systems. They are paralleling the Defective by Design campaign against digital rights management technologies, but they instead target Microsoft's operating systems instead of DRM itself.BadVista[edit]BadVista was a campaign by the Free Software Foundation to oppose adoption of Microsoft Windows Vista and promote free software alternatives. It aimed to encourage the media to make free software part of their agenda.[1]The campaign was initiated on December 15, 2006 with aims to expose what it views as the harms inflicted on computer users by Microsoft Windows Vista and its embedded digital rights management, as well as providing a user-friendly gateway to free software alternatives.[2] [3]BadVista activists teamed up with Defective by Design members on a Vista launch party on January 30, 2007 at the Times Square. Protesters in hazmat suits held their signs explaining the restrictions Vista may impose on computer users.[3][4][5][6] The campaign ended on January 8, 2009, when victory was declared after Microsoft released its Windows 7 Beta.[7] This victory claim was based on the tepid adoption of Vista, compared to those sticking with the less-DRM infused Windows XP or moving to the FSF-defined less restrictive Mac OS X (now named as macOS) or largely free Linux or FreeBSD. A minority of GNU/Linux distros are recognized as completely free,[8] however like kFreeBSD vanilla Linux kernel contains binary blob device drivers. This is solved by Linux-libre.Windows 7 Sins[edit]In 2009, a campaign targeted towards Windows 7 was launched by the Free Software Foundation under the name Windows 7 Sins.[9] The campaign's site uses graphics from the free software video game XBill.Upgrade from Windows 8[edit]In October 2012, the Free Software Foundation began another campaign called Upgrade from Windows 8, this time targeted towards Windows 8.[10]Windows 10[edit]During the Windows 10 release, the FSF issued a statement urging users to reject it due to its proprietary nature. The Foundation also cited other sources of concern, such as forcing lower-paying customers to test less-secure updates before higher-paying users, Microsoft's implication in the 2013 global surveillance scandal and the new privacy policy enacted by Windows.[11]See also[edit]\nDefective by Design \u2013 an associated anti-digital rights management campaign that also targets Windows XP and higher\nHardware restrictions\nReferences[edit]External links[edit]\nbadvista.fsf.org/badvista-declares-victory - official BadVista website\nen.windows7sins.org - official Windows 7 sins website\nfsf.org/windows8 - official Upgrade from Windows 8 website\nfsf.org/news/the-fsfs-statement-on-windows-10 - official The FSFs statement on Windows 10 website\n", "subtitles": ["BadVista", "Windows 7 Sins", "Upgrade from Windows 8", "Windows 10", "See also", "References", "External links"], "title": "Free Software Foundation anti-Windows campaigns"},
{"content": "Matt Lee (born July 21, 1981) is a British artist, software freedom activist, hacker, and writer. He is a former free software developer at GitLab and was previously technical lead of Creative Commons,[2] from 2014-2016. He is a speaker and webmaster for the GNU Project. He also maintains the GNU social and GNU FM packages.Between 2008 and 2012, Lee was the main contact behind the Free Software Foundation Defective by Design and Play Ogg campaigns. He also served as the chief-webmaster for the GNU Project.[3]In 2007, Lee wrote and produced Happy Birthday to GNU starring Stephen Fry, a short film to commemorate the 25th anniversary of the GNU Project. The final product was released under a Creative Commons license. In 2015, he co-wrote and directed his first feature, Orang-U: An Ape Goes To College.[4]As a speaker for the GNU Project[edit]Lee currently delivers speeches on the following topics in English:[5]\nStrategies for communicating and organizing around free software ideals\nCreating free software for the web\nReferences[edit]External links[edit]\nPersonal homepage\nGitLab\nCreative Commons\nBadVista\nPlay Ogg\nDefective by Design\n", "subtitles": [], "title": "Matt Lee (artist)"},
{"content": "The Thomson Corporation was one of the world's largest information companies. It was established in 1989 following a merger between International Thomson Organisation Ltd (ITOL) and Thomson Newspapers.[1] In 2008, it purchased Reuters Group to form Thomson Reuters. The Thomson Corporation was active in financial services, healthcare sectors, law, science and technology research and tax and accounting sectors. The company operated through five segments (2007 onwards): Thomson Financial, Thomson Healthcare, Thomson Legal, Thomson Scientific and Thomson Tax & Accounting.Until 2007, Thomson was also a major worldwide provider of higher education textbooks, academic information solutions and reference materials. On 26 October 2006, Thomson announced the proposed sale of its Thomson Learning assets. In May 2007, Thomson Learning was acquired by Apax Partners and subsequently renamed Cengage Learning in July. The Thomson Learning brand was used to the end of August 2007.[3]Subsequently, on 15 October 2007, Educational Testing Service (ETS) finalized acquisition of Thomson's Prometric. Thomson sold its global network of testing centres in 135 countries, for a reported $435 million. Prometric now operates as a wholly owned subsidiary of ETS.[4]On 15 May 2007, the Thomson Corporation reached an agreement with Reuters to combine the two companies, a deal valued at $17.2 billion. On 17 April 2008 the new company was created under the name of Thomson Reuters. The chief executive officer of Thomson Reuters is Jim Smith, and the chairman is David Thomson, formerly of the Thomson Corporation. Although it was officially a Canadian company and remained Canadian owned, Thomson was run from its operational headquarters in Stamford, Connecticut, in the United States.History[edit]Thomson had grown from a single Canadian newspaper, the Timmins Daily Press, acquired in 1934 by Roy Thomson, 1st Baron Thomson of Fleet, into a global media concern. The Baron acquired his first non-Canadian newspaper the Independent of St. Petersburg, Florida in 1952 and the next year it expanded to the United Kingdom. It once owned several prominent newspapers in the UK, including The Times and The Scotsman, and it owned Scottish Television.[5]In the 1960s, Thomson's publishing realm expanded further to include Thomson Publication (UK), a consumer magazine and book publishing house, and The Times. In 1965, Thomson Newspapers, Ltd. was formed as a publicly traded company in Canada. Roy Thomson's prolific endeavors in publishing had earned him a hereditary title, Lord Thomson of Fleet. Yet, Thomson's interests moved beyond publishing with the creation of Thomson Travel and acquisition of Britannia Airways in 1965 and 1971,[6] and a foray into a consortium exploring the North Sea for oil and gas. Thomson used its oil profits to buy small newspapers in the United States, starting with the acquisition of Brush-Moore Newspapers in 1967 for $72 million, at the time the largest sale of newspapers.[7]By the end of the 1970s, Thomson Newspapers' circulation in the United States had surpassed the 1 million mark. The merger of Thomson Newspapers and the International Thomson Organization in 1989 created the Thomson Corporation.Over the years, the company has withdrawn from its holdings in the oil and gas business, the travel industry and department stores.[8]When Kenneth Thomson took over from his father Roy in 1976, the company was worth about $500 million. At Kenneth's death in June 2006, the company was valued at about $29.3 billion.[8]Transition to business information[edit]In 1978, the acquisition of Wadsworth Publishing provided Thomson with its first entry into specialised information, college textbooks and professional books.[8] (In 2007, Thomson Learning, including the Wadsworth imprint, was sold and renamed as Cengage Learning.)[9]Starting in the mid-1990s, Thomson invested further in specialised information services (but this time providing them in digital format) and began selling off its newspapers. That was about the time Richard J. Harrington, an accountant, became chief executive officer of the company. One of the first moves came when Thomson spent $3.4 billion to acquire the West Publishing Company, a legal information provider in Eagan, MN.[8]In recent years, Thomson provided much of the specialised information content the world's financial, legal, research and medical organizations rely on every day to make business-critical decisions and drive innovation. While it remained a publishing company, early and aggressive investment in electronic delivery had become a key company goal.[8]Except for its educational division, which still publishes a substantial number of conventional textbooks, Thomson had the good fortune to move into these businesses as customers were demanding electronic delivery of their information, according to a 3 July 2006 article in the New York Times. In some markets, Thomson was able to move past other players who were more cautious about digital conversion.[8]Brands[edit]Some of Thomson's brands are better known than the company name itself. Its brands include Thomson ONE, Westlaw, FindLaw, BarBri, Pangea3, Physician's Desk Reference, RIA, Tax and Accounting (tax and accounting software and services for Accountants) Creative Solutions, Quickfinder, DISEASEDEX, DrugREAX, Medstat, Thomson First Call, Checkpoint, EndNote, Derwent World Patent Index, SAEGIS, Micropatent, Aureka, Faxpat, OptiPat, Just Files, Corporate Intelligence, InfoTrac, Delphion, Arco Test Prep, Peterson's Directories, NewsEdge, TradeWeb, Web of Science and the Arden Shakespeare. Thomson formerly owned Jane's Information Group. These information sources are produced by the many companies of Thomson, including West Publishing, Thomson Financial, ISI, Thomson Gale, Dialog Corporation, Brookers, Carswell, CCBN, Course Technology, Gardiner-Caldwell, IHI, Lawbook Co, Wadsworth, Thomson CompuMark and Sweet & Maxwell.In 2003, the Thomson Corporation bought the Chilton automotive assets.[10]In late 2004, the company sold its Thomson Media group to Investcorp. The B2B publishing group, which features such titles as American Banker, National Mortgage News, and the Bond Buyer, is now known as SourceMedia.In October 2006, the company confirmed it would sell the Thomson Learning market group in three parts. The first part, corporate education and training (NETg), has agreed to be sold to Skillsoft for $285 million. Apax announced its acquisition of Thomson's higher education business on 11 May 2007, for $7.5 billion in cash assets.[citation needed]Thomson Reuters New Zealand Limited has been publishing and updating information on New Zealand law since 1910, formerly as John Friend Ltd, to Brooker and Friend Ltd, to Brookers, to Thomson Brookers'.[11]Thomson had divested many of its traditional media assets \u2013 or combined them with digital products \u2013 and had moved toward a larger reliance on information technology services and products.[citation needed]Restatements[edit]On 1 January 2004, Thomson adopted a new accounting standard, which required restatement of all prior periods. The company restated its financial reports accordingly.[citation needed]Corporate governance[edit]Members of the last board of directors of Thomson were as follows: David K.R. Thomson (chairman of the board since 2002), W. Geoffrey Beattie, Richard Harrington, Ron D. Barbaro, Mary Cirillo, Robert Daleo, Steven Denning, Maureen Darkes, Roger Martin, Vance Opperman, John M. Thompson, Peter Thomson, Richard Thomson and John A. Tory.The Thomson family owned 70% of the company.[8]When Kenneth Thomson died in June 2006, control of the family fortune passed on to David K.R. Thomson under a plan put together decades earlier by company founder Roy Thomson.[8]David, my grandson, will have to take his part in the running of the organisation and David's son, too, Roy wrote in his 1975 autobiography. With the fortune that we will leave to them go also responsibilities. These Thomson boys that come after Ken are not going to be able, even if they want to, to shrug off these responsibilities.[8]The Thomson family controlled the Thomson Corporation through a family-owned entity, the Woodbridge Company, based in Toronto. (Along with 70% of Thomson Corporation, Woodbridge also owns a 40% stake in CTVglobemedia, which now owns the Globe and Mail daily newspaper in Toronto and CTV, Canada's largest commercial TV network.) David K.R. Thomson and his brother, Peter Thomson, became co-chairmen of Woodbridge after their father's death.[8]References[edit]Further reading[edit]\nGoldenberg, Susan (1984). The Thomson Empire. New York: Beaufort Books. ISBN 0825302595. \nProchnau, William (October 1998). In Lord Thomson's Realm. American Journalism Review. College Park, Maryland: University of Maryland Foundation. \nExternal links[edit]\nMary H. Munroe (2004). Thomson Corporation Timeline. The Academic Publishing Industry: A Story of Merger and Acquisition. Archived from the original on 2014-10-20 \u2013 via Northern Illinois University. \n", "subtitles": ["History", "Brands", "Restatements", "Corporate governance", "References", "Further reading", "External links"], "title": "Thomson Corporation"},
{"content": "The quater-imaginary numeral system was first proposed by Donald Knuth in 1960. It is a non-standard positional numeral system which uses the imaginary number 2i as its base. It is able to (almost) uniquely represent every complex number using only the digits 0, 1, 2, and 3.[1] (Numbers less than zero, which are ordinarily represented with a minus sign, are representable as digit strings in quater-imaginary; for example, the number \u22121 is represented as 103 in quater-imaginary notation.)Decompose the quater-imaginary[edit]\n  \n    \n      \n        ...\n        \n          d\n          \n            3\n          \n        \n        \n          d\n          \n            2\n          \n        \n        \n          d\n          \n            1\n          \n        \n        \n          d\n          \n            0\n          \n        \n        .\n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \n          d\n          \n            \u2212\n            2\n          \n        \n        \n          d\n          \n            \u2212\n            3\n          \n        \n        ...\n      \n    \n    {\\displaystyle \\ldots d_{3}d_{2}d_{1}d_{0}.d_{-1}d_{-2}d_{-3}\\ldots }\n  \n means\n\n  \n    \n      \n        ...\n        +\n        \n          d\n          \n            3\n          \n        \n        \u22c5\n        \n          b\n          \n            3\n          \n        \n        +\n        \n          d\n          \n            2\n          \n        \n        \u22c5\n        \n          b\n          \n            2\n          \n        \n        +\n        \n          d\n          \n            1\n          \n        \n        \u22c5\n        b\n        +\n        \n          d\n          \n            0\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \u22c5\n        \n          b\n          \n            \u2212\n            1\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            2\n          \n        \n        \u22c5\n        \n          b\n          \n            \u2212\n            2\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            3\n          \n        \n        \u22c5\n        \n          b\n          \n            \u2212\n            3\n          \n        \n        ...\n      \n    \n    {\\displaystyle \\ldots +d_{3}\\cdot b^{3}+d_{2}\\cdot b^{2}+d_{1}\\cdot b+d_{0}+d_{-1}\\cdot b^{-1}+d_{-2}\\cdot b^{-2}+d_{-3}\\cdot b^{-3}\\ldots }\n  \n\n\n\n  \n    \n      \n        b\n        =\n        2\n        i\n      \n    \n    {\\displaystyle b=2i}\n  \n.\nas we know,\n\n  \n    \n      \n        (\n        2\n        i\n        \n          )\n          \n            2\n          \n        \n        =\n        \u2212\n        4\n      \n    \n    {\\displaystyle (2i)^{2}=-4}\n  \n.\nso,\n\n  \n    \n      \n        ...\n        +\n        \n          d\n          \n            3\n          \n        \n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            3\n          \n        \n        +\n        \n          d\n          \n            2\n          \n        \n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            2\n          \n        \n        +\n        \n          d\n          \n            1\n          \n        \n        \u22c5\n        (\n        2\n        i\n        )\n        +\n        \n          d\n          \n            0\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            \u2212\n            1\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            2\n          \n        \n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            \u2212\n            2\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            3\n          \n        \n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            \u2212\n            3\n          \n        \n        ...\n      \n    \n    {\\displaystyle \\ldots +d_{3}\\cdot (2i)^{3}+d_{2}\\cdot (2i)^{2}+d_{1}\\cdot (2i)+d_{0}+d_{-1}\\cdot (2i)^{-1}+d_{-2}\\cdot (2i)^{-2}+d_{-3}\\cdot (2i)^{-3}\\ldots }\n  \n\n\n  \n    \n      \n        =\n        [\n        .\n        .\n        .\n        \n          d\n          \n            4\n          \n        \n        \u22c5\n        (\n        \u2212\n        4\n        \n          )\n          \n            2\n          \n        \n        +\n        \n          d\n          \n            2\n          \n        \n        \u22c5\n        (\n        \u2212\n        4\n        \n          )\n          \n            1\n          \n        \n        +\n        \n          d\n          \n            0\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            2\n          \n        \n        \u22c5\n        (\n        \u2212\n        4\n        \n          )\n          \n            \u2212\n            1\n          \n        \n        +\n        ...\n        ]\n        +\n        2\n        i\n        \u22c5\n        [\n        .\n        .\n        .\n        +\n        \n          d\n          \n            5\n          \n        \n        \u22c5\n        (\n        \u2212\n        4\n        \n          )\n          \n            2\n          \n        \n        +\n        \n          d\n          \n            3\n          \n        \n        \u22c5\n        (\n        \u2212\n        4\n        \n          )\n          \n            1\n          \n        \n        +\n        \n          d\n          \n            1\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \u22c5\n        (\n        \u2212\n        4\n        \n          )\n          \n            \u2212\n            1\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            3\n          \n        \n        \u22c5\n        (\n        \u2212\n        4\n        \n          )\n          \n            \u2212\n            2\n          \n        \n        +\n        ...\n        ]\n      \n    \n    {\\displaystyle =[...d_{4}\\cdot (-4)^{2}+d_{2}\\cdot (-4)^{1}+d_{0}+d_{-2}\\cdot (-4)^{-1}+\\ldots ]+2i\\cdot [...+d_{5}\\cdot (-4)^{2}+d_{3}\\cdot (-4)^{1}+d_{1}+d_{-1}\\cdot (-4)^{-1}+d_{-3}\\cdot (-4)^{-2}+\\ldots ]}\n  \n.\nThe real and imaginary parts of this complex number are thus readily expressed in base \u22124 as \n  \n    \n      \n        ...\n        \n          d\n          \n            4\n          \n        \n        \n          d\n          \n            2\n          \n        \n        \n          d\n          \n            0\n          \n        \n        .\n        \n          d\n          \n            \u2212\n            2\n          \n        \n        ...\n      \n    \n    {\\displaystyle \\ldots d_{4}d_{2}d_{0}.d_{-2}\\ldots }\n  \n and \n  \n    \n      \n        2\n        \u22c5\n        (\n        ...\n        \n          d\n          \n            5\n          \n        \n        \n          d\n          \n            3\n          \n        \n        \n          d\n          \n            1\n          \n        \n        .\n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \n          d\n          \n            \u2212\n            3\n          \n        \n        ...\n        )\n      \n    \n    {\\displaystyle 2\\cdot (\\ldots d_{5}d_{3}d_{1}.d_{-1}d_{-3}\\ldots )}\n  \n respectively.Converting from quater-imaginary[edit]To convert a digit string from the quater-imaginary system to the decimal system, the standard formula for positional number systems can be used. This says that a digit string \n  \n    \n      \n        ...\n        \n          d\n          \n            3\n          \n        \n        \n          d\n          \n            2\n          \n        \n        \n          d\n          \n            1\n          \n        \n        \n          d\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\ldots d_{3}d_{2}d_{1}d_{0}}\n  \n in base b can be converted to a decimal number using the formula\n\n  \n    \n      \n        \u22ef\n        +\n        \n          d\n          \n            3\n          \n        \n        \u22c5\n        \n          b\n          \n            3\n          \n        \n        +\n        \n          d\n          \n            2\n          \n        \n        \u22c5\n        \n          b\n          \n            2\n          \n        \n        +\n        \n          d\n          \n            1\n          \n        \n        \u22c5\n        b\n        +\n        \n          d\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\cdots +d_{3}\\cdot b^{3}+d_{2}\\cdot b^{2}+d_{1}\\cdot b+d_{0}}\n  \n\nFor the quater-imaginary system, \n  \n    \n      \n        b\n        =\n        2\n        i\n      \n    \n    {\\displaystyle b=2i}\n  \n.Additionally, for a given string \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n in the form \n  \n    \n      \n        \n          d\n          \n            w\n            \u2212\n            1\n          \n        \n        ,\n        \n          d\n          \n            w\n            \u2212\n            2\n          \n        \n        ,\n        .\n        .\n        .\n        \n          d\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle d_{w-1},d_{w-2},...d_{0}}\n  \n, the formula below can be used for a given string length \n  \n    \n      \n        w\n      \n    \n    {\\displaystyle w}\n  \n in base \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n\n\n  \n    \n      \n        Q\n        2\n        \n          D\n          \n            w\n          \n        \n        \n          \n            \n              d\n              \u2192\n            \n          \n        \n        \u2261\n        \n          \u2211\n          \n            k\n            =\n            0\n          \n          \n            w\n            \u2212\n            1\n          \n        \n        \n          d\n          \n            k\n          \n        \n        \u22c5\n        \n          b\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle Q2D_{w}{\\vec {d}}\\equiv \\sum _{k=0}^{w-1}d_{k}\\cdot b^{k}}\n  \n\nExample[edit]To convert the string \n  \n    \n      \n        \n          1101\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 1101_{2i}}\n  \n to a decimal number, fill in the formula above:\n\n  \n    \n      \n        1\n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            3\n          \n        \n        +\n        1\n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            2\n          \n        \n        +\n        0\n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            1\n          \n        \n        +\n        1\n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            0\n          \n        \n        =\n        \u2212\n        8\n        i\n        \u2212\n        4\n        +\n        0\n        +\n        1\n        =\n        \u2212\n        3\n        \u2212\n        8\n        i\n      \n    \n    {\\displaystyle 1\\cdot (2i)^{3}+1\\cdot (2i)^{2}+0\\cdot (2i)^{1}+1\\cdot (2i)^{0}=-8i-4+0+1=-3-8i}\n  \n\nAnother, longer example: \n  \n    \n      \n        \n          1030003\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 1030003_{2i}}\n  \n in base 10 is\n\n  \n    \n      \n        1\n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            6\n          \n        \n        +\n        3\n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            4\n          \n        \n        +\n        3\n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            0\n          \n        \n        =\n        \u2212\n        64\n        +\n        3\n        \u22c5\n        16\n        +\n        3\n        =\n        \u2212\n        13\n      \n    \n    {\\displaystyle 1\\cdot (2i)^{6}+3\\cdot (2i)^{4}+3\\cdot (2i)^{0}=-64+3\\cdot 16+3=-13}\n  \n\nConverting into quater-imaginary[edit]It is also possible to convert a decimal number to a number in the quater-imaginary system. Every complex number (every number of the form a+bi) has a quater-imaginary representation. Most numbers have a unique quater-imaginary representation, but just as 1 has the two representations 1 = 0.999... in decimal notation, so 1/5 has the two quater-imaginary representations 1.(0300)...2i = 0.(0003)...2i.To convert an arbitrary complex number to quater-imaginary, it is sufficient to split the number into its real and imaginary components, convert each of those separately, and then add the results by interleaving the digits. For example, since \u20131+4i is equal to \u20131 plus 4i, the quater-imaginary representation of \u20131+4i is the quater-imaginary representation of \u20131 (namely, 103) plus the quater-imaginary representation of 4i (namely, 20), which gives a final result of \u20131+4i = 1232i.To find the quater-imaginary representation of the imaginary component, it suffices to multiply that component by 2i, which gives a real number; then find the quater-imaginary representation of that real number, and finally shift the representation by one place to the right (thus dividing by 2i). For example, the quater-imaginary representation of 6i is calculated by multiplying 6i \u2022 2i = \u201312, which is expressed as 3002i, and then shifting by one place to the right, yielding: 6i = 302i.Finding the quater-imaginary representation of an arbitrary real integer number can be done manually by solving a system of simultaneous equations, as shown below.But there are faster methods for both real and imaginary integers, as shown in the negative base article.Example: Real number[edit]As an example of an integer number we can try to find the quater-imaginary counterpart of the decimal number 7 (or 710 since the base of the decimal system is 10). Since it is hard to predict exactly how long the digit string will be for a given decimal number, it is safe to assume a fairly large string. In this case, a string of six digits can be chosen. When an initial guess at the size of the string eventually turns out to be insufficient, a larger string can be used.To find the representation, first write out the general formula, and group terms:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  7\n                  \n                    10\n                  \n                \n              \n              \n                \n                =\n                \n                  d\n                  \n                    0\n                  \n                \n                +\n                \n                  d\n                  \n                    1\n                  \n                \n                \u22c5\n                b\n                +\n                \n                  d\n                  \n                    2\n                  \n                \n                \u22c5\n                \n                  b\n                  \n                    2\n                  \n                \n                +\n                \n                  d\n                  \n                    3\n                  \n                \n                \u22c5\n                \n                  b\n                  \n                    3\n                  \n                \n                +\n                \n                  d\n                  \n                    4\n                  \n                \n                \u22c5\n                \n                  b\n                  \n                    4\n                  \n                \n                +\n                \n                  d\n                  \n                    5\n                  \n                \n                \u22c5\n                \n                  b\n                  \n                    5\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  d\n                  \n                    0\n                  \n                \n                +\n                2\n                i\n                \n                  d\n                  \n                    1\n                  \n                \n                \u2212\n                4\n                \n                  d\n                  \n                    2\n                  \n                \n                \u2212\n                8\n                i\n                \n                  d\n                  \n                    3\n                  \n                \n                +\n                16\n                \n                  d\n                  \n                    4\n                  \n                \n                +\n                32\n                i\n                \n                  d\n                  \n                    5\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  d\n                  \n                    0\n                  \n                \n                \u2212\n                4\n                \n                  d\n                  \n                    2\n                  \n                \n                +\n                16\n                \n                  d\n                  \n                    4\n                  \n                \n                +\n                i\n                (\n                2\n                \n                  d\n                  \n                    1\n                  \n                \n                \u2212\n                8\n                \n                  d\n                  \n                    3\n                  \n                \n                +\n                32\n                \n                  d\n                  \n                    5\n                  \n                \n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}7_{10}&=d_{0}+d_{1}\\cdot b+d_{2}\\cdot b^{2}+d_{3}\\cdot b^{3}+d_{4}\\cdot b^{4}+d_{5}\\cdot b^{5}\\\\&=d_{0}+2id_{1}-4d_{2}-8id_{3}+16d_{4}+32id_{5}\\\\&=d_{0}-4d_{2}+16d_{4}+i(2d_{1}-8d_{3}+32d_{5})\\\\\\end{aligned}}}\n  \n\nSince 7 is a real number, it is allowed to conclude that d1, d3 and d5 should be zero. Now the value of the coefficients d0, d2 and d4, must be found. Because d0 \u2212 4 d2 + 16 d4 = 7 and because\u2014by the nature of the quater-imaginary system\u2014the coefficients can only be 0, 1, 2 or 3 the value of the coefficients can be found. A possible configuration could be: d0 = 3, d2 = 3 and d4 = 1. This configuration gives the resulting digit string for 710.\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  7\n                  \n                    10\n                  \n                \n                =\n                \n                  010303\n                  \n                    2\n                    i\n                  \n                \n                =\n                \n                  10303\n                  \n                    2\n                    i\n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}7_{10}=010303_{2i}=10303_{2i}.\\end{aligned}}}\n  \n\nExample: Imaginary number[edit]Finding a quater-imaginary representation of a purely imaginary integer number \u2208 iZ is analogous to the method described above for a real number. For example, to find the representation of 6i, it is possible to use the general formula. Then all coefficients of the real part have to be zero and the complex part should make 6. However, for 6i it is easily seen by looking at the formula that if d1 = 3 and all other coefficients are zero, we get the desired string for 6i. That is:\n\n  \n    \n      \n        \n          \n            \n              \n                6\n                \n                  i\n                  \n                    10\n                  \n                \n                =\n                \n                  30\n                  \n                    2\n                    i\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}6i_{10}=30_{2i}\\end{aligned}}}\n  \n\nAnother conversion method[edit]For real numbers the quater-imaginary representation is the same as negative quaternary (base \u22124). A complex number x+iy can be converted to quater-imaginary by converting x and y/2 separately to negative quaternary. If both x and y are finite binary fractions we can use the following algorithm using repeated Euclidean division:For example: 35+23i=121003.22i\n                35                                 23i\u00f72i=11.5    11=12-0.5\n            35\u00f7(-4)=-8, remainder 3                12\u00f7(-4)=-3, remainder 0         (-0.5)*(-4)=2\n            -8\u00f7(-4)= 2, remainder 0                -3\u00f7(-4)= 1, remainder 1\n             2\u00f7(-4)= 0, remainder 2                 1\u00f7(-4)= 0, remainder 1\n               20003                    +              101000                         +  0.2 = 121003.2\n                         32i+16*2-8i-4*0+2i*0+1*3-2*i/2=35+23i\nRadix point .[edit]A radix point in the decimal system is the usual . (dot) which marks the separation between the integral part and the fractional part of the number. In the quater-imaginary system a radix point can also be used. For a digit string \n  \n    \n      \n        .\n        .\n        .\n        \n          d\n          \n            5\n          \n        \n        \n          d\n          \n            4\n          \n        \n        \n          d\n          \n            3\n          \n        \n        \n          d\n          \n            2\n          \n        \n        \n          d\n          \n            1\n          \n        \n        \n          d\n          \n            0\n          \n        \n        .\n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \n          d\n          \n            \u2212\n            2\n          \n        \n        \n          d\n          \n            \u2212\n            3\n          \n        \n        .\n        .\n        .\n      \n    \n    {\\displaystyle ...d_{5}d_{4}d_{3}d_{2}d_{1}d_{0}.d_{-1}d_{-2}d_{-3}...}\n  \n the radix point marks the separation between non-negative and negative powers of b. Using the radix point the general formula becomes:\n\n  \n    \n      \n        \n          d\n          \n            5\n          \n        \n        \n          b\n          \n            5\n          \n        \n        +\n        \n          d\n          \n            4\n          \n        \n        \n          b\n          \n            4\n          \n        \n        +\n        \n          d\n          \n            3\n          \n        \n        \n          b\n          \n            3\n          \n        \n        +\n        \n          d\n          \n            2\n          \n        \n        \n          b\n          \n            2\n          \n        \n        +\n        \n          d\n          \n            1\n          \n        \n        b\n        +\n        \n          d\n          \n            0\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \n          b\n          \n            \u2212\n            1\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            2\n          \n        \n        \n          b\n          \n            \u2212\n            2\n          \n        \n        +\n        \n          d\n          \n            \u2212\n            3\n          \n        \n        \n          b\n          \n            \u2212\n            3\n          \n        \n      \n    \n    {\\displaystyle d_{5}b^{5}+d_{4}b^{4}+d_{3}b^{3}+d_{2}b^{2}+d_{1}b+d_{0}+d_{-1}b^{-1}+d_{-2}b^{-2}+d_{-3}b^{-3}}\n  \n\nor\n\n  \n    \n      \n        32\n        i\n        \n          d\n          \n            5\n          \n        \n        +\n        16\n        \n          d\n          \n            4\n          \n        \n        \u2212\n        8\n        i\n        \n          d\n          \n            3\n          \n        \n        \u2212\n        4\n        \n          d\n          \n            2\n          \n        \n        +\n        2\n        i\n        \n          d\n          \n            1\n          \n        \n        +\n        \n          d\n          \n            0\n          \n        \n        +\n        \n          \n            1\n            \n              2\n              i\n            \n          \n        \n        \n          d\n          \n            \u2212\n            1\n          \n        \n        +\n        \n          \n            1\n            \n              \u2212\n              4\n            \n          \n        \n        \n          d\n          \n            \u2212\n            2\n          \n        \n        +\n        \n          \n            1\n            \n              \u2212\n              8\n              i\n            \n          \n        \n        \n          d\n          \n            \u2212\n            3\n          \n        \n      \n    \n    {\\displaystyle 32id_{5}+16d_{4}-8id_{3}-4d_{2}+2id_{1}+d_{0}+{\\frac {1}{2i}}d_{-1}+{\\frac {1}{-4}}d_{-2}+{\\frac {1}{-8i}}d_{-3}}\n  \n\n\n  \n    \n      \n        =\n        32\n        i\n        \n          d\n          \n            5\n          \n        \n        +\n        16\n        \n          d\n          \n            4\n          \n        \n        \u2212\n        8\n        i\n        \n          d\n          \n            3\n          \n        \n        \u2212\n        4\n        \n          d\n          \n            2\n          \n        \n        +\n        2\n        i\n        \n          d\n          \n            1\n          \n        \n        +\n        \n          d\n          \n            0\n          \n        \n        \u2212\n        \n          \n            i\n            2\n          \n        \n        \n          d\n          \n            \u2212\n            1\n          \n        \n        \u2212\n        \n          \n            1\n            4\n          \n        \n        \n          d\n          \n            \u2212\n            2\n          \n        \n        +\n        \n          \n            i\n            8\n          \n        \n        \n          d\n          \n            \u2212\n            3\n          \n        \n      \n    \n    {\\displaystyle =32id_{5}+16d_{4}-8id_{3}-4d_{2}+2id_{1}+d_{0}-{\\frac {i}{2}}d_{-1}-{\\frac {1}{4}}d_{-2}+{\\frac {i}{8}}d_{-3}}\n  \nExample[edit]If the quater-imaginary representation of the complex unit i has to be found, the formula without radix point will not suffice. Therefore, the above formula should be used. Hence:\n\n  \n    \n      \n        \n          \n            \n              \n                i\n              \n              \n                \n                =\n                32\n                i\n                \n                  d\n                  \n                    5\n                  \n                \n                +\n                16\n                \n                  d\n                  \n                    4\n                  \n                \n                \u2212\n                8\n                i\n                \n                  d\n                  \n                    3\n                  \n                \n                \u2212\n                4\n                \n                  d\n                  \n                    2\n                  \n                \n                +\n                2\n                i\n                \n                  d\n                  \n                    1\n                  \n                \n                +\n                \n                  d\n                  \n                    0\n                  \n                \n                +\n                \n                  \n                    1\n                    \n                      2\n                      i\n                    \n                  \n                \n                \n                  d\n                  \n                    \u2212\n                    1\n                  \n                \n                +\n                \n                  \n                    1\n                    \n                      \u2212\n                      4\n                    \n                  \n                \n                \n                  d\n                  \n                    \u2212\n                    2\n                  \n                \n                +\n                \n                  \n                    1\n                    \n                      \u2212\n                      8\n                      i\n                    \n                  \n                \n                \n                  d\n                  \n                    \u2212\n                    3\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                i\n                (\n                32\n                \n                  d\n                  \n                    5\n                  \n                \n                \u2212\n                8\n                \n                  d\n                  \n                    3\n                  \n                \n                +\n                2\n                \n                  d\n                  \n                    1\n                  \n                \n                \u2212\n                \n                  \n                    1\n                    2\n                  \n                \n                \n                  d\n                  \n                    \u2212\n                    1\n                  \n                \n                +\n                \n                  \n                    1\n                    8\n                  \n                \n                \n                  d\n                  \n                    \u2212\n                    3\n                  \n                \n                )\n                +\n                16\n                \n                  d\n                  \n                    4\n                  \n                \n                \u2212\n                4\n                \n                  d\n                  \n                    2\n                  \n                \n                +\n                \n                  d\n                  \n                    0\n                  \n                \n                \u2212\n                \n                  \n                    1\n                    4\n                  \n                \n                \n                  d\n                  \n                    \u2212\n                    2\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}i&=32id_{5}+16d_{4}-8id_{3}-4d_{2}+2id_{1}+d_{0}+{\\frac {1}{2i}}d_{-1}+{\\frac {1}{-4}}d_{-2}+{\\frac {1}{-8i}}d_{-3}\\\\&=i(32d_{5}-8d_{3}+2d_{1}-{\\frac {1}{2}}d_{-1}+{\\frac {1}{8}}d_{-3})+16d_{4}-4d_{2}+d_{0}-{\\frac {1}{4}}d_{-2}\\\\\\end{aligned}}}\n  \n\nfor certain coefficients dk. Then because the real part has to be zero: d4 = d2 = d0 = d\u22122 = 0. For the imaginary part, if d5 = d3 = d\u22123 = 0 and when d1=1 and d\u22121=2 the digit string can be found. Using the above coefficients in the digit string the result is:\n\n  \n    \n      \n        \n          \n            \n              \n                i\n                =\n                \n                  10.2\n                  \n                    2\n                    i\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}i=10.2_{2i}\\end{aligned}}}\n  \n.\nAddition and subtraction[edit]It is possible to add and subtract numbers in the quater-imaginary system. In doing this, there are two basic rules that have to be kept in mind:\nWhenever a number exceeds 3, subtract 4 and carry \u22121 two places to the left.\nWhenever a number drops below 0, add 4 and carry +1 two places to the left.\nOr for short: If you add four, carry +1. If you subtract four, carry \u22121. This is the opposite of normal long addition, in which a carry in the current column requires adding 1 to the next column to the left, and a borrow requires subtracting. In quater-imaginary arithmetic, a carry subtracts from the next-but-one column, and a borrow adds.Example: Addition[edit]Below are two examples of adding in the quater-imaginary system:\n  1 - 2i                1031             3 - 4i                 1023\n  1 - 2i                1031             1 - 8i                 1001\n  ------- +     <=>     ----- +          ------- +      <=>     ----- +\n  2 - 4i                1022             4 - 12i               12320\nIn the first example we start by adding the two 1s in the first column (the ones' column), giving 2. Then we add the two 3s in the second column (the 2is column), giving 6; 6 is greater than 3, so we subtract 4 (giving 2 as the result in the second column) and carry \u22121 into the fourth column. Adding the 0s in the third column gives 0; and finally adding the two 1s and the carried \u22121 in the fourth column gives 1.In the second example we first add 3+1, giving 4; 4 is greater than 3, so we subtract 4 (giving 0) and carry \u22121 into the third column (the \u22124s column). Then we add 2+0 in the second column, giving 2. In the third column, we have 0+0+(\u22121), because of the carry; \u22121 is less than 0, so we add 4 (giving 3 as the result in the third column) and borrow +1 into the fifth column. In the fourth column, 1+1 is 2; and the carry in the fifth column gives 1, for a result of \n  \n    \n      \n        \n          12320\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 12320_{2i}}\n  \n.Example: Subtraction[edit]Subtraction is analogous to addition in that it uses the same two rules described above. Below is an example:\n        - 2 - 8i                       1102\n          1 - 6i                       1011  \n          ------- -         <=>        ----- -\n        - 3 - 2i                       1131\nIn this example we have to subtract \n  \n    \n      \n        \n          1011\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 1011_{2i}}\n  \n from \n  \n    \n      \n        \n          1102\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 1102_{2i}}\n  \n. The rightmost digit is 2\u22121 = 1. The second digit from the right would become \u22121, so add 4 to give 3 and then carry +1 two places to the left. The third digit from the right is 1\u22120 = 1. Then the leftmost digit is 1\u22121 plus 1 from the carry, giving 1. This gives a final answer of \n  \n    \n      \n        \n          1131\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 1131_{2i}}\n  \n.Multiplication[edit]For long multiplication in the quater-imaginary system, the two rules stated above are used as well. When multiplying numbers, multiply the first string by each digit in the second string consecutively and add the resulting strings. With every multiplication, a digit in the second string is multiplied with the first string. The multiplication starts with the rightmost digit in the second string and then moves leftward by one digit, multiplying each digit with the first string. Then the resulting partial products are added where each is shifted to the left by one digit. An example:\n             11201\n             20121  x\n             --------\n             11201      <--- 1 x 11201\n            12002       <--- 2 x 11201\n           11201        <--- 1 x 11201\n          00000         <--- 0 x 11201\n         12002      +   <--- 2 x 11201\n         ------------\n         120231321\nThis corresponds to a multiplication of \n  \n    \n      \n        (\n        9\n        \u2212\n        8\n        i\n        )\n        \u22c5\n        (\n        29\n        +\n        4\n        i\n        )\n        =\n        293\n        \u2212\n        196\n        i\n      \n    \n    {\\displaystyle (9-8i)\\cdot (29+4i)=293-196i}\n  \n.Tabulated conversions[edit]Below is a table of some decimal and complex numbers and their quater-imaginary counterparts.Examples[edit]Below are some other examples of conversions from decimal numbers to quater-imaginary numbers.\n\n  \n    \n      \n        5\n        =\n        16\n        +\n        (\n        3\n        \u22c5\n        \u2212\n        4\n        )\n        +\n        1\n        =\n        \n          10301\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 5=16+(3\\cdot -4)+1=10301_{2i}}\n  \n\n\n\n  \n    \n      \n        i\n        =\n        2\n        i\n        +\n        2\n        \n          (\n          \n            \u2212\n            \n              \n                1\n                2\n              \n            \n            i\n          \n          )\n        \n        =\n        \n          10.2\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle i=2i+2\\left(-{\\frac {1}{2}}i\\right)=10.2_{2i}}\n  \n\n\n\n  \n    \n      \n        7\n        \n          \n            3\n            4\n          \n        \n        \u2212\n        7\n        \n          \n            1\n            2\n          \n        \n        i\n        =\n        1\n        (\n        16\n        )\n        +\n        1\n        (\n        \u2212\n        8\n        i\n        )\n        +\n        2\n        (\n        \u2212\n        4\n        )\n        +\n        1\n        (\n        2\n        i\n        )\n        +\n        3\n        \n          (\n          \n            \u2212\n            \n              \n                1\n                2\n              \n            \n            i\n          \n          )\n        \n        +\n        1\n        \n          (\n          \n            \u2212\n            \n              \n                1\n                4\n              \n            \n          \n          )\n        \n        =\n        \n          11210.31\n          \n            2\n            i\n          \n        \n      \n    \n    {\\displaystyle 7{\\frac {3}{4}}-7{\\frac {1}{2}}i=1(16)+1(-8i)+2(-4)+1(2i)+3\\left(-{\\frac {1}{2}}i\\right)+1\\left(-{\\frac {1}{4}}\\right)=11210.31_{2i}}\n  \n\nZ-order curve[edit]The representation\n\n  \n    \n      \n        z\n        =\n        \n          \u2211\n          \n            k\n            \u2265\n            n\n          \n        \n        \n          z\n          \n            k\n          \n        \n        \u22c5\n        (\n        2\n        i\n        \n          )\n          \n            \u2212\n            k\n          \n        \n      \n    \n    {\\displaystyle z=\\sum _{k\\geq n}z_{k}\\cdot (2i)^{-k}}\n  \n\nof an arbitrary complex number \n  \n    \n      \n        z\n        \u2208\n        \n          C\n        \n      \n    \n    {\\displaystyle z\\in \\mathbb {C} }\n  \n with \n  \n    \n      \n        \n          z\n          \n            k\n          \n        \n        \u2208\n        {\n        0\n        ,\n        1\n        ,\n        2\n        ,\n        3\n        }\n      \n    \n    {\\displaystyle z_{k}\\in \\{0,1,2,3\\}}\n  \n gives rise to an injective mapping\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \u03c6\n                  :\n                \n                \n                  \n                    C\n                  \n                \n                \n                  \u2192\n                \n                \n                  \n                    R\n                  \n                \n              \n              \n                \n                \n                  \n                    \u2211\n                    \n                      k\n                      \u2265\n                      n\n                    \n                  \n                  \n                    z\n                    \n                      k\n                    \n                  \n                  \u22c5\n                  (\n                  2\n                  i\n                  \n                    )\n                    \n                      \u2212\n                      k\n                    \n                  \n                \n                \n                  \u21a6\n                \n                \n                  \n                    \u2211\n                    \n                      k\n                      \u2265\n                      n\n                    \n                  \n                  \n                    z\n                    \n                      k\n                    \n                  \n                  \u22c5\n                  \n                    r\n                    \n                      \u2212\n                      k\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\begin{array}{llcl}\\varphi \\colon &\\mathbb {C} &\\to &\\mathbb {R} \\\\&\\sum _{k\\geq n}z_{k}\\cdot (2i)^{-k}&\\mapsto &\\sum _{k\\geq n}z_{k}\\cdot r^{-k}\\\\\\end{array}}}\n  \n\nwith some suitable \n  \n    \n      \n        r\n        \u2208\n        \n          Z\n        \n      \n    \n    {\\displaystyle r\\in \\mathbb {Z} }\n  \n. Here \n  \n    \n      \n        r\n        =\n        4\n      \n    \n    {\\displaystyle r=4}\n  \n cannot be taken as base because of\n\n  \n    \n      \n        \n          \n            \u2211\n            \n              k\n              >\n              0\n            \n          \n          3\n          \u22c5\n          (\n          2\n          i\n          \n            )\n            \n              \u2212\n              k\n            \n          \n          =\n          \n            \n              \n                \n                  \u2212\n                  3\n                  \u2212\n                  6\n                  i\n                \n                5\n              \n            \n          \n          \n          \n          \n          \n          =\u0338\n          \n          \n          \n          \n          1\n          =\n          \n            \u2211\n            \n              k\n              >\n              0\n            \n          \n          3\n          \u22c5\n          \n            4\n            \n              \u2212\n              k\n            \n          \n          .\n        \n      \n    \n    {\\displaystyle \\textstyle \\sum _{k>0}3\\cdot (2i)^{-k}={\\tfrac {-3-6i}{5}}\\;\\;\\;\\;\neq \\;\\;\\;\\;1=\\sum _{k>0}3\\cdot 4^{-k}.}\n  \n\nThe image \n  \n    \n      \n        \u03c6\n        (\n        \n          C\n        \n        )\n        \u2282\n        \n          R\n        \n      \n    \n    {\\displaystyle \\varphi (\\mathbb {C} )\\subset \\mathbb {R} }\n  \n is a Cantor set which allows to linearly order \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n similar to a Z-order curve. Consequently, \n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n  \n is not continuous.See also[edit]\nQuaternary numeral system\nComplex-base system\nNegative base\nReferences[edit]Further reading[edit]\nKnuth, Donald Ervin. Positional Number Systems. The Art of Computer Programming. 2 (3 ed.). Addison-Wesley. p. 205. \nWarren Jr., Henry S. (2013) [2002]. Hacker's Delight (2 ed.). Addison Wesley - Pearson Education, Inc. p. 309. ISBN 978-0-321-84268-8. 0-321-84268-5. \n", "subtitles": ["Decompose the quater-imaginary", "Converting from quater-imaginary", "Converting into quater-imaginary", "Radix point \".\"", "Addition and subtraction", "Multiplication", "Tabulated conversions", "Examples", "Z-order curve", "See also", "References", "Further reading"], "title": "Quater-imaginary base"},
{"content": "In computer science, dancing links is the technique suggested by Donald Knuth to efficiently implement his Algorithm X.[1] Algorithm X is a recursive, nondeterministic, depth-first, backtracking algorithm that finds all solutions to the exact cover problem. Some of the better-known exact cover problems include tiling, the n queens problem, and Sudoku.The name dancing links stems from the way the algorithm works, as iterations of the algorithm cause the links to dance with partner links so as to resemble an exquisitely choreographed dance. Knuth credits Hiroshi Hitotsumatsu and Ko\u0304hei Noshita with having invented the idea in 1979,[2] but it is his paper which has popularized it.Implementation[edit]As the remainder of this article discusses the details of an implementation technique for Algorithm X, the reader is strongly encouraged to read the Algorithm X article first.Main ideas[edit]The idea of DLX is based on the observation that in a circular doubly linked list of nodes,\nx.left.right \u2190 x.right;\nx.right.left \u2190 x.left;\nwill remove node x from the list, while\nx.left.right \u2190 x;\nx.right.left \u2190 x;\nwill restore x's position in the list, assuming that x.right and x.left have been left unmodified. This works regardless of the number of elements in the list, even if that number is 1.Knuth observed that a naive implementation of his Algorithm X would spend an inordinate amount of time searching for 1's. When selecting a column, the entire matrix had to be searched for 1's. When selecting a row, an entire column had to be searched for 1's. After selecting a row, that row and a number of columns had to be searched for 1's. To improve this search time from complexity O(n) to O(1), Knuth implemented a sparse matrix where only 1's are stored.At all times, each node in the matrix will point to the adjacent nodes to the left and right (1's in the same row), above and below (1's in the same column), and the header for its column (described below). Each row and column in the matrix will consist of a circular doubly linked list of nodes.Header[edit]Each column will have a special node known as the column header, which will be included in the column list, and will form a special row (control row) consisting of all the columns which still exist in the matrix.Finally, each column header may optionally track the number of nodes in its column, so that locating a column with the lowest number of nodes is of complexity O(n) rather than O(n\u00d7m) where n is the number of columns and m is the number of rows. Selecting a column with a low node count is a heuristic which improves performance in some cases, but is not essential to the algorithm.Exploring[edit]In Algorithm X, rows and columns are regularly eliminated from and restored to the matrix. Eliminations are determined by selecting a column and a row in that column. If a selected column doesn't have any rows, the current matrix is unsolvable and must be backtracked. When an elimination occurs, all columns for which the selected row contains a 1 are removed, along with all rows (including the selected row) that contain a 1 in any of the removed columns. The columns are removed because they have been filled, and the rows are removed because they conflict with the selected row. To remove a single column, first remove the selected column's header. Next, for each row where the selected column contains a 1, traverse the row and remove it from other columns (this makes those rows inaccessible and is how conflicts are prevented). Repeat this column removal for each column where the selected row contains a 1. This order ensures that any removed node is removed exactly once and in a predictable order, so it can be backtracked appropriately. If the resulting matrix has no columns, then they have all been filled and the selected rows form the solution.Backtracking[edit]To backtrack, the above process must be reversed using the second algorithm stated above. One requirement of using that algorithm is that backtracking must be done as an exact reversal of eliminations. Knuth's paper gives a clear picture of these relationships and how the node removal and reinsertion works, and provides a slight relaxation of this limitation.Optional constraints[edit]It is also possible to solve one-cover problems in which a particular constraint is optional, but can be satisfied no more than once. Dancing Links accommodates these with primary columns which must be filled and secondary columns which are optional. This alters the algorithm's solution test from a matrix having no columns to a matrix having no primary columns and if the heuristic of minimum one's in a column is being used then it needs to be checked only within primary columns. Knuth discusses optional constraints as applied to the n queens problem. The chessboard diagonals represent optional constraints, as some diagonals may not be occupied. If a diagonal is occupied, it can be occupied only once.See also[edit]\nSudoku solving algorithms\nReferences[edit]External links[edit]\nA distributed Dancing Links implementation as a Hadoop MapReduce example\nFree Software implementation of an Exact Cover solver in C - uses Algorithm X and Dancing Links. Includes examples for sudoku and logic grid puzzles.\nDlxLib NuGet package - a C# class library that implements DLX\ndlxlib npm package - a JavaScript library that implements DLX\nDonald Knuth's original implementation of dancing links written in CWEB. (See also his frontend for solving sudoku puzzles.)\n", "subtitles": ["Implementation", "See also", "References", "External links"], "title": "Dancing Links"},
{"content": "-yllion is a proposal from Donald Knuth for the terminology and symbols of an alternate decimal superbase system. In it, he adapts the familiar English terms for large numbers to provide a systematic set of names for much larger numbers. In addition to providing an extended range, -yllion also dodges the long and short scale ambiguity of -illion.Knuth's digit grouping is exponential instead of linear; each division doubles the number of digits handled, whereas the familiar system only adds three or six more. His system is basically the same as one of the ancient and now-unused Chinese numeral systems, in which units stand for 104, 108, 1016, 1032, ..., 102n, and so on. Today the corresponding characters are used for 104, 108, 1012, 1016, and so on.Details and examples[edit]In Knuth's -yllion proposal:\n1 to 999 have their usual names.\n1000 to 9999 are divided before the 2nd-last digit and named foo hundred bar. (e.g. 1234 is twelve hundred thirty-four; 7623 is seventy-six hundred twenty-three)\n104 to 108 \u2212 1 are divided before the 4th-last digit and named foo myriad bar. Knuth also introduces at this level a grouping symbol (comma) for the numeral. So, 382,1902 is three hundred eighty-two myriad nineteen hundred two.\n108 to 1016 \u2212 1 are divided before the 8th-last digit and named foo myllion bar, and a semicolon separates the digits. So 1,0002;0003,0004 is one myriad two myllion, three myriad four.\n1016 to 1032 \u2212 1 are divided before the 16th-last digit and named foo byllion bar, and a colon separates the digits. So 12:0003,0004;0506,7089 is twelve byllion, three myriad four myllion, five hundred six myriad seventy hundred eighty-nine.\netc.\nEach new number name is the square of the previous one \u2014 therefore, each new name covers twice as many digits. Knuth continues borrowing the traditional names changing illion to yllion on each one. Abstractly, then, one n-yllion is \n  \n    \n      \n        \n          10\n          \n            \n              2\n              \n                n\n                +\n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 10^{2^{n+2}}}\n  \n. One trigintyllion (\n  \n    \n      \n        \n          10\n          \n            \n              2\n              \n                32\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 10^{2^{32}}}\n  \n) would have 232+1, or 42;9496,7297, or nearly forty-three myllion (4300 million) digits (by contrast, a conventional trigintillion has merely 94 digits \u2014 not even a hundred, let alone a thousand million, and still 7 digits short of a googol). Better yet, one centyllion (\n  \n    \n      \n        \n          10\n          \n            \n              2\n              \n                102\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 10^{2^{102}}}\n  \n) would have 2102+1, or 507,0602;4009,1291:7605,9868;1282,1505, or about a half tryllion digits, whereas a conventional centillion has only 304 digits.For a more extensive table, see Myriad system. The corresponding Chinese numerals are given, with the traditional form listed before the simplified form. Today these numerals are still in use, but are used for different values.See also[edit]\nAlternatives to Knuth's proposal that date back to the French Renaissance came from Nicolas Chuquet and Jacques Peletier du Mans.\nA related proposal by Knuth is his up-arrow notation.\nThe Sand Reckoner\nReferences[edit]\nDonald E. Knuth. Supernatural Numbers in The Mathematical Gardener (edited by David A. Klarner). Wadsworth, Belmont, CA, 1981. 310\u2014325.\nRobert P. Munafo. The Knuth -yllion Notation (Archived 2012-02-25), 1996-2012.\n", "subtitles": [], "title": "-yllion"},
{"content": "The Donald E. Knuth Prize is a prize for outstanding contributions to the foundations of computer science, named after Donald E. Knuth.History[edit]The Knuth Prize has been awarded since 1996 and includes an award of $5000. The prize is awarded by ACM SIGACT and by IEEE Computer Society's Technical Committee on the Mathematical Foundations of Computing. Prizes are awarded in alternation at the ACM Symposium on Theory of Computing and at the IEEE Symposium on Foundations of Computer Science, which are among the most prestigious conferences in theoretical computer science.In contrast with the Go\u0308del Prize, which recognizes outstanding papers, the Knuth Prize is awarded to individuals for their overall impact in the field.Winners[edit]Since the prize was instituted in 1996, it has been awarded to:[1]\n1996 \u2013 Andrew Yao\n1997 \u2013 Leslie Valiant\n1999 \u2013 La\u0301szlo\u0301 Lova\u0301sz\n2000 \u2013 Jeffrey Ullman\n2002 \u2013 Christos Papadimitriou\n2003 \u2013 Miklo\u0301s Ajtai\n2005 \u2013 Mihalis Yannakakis\n2007 \u2013 Nancy Lynch\n2008 \u2013 Volker Strassen\n2010 \u2013 David S. Johnson\n2011 \u2013 Ravi Kannan\n2012 \u2013 Leonid Levin\n2013 \u2013 Gary Miller\n2014 \u2013 Richard J. Lipton[2]\n2015 \u2013 La\u0301szlo\u0301 Babai\n2016 \u2013 Noam Nisan[3]\n2017 \u2013 Oded Goldreich\nReferences[edit]External links[edit]\nKnuth Prize website\n", "subtitles": ["History", "Winners", "References", "External links"], "title": "Knuth Prize"},
{"content": "Knuth reward checks are checks or check-like certificates awarded by computer scientist Donald Knuth for finding mathematical errors, or making substantial suggestions for his publications. The MIT Technology Review describes the checks as among computerdom's most prized trophies.[1]History[edit]Initially, Knuth sent real, negotiable checks to recipients. He stopped doing so in October 2008 because of problems with check fraud. As a replacement, he started his own Bank of San Serriffe, in the fictional nation of San Serriffe, which keeps an account for everyone who found an error since 2006.[2] Knuth now sends out hexadecimal certificates instead of negotiable checks.As of October 2001[update], Knuth reported having written more than 2,000 checks, with an average value exceeding $8 per check.[3] By March 2005[update], the total value of the checks signed by Knuth was over $20,000.[4] Very few of these checks were actually cashed, even the largest ones. More often they have been framed and kept as bragging rights.[5][6]Amount[edit]In the preface of each of his books and on his website,[8] Knuth offers a reward of $2.56 (USD) to the first person to find each error in his published books, whether it be technical, typographical, or historical. Knuth explains that $2.56, or 256 cents, corresponds to one hexadecimal dollar.[9] Valuable suggestions are worth 32 cents, or about \u200b1\u20448 of the errors in the book (0.2 hexadecimal dollars or 20 hexadecimal cents). In his earlier books a smaller reward was offered. For example, the 2nd edition of The Art of Computer Programming, Volume 1, offered $2.00.The reward for coding errors found in Knuth's TeX and Metafont programs (as distinguished from errors in Knuth's books) followed an audacious scheme inspired by the Wheat and Chessboard Problem.[10] It started at $2.56,[3] and doubled every year until it reached $327.68.[3] Recipients of this sweepstakes reward include Chris Thompson (Cambridge) and Bogus\u0142aw L. Jackowski (Gdan\u0301sk),[11] and also Peter Breitenlohner on 20 March 1995.[12]Each check's memo field identifies the book and page number. 1.23 indicates an error on page 23 of Volume 1. (1.23) indicates a valuable suggestion on that page. The symbol \u0398 denotes the book Things a Computer Scientist Rarely Talks About, KLR denotes the book Mathematical Writing (by Knuth, Larrabee, and Roberts), GKP and CM denote the book Concrete Mathematics (by Graham, Knuth, and Patashnik), f1 denotes fascicle 1, CMT denotes the book Computer Modern Typefaces, DT denotes the book Digital Typography, SN denotes Surreal Numbers, CWEB denotes the book The CWEB System of Structured Documentation, DA denotes the book Selected Papers on Design of Algorithms, FG denotes the book Selected Papers on Fun and Games, and MM denotes the book MMIXware - A RISC Computer for the Third Millennium.Delays[edit]Knuth is often unable to answer immediately when a reader finds a mistake in one of his books or programs. In some cases, the delay has been several years. For example, on 1 July 1996, Knuth sent out more than 250 letters, 125 of which contained checks, for errors reported in The Art of Computer Programming since the summer of 1981. A few of these remain unclaimed as of May 2006.[13] When Knuth is not able to reply immediately, he adds 5% interest, compounded continuously, to the reward.[14]See also[edit]\nErdo\u030bs's problems\nReferences[edit]External links[edit]\nThe Bank of San Serriffe\nInterview (RealVideo format) (or Transcript) with Knuth on National Public Radio\n", "subtitles": ["History", "Amount", "Delays", "See also", "References", "External links"], "title": "Knuth reward check"},
{"content": "The man or boy test was proposed by computer scientist Donald Knuth as a means of evaluating implementations of the ALGOL 60 programming language. The aim of the test was to distinguish compilers that correctly implemented recursion and non-local references from those that did not.\nThere are quite a few ALGOL60 translators in existence which have been designed to handle recursion and non-local references properly, and I thought perhaps a little test-program may be of value. Hence I have written the following simple routine, which may separate the man-compilers from the boy-compilers.\n\u2014 Donald Knuth[1]\nKnuth's example[edit]In Pascal:This creates a tree of B call frames that refer to each other and to the containing A call frames, each of which has its own copy of k that changes every time the associated B is called. Trying to work it through on paper is probably fruitless, but for k=10, the correct answer is \u221267, despite the fact that in the original paper Knuth conjectured it to be \u2212121. The survey paper by Charles H. Lindsey mentioned in the references contains a table for different starting values. Even modern machines quickly run out of stack space for larger values of k, which are tabulated below ( A132343).[2]Explanation[edit]There are three Algol features used in this program that can be difficult to implement properly in a compiler:\nNested function definitions: Since B is being defined in the local context of A, the body of B has access to symbols that are local to A \u2014 most notably k which it modifies, but also x1, x2, x3, x4, and x5. This is straightforward in the Algol descendant Pascal, but not possible in the other major Algol descendant C (without manually simulating the mechanism by using C's address-of operator, passing around pointers to local variables between the functions).\nFunction references: The B in the recursive call A(k,B,x1,x2,x3,x4) is not a call to B, but a reference to B, which will be called only when it appears as x4 or x5 in the statement A:=x4+x5. This is straightforward in standard Pascal (ISO 7185), and also in C. Some variants of Pascal (i.e. Turbo Pascal) do not support functions references, but when the set of functions that may be referenced is known beforehand (in this program it is only B), this can be worked around.\nConstant/function dualism: The x1 through x5 parameters of A may be numeric constants or references to the function B \u2014 the x4+x5 expression must be prepared to handle both cases as if the formal parameters x4 and x5 had been replaced by the corresponding actual parameter (call by name). This is probably more of a problem in statically typed languages than in dynamically typed languages, but the standard work-around is to reinterpret the constants 1, 0, and \u22121 in the main call to A as functions without arguments that return these values.\nThese things are however not what the test is about; they're merely prerequisites for the test to at all be meaningful. What the test is about is whether the different references to B resolve to the correct instance of B \u2014 one that has access to the same A-local symbols as the B that created the reference. A boy compiler might for example instead compile the program so that B always accesses the topmost A call frame.See also[edit]\nFunarg problem\nJensen's Device\nReferences[edit]External links[edit]\nThe Man or Boy Test, ALGOL Bulletin 17, p. 7 (available at chilton-computing.org)\nMan or boy test examples in many programming languages\n", "subtitles": ["Knuth's example", "Explanation", "See also", "References", "External links"], "title": "Man or boy test"},
{"content": "Potrzebie (/p\u0252tr\u0259\u02c8zi\u02d0bi/; Polish pronunciation: [p\u0254t\u02c8\u0282\u025bbje] dative/locative of potrzeba, a need) is a Polish word popularized by its non sequitur use as a running gag in the early issues of Mad not long after the comic book began in 1952.Origin[edit]Mad editor Harvey Kurtzman spotted the word printed in the Polish language section of a multi-languaged Instructions for Use sheet accompanying a bottle of aspirin, and Kurtzman, who was fascinated with unusual words, decided it would make an appropriate but meaningless background gag. After cutting the word out of the instruction sheet, he made copies and used rubber cement to paste Potrzebie randomly into the middle of Mad satires.Appearances[edit]Potrzebie was first used in a story in Mad 11 (May 1954), where it was the exclamation of a character who spoke only in foreign languages and song lyrics, in Murder the Story, a parody illustrated by Jack Davis. It was used again in Bernard Krigstein's From Eternity Back to Here! in Mad 12 (June 1954) on an airplane advertising banner. With the same type font, it reappeared in Jack Davis's Book! Movie! in Mad 13 (July 1954), pasted into a panel as the title of an abstract painting seen in the background. In the same issue the word appears as POTS-REBIE, emblazoned on a cauldron in which Robinson Crusoe is roasting a frankfurter. This piece reappeared in one of the earliest Mad paperbacks, Bedside Mad[1] It was illustrated as a rebus in Puzzle Pages! in Mad 19 (January 1955). These stories, like others in Mad comics, were written by Harvey Kurtzman. Frequent repetition gave it the status of a catch phrase or in-joke among the readership which continues to the present day. In the first Mad Style Guide, edited by Bhob Stewart in 1994, the word was made available for display on T-shirts and other licensed Mad products. It also sees occasional use as a metasyntactic variable by hackers.A typical appearance of the word is exemplified by the Mad version of Chaucer's Canterbury Tales (from Mad 43, December 1958), which begins:\nWhon thot Aprille swithin potrzebie,\nThe burgid prillie gives one heebie-jeebie.\nSystem of measurement[edit]In issue 33, Mad published a partial table of the Potrzebie System of Weights and Measures, developed by 19-year-old Donald E. Knuth, later a famed computer scientist. According to Knuth, the basis of this new revolutionary system is the potrzebie, which equals the thickness of Mad issue 26, or 2.263348517438173216473 mm. A standardization in terms of the wavelength of the red line of the emission spectrum of cadmium is also given, which if the 1927 definition of the A\u030angstrom is taken for the value of that wavelength, would equal 2.263347539605392 mm.[2]Volume was measured in ngogn (equal to 1000 cubic potrzebies), mass in blintz (equal to the mass of 1 ngogn of halavah, which is a form of pie [with] a specific gravity of 3.1416 and a specific heat of .31416), and time in seven named units (decimal powers of the average earth rotation, equal to 1 clarke). The system also features such units as whatmeworry, cowznofski, vreeble, hoo and hah.According to the Date system in Knuth's article, which substitutes a 10-clarke mingo for a month and a 100-clarke cowznofski, for a year, the date of October 29, 2007, is rendered as Cal 7, 201 C.M. (for Cowznofsko Madi, or in the Cowznofski of our MAD). The dates are calculated from October 1, 1952, the date MAD was first published. Dates before this point are referred to, tongue-in-cheek, as B.M. (Before MAD.) The ten Mingoes are: Tales (Tal.) Calculated (Cal.) To (To) Drive (Dri.) You (You) Humor (Hum.) In (In) A (A) Jugular (Jug.) Vein (Vei.)Google's calculator can perform conversions from potrzebie system to other units.[3]Other media[edit]The word made an impression on many readers, for example jazz guitarist Jimmy Raney, who recorded the tune Potrezebie  [sic] on the album The Dual Role of Bob Brookmeyer (1954; reissued on compact disc in 1992). In the late 1960s, Potrzebie was a Jeopardy category.Potrzebie became the default password for the #1 (which is God or the root account) user account in several MUSHes and MUCKs (e.g., PennMUSH, TinyMUCK, Fuzzball MUCK, TinyMUSH, and TinyMUX).Other odd words favored by Kurtzman and popularized by him through their use as running gags in Mad were veeblefetzer, axolotl, hoohah, osszefogva, furshlugginer, Moxie, ganef and halavah. Many of these are of Yiddish or Jewish origin.In the Bill Griffith comic strip Zippy for February 27, 2007, Zippy and Zerbina mention both potrzebie and axolotl in a panel captioned, They like to use out-of-date words and catchphrases.In Agatha H. and the Clockwork Princess, the second of the novelizations of Phil and Kaja Foglio's Girl Genius webcomic, the character Herr Doktor Potrezbie Spu\u0308n is one of the many footnoted references.References[edit]External links[edit]\nThe Dual Role of Bob Brookmeyer: Jimmy Raney's Potrezebie (sic)\nSalon: The Art of Don E. Knuth by Mark Wallace\nPotrzebie System on Google Calculator\n", "subtitles": ["Origin", "Appearances", "System of measurement", "Other media", "References", "External links"], "title": "Potrzebie"},
{"content": "Deram Records was a subsidiary record label of Decca Records established in the United Kingdom in 1966. At this time U.K. Decca was a different company from the Decca label in the United States, which was owned by MCA Inc. Deram recordings were distributed in the U.S. through UK Decca's American branch known as London Records. Deram was active until 1979, then continued as a reissue label.[1]1966\u20131968[edit]In the 1960s Decca recording engineers experimented with ways of improving stereo recordings. They created a technique called Decca Panoramic Sound. The term Deramic was created as abbreviation of this. The new concept allowed for more space between instruments, rendering these sounds softer to the ear. Early stereo recordings of popular music usually were mixed with sounds to the hard left, center, or hard right only. This was because of the technical limitations of the professional 4-track reel-to-reel recorders which were state of the art until about 1967.Decca initially conceived Deram Records as an outlet for Deramic Sound recordings of contemporary pop and rock music, but not all of the early recordings on Deram used this technique. 'Deramic Sound' was intended to create recordings that had a more natural stereo spread. The basic difference was that, instead of overdubbing and mixing 4 individual (mono) tracks from a 4-track recorder, the Decca recording engineers used a pair of 4-track machines to layer multiple 2-channel (stereo) recordings. This new concept, with additional tracks, permitted the engineer to place instruments more easily in any position within the stereo field.To launch the 'Deramic Sound' concept Deram issued a series of six easy listening orchestral pop albums in October 1967. The albums all included the word Night in the title, i.e. Strings in the Night, Brass in the Night, etc. The label was soon moulded into a home for 'alternative' or 'progressive' artists. Among the first recordings in this series was the November 1967 album release Days of Future Passed by the Moody Blues.Professional quality 8-track recorders began to appear in many British studios starting with Advision Studios and Trident Studios in 1968. These 8-track machines were far more flexible than the dual 4-track recorder setup. Since Decca engineers no longer had more tracks than other major studios the 'Deramic Sound' concept quickly became outdated and was dropped. By late 1968 or early 1969 Decca had obtained its own 8-track recorder.1969\u20131979[edit]The roster later included British jazz and folk. Some of the more progressive jazz musicians of the late 1960s were released under the Deram imprint, including Mike Gibbs, John Surman, and Mike Westbrook. Deram albums bore a DML prefix for mono and an SML prefix for stereo releases. As with other UK Decca subsidiary labels, Deram's U.S. counterpart was distributed under London Records. Decca positioned it against Island Records, Harvest Records (started by EMI), and Vertigo Records (started by Philips Records), but it failed to compete. An 'extra' progressive series with SDL prefixes did not improve the situation.From the start, Decca placed pop records next to progressive artists on Deram. Cat Stevens found early success there before moving to Island Records, and David Bowie's first album appeared on the label. Three of Deram's earliest hits, Procol Harum's A Whiter Shade of Pale and the Move's Night of Fear and I Can Hear the Grass Grow, were produced outside the company by artists not directly signed to Deram. They were part of a deal with Straight Ahead Productions, who later moved their acts to EMI and had them released on the re-introduced Regal Zonophone imprint.In 1969, Decca launched Nova, a progressive label that lasted less than a year. This caused further confusion as simultaneous releases on Deram Nova and Decca Nova appeared. Decca released Justin Hayward's Songwriter (1977) and Night Flight (1980) vinyl albums on Deram. The label name was briefly revived in the early 1980s when its roster included Bananarama, the Mo-dettes, and Splodgenessabounds. Deram has also been used as a reissue imprint for other recordings in the Decca/London catalogue.Discography[edit]1966[edit]1967[edit]1968[edit]1969[edit]1970[edit]1971[edit]1972[edit]1973[edit]1974[edit]1975[edit]1977[edit]1979[edit]1980[edit]1981 - 1990[edit]Notes[edit]References[edit]\nRecord Collector   (June 1981)\nRecord Collector   (July 1981)\nDeram Label Discography - 45cat. www.45cat.com. Retrieved 2010-05-24. \nDoggett, Peter (December 1988). Deram Psychedelia. Record Collector (112): 59. \nGambaccini, Paul; Tim Rice; Jo Rice (1995). British Hit Singles (10th ed.). London: Guinness Publishing. ISBN 0-85112-633-2. \nExternal links[edit]\nDeram Records from BSN Pubs\nA discography of American Deram singles\nA discography of Canadian Deram releases\n", "subtitles": ["1966\u20131968", "1969\u20131979", "Discography", "Notes", "References", "External links"], "title": "Deram Records"},
{"content": "The Golden Jubilee of Queen Elizabeth II was the international celebration held in 2002 marking the 50th anniversary of the accession of Queen Elizabeth II to the thrones of seven countries,[1] upon the death of her father, King George VI, on 6 February 1952, and was intended by the Queen to be both a commemoration of her 50 years as monarch and an opportunity for her to officially and personally thank her people for their loyalty.[2][3] Despite the deaths of her sister, Princess Margaret, and mother, Queen Elizabeth The Queen Mother, in February and March 2002 respectively, and predictions in the media that the anniversary would be a non-event, the jubilee was marked with large-scale and popular events throughout London in June of the same year, bookended by events throughout the Commonwealth realms. Elizabeth attended all of the official celebrations as scheduled, along with her husband, the Duke of Edinburgh; over twelve months, the royal couple journeyed more than 40,000 miles (64,000 km) to the Caribbean, Australia, New Zealand, then around the United Kingdom, and wrapped up the jubilee year in Canada.[2] Numerous landmarks, parks, buildings, and the like, were also named in honour of the golden jubilee and commemorative medals, stamps, and other symbols were issued.Jamaica[edit]Elizabeth's first official engagements related to the Golden Jubilee took place in Jamaica; for the country, the Queen had acceded in 1952 as monarch of the United Kingdom and became distinctly Queen of Jamaica 10 years later; her tour of the island therefore coincided with the country's 40th anniversary of independence.[4] She arrived for the celebrations on 18 February 2002, nine days following the death of her sister, Princess Margaret, Countess of Snowdon; the Queen established a short period of private, though not state, mourning.[5] Elizabeth was first welcomed in Montego Bay, after which she travelled to Kingston and stayed at her Jamaican Prime Minister's residence, Jamaica House.Despite some anti-monarchical sentiment in the country at the time, the Queen and Duke of Edinburgh were enthusiastically welcomed by Jamaicans; 57% of those polled said the visit was important to the country and large crowds turned out to see Elizabeth, though there were small protests by Rastafarians seeking reparations for slavery and their repatriation to Africa.[4] The Queen received an official welcome at King's House, the Governor-General's residence, met with Jamaican veterans of the First World War,[6] addressed her Jamaican parliament, and visited an underprivileged area of Kingston, known as Trenchtown, viewing urban poverty projects while there.[4] The tour ended on a unique note when, at the final banquet in Jamaica, a power outage plunged King's House into darkness during the meal; Elizabeth described the event as memorable.[7]New Zealand[edit]Following her tour of Jamaica, the Queen next toured New Zealand, making stops in Auckland, Taupo, Christchurch, and Wellington. She and the Duke of Edinburgh arrived in the country on 22 February, just after Prime Minister Helen Clark said in a speech that she felt it inevitable that New Zealand will become a republic.[8] The royal couple were greeted by the Governor-General and other officials when they disembarked from the Royal Flight;[9] Clark was absent, as she was at a meeting of centre-left leaders in Stockholm, Sweden.[10] A low turn out was reported to see the Queen when she arrived at the airport,[9] while an estimated 4,000 people came to view the Queen in Auckland.[11]Australia[edit]Queen Elizabeth was then on 27 February received in Adelaide by the Governor-General, Peter Hollingworth; the Australian viceroy, at the time, was in the midst of controversy involving allegations of child abuse cover-ups in the Anglican Church and demonstrators were present when the Queen and Prince Philip landed.[12] The royal couple undertook a five-day tour through South Australia and Queensland, which also coincided with that year's Commonwealth Heads of Government Meeting in Coolum Beach.[5] On the Queen's Birthday holiday for 2002, services of thanksgiving were held in churches and a bonfire was lit during a party at the Governor-General's residence in Canberra.[13]United Kingdom[edit]Celebrations for Elizabeth II's Golden Jubilee took place throughout the United Kingdom between May and July 2002. In the lead-up to those festive weeks, the British media\u2014The Guardian, in particular\u2014predicted that the jubilee would be a failure,[14][15] arguing that Britain was no longer interested in the monarchy; a pervading sense of apathy amongst the populace seemed to confirm this. However, the predictions were proven wrong, especially during the official jubilee weekend, when people numbering in the hundreds of thousands turned out to participate in the fe\u0302tes. These festivities culminated in the 4 June event on The Mall in London, when over one million attended the parade and flypast. The Daily Mail stated in its editorial: How the sour anti-Royalists in The Guardian newspaper and elsewhere have been confounded. They were convinced that the occasion would be a flop, that the House of Windsor was no longer capable of inspiring the loyalties it once did and that anyway the concept of royalty was passe in cool Britannia.[16]It was on 3 March that the Queen and the Duke of Edinburgh returned to London from Australia. Eight days later, on Commonwealth Day, the Commonwealth Secretariat unveiled at Buckingham Palace a portrait of Elizabeth, painted by Chinwe Chukwuogo-Roy that had been commissioned to mark the Queen's 50 years as Head of the Commonwealth;[17] the work now hangs at Marlborough House,[18][19] with a study kept as part of the Queen's collection at St James's Palace. At the end of the month, however, the Queen was dealt another blow when her mother died on 30 March; the Commonwealth realms observed a period of mourning, and on 9 April, the day of her funeral, more than one million people filled the area outside Westminster Abbey and along the 23-mile (37 km) route from central London to the Queen Mother's final resting place beside her husband and younger daughter in St George's Chapel at Windsor Castle.[20]Plans for the Golden Jubilee in the United Kingdom went ahead as planned, and, after a dinner hosted by Tony Blair at 10 Downing Street for her and all her living former British Prime Ministers (Sir John Major, The Baroness Thatcher, Sir Edward Heath, and The Lord Callaghan of Cardiff),[21] the Queen officially launched the celebrations in the UK with a speech to both houses of the British parliament at Westminster Hall on 30 April,[22] marking the fifth time in five decades that Elizabeth II addressed her British parliament on her own account. The Queen spoke of 50 unforgettable years and the changes to British life and society in that time, and elaborated that the monarchy must change also; Elizabeth said she had witnessed the transformation of the international landscape through which [the United Kingdom] must chart its course and declared her resolve to continue, with the support of [the Royal Family], to serve the people... to the best of [her] ability through the changing times ahead.For the Queen's goodwill visits, which commenced on 1 May, two to three days were spent in each corner of England; the Queen and the Duke first stopped in Cornwall, Devon, and Somerset before travelling to Tyne and Wear, then finally to Buckinghamshire and Berkshire. On 13 May, the couple were received in Northern Ireland, and visited such areas as County Fermanagh, Cookstown, and Omagh.[23] Then, throughout much of mid-May, the royal couple were in London devoting much time to the promotion of the arts, attending the Chelsea Flower Show, dedicating the Queen's Gallery at Buckingham Palace, and attending a reception at the Royal Academy of Arts. The jubilee trips recommenced on 23 May with a six-day trip to Scotland; the royals first stopped in Glasgow, and then travelled on to Edinburgh, Dundee, Stornoway and Aberdeen, and, following the jubilee weekend in London, the Queen and Duke of Edinburgh on 7 June toured West Sussex, spent three days in Wales, touring Anglesey, Llanelli, and Cardiff. The next month, the royal couple made two-day trips to the West Midlands, Yorkshire (where the Queen visited the set of the soap opera Emmerdale),[2] and the counties of Suffolk and Norfolk, as well as undertaking a three-day goodwill trip to Liverpool and Manchester, where the Queen opened the 2002 Commonwealth Games.[22] The Queen closed out July by touring the East Midlands, and ended her domestic tour by visiting Lancashire.[24]Amongst several other events independently organised to celebrate the Jubilee in June 2002 were the British Army's staging at Portsmouth of a special parade of 6,000 personnel from all three branches of the British Armed Forces, and the Queen's bodyguards mounted a conjoined parade, wherein 300 members of the Gentlemen at Arms, Yeoman of the Guard, and Yeoman Warders all marched together for the first time in the centuries since their respective foundations. Elizabeth also hosted a banquet for all of Europe's reigning kings and queens, one for all her incumbent Governors-General, and garden parties at both Buckingham Palace and Holyrood Palace for people born on Accession Day 1952.[22] Around the country, street parties were organised, for which some 40,000 toolkits were distributed.[2]Golden Jubilee Weekend[edit]The Golden Jubilee Weekend took place between 1 and 4 June 2002 in London,[22] for which the Queen and Duke of Edinburgh left Scotland on 29 May to make final preparations. On the first evening, the Saturday, the Prom at the Palace took place in the gardens of Buckingham Palace and highlighted classical music; out of the two million who applied for tickets, 12,500 people were selected to attend,[25] making the event the largest ever held on the royal property. The crowds were entertained by the BBC Symphony Orchestra and BBC Symphony Chorus, conducted by Sir Andrew Davis, and guest vocalists included Kiri Te Kanawa, Thomas Allen, Angela Gheorghiu, and Roberto Alagna.The following day, the Queen and her husband attended a church service at St. George's Chapel, Windsor Castle, while their family were present at thanksgiving services elsewhere in the United Kingdom; The Prince of Wales and his sons, Princes William and Harry, in Swansea; The Earl and Countess of Wessex in Salisbury; and The Princess Royal in Ayr.After time on 3 June touring Eton and Slough, Queen Elizabeth II and the Duke of Edinburgh returned to London and the former at 1:00 pm launched the nationwide BBC Music Live Festival, in which more than 200 towns and cities across the United Kingdom publicly played the Beatles song All You Need Is Love. During the day, street parties were held around the country, and that evening, the Queen, the Duke, and other members of the immediate Royal Family, made themselves present at another concert on the grounds of Buckingham Palace; this fe\u0302te, called Party at the Palace, showcased achievements in pop music over the previous 50 years, with headlining acts including Paul McCartney, Eric Clapton, Cliff Richard, and Tony Bennett. Queen guitarist Brian May commenced the event by playing his arrangement of God Save the Queen from the roof of the palace, and Paul McCartney concluded the night with such numbers as While My Guitar Gently Weeps and Hey Jude, which were each performed before and after the Queen lit the National Beacon at the Victoria Memorial, the last in a string of 2,006 beacons to be lit in a chain throughout the world,[2] echoing Queen Victoria's own Golden Jubilee in 1887. 12,000 guests were allowed into the concert, while an additional one million people thronged The Mall to watch and listen to the festivities on giant television screens and join in with the palace audience's singing from outside the gates of Buckingham Palace,[25] and a further 200 million watched the televised event around the world.[2]On 4 June, the entire royal family attended the National Service of Thanksgiving at St Paul's Cathedral, to which the Queen rode in the Gold State Coach,[25] followed by lunch at the Guildhall. There the Queen addressed the crowd and expressed pride at the Commonwealth's achievements, both during her reign as queen and throughout time; Elizabeth was quoted as saying: Gratitude, respect and pride, these words sum up how I feel about the people of this country and the Commonwealth\u2014and what this Golden Jubilee means to me.[26] The jubilee procession then started along The Mall in the early afternoon; in addition to entertainers performing for the Queen, numerous floats were decorated to illustrate British life through the years of Elizabeth's reign and driven through The Mall. The parade concluded with 5,000 adults and children from the 54 member-states of the Commonwealth of Nations marching in their various national costumes before the Queen and presenting to her a rainbow of wishes, consisting of handwritten notes from school children across the Commonwealth. In front of more than one million people,[2] the Royal Family assembled on the balcony of the Centre Room of Buckingham Palace and watched a flypast consisting of every type of Royal Air Force aircraft in service (27 in all),[2] Concorde, and the Red Arrows. There was only one publicly noted negative event in relation to the jubilee when approximately 40 activists, mostly drawn from the anarchist Movement Against the Monarchy, were arrested during a protest in the run-up to the Jubilee Weekend.[27]Celebrations in The Turks & Caicos Islands[edit]In the Turks and Caicos Islands, a British Overseas Territory, for the first four days of June, celebrations took place throughout the Islands, presided over by Governor Mervyn Jones. The Public Relations Department of the Tourist Board for the Jubilee Committee produced the Jubilee Souvenir Brochure, with text and images covering historical Royal Visits provided by the National Museum; only 5,000 were produced, issue number 1 being given to Queen Elizabeth II herself. The museum also provided photographs for the production of three sets of stamps, and, for the Jubilee Weekend, prepared a temporary exhibition on royal visits, with other items from the past, such as the coronation medals issued in to some local residents in 1953. Other items produced to commemorate the Jubilee were a straw crown made on Middle Caicos by Loathie Harvey and Judy Geddis, two 20-crown coins, and a badge given to all school children as a memento of the historic occasion.[28]Canada[edit]Throughout the year, events were held across Canada to mark the jubilee, such as the Jubilee Leve\u0301e held by Lieutenant Governor of Alberta Lois Hole, which was attended by more than 4,000 Albertans and at which Hole stated: what we want to realize is how important the monarchy is to Canada and certainly to Alberta.[30]For 12 days in October 2002, the Queen and the Duke of Edinburgh toured Canada, making stops in Victoria, Vancouver, Winnipeg, Toronto, Hamilton, Hull, Fredericton, Sussex, Moncton, and Ottawa. The trip was also unique in that it was the first royal visit to the new territory of Nunavut, where the royal couple made their first Canadian stop in Iqaluit. There, on 4 October, the Queen opened and addressed the new legislative assembly, stating in her speech: I am proud to be the first member of the Canadian Royal Family to be greeted in Canada's newest territory.[31] After a walk-about through Iqaluit, the Queen unveiled one of the street signs on the town's main thoroughfare, which had been renamed in her honour.From Nunavut, the royal party flew to Victoria, where the Queen and Duke of Edinburgh were received by the province's lieutenant governor. Saturday was spent at a private retreat and, on the Sunday, the Queen attended religious services at Christ Church Cathedral, performed an unscheduled walk-about after the sermon, and travelled to the provincial parliament building to unveil a stained glass window commemorating the Golden Jubilee. Once Her Majesty was outside of the legislature, the Snowbirds performed an acrobatic fly-by for the sovereign and a gathered audience of some 16,000.In Vancouver, on 6 October, the Queen, accompanied by Wayne Gretzky, and in front of a crowd of 18,000 at General Motors Place, dropped the ceremonial first puck for the National Hockey League exhibition game between the Vancouver Canucks and San Jose Sharks; this was the first time any reigning monarch, Canadian or otherwise, had performed the task.[32][33] The Queen and the Duke then watched the first period of the game from the royal box\u2014the first time they had done so since their first hockey game at Maple Leaf Gardens in 1951.[34] Premier Gordon Campbell said during the visit: Your Majesty, much as the world has changed in the last 50 years, one thing has always remained constant \u2013 the sincere affection between the people of British Columbia and their Queen.[35]The couple was next in Saskatchewan, unveiling on the grounds of the provincial parliament the product of the Golden Jubilee Statue Project: a bronze equestrian statue of the Queen riding Burmese, a horse gifted in 1969 to the Queen by the RCMP. In Winnipeg, Manitoba, the Queen performed a walk-about at The Forks, re-dedicated the newly restored Golden Boy statue atop the Manitoba Legislative Building, and attended an evening performance of the Royal Winnipeg Ballet, accompanied by the Winnipeg Symphony Orchestra and Loreena McKennitt.[36]Her Majesty and His Royal Highness were on 9 October welcomed to Ontario by the lieutenant governor and thousands onlookers in Toronto, and, that evening, appeared at a festival, mounted at Exhibition Place, highlighting the advance of the province over the previous five decades. After a day of relaxation, the Queen then ventured to Sheridan College, to view students learning computer animation, and Hamilton, where at Copps Coliseum she, as their colonel-in-chief, presented the Argyll and Sutherland Highlanders of Canada with their new Colours. Rejoined by her husband, Elizabeth attended at the Canadian Broadcasting Corporation's Toronto headquarters an event marking the organisation's 50th anniversary; there, she viewed exhibits and was amused by a video display showing her earlier tours of Canada in the 1950s. Finally, the royal couple were in the audience at Roy Thomson Hall for a gala concert of Canadian talent, including Oscar Peterson, Evelyn Hart, Rex Harrington, Cirque du Soleil, The Tragically Hip, and others.[37] At the same time, the Lieutenant-Governor-in-Council named a park near Gravenhurst as the Queen Elizabeth II Wildlands Provincial Park and created the Ontario Golden Jubilee Award for Civilian Bravery.[38][39]As the tour continued on to the maritime provinces, the royal party arrived at Government House in Fredericton, New Brunswick, where they were welcomed by thousands. The stop in this province was brief, however\u2014only 25 hours in total\u2014with the Queen and Duke of Edinburgh flying by helicopter the following morning from Fredericton to Sussex and then on to Moncton, where they attended a luncheon in Dieppe to celebrate the town's 50th anniversary and officially opened a new terminal at Greater Moncton International Airport.[40]From the east coast the royal couple flew westwards again to the national capital, Ottawa, to be greeted there by Deputy Prime Minister John Manley, who had earlier, on the day of the Queen's arrival in Canada, caused controversy by stating Canada should become a republic. The day following, 13 October, a multi-faith Thanksgiving celebration was held on Parliament Hill for about 3,500 people, and the Queen laid a wreath at the Tomb of the Unknown Soldier. A state dinner was held that evening at the Canadian Museum of Civilization in Gatineau, Quebec, at which Her Majesty said: [I wish] to express my profound gratitude to all Canadians... for the loyalty, encouragement and support you have given to me over these past 50 years. As her motorcade passed across the Ottawa River into Quebec, about 100 protesters yelled obscenities at the Queen in French, waving Quebec flags and chanting We want a country, not a monarchy; it was the only protest during the jubilee tour of Canada.[41][42]On the last full day of the tour, the Queen, as Honorary Commissioner, watched a performance of the Royal Canadian Mounted Police's Musical Ride before moving to her final major event in Canada: a lunch at Rideau Hall for fifty distinguished Canadians\u2014one from each year of Elizabeth's reign. The Queen also planted another tree on the grounds of her Canadian residence, and met with members of the Royal Commonwealth Society.[43] The Queen and the Duke of Edinburgh then departed Canada on 15 October.Celebrations outside the Commonwealth[edit]The Golden Jubilee was also marked in New York City, where the pinnacle of the Empire State Building was lit in royal purple and gold. The city's mayor, Michael Bloomberg, and officials at the British consulate said the tribute was a sign of thanks both to the Queen for having had the American national anthem played at Buckingham Palace during the Changing of the Guard on 13 September 2001 and to the British people for their support afterwards.[44] It had been more than 10 years since the Empire State Building gave such an honour to an individual not from the United States; the most recent instance was when Nelson Mandela visited New York after his release from prison in 1990.[44]Monuments and souvenirs[edit]Before, during, and after the jubilee year, souvenirs were created, monuments unveiled, and public works named in commemoration of the royal event. In Australia, Australia Post released a special stamp combining old and new images of Queen Elizabeth II, along with a booklet outlining the Queen's reign.[45]In Canada, the Governor-in-Council earmarked $CAD 250,000 as a donation in the Queen's name to the Dominion Institute's Memory Project, aimed at educating Canadian youth on the experiences and contributions of the country's veterans from the First World War through to modern peacekeeping missions.[46] The provinces also marked the milestone; the Ontario Governor-in-Council, on the advice of his premier, approved the renaming of Dalton Digby Wildlands Provincial Park as the Queen Elizabeth II Wildlands Provincial Park and,[47] in Saskatchewan, an equestrian statue of Queen Elizabeth II was commissioned and erected alongside the Queen Elizabeth II Gardens on the grounds of the Legislative Building.[48] In Alberta, the Queen Elizabeth II Golden Jubilee Recognition Act established the Queen's Golden Jubilee Citizenship Medal, the Queen's Golden Jubilee Scholarship for the Visual and Performing Arts, and the Premier's Citizenship Award in Recognition of the Queen's Golden Jubilee.[49]A special \u00a35 coin was released in the United Kingdom to celebrate the event, and the annual Queen's Golden Jubilee Award for volunteer service groups was founded in 2002, while private enterprises produced various ornaments and trinkets as memorabilia of the jubilee; manufacturers such as Spode created various forms of commemorative china and crystalware.[50] At Windsor Castle, the Jubilee Gardens were opened, the first new public area to be created since 1820,[2] and a 167 feet (51-metre) inverted roller coaster, Jubilee Odyssey, was constructed at the Fantasy Island theme park in Lincolnshire.[51]Result[edit]It was argued in retrospective analysis that the jubilee had been of benefit both to nationalism and the monarchy;[52] the Daily Mail stated: Below and in front of her an event as magical and magnificent as the Golden Jubilee itself was unfurling before her captivated eyes\u2014Britain was rediscovering the land of hope and glory,[53] and the Globe and Mail said: When she daintily bent over to drop a puck at an NHL game... she achieved perhaps the most brilliant melding of symbolism in Canadian history... The Jumbotron in Vancouver's GM Place said it all, flashing the Queen's golden EIIR cypher on the giant screen atop the beer advertisement: 'I am Canadian'. The crowd went hysterical.[54]See also[edit]\nQueen Elizabeth II Golden Jubilee Medal\n2002 Golden Jubilee Honours\nSilver Jubilee of Elizabeth II\nDiamond Jubilee of Elizabeth II\nReferences[edit]External links[edit]\nCBC website on the Golden Jubilee\nBBC website on the Golden Jubilee\nDepartment of Canadian Heritage: Golden Jubilee, a Canadian Celebration\nArchives of Ontario celebrates the Queen's Golden Jubilee\nTown of Markham, Ontario: Golden Jubilee, The Fiftieth Anniversary of the Reign of Her Majesty Queen Elizabeth II\n", "subtitles": ["Jamaica", "New Zealand", "Australia", "United Kingdom", "Canada", "Celebrations outside the Commonwealth", "Monuments and souvenirs", "Result", "See also", "References", "External links"], "title": "Golden Jubilee of Queen Elizabeth II"},
{"content": "The Sage Group plc, commonly known as Sage, is a British multinational enterprise software company headquartered in Newcastle upon Tyne, United Kingdom. It is the UK's second largest technology company[2] and is the world's third-largest supplier of enterprise resource planning software (behind Oracle and SAP), the largest supplier to small businesses, and has 6.1 million customers worldwide.[3] It has offices in 24 countries.[4] The company is the patron of the Sage Gateshead music venue in Gateshead.[5]Sage is listed on the London Stock Exchange and is a constituent of the FTSE 100 Index.History[edit]1981 to 2000[edit]The Company was founded by David Goldman, Paul Muller and Graham Wylie in 1981 in Newcastle, to develop estimating and accounting software for small businesses.[6]A student at Newcastle University, Graham Wylie, took a summer job with an accountancy firm funded by a government small business grant to write software to help their record keeping. This became the basis for Sage Line 50. Next, hired by David Goldman to write some estimating software for his printing company, Campbell Graphics, Graham used the same accounting software to produce the first version of Sage Accounts. David was so impressed that he hired Graham and academic Paul Muller to form Sage, selling their software first to printing companies, and then to a wider market through a network of resellers.[7]In 1984 the Company launched Sage software, a product for the Amstrad PCW word processor,[6] which used the CP/M operating system. Sage software sales escalated in that year from 30 copies a month to over 300.[6] The Company was first listed on the London Stock Exchange in 1989.[6]In 1994 Paul Walker was appointed Chief Executive. In 1998 Sage's Professional Accountants Division was established. In 1999 Sage entered FTSE 100[6] and launched a dedicated Irish division, based in Dublin as well as its e-business strategy. In that same year the UK acquisition of Tetra saw Sage enter the mid-range business software market.[8][9]2000 to 2010[edit]In 2000 Sage shares were named 'best performing share of the 90s' in the UK business press.[10] In 2001 Sage acquired Interact Commerce Inc.[11] and entered the CRM/contact management market and in 2002 Sage won 'Business of The Year' in National Business Awards.[12] Also that year Sage sponsored the new Music Centre in Gateshead for \u00a36m \u2013 now known as Sage Gateshead \u2013 the largest ever UK arts/business sponsorship.[13] Sage are one of two technology stocks listed on the FTSE 100 Index,[14] the other being Micro Focus.[15] In 2003 at age 43 Graham Wylie retired with 108.5 million shares in Sage worth \u00a3146m. He was rated Britain's 109th richest person in the 2002 Sunday Times' rich list.[7]Tony Hobson joined the Sage board of directors in June 2004 and became chairman in May 2007.[16]2010 to present[edit]On 19 April 2010, Sage announced that its CEO, Paul Walker, had indicated an interest in stepping down from his position, which he had held for 16 years.[17] The Financial Times reported that his departure would lead to speculation over Sage's mergers and acquisitions, which have been a key component to the group's growth in the past 20 years. In an interview with The Times, the CEO of Sage's UK business stated that: Acquisitions are part of our DNA.[18]Walker was one of the longest serving CEOs of a FTSE100 company, only exceeded by Sir Martin Sorrell at WPP and Tullow Oil's Aidan Heavey.[19] According to the Daily Mail, Walker is likely to have left Sage with as much as \u00a321 million given his shares, bonus plan and salary.[20] Walker left the company on 1 December 2010.[21]On 1 October 2010 Guy Berruyer became CEO of Sage Group; Berruyer had previously been CEO of Sage's Mainland Europe & Asia operations.[21]On 15 February 2013, Sage announced that Accel-KKR intended to buy Sage Nonprofit Solutions, the division of Sage that produces software designed for nonprofit organisations and governmental agencies.[22]In August 2014, Sage announced that Guy Berruyer was to retire; Stephen Kelly, the UK government\u2019s former chief operating officer, became Group CEO in November 2014.[23]In July 2017, Sage announced that it would purchase Intacct for $850M.[24]Operations[edit]Founded and headquartered in Newcastle upon Tyne, United Kingdom, the company initially grew organically, but more recently has grown primarily through acquisitions. In 2004 the company's new headquarters was completed in the Great Park area of Newcastle upon Tyne; the company was previously located at Benton Park House. It now operates worldwide. The company's US headquarters are in Atlanta, Georgia, the Canadian headquarters are in Richmond, British Columbia, the Africa, Middle East & Australia headquarters are in Johannesburg, South Africa and the French and Continental European headquarters are in Paris, France. Sage has 6.1 million customers and 13,400 employees across the world. Key industry focus includes: Healthcare; HR & Payroll; Construction/ Real-Estate; Transport/ Distribution; Payment Processing; Accountancy; Not-for-Profit; Manufacturing; Retail; Automotive Distribution.[25]Financial information[edit]Financial results are as follows:[26]Products[edit]The company's core product set can be divided into three areas: Accounting, Payroll & Human Capital Management and Payments.[27]As Sage operates in a large number of countries the available product set varies and typically includes products specifically tailored for each region's nuanced legislation regarding accounting, payroll and taxation. Sage's worldwide products include Sage One, Sage Live, Sage X3, Sage Pay, Sage Payments and Sage People. Sage's more regional product ranges include ProvideX, Sage 50c Accounts (UK), Sage 50 Accounting, Sage 50 Payroll, Sage 100, Pastel Accounting, Sage 200, Sage 300, Sage 1000, Sage X3, Sage X3 People and Sage CRM.Sponsorships[edit]The Sage Group is a patron of The Sage Gateshead, a Tyneside music venue designed by Sir Norman Foster. The Sage Gateshead was completed in 2004 at a cost of \u00a370 million, and has since become a main sight on the River Tyne. It is primarily used as a concert venue and centre for musical education, but also hosts other events including conferences.[13]In 2008 Sage funded the revival of The Krypton Factor television series for ITV as a part of the Business Brain Training campaign.[28] Sage were the football shirt sponsor in May 2011 for Whitley Bay F.C.'s FA Vase winning match.[29]For the 2012 Formula One season Sage were an official supplier for the Marussia F1 team, and for the 2013 and 2014 seasons Sage logos were placed on the car.[30]Sage have sponsored the Invictus Games in 2016 and 2017.[31] In the 2017\u201318 season Sage has partnered with Bristol City F.C. as minor sponsor through their provision of Sage X3 for Bristol Sport.[32][33]See also[edit]\nComparison of accounting software\nComparison of CRM systems\nList of ERP software packages\nReferences[edit]External links[edit]\nOfficial website\nCoordinates: 55\u00b002\u203206\u2032\u2032N 1\u00b038\u203257\u2032\u2032W\ufeff / \ufeff55.03509\u00b0N 1.64904\u00b0W\ufeff / 55.03509; -1.64904", "subtitles": ["History", "Operations", "Financial information", "Products", "Sponsorships", "See also", "References", "External links"], "title": "Sage Group"},
{"content": "Lulu is an eponymous album released by Lulu on Alfa Records in 1981. It is notable for containing the hit single I Could Never Miss You (More Than I Do), which became the second-highest-charting single of Lulu's career in the US, hitting the top 20 on the Billboard Hot 100 and No. 2 on the Adult Contemporary chart in 1981.History[edit]Alfa Records released the album Lulu in August 1981, in response to the chart success of I Could Never Miss You (More Than I Do), originally contained on Lulu's 1978 album, Don't Take Love for Granted. In addition to I Could Never Miss You, Lulu featured two other songs from the 1978 album, being the title track, Don't Take Love for Granted and You Are Still a Part of Me, all of which had been written by Neil Harrison. A new Harrison track, Can't Hold Out on Love, was included, being one of seven new tracks produced by Mark London.Lulu reached No. 126 on the Billboard albums chart, making it Lulu's third US charting album\u2014her first in eleven years\u2014and her last to date.[1]If I Were You, which had been a minor hit (No. 70) for Toby Beau in 1980, [2][3] was released as the follow-up single to I Could Never Miss You\u2014with You Win, I Lose as the B-side\u2014and became Lulu's final Hot 100 appearance to date, reaching No. 44[1] (No. 42 Cash Box)[4] in January 1982. It also hit No. 27 on the Adult Contemporary chart. In August 1982, If I Were You reached No. 6 in New Zealand.The track Who's Foolin' Who earned Lulu a nomination for Grammy Award for Best Female Rock Vocal Performance. Lulu lost to Pat Benatar.[5]Who's Foolin' Who was released as a single, with You Win, I Lose again serving as the B-side, and peaked at No. 6 on the Bubbling Under Hot 100 Singles chart.Track listing[edit]\nI Could Never Miss You (More Than I Do) (Neil Harrison) \u2013 3:08\nThe Last Time (Mick Jagger, Keith Richards) \u2013 3:17\nIf I Were You (Jerry Fuller, John Hobbs) \u2013 3:13\nLoving You (Jerry Leiber, Mike Stoller) \u2013 4:30\nCan't Hold Out on Love (Neil Harrison) \u2013 3:18\nYou Win, I Lose (Arlene Matza, Guy Thomas) \u2013 3:40\nDon't Take Love for Granted (Neil Harrison) \u2013 3:24\nWho's Foolin' Who (Dan Walsh, Michael Price, Steve Barri, Michael Omartian) \u2013 3:36\nYou Are Still a Part of Me (Neil Harrison) \u2013 3:16\nIf You're Right (Peter Sinfield, Andy Hill) \u2013 3:12\nPersonnel[edit]\nLulu \u2013 vocals\nRay Russell, Ronnie Caryl \u2013 guitar\nAlan Jones, Alan Tarney \u2013 bass\nLynton Naiff, Mike Moran \u2013 keyboards, arrangements\nGraham Jarvis, Peter Van Hooke, Trevor Spencer \u2013 drums\nRay Cooper \u2013 percussion\nCarol Kenyon, Ronnie Carroll, Tony Rivers \u2013 background vocals\nColin Fairley, Jon Kelly \u2013 engineers\nMarion London \u2013 director\nReferences[edit]", "subtitles": ["History", "Track listing", "Personnel", "References"], "title": " (1981 album)"},
{"content": "The Party at the Palace, was a British music concert and celebration held in London in 2002. The event was in commemoration of the Golden Jubilee of Queen Elizabeth II held over the Golden Jubilee Weekend 1\u20134 June 2002. The event itself was hosted at Buckingham Palace Garden on 3 June 2002. It was the pop/rock equivalent of the Prom at the Palace, that showcased classical musicEvent and venue[edit]The concert was held at the gardens of Buckingham Palace Garden as part of the Golden Jubilee. The event was touted as the greatest concert in Britain since Live Aid or possibly ever. Tickets to the event were determined by a lottery. 12,000 people attended the concert.[1] An estimated 1 million people watched outside the Palace in The Mall and around the Queen Victoria Memorial,[2] and 200 million on television.[3] The concert included performances of many hit songs from the reign of Queen Elizabeth II. The event was the culmination of a national day of partying. The BBC Music Live Festival also occurred on the day. At 13:00 towns across the United Kingdom had bands play The Beatles hit All You Need Is Love before church bells were rung around the country.Entertainers[edit]Amongst others, performers included:Paul McCartney, Bryan Adams, Queen, Elton John, Shirley Bassey, Eric Clapton, Joe Cocker, Phil Collins, Ray Cooper, Ray Davies, Dame Edna Everage, Tony Iommi, Tom Jones, Ladysmith Black Mambazo, Annie Lennox, S Club 7, Ricky Martin, Ozzy Osbourne, Rod Stewart, Tony Bennett, Blue, Emma Bunton, Atomic Kitten, Mis-Teeq, The Corrs, Cliff Richard, Will Young, Ruby Wax, Steve Winwood and Brian Wilson.Also performing was the London cast of the musical We Will Rock You. Several newspapers mentioned the absence of The Rolling Stones. The Stones said the event conflicted with their upcoming world tour.House band[edit]The house band for the performance consisted of Phil Palmer (guitar), Pino Palladino (bass), Paul Wickens (keyboards), Phil Collins (drums), Ray Cooper (percussion), Jason Robinson (saxophone), Sam Brown, Margo Buchanan and Claudia Fontaine (backing vocals) and the Royal Academy of Music Symphony Orchestra conducted by Michael Kamen. Some performers brought their own musicians to the concert.Hosts[edit]The concert was hosted by Lenny Henry and Ben Elton. Between some acts were short comedy segments featuring Meera Syal, Nina Wadia, Ruby Wax, Kermit the Frog (voiced by Steve Whitmire), and Barry Humphries (in characters as Dame Edna Everage and Sir Les Patterson).Performances[edit]Aspects of concert[edit]The concert began with Brian May performing God Save the Queen on the roof of Buckingham Palace as a guitar solo with support from the orchestra onstage in the Garden far below.[4] This sequence was spectacularly filmed, including some upward photography of May in full rock god mode and shots of the crowd in the Garden below. It has become an iconic moment and Brian May himself has said in interview that he hoped that he would strike the last chord at the same time as the orchestra in the gardens far below. Once it was finished, said May, the arm and fist went up, and the guitar was free, for it had done its work.[5] Ozzy Osbourne recently said in the same interview that this was the greatest moment of his career and pronounced the Queen to be a beautiful woman.Phil Collins played drums for many of the artists, as well as singing his 1983 UK number one single You Can't Hurry Love, with Queen's Roger Taylor playing drums. Taylor took late singer Freddie Mercury's place by singing lead vocals for the band's 1984 number two hit Radio Ga Ga (which Taylor had also written), with Collins playing drums in place of Taylor.S Club 7's performance of Don't Stop Movin' was announced as the last time the group would be performing as a septet, as Paul Cattermole had announced his departure from the group prior to the event.Royal family commemoration[edit]The event ended with the Royal Family joining the stars onstage. Prince Charles thanked his mother for her fifty years on the throne, famously beginning his speech with the words, Your Majesty.....MUMMY! to the delight of the crowd and bemusement of the Queen.[6]Following this the Queen and Prince Philip went to light the National Beacon on the Mall. After the lighting of the beacon the largest fireworks show in the history of London took place. During this time different symbols were projected onto the palace including a Union Flag.Recordings[edit]A DVD has been issued of the performance. Some portions have been cut, e.g. Ruby Wax's monologue, Dame Edna's introduction of Paul McCartney performing Blackbird and Paul McCartney's spontaneous performance of Her Majesty.[7]A live CD recording of the performance was also released in 2002.[8]References[edit]External links[edit]\namazon.com CD listing with listening facility\namazon.com DVD listing\n", "subtitles": ["Event and venue", "Entertainers", "House band", "Hosts", "Performances", "Aspects of concert", "Royal family commemoration", "Recordings", "References", "External links"], "title": "Party at the Palace"},
{"content": "Lulu OBE (born Marie McDonald McLaughlin Lawrie; 3 November 1948) is a Scottish singer-songwriter.She is internationally known, especially by North American audiences, for the song To Sir With Love from the film of the same name and with the title song to the James Bond film The Man with the Golden Gun. In European countries, she is also widely known for her Eurovision Song Contest winning entry Boom Bang-a-Bang, and in the UK for her 1964 hit Shout, which was performed at the closing ceremony of the 2014 Commonwealth Games in Glasgow.Life and career[edit]Marie McDonald McLaughlin Lawrie was born in Lennoxtown, Stirlingshire, and grew up in Dennistoun, Glasgow, where she attended Thomson Street Primary School and Onslow Drive School.[1] She lived in Gallowgate for a while before moving to Garfield Street, Dennistoun.[2] At the age of 12 or 13, she and her manager approached a band called the Bellrocks seeking stage experience as a singer. She appeared with them every Saturday night: Alex Thomson, the group's bass player, has reported that even then her voice was remarkable. She has two brothers and a sister, and her father was a heavy drinker.[3]In August 2017, Lulu's family history was the subject of an episode in the UK series of Who Do You Think You Are? The research showed that her mother had been brought up by another family. The investigation into her genealogy showed that Lulu's maternal grandparents had come from across the religious divide in Glasgow. Her grandfather Hugh Cairns was a Catholic and her grandmother, Helen Kennedy, was a Protestant. Cairns had been a member of a Catholic gang and was found in the research to have been in and out of prison at the time of the birth of Lulu's mother. Kennedy was found to be the daughter of a Worthy Mistress of the Ladies' Orange Lodge 52 and explained why the two families were against the union between Kennedy and Cairns.[4]Early chart hits[edit]In 1964, under the wing of Marion Massey, she was signed to Decca Records, and when she was only fifteen, her version of the Isley Brothers' Shout, credited to 'Lulu & the Luvvers' and delivered in a raucous but mature voice, reached the UK charts, where it peaked at #7. Massey guided her career for more than 25 years, for most of which time they were partners in business, and Massey's husband Mark produced some of Lulu's recordings.[5]After the success of Shout, Lulu's next three singles failed to make an impact on the charts. She released Leave A Little Love in 1965, which returned her to the UK Top Ten. Her next record, Try to Understand made the Top 30.In 1966, Lulu toured Poland with the Hollies, the first British female singer to appear live behind the Iron Curtain.[6] In the same year, she recorded two German-language tracks; Wenn du da bist and So fing es an for the Decca Germany label. All her Decca recordings were made available in 2009 on a 2-CD set entitled Shout!, issued on RPM Records.[7] After two hit singles with the Luvvers, Lulu embarked on a solo career.After failing to reach the charts in 1966, Lulu left Decca and signed with Columbia, to be produced by Mickie Most. She returned to the UK singles chart in April 1967, reaching #6 with The Boat That I Row, written by Neil Diamond. All seven singles she cut with Mickie Most made the UK Singles Chart. However, in her autobiography I Don't Want To Fight, published in 2002, she described him as cheap and had little positive to say about their working relationship, which she ended in 1969 after her biggest UK solo hit. Nonetheless, when Most died in 2003, Lulu was full of praise for him and told the BBC that they had been very close.[8]She made her acting debut in 1967 To Sir, with Love, a British vehicle for Sidney Poitier. Lulu both acted in the film and sang the title song, with which she had a major hit in the United States, reaching #1. To Sir With Love became the best-selling single of 1967 in the United States, selling well in excess of 1,000,000 copies; it was awarded a gold disc.,[9] and was ranked by Billboard magazine as the #1 song of the year. In the UK, To Sir With Love was released on the B-side of Let's Pretend, a #11 hit.Television series[edit]In the late 1960s, Lulu's pop career in the UK thrived and she had several television series of her own. Her first BBC series aired in 1965 on BBC Two, where she co-hosted Gadzooks! It's The In-Crowd, with Alan David, completing the run as solo host under the rebranded Gadzooks! In 1966, she made regular appearances on BBC One's Stramash!. After appearing again on BBC Two in 1967 in a successful TV series that featured music and comedy, Three of a Kind, Lulu was given her own BBC One TV series in 1968, which ran annually until 1975 under various titles including Lulu's Back in Town, Happening For Lulu, It's Lulu and Lulu. The series often featured resident guests, including Adrienne Posta, Roger Kitter, Paul Greenwood and Pan's People, along with dance troupes choreographed by Nigel Lythgoe and Dougie Squires. The 1972 series was billed as It's Lulu... Not to mention Dudley Moore, with Dudley Moore and his trio appearing in each of the thirteen shows. Bernie Clifton was her resident guest for the last of the BBC series, airing from January to April 1975. Her BBC series included music and comedy sketches and appearances by star guests.One episode, from January 1969, is remembered for an unruly live appearance from The Jimi Hendrix Experience. During this appearance, after playing about two minutes of Hey Joe, Hendrix stopped and announced, We'd like to stop playing this rubbish and dedicate a song to Cream, regardless of what kind of group they may be in, dedicate to Eric Clapton, Ginger Baker, and Jack Bruce. Hendrix and his band then broke into Sunshine of Your Love. The studio director signalled for Hendrix to stop, but he continued. Hendrix was told he would never work at the BBC again, but was unrepentant. He told his girlfriend Kathy Etchingham, I'm not going to sing with Lulu. I'd look ridiculous.[10]Concurrently with her TV series, Lulu also hosted several 'one-off' specials. These included Lulu At Bern's Restaurant in 1969; a show recorded in Sweden with the Young Generation;[11] 1970's The Young Generation Meet Lulu (also recorded in Sweden)[12] and Bruce Forsyth Meets Lulu in 1975.[13]Eurovision Song Contest[edit]On 29 March 1969, she represented the United Kingdom in the Eurovision Song Contest performing the song Boom Bang-a-Bang,[14] written by Peter Warne and Alan Moorhouse, the song chosen from a selection of six by viewers of her BBC1 variety series Happening for Lulu and on a special show hosted by Michael Aspel in which she performed all six one after another. One song, I Can't Go On..., written by Elton John and Bernie Taupin, came last in the postcard vote but was later recorded by Cilla Black, Sandie Shaw, Polly Brown and Elton John himself as well as by Lulu. In Madrid, Lulu was accompanied by Sue and Sunny while the orchestra was conducted by Lulu's musical director Johnny Harris. Lulu later recalled:\nI had a series on TV, and Bill Cotton was the Head of [BBC] Light entertainment [at the BBC], and he said to my manager: I'd like her to do the Eurovision Song Contest, on the series. And she came to me and I went Why? What do I want to do that for?... and she said that he said that you'll get good ratings, and he is the boss, and he wants you to have good ratings. Maybe I could have said no, but I felt I didn't really have a choice in the matter. And I thought... I was full of myself, thinking ratings isn't what it's all about... But, you know, Elton John and Bernie Taupin wrote a great song that didn't go through... I had this amazing band, like 20 pieces. We did all these different songs... every single one of us said Which one is gonna win? Which one is gonna win? and we all laughed and went: Bet you it's that Boom boom bang a bang a bang a bang... But then it won. Somehow there was an intelligence working there... and it was a huge success.\nBoom Bang-a-Bang won, though three other songs, from Spain, (Vivo cantando by Salome\u0301), the Netherlands, (De troubadour by Lenny Kuhr) and France, (Un jour, un enfant by Frida Boccara) tied with her on 18 votes each. The rules were subsequently altered to prevent such ties in future years, but the result caused Austria, Portugal, Norway, Sweden and Finland not to enter the 1970 contest.[15] Lulu's song came out the best in sales, with German, French, Spanish and Italian versions alongside the original English. Later she told John Peel; I know it's a rotten song, but I won, so who cares? I'd have sung Baa, Baa, Black Sheep standing on my head if that's what it took to win.... I am just so glad I didn't finish second like all the other Brits before me, that would have been awful. Despite her dislike it is her second biggest UK hit to date, reaching No.2 on the chart in 1969.In 1975, Lulu herself hosted the BBC's A Song for Europe, the qualifying heat for the Eurovision Song Contest, in which the Shadows would perform six shortlisted songs. In 1981 she joined other Eurovision winners at a charity gala held in Norway and she was a panellist at the 1989 UK heat, offering views on two of the competing eight entries. In 2009, she provided comment and support to the six acts shortlisted to represent the UK at Eurovision 2009 on BBC1 TV.Just weeks before her 1969 Eurovision appearance, Lulu had married Maurice Gibb of the Bee Gees in a ceremony in Gerrards Cross.[16] Maurice's older brother Barry was opposed to their marriage as he believed them to be too young.[17] Their honeymoon in Mexico had to be postponed because of Lulu's Eurovision commitment. Their careers and his heavy drinking forced them apart and they divorced in 1973, but remained on good terms.[18]Late 60s and Muscle Shoals Recordings[edit]From 30 June to 2 July 1967, Lulu appeared with The Monkees at the Empire Pool, Wembley, and her brief romance with Davy Jones of the Monkees during a concert tour of the USA in March 1968 received much publicity in the UK press.[19] Lulu described her relationship with Jones as He was a kind of boyfriend but it was very innocent \u2013 nothing untoward happened. It faded almost as soon as it had blossomed.[20] In 1969, Lulu recorded New Routes, a new album, at Muscle Shoals studios: several of the songs, including a version of Jerry Jeff Walker's Mr. Bojangles, featured slide guitarist Duane Allman. The album was recorded for Atlantic's Atco label and produced by Jerry Wexler, Tom Dowd and Arif Mardin[21]1970s[edit]Lulu began 1970 by appearing on the BBC's highly rated review of the 1960s music scene Pop Go the Sixties, performing Boom Bang-A-Bang live on BBC1, 31 December 1969. She recorded another Jerry Wexler, Tom Dowd and Arif Mardin album in the USA, Melody Fair,[22] and scored a US Top 30 hit, Oh Me Oh My (I'm a Fool for You Baby), (later covered by Aretha Franklin, Tina Arena, Buster Poindexter, and John Holt) and collaborated with the Dixie Flyers on Hum a Song (From Your Heart)Four more German language tracks, (Ich brauche deine Liebe, Wach' ich oder tra\u0308um' ich, Warum tu'st du mir weh, and Traurig, aber wahr) were recorded on the Atlantic/WEA label.[23][24]She was one of the main artists invited to appear on the BBC's anniversary show Fifty Years Of Music in 1972. The same year she starred in the Christmas pantomime Peter Pan at the Opera House, Manchester and repeated her performance at the London Palladium in 1975, and returned to the same role in different London-based productions from 1987 to early 1989. She made an appearance on the Morecambe and Wise Show in 1973, singing All the Things You Are and Happy Heart. Also in 1972, Lulu made a brief but memorable appearance (alongside Ringo Starr) on Monty Python's Flying Circus, where she and Starr fight with Michael Palin, in his It's Man character as a talk show host whose program goes awry.On 27 May 1974, BBC1 screened Bruce Forsyth Meets Lulu a special variety TV show for the UK bank holiday.[25]In 1974, she performed the title song for the James Bond film The Man with the Golden Gun.[26] Two slightly different versions of the song were used, at the start and end respectively; James Bond was mentioned in the end version. Released as a single, it is the only Bond film title track not to chart as a single in either the United Kingdom or the United States.The same year she covered David Bowie's songs The Man Who Sold the World and Watch That Man.[27] Bowie and Mick Ronson produced the recordings.[27] Bowie played saxophone and provided back-up vocals and rumours of a brief affair were confirmed in her 2002 autobiography.[28] The Man Who Sold the World became her first Top 10 hit in five years, peaking at #3 in the UK chart in February 1974 and was a Top 10 hit in several European countries.She had a reasonable hit in 1975, when she released the disco single Take Your Mama For A Ride; this peaked in the UK charts at #37, remaining in the Top 75 for four weeks.On 31 December 1976 Lulu performed Shout on BBC One's A Jubilee of Music, celebrating British pop music for Queen Elizabeth II's impending Silver jubilee.In 1977, Lulu became interested in Siddha Yoga[29] and married hairdresser John Frieda. They divorced in 1991.[30] They had one son, Jordan Frieda.[31]1980s[edit]Lulu's chart success waned but she remained in the public eye, acting and hosting a long-running radio show on London's Capital Radio station.[32] She was associated with Freemans fashion catalogue during the late-1970s and early-1980s. In August 1979 after a performance in Margate, Kent she was in a car accident that nearly killed her, colliding head-on with another car on Brooksend Hill and spent a week in hospital recovering.[33] That same year, she recorded for Elton John's record label named The Rocket Record Company and seemed about to hit the charts again, with the lauded I Love to Boogie, but despite critical acclaim and much airplay, it did not make the Top 75.Notable London stage appearances came in the early-1980s in Andrew Lloyd Webber's Song and Dance and the Royal National Theatre's Guys and Dolls. She damaged her vocal cords while performing in the Lloyd Webber show, requiring surgery that threatened her singing voice. She co-hosted a revived series of Oh Boy! for ITV in the early 1980s. In 1981 she returned to the US charts with I Could Never Miss You (More Than I Do), a Top 20 hit that also reached #2 on the Adult Contemporary chart despite stalling at #62 in the UK. Early the following year she had a more modest US hit with If I Were You, which just missed the Top 40, appeared in the video for Ant Rap alongside Adam and the Ants and was nominated for a Grammy for Who's Foolin' Who from the Lulu album.She won the Rear of the Year award in 1983[34] and re-recorded a number of her songs. These included Shout, which reached the Top 10 in 1986 in the UK, securing her a spot on Top of the Pops. Lulu was one of only two performers (Cliff Richard being the other) to have sung on Top of the Pops in each of the five decades that the show ran. A follow up single to Shout, an updated version of Millie's 1960s hit My Boy Lollipop, failed to chart and Lulu stopped recording until 1992, focusing instead on TV, acting and live performances. These tracks were released on the Jive Records label. Lulu has had hits on the Decca, Columbia, Atco, Polydor, Chelsea, Alfa, Jive, Dome, RCA, Mercury and Universal labels. She has also released singles for GTO, Atlantic, Globe, EMI, Concept, Lifestyle, Utopia and Rocket, and Epic in the US. For a while, she held the record for number of hit record labels in the UK charts.In 1985, she published her first book, Lulu \u2013 Her Autobiography.On television, she replaced Julie Walters as Adrian Mole's mother in The Secret Diary of Adrian Mole in 1987. In 1989\u201390 she voiced the title character in the animated series Nellie the Elephant on ITV.1990s[edit]In 1993, Lulu made a recording comeback with the single Independence which reached #11 in the UK Singles Chart. This was the title track from the Independence album; all four singles released from this album reached the UK charts, as did two later singles released in 1994. Her second single after Independence was I'm Back for More, a duet with soul singer Bobby Womack, which charted at #27. Also in 1993, the song I Don't Wanna Fight, co-written by Lulu with Billy Lawrie and Steve DuBerry, became an international hit for Tina Turner.Later that year she guested on the cover version of the Dan Hartman song Relight My Fire, with boy band Take That. The single reached #1 on the UK Singles Chart and Lulu appeared as Take That's supporting act on their 1994 tour. At this time she also appeared as an unhappy public relations client of Edina Monsoon in two episodes of the BBC television programme Absolutely Fabulous and teamed with French & Saunders many times, including their send up of the Spice Girls (the Sugar Lumps) for Comic Relief in 1997, when she took the role of Baby Spice, mimicking Emma Bunton. An album, provisionally titled Where the Poor Boys Dance, was completed in late-1997 and due for release in early-1998 but was postponed by the record label Mercury.[35] A single Hurt Me So Bad was released in April 1999, which rose no higher than #42 in the UK, and a year later the title track from the cancelled album reached #24, with an appearance on Top of the Pops to promote it.In 1999, Lulu returned to BBC One to host their Saturday night National Lottery game show Red Alert and the theme song, sung by Lulu was released as a single, but it only managed to scrape the lower regions of the UK Top 75.She also co-wrote and recorded a duet with UK pop singer Kavana entitled Heart Like the Sun, but it was not released commercially until Kavana's 2007 greatest hits collection, Special Kind of Something: The Best of....2000s[edit]Now known as Lulu Kennedy-Cairns[36] (her late mother's birth name before she was adopted by the McDonald family[37]), in 2000 she was awarded an OBE by Queen Elizabeth. Her autobiography, published in 2002, was titled I Don't Want to Fight after the hit song she and her brother wrote with hit songwriter Steve DuBerry for Tina Turner, a song that Lulu herself released in 2003 as part of her album The Greatest Hits. Her 2002 gold album Together was a collection of duets with Elton John and Paul McCartney among others, tracks from which were performed in a high-profile TV special for ITV, An Audience With Lulu, which saw Lulu reunited with her first husband Maurice Gibb for a live performance of First of May.In 2000, Lulu sat on the 5,387,862nd and final classic Mini that came off the production line, bringing to an end a chapter in British motoring history.[38] In a ceremony at the Birmingham factory, Lulu drove a red Mini Cooper, registration 1959\u20132000, off of the track to music from The Italian Job, the 1969 film in which several Mini Coopers featured prominently.In 2004, she released the album Back on Track and went on a UK-wide tour to celebrate forty years in the music business, the album charting at a low #68. In late-2004 she returned to radio as the host of a two-hour radio show on BBC Radio 2, playing an eclectic blend of music from the 1950s to the 2000s. In 2005, Lulu released A Little Soul in Your Heart, a collection of soul classics that entered the UK Albums Chart at #28. In March 2006, she launched her official MySpace profile. Lulu also appeared on the popular British comedy programme The Kumars at No. 42.Lulu continued to act occasionally and starred alongside Tom Courtenay and Stephen Fry in the British film Whatever Happened to Harold Smith?. She also appeared in the BBC's reality TV show Just the Two of Us in 2006 as a judge, alongside Trevor Nelson, CeCe Sammy and Stewart Copeland. She was replaced by Tito Jackson for Series Two in 2007. In late-June and early-July 2006 appeared on Take That's tour of the UK & Ireland to perform their song Relight My Fire. She appeared on American Idol Season 6 on 20 March 2007 as a mentor for the female contestants and the following night performed To Sir With Love. Later in 2007 she appeared in the UK as a guest for Jools Holland in a series of concerts and features and on Holland's CD release Best of Friends, performing Where Have All the Good Guys Gone?Lulu's complete Atco recordings (made between 1969-1972) were released on 12 November 2007. The two-CD set included previously unreleased and demo versions of some of her recordings from this period. In December 2007 she released a download single on iTunes in the UK, called Run Rudolph Run. At this time Lulu was also promoting a range of beauty products on QVC, called Time Bomb, and appeared on a 2007 Christmas television advert for Morrisons, a popular supermarket chain in the UK.In February 2008, Lulu fans created an e-petition to get Lulu an Outstanding Achievement Award from the Brits.In November 2008, Lulu was announced as one of a number of Scottish celebrities to feature in the advertising campaign for Homecoming Scotland, a year-long event to encourage people around the world with Scottish heritage to return to Scotland. Also in November 2008, Lulu posted the following message on her website, celebrating the election of Barack Obama as 44th President of the United States: Barack Obama Is In \u2013 Yippee, now we have got hope in the World. I\u2019ve just turned 60, Obama is the new president of the USA and I think its going to be a fantastic year. Love Lu X. In the 1979, 1983 and 1987 UK general elections, Lulu was a supporter of Prime Minister Margaret Thatcher's Conservative Party.[39]In January 2009, Lulu began a four-week stint as an advisor/coach on the BBC show Eurovision: Your Country Needs You, helping to choose the singer to represent the UK at the 2009 Eurovision Song Contest.In the summer of 2009, Lulu guest presented on STV's daily lifestyle show The Hour, alongside main presenter Stephen Jardine. She appeared between 27 and 31 July. The Scottish magazine programme airs weekdays at 5pm. As of 2009, she continues to pitch her range of Lulu's anti-ageing products and other cosmetics through the QVC (UK) home shopping channel, using her youthful appearance as a promotional tool.After appearing at an ABBA tribute concert in Hyde Park, London during September 2009, Lulu announced that she would be touring the UK in a Here Come the Girls alongside Chaka Khan and Anastacia. The trio promoted the concert series on UK TV, ahead of the first performance in November 2009, which took on twenty different dates.2010s[edit]In early 2010, Lulu performed the theme The Word Is Love to the film Oy Vey! My Son Is Gay!! and toured the UK a second time with Here Come the Girls alongside Anastacia and Heather Small. In November 2010 she hosted the BBC TV series Rewind the 60s. Each episode focused on a year during the 1960s highlighting the social and political issues of the decade as well as music and interviews with personalities from the decade.[40]On 26 February 2011, Lulu appeared in the second heat in the third series of Let's Dance for Comic Relief. She danced to Soulja Boy's hit Crank That. In May 2011, she made an appearance on the ITV2 programme, Celebrity Juice and, in July 2011, she performed at the Llangollen International Musical Eisteddfod.[41]In October and November 2011, Lulu took part in the BBC series Strictly Come Dancing.[42]In August 2014, Lulu opened the closing ceremony of the 2014 Glasgow Commonwealth Games.[43]On 11 February 2015, she appeared on The Great Comic Relief Bake Off in aid of Comic Relief, when she revealed that she had never before made a pastry.[44]On 1 April 2017, she appeared as a guest on All Round to Mrs. Brown's alongside Holly Willoughby and Philip Schofield.On 17 August 2017, she took part in the BBC's Who Do You Think You Are programme.On 19 March 2018, she joined the cast of 42nd Street (musical) playing the lead role Dorothy Brock for a 16 week tenure.Discography[edit]BBC TV Series[edit]Gadzooks![edit]Produced by Barry Langford.Broadcast Mondays on BBC2 at 7:00pm.Prior to hosting the series, Lulu was the guest on Gadzooks! It's All Happening, broadcast Monday, April 26, 1965 at 7:00pm.[54]Three Of A Kind[edit]Produced by John Ammonds.Series 1: Broadcast Mondays on BBC2 at 8:05pm.Series 2: Broadcast Mondays on BBC2 at 8:05pmLulu\u2019s Back In Town[edit]Produced by John Ammonds.Broadcast Tuesdays on BBC1 at 9:05pmLulu (Series 1)[edit]Produced by Stanley Dorfman.Broadcast Saturdays on BBC1 at 6:15pm. Title changed to 'Lulu' from 11 January 1969.Show Of The Week[edit]Broadcast on BBC2. Co-Produced by BBC TV, Sveriges Radio and SFB Germany.It\u2019s Lulu[edit]Produced by Stewart Morris & Colin Charman.Series 1: Broadcast Saturdays on BBC1 at 8:20pmFrom Sunday 18 October 1970 to 6 December 1970, Lulu was the weekly guest on the seven-part The Ray Stevens Show broadcast weekly on Sundays on BBC2.[58]It's Lulu Series 2: Broadcast Saturdays on BBC1. Produced by Stewart Morris.It's Lulu - series 3: Broadcast Saturdays on BBC1. Produced by Stewart Morris.It's Lulu - series 4: Broadcast Saturdays on BBC1. Executive Producer John Ammonds and Produced by Vernon Lawrence.Episodes 1, 2, 5, 6, 9 & 10 were repeated on BBC2 in a different running order under the banner \u2018\u2019Show Of The Week: It\u2019s Lulu\u2019\u2019 from Thursday 25\u20135 July September 1974.[59]Lulu (Series 2)[edit]Broadcast Saturdays on BBC1. Produced by Stewart Morris. Theme Song: The Man With The Golden GunFrom Saturday 21 January \u2013 1 April 1978, Lulu was the regular guest on The Les Dawson Show on BBC1.[60]TV Specials[edit]Red Alert[edit]Series 1 Produced by Jon Rowlands. Broadcast Saturdays on BBC1.Series 2 Produced by Mobishar Dar. Broadcast Saturdays on BBC1.Filmography[edit]\nGonks Go Beat (1965)\nTo Sir, with Love (1967)\nCucumber Castle (1970)\nThe Cherry Picker (1972)\nAlicja (1982) (voice)\nTo Sir, with Love II (1996)\nWhatever Happened to Harold Smith? (1999)\nAb Fab: The Movie (2016)\nSee also[edit]\nHere Come the Girls (concert tour)\nList of number-one hits (United States)\nList of artists who reached number one in the United States\nMononymous person\nReferences[edit]Bibliography[edit]\nLulu, I Don't Want to Fight, TimeWarner Books, 2002\nLulu, Secrets To Looking Good, Harper Collins, 2010\nExternal links[edit]\nOfficial website\nLulu's Place\nLulu Brit Award Petition Online\nLulu on IMDb\nLulu discography at Discogs\nLulu partial discography\nLulu Interview on What's on Wales\nPortraits of Lulu at the National Portrait Gallery, London \n", "subtitles": ["Life and career", "Discography", "BBC TV Series", "Filmography", "See also", "References", "Bibliography", "External links"], "title": "Lulu (singer)"},
{"content": "I Could Never Miss You (More Than I Do) was the fourth and final US Top 40 hit for Lulu.History[edit]I Could Never Miss You (More Than I Do) was introduced on Lulu's 1978 album Don't Take Love For Granted, a Rocket Records release co-produced by Mark London the co-writer of Lulu's signature song To Sir, With Love and also the husband of Lulu's longtime manager Marion Massey. The album's other co-producer was Lem Lubin onetime bassist with Unit 4 + 2 and Christie and from 1977 a&r head for Rocket Records.According to Lulu, Mark London had discovered Neil Harrison and asked Lulu to record demos of Harrison's compositions to pitch to another singer: (quote Lulu:) as soon as we did the demos it was very obvious that they weren't going to be demos. They were obviously going to be for me.[2] A total of four Harrison compositions would appear on the Don't Take Love For Granted including the title cut and Love is the Sweetest Mistake which were respectively the A-side and B-side of the overlooked lead single.In 1981 Alfa Records acquired Lulu's Rocket Records recordings and released I Could Never Miss You as a single backed with Dance to the Feeling in Your Heart - the latter track had been a non-album B-side being the flip of I Love to Boogie the second single off the UK edition of the Don't Take Love For Granted album. [3] I Could Never Miss You was issued in July 1981 in the US where Lulu's US profile had received a recent boost via her participation in two ATV series devoted to rock and roll music: Oh Boy aired in the autumn of 1980 while Let's Rock ran over the summer of 1981.[4] Also the early 1980s saw a considerable boost in the popularity of easy listening music as exemplified by the success of the comparable Sheena Easton.I Could Never Miss You debuted on the Billboard Hot 100 in August 1981, rising to a #18 peak in October. This marked Lulu's first appearance in the US Top 20 since To Sir, with Love in 1967. [5] I Could Never Miss You - whose Cash Box peak was #14 [6] - also reached #2 on Billboard's Adult Contemporary chart.[5]The US success of I Could Never Miss You only translated into a glimmer of interest in Lulu's native UK, where the single - issued October 1981 - peaked at #62 in the final week of 1981 \u2013 it would mark Lulu's sole UK charting between Take Your Mama For a Ride in 1975 and Shout in 1986. [7] I Could Never Miss You also charted low in Australia at #71, although this was somewhat offset by a 16-week run. Canada's RPM magazine ranked I Could Never Miss You with a #10 peak. [1] The track had its strongest chart impact in New Zealand with an April 1982 peak of #3, which remains the highest post-1960s' peak on a national Pop chart for a solo recording by Lulu (tying with the 1974 UK chart peak of The Man Who Sold the World).The 1981 success of I Could Never Miss You resulted in Alfa issuing a self-titled album by Lulu featuring I Could Never Miss You plus two other tracks from the Don't Take Love For Granted album: the title cut plus You Are Still a Part of Me, with seven newly recorded tracks completing the album.Other versions[edit]\nMelba Moore as I Could Never Miss You More for her 1980 album Closer [8]\nBobbi Walker as I Could Never Miss You for her 1980 album Diamond in the Rough [9]\nShirley Bassey as Nadie Ma\u0301s Te Quiso (Como Yo) (Nobody loves you more [than me]) for her 1989 Spanish language album La Mujer whose producer Leonardo Schultz wrote the new lyrics.[10]\nSyd Dale as an instrumental on his album Love Isn't Just For The Young [11]\nReferences[edit]", "subtitles": [], "title": "I Could Never Miss You (More Than I Do)"},
{"content": "The Code is an English-language Finnish documentary about Linux from 2001, featuring some of the most influential people of the free software movement.Featured advocates[edit]Free and Open-source advocates or programmers in the film:\nLinus Torvalds\nRichard Stallman\nAlan Cox\nEric S. Raymond\nRobert Bob Young\nJon maddog Hall\nTheodore Y. Ted Ts'o\nDavid S. Miller\nMiguel de Icaza\nAri Lemmke\nEric Allman\nAndrew Leonard\nLarry Augustin\nMARTTI TIENARI\nSUN YU-FANG\nLIANG CHANGTAI\nJAY SALZENBERG\nSee also[edit]\nRevolution OS: A 2001 documentary that traces the twenty-year history of GNU, Linux, open source, and the free software movement.\nExternal links[edit]\nOfficial homepage\nThe Code on IMDb\n", "subtitles": [], "title": " (2001 film)"},
{"content": "EFY Group is a privately held Indian technology-oriented publishing organisation based in New Delhi. The initial publication of the EFY Group was Electronics For You, a monthly electronics magazine that was first published in 1969. The EFY Group currently manages 6 magazines, 6 web portals, 5 annual events, 4 Facebook communities, a directory, and around 30 book titles. The company also provides hands-on training courses, and manufacture & market Do-It-Yourself electronics projects and hobby kits[2] and earns a revenue of over Rs. 50,00,00,000 per annum. They have 200 employees situated mostly in south east Asia. Two more organisations are part of the group: IT Solutions India Pvt Ltd and Kits\u2019n\u2019Spares.[3]EFY Group publications[edit]Some magazines & web properties by EFY Group are:[4]\nElectronics For You\nOpen Source For You (before Linux For You[5])\nEFY Times\nEFY Mag Online\nElectronics For U\nElectronics Industry Directory\nFacts For You\nElectronics Bazaar\nBPO Times\nEFY Training & Events[edit]EFY also conducts a set of major events on a regular basis, targeting design engineers, developers, technologists, and technical decision makers. The biggest among these is EFY Conferences, under which comes Electronics Rocks as well as the IoTShow.in event. These events also have short-term technical courses that are designed to provide students with practical hands-on training.References[edit]", "subtitles": [], "title": "EFY Group"},
{"content": "Phoronix is a technology website that offers insights regarding the development of the Linux kernel, product reviews, interviews, and news regarding free and open-source software by monitoring the Linux kernel mailing list or interviews.Phoronix was started in June 2004 by Michael Larabel, who currently serves as the owner and editor-in-chief.History[edit]Founded on 5 June 2004,[1] Phoronix started as a website with a handful of hardware reviews and guides,[2][3] moving to articles covering operating systems based on Linux and open source software around the start of 2005, such as Ubuntu, Fedora, SUSE[4] and Mozilla (Firefox/Thunderbird).[5] Phoronix heavily focuses on benchmarking hardware running Linux, with a heavy slant towards graphics articles that monitor and compare free and open-source graphics device drivers and Mesa 3D with AMD's and Nvidia's proprietary graphics device drivers. In June 2006 the website added forums in addition to news content.[6] On 20 April 2007, Phoronix redesigned its website,[7] and began Solaris hardware reviews and news in addition to Linux content.[8]Phoronix benchmarks have been cited by a number of other technical publications such as CNET News[9][10] and Slashdot.[11]Phoronix Test Suite[edit]On 5 June 2008, the 1.0 release of the Phoronix Test Suite was announced. This software was made available under the GPLv3 and is designed to validate software and hardware on Linux, Solaris, Mac OS X, Windows NT, and BSD systems.[12] Version 1.0 was made up of 57 test profiles and 23 test suites.OpenBenchmarking.org[edit]OpenBenchmarking.org is a new cloud based service created to work with the Phoronix Test Suite. It is a collaborative platform that allows users to share their hardware and software benchmarks through an organized online interface.[13]See also[edit]\nLWN.net\nReferences[edit]External links[edit]\nOfficial website\nPhoronix Test Suite\nOpenBenchmarking.org\n", "subtitles": ["History", "Phoronix Test Suite", "See also", "References", "External links"], "title": "Phoronix"},
{"content": "LWN.net is a computing webzine with an emphasis on free software and software for Linux and other Unix-like operating systems. It consists of a weekly issue, separate stories which are published most days, and threaded discussion attached to every story. Most news published daily are short summaries of articles published elsewhere, and are free to all viewers. Original articles are usually published weekly on Thursdays and are available only to subscribers for one week, after which they become free as well. LWN.net is part of Eklektix, Inc.LWN caters to a more technical audience than other Linux/free software publications. It is often praised for its in-depth coverage of Linux kernel internals.[3][4][5][6][7][8]The acronym LWN originally stood for Linux Weekly News; that name is no longer used because the site no longer covers exclusively Linux-related topics, and it has daily as well as weekly content.[9]History[edit]Founded by Jonathan Corbet and Elizabeth Coolbaugh and published since January 1998,[2] LWN was originally a free site devoted to collecting Linux news, published weekly.At the end of May 2002, LWN announced a redesigned site.[10] Among the changes was a facility for readers to post comments about stories.On July 25, 2002, LWN announced that due to its inability to raise enough funds through donations, the following issue would be its last.[11][12]Following an outpouring of support from readers, however, the editors of LWN decided to continue publishing, albeit with a subscription model. New weekly editions of LWN are initially only available to readers who subscribe at one of three levels (group subscriptions are also available). After a 1-week delay, each issue becomes freely available to readers who are unable or unwilling to pay.Contributors[edit]LWN.net staff currently consists of:[13]\nJonathan Corbet, who oversees the front and kernel pages, as well as overall executive editor functions;\nJake Edge, who manages the security page and miscellaneous functions;\nRebecca Sobol, who edits the distributions page and daily updates;\nNathan Willis, who maintains the development page.\nLWN.net also purchases a number of articles from freelance authors.[13]See also[edit]\nDistroWatch\nSlashdot\nPhoronix\nReferences[edit]External links[edit]\nOfficial website\nTimeline page - Also includes the site's own history at the bottom\n2007 Subscribers survey, showing demographics and what sections of the site are liked\n", "subtitles": ["History", "Contributors", "See also", "References", "External links"], "title": "LWN.net"},
{"content": "OMG! Ubuntu! is an English blog that covers topics related to the Ubuntu Linux distribution. OMG! Ubuntu! was launched in August, 2009 and is run by Joey-Elijah Sneddon.[1]Originally, Blogger.com was used to manage the website. During a major redesign the blog switched to the WordPress content management system.[2]The blog is a source of user feedback from the Ubuntu community that provides information for both users and developers.[3]Format[edit]The blog covers recent news about Ubuntu and its related distributions including Kubuntu, Lubuntu and Xubuntu and has published interviews with key people involved in the Linux community such as Jono Bacon,[4] Linus Torvalds[5] and Jeff Waugh.[6]Reach[edit]Other media such as Pro-Linux, Heise online and derStandard.at often refer to the blog as it is often the first source to cover Ubuntu news.[7][8][9]On February 25, 2017, the blog ranked 14,429 on the Alexa global page rank.[10]According to Sneddon on May 24, 2011, the blog has 3 million visits per month.[11]References[edit]External links[edit]\nOfficial website\n", "subtitles": ["Format", "Reach", "References", "External links"], "title": "OMG! Ubuntu!"},
{"content": "The IEEE Registration Authority is the administrative body that is responsible for registering and administering Organizationally Unique Identifiers (OUI) and other types of identifiers which are used in the computer and electronics industries (Individual Address Blocks (IAB), Manufacturer IDs, Standard Group MAC Addresses, Unique Registration Numbers (URN), EtherType values, etc.)The IEEE Registration Authority was formed in 1986 in response to a need for this service that was recognized by the P802 (LAN/MAN) standards group. The IEEE Registration Authority is currently recognized by ISO/IEC as the authorized registration authority to provide the service of globally assigning, administering, and registering OUIs.\nNote: The term 'Registration' as used in this context is the assignment of unambiguous names to objects in a way which makes the assignment available to interested parties.[1]\nReferences[edit]External links[edit]\nIEEE OUI FAQ\nIEEE OUI and Company_id assignments\nList of registered OUIs\nThe IEEE Frequently Asked Questions, Registration Authority\nThe IEEE OUI Search Page\n", "subtitles": [], "title": "IEEE Registration Authority"},
{"content": "The Institute of Electrical and Electronics Engineers (IEEE) style is a widely accepted format for writing research papers, commonly used in technical fields, particularly in computer science.[1] IEEE style is based on the Chicago Style.[2] In IEEE style, citations are numbered, but citation numbers are included in the text in square brackets rather than as superscripts. All bibliographical information is exclusively included in the list of references at the end of the document, next to the respective citation number.References[edit]External links[edit]\nArticle Preparation and Submission \u2013 IEEE author resources\nIEEE Template \u2013 Templates for Transactions: Template and Instructions on How to Create Your Paper (DOC, 506 KB)\nIEEE Editorial Style Manual \u2013 Editing guidelines for Transactions, Journals, and Letters (PDF, 434 KB)\nIEEE Standards Style Manual \u2013 Style and structure for IEEE standards (PDF, 904 KB)\nIEEE Citation Reference \u2013 official (PDF, 440KB)\n", "subtitles": [], "title": "IEEE style"},
{"content": "The publications of the Institute of Electrical and Electronics Engineers publications (IEEE) constitute around 30% of the world literature in the electrical and electronics engineering and computer science fields,[1] publishing well over 100 peer-reviewed journals.[2] The content in these journals as well as the content from several hundred annual conferences are available in the IEEE's online digital library.[3] The IEEE also publishes more than 750 conference proceedings every year.[4] In addition, the IEEE Standards Association maintains over 1,300 standards in engineering.IEEE academic journals[edit]IEEE Magazines[edit]Other[edit]\nCommunications and Networks, Journal of, by the Korean Institute of Communications Sciences (KICS) and technically cosponsored by the IEEE Communications Society\nSee also[edit]\nCategory:IEEE conferences, many with published proceedings.\nReferences[edit]", "subtitles": ["IEEE academic journals", "IEEE Magazines", "Other", "See also", "References"], "title": "List of IEEE publications"},
{"content": "Technical Committee on VLSI (TCVLSI) is a constituency of IEEE Computer Society (IEEE-CS) that oversees various technical activities related to computer hardware, integrated circuit design, software for computer hardware design.[1] TCVLSI is one of the 26 technical committees/councils of IEEE-CS that covers various specializations of computer science and computer engineering discipline.[2] IEEE-CS is the largest of the 39 societies of Institute of Electrical and Electronics Engineers (IEEE).[3] The technical scope of TCVLSI covers the Computer-aided design (CAD) or electronic design automation (EDA) techniques to facilitate the VLSI design process. The VLSI may include various types of circuits and systems, such as digital circuits and systems, analog circuits, as well as mixed-signal circuits and systems. The emphasis of TCVLSI widely covers the integrating the design, Computer-aided design (CAD), fabrication, application, and business aspects of Very-large-scale integration (VLSI) while encompassing both hardware and software.Membership[edit]Membership in TCVLSI is open and free of charge to researchers, practitioners and students, and general prospective members are not required to be members of IEEE or IEEE Computer Society.[4] However, to serve on the executive committee, a member needs to belong to the IEEE Computer Society. The Chair of the TCVLSI is elected by the voting members of TCVLSI.[5] Other executive members of TCVLSI are appointed by the Chair.Technical Activities[edit]The TCVLSI sponsors conferences, special sessions, and workshops for the IEEE-CS. TCVLSI also runs VLSI Circuits and Systems Letter, three times a year, which has many components including a very selective dissemination of quick papers, TCVLSI member news, upcoming conferences, workshops, call for papers, and funding opportunities of interest to members of TCVLSI. TCVLSI provides several student travel grants for the TCVLSI sponsored conferences. TCVLSI also sponsors best paper awards for the sponsored conferences.TCVLSI Awards[edit]TCVLSI, IEEE-CS introduces the following awards from 2018. More information of each award is available at the following link: [6]\nIEEE-CS TCVLSI Technical Excellence Award\nIEEE-CS TCVLSI Distinguished Leadership Award\nIEEE-CS TCVLSI Distinguished Research Award\nIEEE-CS TCVLSI Mid-Career Research Achievement Award\nIEEE-CS TCVLSI Outstanding Editor Award\nIEEE VLSI Circuits and Systems Letter[edit]The VLSI Circuits and Systems Letter is freely available to the global audience online. At present, VLSI Circuits and Systems Letter (VCAL) is published twice a year which provides timely updates on science, engineering, and technologies as well as educations and opportunities related to VLSI circuits and systems. At this point, the letter contains the following sections: Features, Opinion, Updates, and Outreach and Community. The published issues has been made available below for quick access to the readers. The editorial team of the letter is also presented.Published Volumes and Issues[edit]Volume 4[edit]\nVLSI Circuits and Systems Letter: Volume 4, Issue 1, Feb 2018: pdf version\nVolume 3[edit]\nVLSI Circuits and Systems Letter: Volume 3, Issue 3, Oct 2017: pdf version\nVLSI Circuits and Systems Letter: Volume 3, Issue 2, June 2017: pdf version\nVLSI Circuits and Systems Letter: Volume 3, Issue 1, Feb 2017: pdf version\nVolume 2[edit]\nVLSI Circuits and Systems Letter: Volume 2, Issue 2, Oct 2016: pdf version\nVLSI Circuits and Systems Letter: Volume 2, Issue 1, April 2016: pdf version\nVolume 1[edit]\nVLSI Circuits and Systems Letter: Volume 1, Issue 2, October 2015: pdf version\nVLSI Circuits and Systems Letter: Volume 1, Issue 1, April 2015: pdf version\nEditor-in-Chiefs (EiCs)[edit]\nSaraju Mohanty, University of North Texas, USA[7]\nAnirban Sengupta, Indian Institute of Technology Indore, India[8]\nDeputy Editor-in-Chief[edit]\nYiyu Shi, University of Notre Dame, USA[9]\nAssociate Editors[edit]\nHelen Li, Duke University, USA[10]\nHideharu Amano, Keio University, Japan\nHimanshu Thapliyal, University of Kentucky, USA[11]\nJun Tao, Fudan University, China\nMichael Hu\u0308bner, Ruhr University Bochum, Germany[12]\nMike Borowczak, University of Wyoming, USA[13]\nQi Zhu, University of California, Riverside, USA[14]\nSaket Srivastava, University of Lincoln, UK[15]\nShiyan Hu, Michigan Technological University, USA[16]\nYasuhiro Takahashi, Gifu University, Japan\nSergio Saponara, University of Pisa, Italy[17]\nEmeritus Editor-in-Chief (EiC)[edit]\nXin Li, Duke University, USA[18]\nPast Associate Editors[edit]\nPrasun Ghosal, Indian Institute of Engineering Science and Technology (IIEST), India[19]\nJawar Singh, Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, India[20]\nKey People[edit]Executive Committee[edit]\nChair - Saraju Mohanty, University of North Texas, USA\nVice Chair for Conferences - Jia Di, University of Arkansas, USA\nTreasurer - Hai (Helen) Li, Duke University, USA\nVice Chair for Membership - Dhruva Ghai, Oriental University Indore, India\nVice Chair for Liaison - Nagi Naganathan, Broadcom Limited, USA\nVice Chair for Outreach and Webmaster - Mike Borowczak, University of Wyoming, USA\nIEEE VCAL, Editor-in-Chiefs (EiCs)\u2013\n\nSaraju Mohanty, University of North Texas, USA\nAnirban Sengupta, Indian Institute of Technology Indore\n\n\nPast Chairs[edit]\n2002-2014: Joseph Cavallaro, Rice University.[21]\n2000-2002: Vijaykrishnan Narayanan, Pennsylvania State University.[22]\n1996-2000: Nagarajan Ranganathan, University of South Florida.[23]\n1984-1986: Amar Mukherjee, University of Central Florida.[24]\nTCVLSI Sister Conferences[edit]Sponsored Conferences[edit]\nARITH, IEEE Symposium on Computer Arithmetic\n\nARITH 25 (2018): July 25\u201327, 2017, Amherst, MA, USA\nARITH 24 (2017): July 24\u201326, 2017, London, UK\nARITH 23 (2016): July 10\u201313, 2016, Santa Clara, California, USA\nARITH 22 (2015): June 22\u201324, 2015, Lyon, France\nSteering Committee:\n\nEarl Swartzlander, University of Texas at Austin, Chair\nElisardo Antelo, University of Santiago de Compostela, Spain\nJean-Claude Bajard, Universite\u0301 Pierre et Marie Curie, Paris, France\nJavier Bruguera, ARM Cambridge, UK\nNeil Burgess, ARM, USA\nMarius Cornea, Intel, USA\nDebjit DasSarma, AMD, USA\nMilos Ercegovac, University of California at Los Angeles, USA\nDavid Hough, Oracle, USA\nPaolo Ienne, EPFL, Switzerland\nIsrael Koren, University of Massachusetts, USA\nPeter Kornerup, University of Southern Denmark, Denmark\nDavid Matula, Southern Methodist University, USA\nPaolo Montuschi, Politecnico di Torino, Italy\nJean-Michel Muller, CNRS, France\nAlberto Nannarelli, Technical University of Denmark, Denmark\nVojin G. Oklobdzija, ACSEL, USA\nMichael Schulte, AMD, USA\nEric Schwarz, IBM, USA\nPeter-Michael Seidel, AMD, USA\nNaofumi Takagi, Kyoto University, Japan\nPing Tak Peter Tang, Intel, USA\nArnaud Tisserand, CNRS, IRISA, France\nJulio Villalba, University of Malaga, Spain\n\n\n\n\nASAP, IEEE International Conference on Application-specific Systems, Architectures and Processors\n\nASAP 2017: July 10\u201312, 2017, Seattle, WA. Website: http://www.asapconference.org/\nASAP 2016: July 6\u20138, 2016, London, England. Website: http://www.asap2016.org/\nASAP 2015: July 27\u201329, 2015, Toronto, Canada. Website: http://www.eecg.toronto.edu/asap2015/\nSteering Committee :\n\nJose\u0301 A.B. Fortes, University of Florida, USA\nSun-Yuan Kung, Princeton University, USA\nWayne Luk, Imperial College London\nMichael J. Schulte, University of Wisconsin Madison, USA\nEarl Swartzlander, The University of Texas at Austin, USA\n\n\n\n\nASYNC, IEEE International Symposium on Asynchronous Circuits and Systems\n\nASYNC 2019: May 12\u201315, 2019, Aomori, Japan\nASYNC 2018: May 13\u201316, 2018, Vienna, Austria, Website: http://www.async2018.wien/\nASYNC 2017: May 21\u201324, 2017, San Diego, CA, USA, Website: http://www.async2017.org/\nASYNC 2016: May 8\u201311, 2016, Porto Alegre, Brazil, Website: http://www.inf.pucrs.br/async2016/\nASYNC 2015: May 4\u20136, 2015, Mountain View, CA, USA, Website: http://ee.usc.edu/async2015/\nSteering Committee:\n\nMontek Singh, University of North Carolina at Chapel Hill, Chair\nPeter A. Beerel, University of Southern California\nEdith Beigne\u0301, CEA-LETI, France\nErik Brunvand, University of Utah\nNey Laert Vilar Calazans, PUCRS, Brazil\nHong Chen, Tsinghua University, China\nMark Greenstreet, University of British Columbia, Canada\nIan Jones, Oracle Corporation\nJoycee Mekie, Indian Institute of Technology Gandhinagar, India\nMilos Krstic, IHP, Germany\nJens Spars\u00f8, Technical University of Denmark\nAndreas Steininger, Vienna University of Technology\nPascal Vivet, CEA-LETI, France\nEslam Yahya, Benha University, Egypt\nTomohiro Yoneda, NII, Japan\nJordi Cortadella, UPC, Spain\n\n\n\n\niSES, IEEE International Symposium on Smart Electronic Systems (formerly IEEE International Symposium on Nanoelectronic and Information Systems)\n\niSES 2018: December 17\u201319, 2018, Hyderabad, India\niNIS 2017: December 18\u201320, 2017, Bhopal, India\niNIS 2016: December 19\u201321, 2016, Gwalior, India\niNIS 2015: December 21\u201323, 2015, Indore, India\nSteering Committee:\n\nSaraju P. Mohanty, University of North Texas, USA, Chair\nDhruva Ghai, Oriental University, India, Vice Chair\nAida Todri-Sanial, CNRS-LIRMM, France\nAshok Srivastava, Louisiana State University, USA\nAnirban Sengupta, Indian Institute of Technology Indore, India\nHai (Helen) Li, University of Pittsburgh, USA\nHimanshu Thapliyal, University of Kentucky, USA\nJia Di, University of Arkansas, USA\nNabanita Das, Indian Statistical Institute, India\nPrasun Ghosal, Indian Institute of Engineering Science and Technology, Shibpur, India\nSudeep Pasricha, Colorado State University, USA\nXin Li, Carnegie Mellon University, USA\n\n\n\n\nISVLSI, IEEE Computer Society Symposium on VLSI\n\nISVLSI 2020: July 6\u20138, 2020, Cyprus\nISVLSI 2019: July 8\u201310, 2019, Miami, FL, USA\nISVLSI 2018: July 9\u201311, 2018, Hong Kong\nISVLSI 2017: July 3\u20135, 2017, Bochum, Germany\nISVLSI 2016: July 11\u201313, 2016, Pittsburgh, Pennsylvania, USA\nISVLSI 2015: July 10\u201312, 2015, Montpellier, France\nISVLSI 2014: July 9\u201311, 2014, Tampa, Florida, USA\nISVLSI 2013: August 5\u20137, 2013, Natal, Brazil\nISVLSI 2012: August 19\u201321, 2012, Amherst, USA\nSteering Committee:\n\nJu\u0308rgen Becker, Karlsruhe Institute of Technology, Germany, Chair\nSaraju P. Mohanty, University of North Texas, USA, Vice-Chair\nHai (Helen) Li, University of Pittsburgh, USA\nLionel Torres, University of Montpellier, France\nMichael Hu\u0308bner, Ruhr-University of Bochum, Germany\nNikolaos Voros, Technological Educational Institute of Messolonghi, Greece\nRicardo Reis, Universidade Federal do Rio Grande do Sul, Brazil\nSandip Kundu, University of Massachusetts, Amherst, USA\nSanjukta Bhanja, University of South Florida, USA\nSusmita Sur-Kolay, Indian Statistical Institute, Kolkata, India\nVijaykrishnan Narayanan, Pennsylvanian State University, USA\n\n\n\n\nIWLS, IEEE International Workshop on Logic & Synthesis\n\nIWLS 2017: June 17 \u2013 18, 2017, Thompson Conference Center \u2014 Austin, TX\nIWLS 2016: June 10\u201311, 2016, Thompson Conference Center \u2014 Austin, TX\nIWLS 2015: June 12\u201313, 2015, Computer History Museum \u2014 Mountain View, CA\nSteering Committee:\n\nDirk Stroobandt, Ghent University, Belgium\nAndre Reis, UFRGS, Brazil\nIlya Wagner, Intel, USA\nValeria Bertacco, University of Michigan, USA\nPhilip Brisk, University of California Riverside, USA\nStephen A. Edwards, Columbia University, USA\nAlan Mishchenko, University of California Berkeley, USA\n\n\n\n\nMSE, IEEE International Conference on Microelectronic Systems Education\n\nMSE 2017: May 11\u201312, 2017, Banff, Canada\nMSE 2015: May 20\u201321, 2015, Pittsburgh, PA, USA\nSteering Committee:\n\nDon Bouldin, University of Tennessee Knoxville, Chair\n\n\n\n\nSLIP, ACM/IEEE System Level Interconnect Prediction\n\nSLIP 2017: June 17, 2017, Austin Convention Center, Austin, TX, USA\nSLIP 2016: June 4, 2016, Austin Convention Center, Austin, TX, USA\nSLIP 2015: June 6, 2015, Moscone Center, San Francisco, CA, USA\nSteering Committee :\n\nChuck Alpert, Cadence Inc., USA\nDeming Chen, University of Illinois at Urbana-Champaign, USA\nChung-Kuan Cheng, University of California, San Diego, USA\nAndrew B. Kahng, University of California, San Diego, USA\nMichael Kishinevsky, Intel Corp., USA\nRasit O. Topaloglu, IBM Corp., USA\n\n\n\n\nECMSM, IEEE International Workshop of Electronics, Control, Measurement, Signals and their application to Mechatronics\n\nECMSM 2017: June 24\u201326, 2017, Mondragon, Spain, Website: http://ecmsm2017.mondragon.edu/en\nECMSM 2015: June 22\u201324, 2015, Liberec, Czech Republic, Website: http://ecmsm2015.tul.cz/\nSteering Committee:\n\nFrancois Pigache, University of Toulouse, France, Chair\nYannick DEVILLE, France\nPhilippe JOLY, France\nZbynek KOLDOVSKY\u0301, Czechoslovakia\nJiri MALEK, Czechoslovakia\nJ. Carlos MUGARZA, Spain\nJaroslav NOSEK, Czechoslovakia\nZdenek PLIVA, Czechoslovakia\n\n\n\n\nTechnically Co-Sponsored Conferences[edit]\nACSD, International Conference on Application of Concurrency to System Design\n\nACSD 2017: June 25\u201330, 2017, Zaragoza, Spain, Website: http://pn2017.unizar.es/\nACSD 2016: June 19\u201324, 2016, Torun\u0301, Poland, Website: http://pn2016.mat.umk.pl/\nACSD 2015: June 21\u201326, 2015, Brussels, Belgium, Website: http://www.ulb.ac.be/di/verif/pn2015acsd2015/\nSteering Committee:\n\nAlex Yakovlev, Newcastle University, Chair\n\n\n\n\nVLSID, International Conference on VLSI Design\n\nVLSID 2018: January 6\u201310, 2018, Pune, India\nVLSID 2017: January 7\u201311, 2017, Hyderabad, India\nVLSID 2016: January 4\u20138, 2016, Kolkata, India\nVLSID 2015: January 3\u20137, 2016, Bangalore, India\nSteering Committee:\n\nVishwani D. Agrawal, Auburn University, Chair\n\n\n\n\nReferences[edit]", "subtitles": ["Membership", "Technical Activities", "TCVLSI Awards", "IEEE VLSI Circuits and Systems Letter", "Key People", "TCVLSI Sister Conferences", "References"], "title": "Technical Committee on VLSI"},
{"content": "Syd Dale (20 May 1924 \u2013 15 August 1994) was an English self-taught composer and arranger of funk, easy listening and library music. His music played an important role on TV, radio and advertising media of the 1960s and 1970s and is still used.Biography[edit]Dale started as an apprentice engineer at Rowntree's chocolate factory at 16. Soon big band music, very popular in the 1940s, became his passion. He spent as much time as possible listening to the Big Bands and studying the arrangements. Three years later, in 1945, he left the factory and joined several local bands as pianist and arranger.His music, which emphasized melody and harmony with intricate arrangements, was composed for many television and radio projects. He was musical director on Oh Boy, Six-Five Special and Braden's Week. He had also co-arranged and co-produced some 007 themes as many other commercial successes. Another of his many production music pieces, the bongo drum and harpsichord-driven Cuban Presto (originally released on the 1966 KPM album Accent on Percussion), was used by WPIX (Channel 11) in New York City as the theme for its late-night movie show, The Channel 11 Film Festival, from the late 1960s to the 1980s. [1][2]Two years later he produced a track entitled Walk and Talk, which was used for many years on BBC Two as the countdown music before television transmitter information bulletins were read over the air.[3][4] It also appeared in the 1967 ABC television animated series Spider-Man along with many other Dale library tracks. In the early 1990s the track was sampled by Meryn Cadell for her recitation The Sweater, which was used by skater Jose\u0301e Chouinard in one of her award-winning routines. The late rapper Eazy-E also sampled the track for his performance in Gimme Datt Nutt.In 1971, he founded Amphonic Music record label for the express purpose of recording and producing his compositions and supplying music to the TV, film and radio business.In 1970 his track Marching There and Back was used as the theme music to the BBC Television children's programme Screen Test, presented initially by Michael Rodd.Through the 1970s and 1980s his The Hellraisers composition was used as the theme music to the BBC World Service Outlook topical programme. It was also used as the theme music to Orlando, a children's television thriller serial starring Sam Kydd which ran for 76 episodes from 1965 to 1968.His music is still used in productions today. For example, his Beauty Parade was used in the SpongeBob SquarePants episode Spy Buddies when Plankton get all of the customers out of Mr. Krabs's restaurant, the Krusty Krab. Plankton played it very loudly while flying over the Krusty Krab in his blimp. In the TV comedy series Episodes, Matt LeBlanc uses the tune Two Time as his iPhone's ringtone. Man Friday was used as the theme tune to LWT's Tarrant on TV; and The Penthouse Suite in the episode of Speed 3 with Milkman Pat Mustard, in Father Ted.Dale's tracks have been widely used by NFL Films over some four decades; his track Artful Dodger is given prominent use in such films as the official film recapping Super Bowl V.Dale died on 15 August 1994, at the age of 70.[5]Discography[edit]The following list is only a small sample of his work.\nThe Penthouse Suite\nWalk and Talk\nLPs[edit]\nThe Sounds of Syd Dale (1966)\nImpact and Action (1967)\nFlamboyant Themes - Vol. II (1968)\nImpact & Action - Vol. 2 (1970)\nLove Isn't Just For The Young Various Volumes\nPost-mortem compilations[edit]\nSyd Dale: Retro\nKitsch UK\nCinemaphonic Soul Punch\nSwinging 60's\nCocktail Lounge\nDusty Fingers Volume 13\nKpm 1000 Series: On The Lighter Side\nReferences[edit]External links[edit]\nSyd Dale at AllMusic\nSyd Dale discography at Discogs\nSyd Dale on IMDb\n", "subtitles": ["Biography", "Discography", "References", "External links"], "title": "Syd Dale"},
{"content": "The Man Who Sold the World is a song written and performed by David Bowie. It is the title track of his third album, with the same name, which was released in the US in November 1970 and in the UK in April 1971. The song has been covered by a number of other artists, notably by Lulu, who had a UK No. 3 hit with her version in 1974, and Nirvana, whose 1993 performance of the song for the television program MTV Unplugged introduced it to a new audience.The song was reworked by Bowie, featuring a heavy bassline, gu\u0308iro as percussion and a notably darker mood, for performances in concerts from 1995 to 1997, including the 1995 MTV Europe Music Awards. Bowie later returned to playing the original version in the 2000s.Inspiration and explanation[edit]The persona in the song has an encounter with a kind of doppelga\u0308nger, as suggested in the second chorus where I never lost control is replaced with We never lost control.[1] Beyond this, the episode is unexplained: as James E. Perone wrote,\nBowie encounters the title character, but it is not clear just what the phrase means, or exactly who this man is. ... The main thing that the song does is to paint \u2013 however elusively \u2013 the title character as another example of the societal outcasts who populate the album.[2]\nIn common with a number of tracks on the album, the song's themes have been compared to the horror-fantasy works of H. P. Lovecraft.[3] The lyrics are also cited as reflecting Bowie's concerns with splintered or multiple personalities, and are believed to have been partially inspired by the poem Antigonish by William Hughes Mearns:[4]In the BBC Radio 1 special programme ChangesNowBowie, broadcast on 8 January 1997, Bowie was interviewed by Mary Anne Hobbs and was asked about the song. He commented: I guess I wrote it because there was a part of myself that I was looking for. Maybe now that I feel more comfortable with the way that I live my life and my mental state (laughs) and my spiritual state whatever, maybe I feel there's some kind of unity now. That song for me always exemplified kind of how you feel when you're young, when you know that there's a piece of yourself that you haven't really put together yet. You have this great searching, this great need to find out who you really are.[5]Other releases by Bowie[edit]\nThe Man Who Sold the World appeared as the B-side on the American single release of the song Space Oddity (1973 rerelease) and British single Life on Mars? (1973). It also appears on various Bowie compilations such as Sound + Vision (1989), The Best of David Bowie 1969/1974 (1997), Best of Bowie (2002), The Platinum Collection (2006), Nothing Has Changed (2014), and Bowie Legacy (2016).\nBowie performed the song on Saturday Night Live in December 1979, with Klaus Nomi and Joey Arias. A portion of this show is included in the film The Nomi Song.\nA new studio version of the song, recorded by Bowie in 1995 and mixed by Brian Eno, appears as a B-side on the CD single Strangers When We Meet. This version also appears on the bonus disc that followed some versions of Outside - Version 3. It was this arrangement that appeared in Bowie's 2016 stage musical, Lazarus.\nA live version recorded at BBC Radio Theatre, London, on 27 June 2000 was released on the bonus disc accompanying the first releases of Bowie at the Beeb in 2000.\nA November 2003 live performance from the Reality Tour is featured on the A Reality Tour DVD, released in 2004, as well as the A Reality Tour album, released in 2010.\nBowie personnel[edit]\nDavid Bowie \u2013 vocals, acoustic guitar, organ\nMick Ronson \u2013 electric guitar\nTony Visconti \u2013 bass guitar, backing vocals\nWoody Woodmansey \u2013 drums, percussion\nCover versions[edit]Lulu[edit]The song was covered by the Scottish singer Lulu in 1974, who, according to biographer David Buckley, performed it in a sleazy, almost Berlin cabaret style.[6] Lulu would recall Bowie inviting her to a concert he gave after which he met her in his hotel room saying: I want to make an MF of a record with you [because] you're a great singer. Lulu - I didn't think it would happen but [Bowie] followed up two days later. He was u\u0308bercool at the time and I just wanted to be led by him. I loved everything he did. I didn't think 'The Man Who Sold the World' was the greatest song for my voice, but it was such a strong song in itself. I had no idea what it was about. In the studio Bowie kept telling me to smoke more cigarettes, to give my voice a certain quality.[7] Bowie produced the Lulu recording of The Man Who Sold the World with Mick Ronson during the July 1973 Pin Ups sessions and also contributed guitar, saxophone and backing vocals. The remainder of the band included Ronson on guitar, Trevor Bolder on bass, Mike Garson on piano, and Aynsley Dunbar on drums.[8]Lulu's The Man Who Sold the World was released as a single on 11 January 1974 having been introduced by Lulu on the TOTP broadcast of 10 January 1974: the track only made its Top 50 debut (at #27) on the chart dated 26 January 1974 following a reprise performance by Lulu on TOTP two days earlier on 24 January 1974, with a third TOTP performance by Lulu on 7 February 1974 broadcast facilitating a boost from No. 13 to No. 5 on the chart dated 9 February 1974. In her TOTP performances in support of The Man Who Sold the World Lulu has been characterized as dressed and sounding exactly like a diminutive Bowie.[9] Lulu performed the song in the second-season finale of French and Saunders.\nLulu's chart positions\nLulu Personnel[edit]\nLulu \u2013 lead vocals\nDavid Bowie \u2013 sax, backing vocals\nMick Ronson \u2013 guitars\nTrevor Bolder \u2013 bass guitar\nMike Garson \u2013 piano\nAynsley Dunbar \u2013 drums\nMidge Ure[edit]Midge Ure covered this song in a 1982 studio release, which appeared on the Party Party Original Motion Picture Soundtrack (released 3 December 1982) and promotional 7 single (backed with Band Of Gold by Modern Romance). The track was subsequently re-recorded/re-mixed and released as a B-side to Midge Ure's If I Was 12 single (released 13 September 1985). This later version is featured as the title song of the 2015 video game Metal Gear Solid V: The Phantom Pain.Richard Barone[edit]The song was covered by American singer Richard Barone in 1987 on his proto-chamber pop album, Cool Blue Halo. Using cello, acoustic guitar and symphonic percussion in a live setting.Nirvana[edit]In his journals, Kurt Cobain of the American grunge band Nirvana ranked the album The Man Who Sold the World at number 45 in his top 50 favourite albums.[13] A live rendition of the song was recorded by the band in 1993 during their MTV Unplugged appearance, and it was released on their MTV Unplugged in New York album the following year. The song was also released as a promotional single for the album,[14] and received considerable airplay on alternative rock radio stations. It was also thrown into heavy rotation on music video stations such as MTV. Nirvana regularly covered the song during live sets after their memorable acoustic performance up until lead singer Cobain's death in 1994. In 2002, the song was re-released on Nirvana's self-titled best of compilation.Bowie said of Nirvana's cover: I was simply blown away when I found that Kurt Cobain liked my work, and have always wanted to talk to him about his reasons for covering 'The Man Who Sold the World' and that it was a good straight forward rendition and sounded somehow very honest. It would have been nice to have worked with him, but just talking with him would have been real cool.[15] Bowie called Nirvana's cover heartfelt, noting that until this [cover], it hadn't occurred to me that I was part of America's musical landscape. I always felt my weight in Europe, but not [in the US].[16] In the wake of its release, Bowie bemoaned the fact that when he performed the number himself he would encounter kids that come up afterwards and say, 'It's cool you're doing a Nirvana song.' And I think, 'Fuck you, you little tosser!'[17]On 14 February 2016, surviving Nirvana band members Krist Novoselic, Dave Grohl and Pat Smear teamed up with Beck to perform The Man Who Sold the World at a pre-Grammy Awards party, in tribute to Bowie, with Beck performing the vocals.[18] In 2017, to mark what would have been Kurt Cobain's 50th birthday, the Phonographic Performance Limited released a list of the top twenty most played Nirvana songs on the TV and radio in the UK in which The Man Who Sold the World was ranked at number six.[19]A louder electric guitar cover appears on the bands 'Live and Loud' set list.\nNirvana's chart positions\nNirvana personnel[edit]\nKurt Cobain \u2013 vocals, lead guitar\nPat Smear \u2013 rhythm guitar\nKrist Novoselic \u2013 bass guitar\nDave Grohl \u2013 drums\nLori Goldston \u2013 cello\nFive Years (1969\u20131973)[edit]The song appears on the compilation album Five Years (1969\u20131973). Metrobolist was the album's original title, planned for release by Bowie as a gatefold presentation, with hand drawn title accompanying cartoon-style drawings front and back, opening up to display a double sleeve photo-spread inside. But the only substantial evidence Metrobolist was ever proposed as a Mercury record company product are labels with the title \u201cMetrobolist\u201d printed on surviving tape boxes.[29]Other covers[edit]\nLea Laven as Mies Joka Myi Maailman on her album Niin (1974).\nMidge Ure on the film soundtrack Party Party (1982). This version is also included on No Regrets: The Very Best of Midge Ure, and the compilations The David Bowie Songbook and Starman: Rare and Exclusive Versions of 18 Classic David Bowie Songs, CD premium from the March 2003 issue of Uncut magazine. This version is also played during the opening scene and end credits of the video game Metal Gear Solid V: The Phantom Pain.\nHere & Now on the album Fantasy Shift (1983).\nElektric\u030cni Orgazam on the album Les Chansones Populaires (1983).\nEd Kuepper on the album The Exotic Mail Order Moods of Ed Kuepper (1995).\nSimple Minds on the covers album Neon Lights (2001).\n3 Melancholy Gypsys sampled the Nirvana version in their song 2010. which appears on the Living Legends album Legendary Music, Vol. 1.\nJordis Unga on Rock Star INXS, also released as a digital single.\nCocosuma on BowieMania: Mania, une collection obsessionelle de Beatrice Ardisson (2007).\nApoptygma Berzerk uses the guitar melody for a live rendition of the song Mourn, which can be heard on the album APBL2000 (2001).\nCross Canadian Ragweed have also covered the song on various occasions.\nMeat Puppets have also covered this song.\nJohn Cougar Mellencamp performed it as a bonus track on his album The Kid Inside (1983).\nMohsen Namjoo used the main riff on the song Morq-e Sheida\u0302.\nArtist Jeremy Deller uses the song, as performed by the Melodians Steel Orchestra (a steel band from South London), as part of the soundtrack for his 2013 short film English Magic.[30]\nKamyaniy Gist covered this song in Ukrainian (album \u00ab70/80\u00bb, 2015). Source.\nActor Gary Oldman, who was a close friend of Bowie's, performed it in tribute on February 8, 2016 at the Roxy Theatre in Los Angeles.\nMarch 29, 2016 Michael Stipe of R.E.M. performs the song on The Tonight Show Starring Jimmy Fallon accompanied by only a piano in tribute to David Bowie.[31][32]\nOctober 31, 2016 Bubbles from Trailer Park Boys released a cover. Source\nReferences[edit]External links[edit]\nThe Man Who Sold the World cover by Nirvana Official music video (Live at MTV Unplugged) on YouTube\nLyrics of this song at MetroLyrics\n", "subtitles": ["Inspiration and explanation", "Other releases by Bowie", "Bowie personnel", "Cover versions", "References", "External links"], "title": "The Man Who Sold the World"},
{"content": "Beatrice Melba Hill[1] (born October 29, 1945), known by her stage name, Melba Moore is an American singer, actress, voice actress, and entertainer.[2] Moore is the daughter of saxophonist Teddy Hill and R&B singer Bonnie Davis.Early life[edit]Moore was born Beatrice Melba Hill on October 29, 1945,[5] in New York City, New York, to Gertrude Melba Smith (known professionally as Bonnie Davis) and Teddy Hill, and raised in Harlem, New York, until she was 9 and her divorced mother remarried jazz pianist Clement Leroy Moorman. She attended Newark Arts High School in Newark, New Jersey,[6] Graduating in 1958.[7]Her mother, Bonnie Davis, had a No. 1 R&B hit with Don't Stop Now, prior to Melba's birth. Although her biological father was Big Band leader and saxophonist Teddy Hill, it was her stepfather Moorman (who played on Don't Stop Now) who became a prime influence and encouragement in Moore's musical pursuits, insisting that she learn to play the piano. When she graduated from college she worked as a music teacher, but she soon decided to pursue the spotlight.Early career[edit]Moore began her recording career in 1967, cutting the track Magic Touch which was left unreleased until 1986. It has become an enormous track on the Northern Soul Scene, eventually leading to Moore performing it live in 2009 at the Baltic Soul Weekender 3 in Germany north of Hamburg. She began her performing career in 1967 as Dionne in the original cast of the musical Hair along with Ronnie Dyson and Diane Keaton.Moore replaced Keaton in the role of Sheila. In 1970, she won a Tony Award for Best Performance by a Featured Actress in a Musical for her portrayal of Lutiebelle in Purlie. She would not return to Broadway until 1978 when she appeared (as Marsinah) with Eartha Kitt in Timbuktu! but left the show after a few weeks and was replaced by Vanessa Shaw.Following the success of Purlie, Moore landed two big-screen film roles, released two successful albums, 1970's I Got Love and Look What You're Doing to the Man, and co-starred with actor Clifton Davis in the then-couple's own successful variety television series in 1972. Both Moore and Davis revealed that the show was canceled after its brief run when their relationship ended. When Moore's managers and accountants left her in 1973, she returned to Newark and began singing in benefit concerts. Her career picked up after she met record manager and business promoter Charles Huggins after a performance at the Apollo Theater in 1974. They married in 1975.Music career[edit]In 1975 Moore signed with Buddah Records and released the critically successful R&B album, Peach Melba, which included the minor hit, I Am His Lady. The following year she scored her first significant hit with the Van McCoy-penned This Is It, which reached the Billboard Hot 100, the top-20 position on the R&B chart, and top-10 in the UK, becoming her biggest success in that country. 'This is It' also became the number 1 disco track in the UK for that year. It would be 18 years later that Australian singer Dannii Minogue will cover this song and make it to number 10 on the ARIA charts.In 1976 she scored her third Grammy nomination with the R&B ballad Lean on Me, which had been recorded originally by Vivian Reed and later by Moore's idol Aretha Franklin who recorded the song as a B-side to her 1971 hit Spanish Harlem. The song is most notable for Moore's extended long note at the end. In 1983 she re-recorded the song as a tribute to McCoy, who had died four years earlier. Throughout the rest of the 1970s, Moore struggled to match the success of This Is It with minor R&B/dance hits. However, her hit 'Pick me up I'll dance' released in May 1979 produced by McFadden & Whitehead and released on Epic Records did have considerable UK disco success, reaching UK chart position 48, along with a further hit that same year, also produced by McFadden & Whitehead with a cover version of the Bee Gees' hit You Stepped Into My Life, which reached the top 20 on the R&B charts and 47 on the Billboard Hot 100.In 1981 Moore signed with Capitol Records and reached the top 5 on the R&B charts with the dance-pop/funk single Love's Comin' At Ya, which also hit the top 20 in the UK (on EMI America EA 146) and became a sizable hit in some European countries for its post-disco sound and followed by Mind Up Tonight, which was another top 40 hit in the UK reaching position number 22. A string of R&B hits followed, including 1983's Keepin' My Lover Satisfied and Love Me Right, 1984's Livin' For Your Love, 1985's Read My Lips\u2014which later won Moore a fourth Grammy nomination for Best Female Rock Vocal Performance, making her just the third black artist after Donna Summer and Michael Jackson to be nominated in the rock category\u2014and 1985's When You Love Me Like This.In 1986, she scored two number 1 R&B hits, including the duet A Little Bit More with Freddie Jackson and Falling. She scored other popular R&B hits including Love the One I'm With (A Lot of Love) and It's Been So Long. In 1986, Moore also headlined the CBS television sitcom Melba; its debut aired the same night as the Challenger explosion and the show was abruptly cancelled, though five episodes aired that summer. Her success began to wane as the decade closed, although she managed two further Top 10 R&B hits, Do You Really (Want My Love) and Lift Every Voice and Sing. Moore had a starring role in the 1990 horror film Def by Temptation.Current work[edit]Moore returned to Broadway in 1995 landing a part in Les Mise\u0301rables. A year later, she started her long-running one-woman show, Sweet Songs of the Soul, later renamed I'm Still Standing. In 2003, Moore was featured in the film, The Fighting Temptations, which starred Cuba Gooding, Jr. and Beyonce\u0301 Knowles. In 2007, she landed a role in the Broadway revival of Ain't Misbehavin'. In 2009 independent label Breaking Records released the EP Book of Dreams, in which Moore was featured. That same year Moore told her life story on TV-One's Unsung and later that year released her first R&B album in nearly 20 years, a duet with Phil Perry called The Gift of Love. Her song called Love Is debuted on the R&B charts in 2011 at #87.Personal life[edit]Moore, a born-again Christian, engaged in a four-year relationship with television star Clifton Davis.[8] Davis later admitted that the relationship didn't work due to his drug abuse and mistreatment of Moore.[9]In 1975 Moore married Charles Huggins and the two formed Hush Productions. After 15 years of marriage, in 1991, Huggins abruptly divorced Moore leaving the singer in financial ruins.[10] In 1999, Huggins filed suit against Moore claiming that she had defamed him in the public as she stated that he abused her economically.[11][12]Awards[edit]In addition to her Tony Award, her music career brought additional accolades. She was nominated for a Grammy Award in 1971 for 'Best New Artist'. Her 1975 second album, Peach Melba, saw her get a Grammy nomination. In 1976, she earned another Grammy nomination for Best Rhythm & Blues Vocal Performance - Female for the song Lean on Me,.[13]Moore was also nominated for Best Female Rock Vocal in 1986 for Read My Lips. Moore is also the 2012 Recipient of the Atlanta Black Theatre Festival Theatre Legend Award. Moore was inducted into the Official Rhythm & Blues Music Hall of Fame on October 4, 2015, in Detroit.Moore received the prestigious 2015 Sandy Hosey Lifetime Achievement Award during the Artists Music Guild's 2015 AMG Heritage Awards broadcast held on November 14, 2015, in North Carolina.[14]Ms. Moore stars in the Westcoast Black Theatre Troupe's production of Lady Day at Emerson's Bar and Grill to great acclaim in the sold-out run. =Stage work==\nHair (1967)\nPurlie (1970)\nTimbuktu! (1978)\nInacent Black (1981)\nBroadway at the Bowl (1988)\nFrom the Mississippi Delta (1993, est)\nLes Mise\u0301rables (1995)\nBrooklyn (2006)\nStraight 2the Head (2013)\nGreat God A'Mighty (2013)\nFilmography[edit]\nCotton Comes to Harlem (1970) \u2013 Singer at the Apollo Theater (uncredited)\nThe Sidelong Glances of a Pigeon Kicker (1970) \u2013 Model at Party\nAll Dogs Go to Heaven (1989) \u2013 Whippet Angel (voice)\nThe Fighting Temptations (2003) \u2013 Bessie Cooley\nDiscography[edit]Albums[edit]Compilation[edit]Singles[edit]\n^1 Let's Stand Together and Take My Love charted together on the US Billboard Dance chart, but charted separately elsewhere.\nSee also[edit]\nList of disco artists (L-R)\nList of post-disco artists and songs\nList of female movie actors by name: M\nGuests on Soul Train\nList of performers on Top of the Pops\nList of Broadway musicals stars\nList of artists who reached number one on the Billboard R&B chart\nReferences[edit]Further reading[edit]\nAls, Hilton (8 February 2010). Critic's Notebook: Let the Sunshine In. The New Yorker. 85 (48): 13. Retrieved 28 September 2011. \nExternal links[edit]\nMelba Moore's Official Myspace page\nMelba Moore at the Internet Broadway Database \nMelba Moore on IMDb\nSoulTracks.com profile of Melba Moore\nMelba Moore @ soulandfunkmusic.com\nMelba Moore 2012 Audio Interview at Soulinterviews.com\n", "subtitles": ["Early life", "Early career", "Music career", "Current work", "Personal life", "Awards", "Filmography", "Discography", "See also", "References", "Further reading", "External links"], "title": "Melba Moore"},
{"content": "Shout is a popular American song, originally recorded by the Isley Brothers. Released in 1959, it was written by the brothers themselves as a call and response answer to Jackie Wilson's Lonely Teardrops, which they would occasionally cover in live performances.History[edit]While the song did not reach higher than #47 on the Billboard Hot 100, it became the brothers' first gold single on the basis of its longevity, and it became a much-covered tune, with many U.S. and international artists recording the song.One month after the initial release, Johnny O'Keefe covered it in his Australian TV show Six O'Clock Rock and released it as a single, reaching #2 in Australia. His 1964 re-recording was only a minor hit at #49.[2] Joey Dee and the Starliters reached #6 with their recording of the song in 1962 (The Starlighters also worked the call-and-response portion of the song into its even bigger hit, Peppermint Twist), while the Isley Brothers' version re-charted that same year at #94.Scottish pop singer Lulu had a #7 UK hit with the song in 1964 (attributed to Lulu and the Luvvers),[3][4] and a #8 UK hit with a re-recorded version in 1986.[4] The Shangri-Las included a version of the song in their debut LP Leader of the Pack[5] in 1965 as did the Kingsmen on their Volume 3 album in 1965 and 15 Great Hits album in 1966. Tommy James and the Shondells recorded a version of the song on their 1967 album, I Think We're Alone Now.[6] The Ronettes frequently covered the song in live performances as well, including their appearance in The Big TNT Show. The Trammps released a version of the song in 1975.The song, as performed by Otis Day and the Knights, was also prominently featured in the 1978 fraternity house film National Lampoon's Animal House. To this day, the song is regularly performed at Dartmouth College, the Ivy League institution in Hanover, New Hampshire, upon which the Animal House story was based, and at the University of Oregon, where the movie was filmed. The 1959 original by the Isley Brothers appeared in the 1982 comedy film Diner, and the Cheers fourth season episode Suspicion. Question Mark & the Mysterians recorded a version of the song on their 1967 album, Action.[7] Alvin and the Chipmunks covered the song for their 1996 album Club Chipmunk: The Dance Mixes with Simon providing the lead vocals. The Beatles included a live version of the song on their 1996 rarities compilation, Anthology 1. American rock group Bon Jovi has covered this song live preceded by Bad Medicine. American punk rock band Green Day performed the song on their 2005 live album Bullet in a Bible after King for a Day.[8] Green Day has also regularly performed the song during their live shows since at least 2005, always after King for a Day. Also Bruce Springsteen often performs this song live in a medley with Twist and Shout. Blaine Anderson (Darren Criss) and Brittany Pierce (Heather Morris) performed the song in the 2013 Glee episode Girls (and Boys) On Film. Robbie Williams performed the song as part of a Call & Response Medley on his Swings Both Ways tour in 2014, along with Reet Petite and Hit the Road Jack.The song was inducted to the Grammy Hall of Fame in 1999. It ranked #118 on Rolling Stone's list of The 500 Greatest Songs of All Time.Cover versions[edit]\nJohnny O'Keefe 1959 (One month after the original release).\nJoey Dee & The Starliters November 1961\nDion July 1962\nCarl Holmes and His Commanders 1962\nKeely Smith 1962\nTeddy Randazzo 1962\nThe Legends 1963\nLulu and the Luvvers April 1964\nJoan Baxter June 1964\nThe Shangri-Las December 1964\nThe Beatles recorded 1964, released 1995 [9]\nThe Kingsmen February 1965\nTrini Lopez August 1965\nPeter Belli & Les Rivals September 1965\nDinah Lee 1965\nTommy James and The Shondells February 1967\nCliff Richard April 1967\nThe Underground 1967\nRicardo Ray Orchestra 1968\nThe Chambers Brothers 1968\nThe Trammps June 1974\nKisa 1974\nOtis Day and the Knights 1978\nJoan Jett 1980\nGarland Jeffreys 1982\nThe Shillelagh Sisters 1984\nMint Juleps 1985\nTom Petty & The Heartbreakers January 1986\nPetticoat 1989\nScooters March 25, 1992\nDeloris & The Sisters & The Ronelles 1992\nSugar Beats 1993\nThe Forever Fabulous Chickenhawks July 6, 1999\nAlex Harvey and His Soul Band August 11, 1999\nThe Rivieras September 12, 2000\nLeo Night & The Moonlighters February 5, 2002\nConnie Fisher 2006\nChoir of Hard Knocks 2007\nLisa del Bo April 4, 2008\nDartmouth Aires 2011\nThe Brown Derbies 2011\nWinston Apple August 2012\nGarth Brooks November 28, 2013\nBoyz Nite Out 2013\nHuman Nature July 22, 2016[10]\nPersonnel[edit]\nRonald Isley \u2013 lead vocals\nRudolph Isley \u2013 background vocals\nO'Kelly Isley Jr. \u2013 background vocals\nThe Shangri-Las version\nMary Weiss \u2014 lead vocals\nMary Ann Ganser \u2014 background vocals\nMargie Ganser \u2014 background vocals\nLulu version\nLulu \u2014 lead vocals\nThe Beatles version\nJohn Lennon \u2014 vocals, lead guitar\nPaul McCartney \u2014 vocals, bass\nGeorge Harrison \u2014 vocals, lead guitar\nRingo Starr \u2014 vocals, drums\nBuffalo Bills version\nScott Kemper \u2014 vocals, keyboards\nI Know/Shout - Save Ferris version\nMonique Powell - vocals\nIn popular culture[edit]Shout has woven itself into many iconic American media such as a dance song in which people progressively crouch down to the dance floor as the song gets quieter. For example, at the end of the third quarter of an Oregon Ducks game at Autzen Stadium, in recognition of National Lampoon's Animal House being filmed at the University of Oregon in 1977-78, the crowd traditionally dances to the song. The National Football League (NFL)'s Buffalo Bills currently use a one-minute version of the song as their fight song.[11][12]References[edit]External links[edit]\nLyrics of this song at MetroLyrics\nPerformance of Shout at The Dick Clark Show on YouTube\nPerformance of Shout live by Johnny O'Keefe on YouTube\n", "subtitles": ["History", "Cover versions", "Personnel", "In popular culture", "References", "External links"], "title": "Shout (The Isley Brothers song)"},
{"content": "RPM (ISSN 0315-5994 and later ISSN 0033-7064) was a Canadian music industry publication that featured song and album charts for Canada. The publication was founded by Walt Grealis in February 1964, supported through its existence by record label owner Stan Klees. RPM ceased publication in November 2000.RPM stood for Records, Promotion, Music. The magazine was reported to have variations in its title over the years such as RPM Weekly and RPM Magazine. RPM maintained several format charts, including Top Singles (all genres), Adult Contemporary, Dance, Urban, Rock/Alternative and Country Tracks (a.k.a. Top Country Tracks) for country music. On 21 March 1966, RPM expanded its Top Singles chart from 40 positions to 100.For the first several weeks of its existence, the magazine did not compile a national chart, but simply printed the current airplay lists of several major market Top 40 stations. A national chart was introduced beginning with the June 22, 1964 issue, with its first-ever national #1 single being Chapel of Love by The Dixie Cups. Prior to the introduction of RPM's national chart, the CHUM Chart from Toronto radio station CHUM was considered the de facto national chart. The final #1 single in the magazine was Music by Madonna.The RPM Awards[edit]The modern Juno Awards had their origins in an annual survey conducted by RPM since its founding year. Readers of the magazine were invited to mail in survey ballots to indicate their choices under various categories of people or companies.The RPM Awards poll was transformed into a formal awards ceremony, The Gold Leaf Awards in 1970. These became the Juno Awards in following years.[1]1964 RPM Awards[edit]The RPM Awards for 1964 were announced in the 28 December 1964 issue:[2]\nTop male vocalist: Terry Black\nTop female singer: Shirley Matthews\nMost promising male vocalist: Jack London\nMost promising female vocalist: Linda Layne\nTop vocal instrumental group: The Esquires[3]\nTop female vocal group: Girlfriends\nTop instrumental group: Wes Dakus & The Rebels\nTop folk group: The Courriers[4]\nTop country male singer: Gary Buck\nTop country female singer: Pat Hervey\nIndustry man of the year: Johnny Murphy of Cashbox Canada\nTop record company: Capitol Records of Canada\nTop Canadian Content record company: Capitol Records of Canada\nTop national record promoter: Paul White, Capitol Records of Canada\nTop regional record promoter: Ed Lawson, Quality Records\nTop album of the year (GMP): That Girl by Phyllis Marshall\nA column on page 6 of that issue noted that the actual vote winner for Top Canadian Content record company was disqualified due to a conflict of interest involving an employee of that company who was also working for RPM. Therefore, runner-up Capitol Records was declared the category's winner.1965 RPM Awards[edit]The Annual RPM Awards for 1965 were announced in the 17 January 1966 issue, with more country music categories than the previous year:[5]\nTop male vocalist: Bobby Curtola\nTop female singer: Catherine McKinnon\nMost promising male vocalist: Barry Allen\nMost promising female vocalist: Debbie Lori Kaye\nTop vocal/instrumental group: The Guess Who\nTop female vocal group: Girlfriends\nTop instrumental group: Wes Dakus & The Rebels\nTop folk group: Malka and Joso\nTop folk singer: Gordon Lightfoot\nBest produced single: My Girl Sloopy, Little Caesar and the Consuls\nBest produced album: Voice of an Angel by Catherine McKinnon\nTop country male singer: Gary Buck\nTop country female singer: Dianne Leigh\nMost promising country male singer: Angus Walker\nMost promising country female singer: Sharon Strong\nTop country instrumental vocal group: Rhythm Pals\nTop country instrumentalist: Roy Penney\nTop country radio personality: Al Fisher, CFGM Toronto\nTop Canadian disc jockey: Chuck Benson, CKYL Peace River\nTop record company: Capitol Records of Canada\nTop Canadian Content record company: Capitol Records of Canada\nTop national record promoter: Paul White, Capitol Records of Canada\nTop regional record promoter: Charlie Camilleri, Quality Records\n1966 RPM Awards[edit]The winners were:[6]\nTop male vocalist: Barry Allen\nTop female singer: Catherine McKinnon\nMost promising male vocalist: Jimmy Dybold\nMost promising female vocalist: Lynda Lane\nTop vocal/instrumental group: Staccatos\nTop female vocal group: Allan Sisters\nTop instrumental group: Wes Dakus & The Rebels\nTop folk group: 3's a Crowd\nTop folk singer: Gordon Lightfoot\nBest produced single: Let's Run Away, Staccatos[7]\nTop country male singer: Gary Buck\nTop country female singer: Dianne Leigh\nMost promising country male singer: Johnny Burke\nMost promising country female singer: Debbie Lori Kaye\nTop country instrumental vocal group: Mercey Brothers\nTop country instrumentalist: Roy Penney\nTop country radio personality: Ted Daigle\nTop country radio station: CFGM\nTop record company: Capitol Records of Canada\nTop Canadian Content record company: Red Leaf Records\nTop national record promoter: Paul White, Capitol Records of Canada\nTop regional record promoter: Al Nair\nTop Canadian music industry man of the year: Stan Klees\nSee also[edit]\nList of RPM number-one alternative rock singles\nList of RPM number-one country singles\nList of RPM number-one dance singles\nReferences[edit]External links[edit]\nRPM archive charts\nRPM (historical information)\nLibrary and Archives Canada: The RPM Story\nThe Canadian Encyclopedia: RPM\nCharts archive from 1964 to 1999 on worldcharts.co.uk\nMegan Thow (Spring 2002). Critical Miss. Ryerson Review of Journalism. Archived from the original on 27 September 2007. Retrieved 15 September 2007. \n", "subtitles": ["The RPM Awards", "See also", "References", "External links"], "title": " (magazine)"},
{"content": "The Adult Contemporary chart is published weekly by Billboard magazine and lists the most popular songs on adult contemporary radio stations in the United States. The chart is compiled based on airplay data submitted to Billboard by stations that are members of the Adult Contemporary radio panel. The chart debuted in Billboard magazine on July 17, 1961.[1] Over the years, the chart has gone under a series of name changes, being called Easy Listening (1961\u20131962; 1965\u20131979), Middle-Road Singles (1962\u20131964), Pop-Standard Singles (1964\u20131965), Hot Adult Contemporary Tracks (1979\u20131982) and Adult Contemporary (1983\u2013present).Chart history[edit]The Billboard Easy Listening chart, as it was first known, was born of a desire by some radio stations in the late 1950s and early 1960s to continue playing current hit songs but distinguish themselves from being branded as rock and roll stations. Billboard had written articles about this trend during the time, and the magazine\u2019s editors decided to publish a separate chart for these songs beginning in 1961. The magazine offered an Easy Listening programming guide beginning January 9, 1961, which continued until the numbered chart appeared in July. The first No. 1 song on the Billboard Easy Listening chart was The Boll Weevil Song by Brook Benton.[1]From 1961 to 1965, this chart was compiled from the Billboard Hot 100 chart by removing songs that were deemed rock and roll by the magazine and re-ranking the remaining songs. Beginning in 1965, the Easy Listening chart would begin to be compiled by a method similar to the one used for other Billboard singles charts: reported playlists from radio stations airing the format as well as sales data submitted by record stores. By the early 1990s, automatic song detection and barcode sales information had begun to be the norm for most of the Billboard charts, although by this time the AC chart was based entirely on radio airplay and no longer incorporated retail sales reports. Currently the Hot Adult Contemporary Tracks chart is compiled in much the same way as for other radio formats.The chart was known as the Easy Listening chart until 1962, when it was renamed Middle-Road Singles. In 1964, the name changed again, this time to Pop-Standard Singles. After alternating the name of this chart twice more in less than a year, Easy Listening was again chosen as the chart name in 1965 when the change in compilation occurred. In April 1979, the Easy Listening chart officially became known as Adult Contemporary, and those two words have remained consistent in the name of the chart ever since.In 1996, Billboard created a new chart called Adult Top 40, which reflects radio station programming that exists somewhere between adult contemporary music and pop music. Although they are sometimes mistaken for each other, the Adult Contemporary chart and the Adult Top 40 chart are separate charts, and songs reaching one chart might not reach the other. In addition, the term hot AC refers to another subgenre of radio programming that is distinct from the Adult Contemporary chart, despite the apparent similarity in name.Decades[edit]The 1960s[edit]In the early years of the Easy Listening chart, the top song on the chart was generally always a Top 10 pop hit as well. The methodology for compiling the chart at that time allowed some rock and roll artists, such as Lesley Gore and The Drifters, to make the chart on occasion with their softer or ballad releases, regardless of whether Easy Listening and middle of the road radio stations were actually playing those songs. In 1965, no #1 pop hits appeared on the Easy Listening chart. After 1965, differences between the Hot 100 chart and the Easy Listening chart became more pronounced. Better reflecting what middle of the road stations were actually playing, the composition of the chart changed dramatically. As rock music continued to harden, there was much less crossover between the Hot 100 and Easy Listening chart than there had been in the early half of the 1960s.[citation needed]Several #1 Easy Listening hits of the late 1960s only Bubbled Under on the pop chart (for example, Andy Russell's 1967 version of It's Such a Pretty World Today that peaked at #119), or (as was the case with John Gary's 1967 hit Cold) failed even to Bubble Under. [2] In 1967, only one single reached #1 on both charts \u2013  Somethin' Stupid by Frank Sinatra and Nancy Sinatra. This trend began to reverse by the end of the decade.Notable artists with multiple #1 songs on this chart during the 1960s include Elvis Presley, Roy Orbison, Connie Francis, Dean Martin, Andy Williams, The 5th Dimension, and Glen Campbell. Love Is Blue by Paul Mauriat held the top of the Easy Listening chart for 11 weeks in 1968, which remained the longest stay at #1 until 1993.[1]The 1970s[edit]The Hot 100 and Easy Listening charts became more similar again toward the end of the 1960s and into the early and mid-1970s, when the texture of much of the music played on Top 40 radio once more began to soften. Contemporary artists who recorded adult-appeal music, such as The Carpenters, Barbra Streisand, Barry Manilow, Anne Murray, John Denver, and Helen Reddy began to be played more often on Top 40 radio. Much of the music recorded by singer-songwriters such as James Taylor, Carole King, and Janis Ian got as much, if not more, airplay on this format than on Top 40 stations. A few of the baby boomer acts that came of age as pop artists targeting younger audiences in the 1960s and early 1970s started moving toward easy listening as they matured (Neil Sedaka, Paul Anka and The Osmonds being prime examples). Easy Listening radio also began including songs by artists who had begun in other genres, such as rock and roll, R&B, or even country (it was during this time frame that a number of songs charted on the country and easy listening charts, often not on the Hot 100).The longest stay at #1 on the Easy Listening chart in the 1970s was Time Passages by Al Stewart, which remained atop the chart for ten weeks. More common, however, was a high turnover rate at the summit of the Easy Listening survey during this decade. Over a three-year period from 1973 through 1975, there were 100 #1 songs on this chart, and most remained atop the chart for a single week. Among songs which topped both the Easy Listening (renamed Adult Contemporary in 1979) and pop charts in the 1970s were (They Long to Be) Close to You and Please Mr. Postman by The Carpenters, Song Sung Blue by Neil Diamond, Annie's Song by John Denver, You Are the Sunshine of My Life by Stevie Wonder, I Honestly Love You and Have You Never Been Mellow by Olivia Newton-John, Love Will Keep Us Together by Captain & Tennille, and You Light Up My Life by Debby Boone.[1]The 1980s[edit]On August 21, 1982, the Adult Contemporary chart began ranking only airplay.[3]Some of the artists who achieved success on the adult contemporary chart in the 1980s were already established names, such as Elton John, Chicago, Barbra Streisand, Dan Fogelberg, Sheena Easton, Kenny Rogers, and Dionne Warwick, while newer acts such as Whitney Houston, Madonna, Air Supply, Lionel Richie, and Gloria Estefan also made an impact on the chart. The amount of crossover between the AC chart and the Hot 100 has varied based on how much the passing pop music trends of the times appealed to adult listeners. Not many disco or new wave songs were particularly successful on the AC chart during the late 1970s and early 1980s, and much of the hip-hop and harder rock music featured on CHR formats later in the decade would have been unacceptable on AC radio.No song spent more than six weeks at #1 on this chart during the 1980s, with nine songs accomplishing that feat. Two were by Lionel Richie, You Are in 1983 and Hello in 1984, which also reached #1 on the Hot 100. Other songs reaching the summit on both the AC and pop charts were Time After Time by Cyndi Lauper, I Just Called to Say I Love You by Stevie Wonder, Live to Tell by Madonna, I Just Can't Stop Loving You by Michael Jackson (his only #1 on both charts), Seasons Change by Expose\u0301, Look Away by Chicago, Tell Her About It by Billy Joel, and Right Here Waiting by Richard Marx.[1]The 1990s[edit]With the above-mentioned changes in compilation to the Billboard Hot 100 chart in the early 1990s, many of the secondary charts began to experience differences as well. Certain songs achieved higher debut positions on the Hot 100 due to the new formulas used to calculate chart positions, and lengthy stays at #1 became more common. This trend began to surface on the AC chart in 1993, when two consecutive singles (The River of Dreams by Billy Joel and Said I Loved You...But I Lied by Michael Bolton) logged twelve weeks apiece atop the AC chart, surpassing Love Is Blue's previous mark of eleven weeks at #1. As the decade progressed, other songs had extended stays at #1, including Change the World by Eric Clapton (13 weeks, 1996), Un-Break My Heart by Toni Braxton (14 weeks, 1997) and Because You Loved Me by Celine Dion (19 weeks, 1996).In addition to Dion, who has had significant success on this chart, other artists with multiple #1s on the AC chart in the 1990s include Mariah Carey, Phil Collins, Michael Bolton, Whitney Houston, and Shania Twain. Newer female singer-songwriters such as Sarah McLachlan, Natalie Merchant, Jewel, Melissa Etheridge, and Sheryl Crow also broke through on the AC chart during this time.[1]The 2000s[edit]A notable pattern that developed during the 2000s has been for certain pop songs to have lengthy runs on the Hot Adult Contemporary Tracks chart, even after the songs have fallen off the Hot 100. Songs such as Love Story and You Belong with Me by Taylor Swift, Waiting on the World to Change by John Mayer, Love Song by Sara Bareilles and You're Beautiful by James Blunt have remained on the AC chart for many weeks, in some cases over a year after the song was originally released. An article on MTV's website by Corey Moss describes this trend: In other words, AC stations are where pop songs go to die a very long death. Or, to optimists, to get a second life.[4] One theory states that many adult contemporary stations play less newer music because they also give ample airtime to hits of the past, so the de-emphasis on new songs slows the progression of the AC chart. Also, certain program directors have asserted that AC is a song-based format, as opposed to other radio formats that are infused with singer-based programming, so there is no guarantee that a new single by a certain artist will appeal to the listeners.[4]The record for most weeks atop the Adult Contemporary chart is 28, achieved by Uncle Kracker featuring Dobie Gray in a 2003 remake of Gray's 1973 hit, Drift Away.[5] A number of other songs have logged more than 20 weeks apiece at the summit, Ed Sheeran's Shape of You from 2017 has logged 24 weeks at #1 on the AC chart. In addition, Celine Dion's A New Day Has Come from 2002 and Kelly Clarkson's 2005 song Breakaway. Both songs spent 21 weeks at #1 on the AC chart. In addition to Clarkson, other American Idol performers who have seen success on this chart include David Cook and Chris Daughtry.Through 2006, Celine Dion has logged 87 weeks atop the AC chart, which is the most for any artist; tied for second place with 47 weeks apiece are Elton John and Lionel Richie. Elton John and the Carpenters are tied for the most chart-toppers on this survey with 15 apiece.[6]In 2011, Billboard announced the top 100 performing songs on the AC chart and the top 50 performing artists to celebrate the 50th anniversary on the chart. The top song on the list was Truly Madly Deeply by Savage Garden, which hit number one for 11 weeks in 1998, spent a total of 58 weeks in the top 10, and spent 123 weeks on the chart. That chart longevity would only be passed by another one of their songs, I Knew I Loved You (which ranked at #21 on that list), from their album Affirmation. [7][8]. Elton John was nominated the top performing AC artist through that time, and also holds the record for the most No. 1 AC singles, top 10 singles, and singles on the chart. His song The One was ranked on #53 on the top 100 performing songs on the AC chart.Other formats[edit]Relatively few urban contemporary and hip-hop artists manage to successfully cross over to AC, although there have been a few recent exceptions, such as Beyonce\u0301's Irreplaceable, Fergie's ballad Big Girls Don't Cry, Gnarls Barkley's Crazy, Rihanna's Take a Bow, and Timbaland's remix of OneRepublic's Apologize. R&B artists who have achieved major success on the AC chart in the past include Dionne Warwick, Aaron Neville, Diana Ross (with her solo career), James Ingram, Lionel Richie, Whitney Houston and Mariah Carey.Crossover from the country charts has also been common on the AC chart since the chart began. Among the country stars who had a number of singles cross over to the AC chart (and the pop chart as well) from the 1960s through the 1980s included Brenda Lee, Ray Price, Patsy Cline, Johnny Cash, Anne Murray, Ronnie Milsap, Barbara Mandrell, Dolly Parton, Kenny Rogers, Eddie Rabbitt, Crystal Gayle, Willie Nelson, and Juice Newton. The huge growth of country music as a radio format in the 1990s brought a number of new country crossovers onto the AC airwaves, including Martina McBride, Wynonna Judd, LeAnn Rimes, Shania Twain, Faith Hill, Lonestar, Mary Chapin Carpenter, and Garth Brooks. More recently, a new wave of country performers has been crossing over to AC, including Tim McGraw, the Dixie Chicks (who topped the AC chart with their cover of Fleetwood Mac's Landslide), Rascal Flatts, Carrie Underwood, Taylor Swift, Sugarland, Lady Antebellum, Jason Aldean (whose AC success came by way of his duet with Kelly Clarkson, Don't You Wanna Stay), and The Band Perry.Contemporary Christian music has also been relatively successful in crossing over to mainstream radio. In the mid-1980s, the most successful CCM artist at the time, Amy Grant, crossed over into secular music with the 1985 single Find a Way, which became a Top Ten AC hit and a #1 Christian single simultaneously. In the 1990s and into the 2000s, other artists such as Lifehouse, MercyMe, Natalie Grant, Kathy Troccoli, Sixpence None the Richer, Steven Curtis Chapman, and Michael W. Smith have crossed in between the Christian and secular worlds with little disapproval from their fan bases.Recurrents[edit]Hot Adult Contemporary Recurrents ranks airplay from the Hot Adult Contemporary Tracks chart that have reached Billboard recurrent criteria. Descending songs are moved to recurrent status based upon the following three-tiered system: if they rank below the top five after 52 weeks, if they rank below the top 10 after 26 weeks, or if they rank below the top 15 after 20 weeks.Exceptions are sometimes made, usually on a case-by-case basis. Occasionally an older song is re-released (for example, featured on a current movie soundtrack and given a renewed promotional push from a record label) or a song can take an extended amount of time to climb to position fifteen. Billboard chart managers ultimately make the decision about which songs can remain on the current chart in such cases.Records and achievements[edit]The top 10 adult contemporary songs (1961\u20132011)[edit]Source:[9]The top 10 adult contemporary artists (1961\u20132011)[edit]Source:[10]Most weeks at number one[edit]28 weeks\nDrift Away \u2013  Uncle Kracker featuring Dobie Gray (2003\u20132004)\n24 weeks\nShape of You \u2013  Ed Sheeran (2017)\n22 weeks\nHey, Soul Sister \u2013  Train (2010\u20132011)\n21 weeks\nA New Day Has Come \u2013  Celine Dion (2002)\nBreakaway \u2013  Kelly Clarkson (2005)\nHello \u2013  Adele (2015\u20132016)\n20 weeks\nJust the Way You Are \u2013  Bruno Mars (2011)\n19 weeks\nBecause You Loved Me \u2013  Celine Dion (1996)\nYou'll Be in My Heart \u2013  Phil Collins (1999)\nBad Day \u2013  Daniel Powter (2006)\nBubbly \u2013  Colbie Caillat (2008)\nRolling in the Deep \u2013  Adele (2011)\nSomebody That I Used to Know \u2013  Gotye featuring Kimbra (2012\u20132013)\nThinking Out Loud \u2013  Ed Sheeran (2015)\n18 weeks\nHeaven \u2013  Los Lonely Boys (2004\u20132005)\nLonely No More \u2013  Rob Thomas (2005\u20132006)\nCan't Stop the Feeling! \u2013  Justin Timberlake (2016\u20132017)\n17 weeks\nI Knew I Loved You \u2013  Savage Garden (1999\u20132000)\nBreathe \u2013  Faith Hill (2000)\n16 weeks\nWaiting on the World to Change \u2013  John Mayer (2007)\nI'm Yours \u2013  Jason Mraz (2008)\nSource:[11][12]Most number-one singles[edit]\nElton John and The Carpenters (15)[13]\nBarry Manilow (13)\nCeline Dion and Lionel Richie (11)\nWhitney Houston and Olivia Newton-John (10)\nNeil Diamond, John Denver, and Michael Bolton (9)\nBarbra Streisand, Stevie Wonder, Anne Murray, Billy Joel, Helen Reddy, Glen Campbell, Phil Collins, and Chicago (8)\nMost chart entries[edit]\nElton John (72)\nBarbra Streisand (64)\nNeil Diamond (58)\nElvis Presley (53)\nBarry Manilow (50)\nJohnny Mathis (50)\nCeline Dion (41)\nSource:[14]See also[edit]\nAdult contemporary music\nList of artists who reached number one on the U.S. Adult Contemporary chart\nList of number-one adult contemporary hits (United States)\nReferences[edit]", "subtitles": ["Chart history", "Decades", "Other formats", "Recurrents", "Records and achievements", "See also", "References"], "title": "Adult Contemporary (chart)"},
{"content": "The UK Singles Chart (currently entitled Official Singles Chart) is compiled by the Official Charts Company (OCC), on behalf of the British record industry, listing the top-selling singles in the United Kingdom, based upon physical sales, paid-for downloads and streaming. The Official Chart, broadcast on BBC Radio 1 and MTV (Official UK Top 40), is the UK music industry's recognised official measure of singles and albums popularity because it is the most comprehensive research panel of its kind, today surveying over 15,000 retailers and digital services daily, capturing 99.9% of all singles consumed in Britain across the week, and over 98% of albums.[1] To be eligible for the chart, a single is currently defined by the Official Charts Company (OCC) as either a 'single bundle' having no more than four tracks and not lasting longer than 25 minutes or one digital audio track not longer than 15 minutes with a minimum sale price of 40 pence.[2] The rules have changed many times as technology has developed, the most notable being the inclusion of digital downloads in 2005 and streaming in July 2014.[3]The OCC website contains the Top 100 chart.[4] Some media outlets only list the Top 40 (such as the BBC) or the Top 75 (such as Music Week magazine) of this list. The chart week runs from 00:01 Friday to midnight Thursday,[5] with most UK physical and digital singles being released on Fridays. From 3 August 1969 until 5 July 2015, the chart week ran from 00:01 Sunday to midnight Saturday.[6]The Top 40 chart is first issued on Friday afternoons by BBC Radio 1 as The Official Chart from 16:00 to 17:45, before the full Official Singles Chart Top 100 is posted on the Official Charts Company's website.[7] A rival chart show, The Vodafone Big Top 40, is based on iTunes downloads and commercial radio airplay across the Global Radio network only, is broadcast on Sunday afternoons from 16:00 to 19:00 on 145 local commercial radio stations across the United Kingdom. The Big Top 40 is not officially regarded by the industry or wider media.[8] There is also a show called Official KISS Top 40, counting down 40 most played songs on Kiss FM every Sunday 17:00 to 19:00.The UK Singles Chart began to be compiled in 1952. According to the Official Charts Company's statistics, as of 1 July 2012, 1,200 singles have topped the UK Singles Chart.[9] The precise number of chart-toppers is debatable due to the profusion of competing charts from the 1950s to the 1980s, but the usual list used is that endorsed by the Guinness Book of British Hit Singles and subsequently adopted by the Official Charts Company. The company regards a selected period of the New Musical Express chart (only from 1952 to 1960) and the Record Retailer chart from 1960 to 1969 as predecessors for the period prior to 11 February 1969, where multiples of competing charts (none official) coexisted side by side. For example, the BBC compiled its own chart based on an average of the music papers of the time; many songs announced as having reached number one on BBC Radio and Top of the Pops prior to 1969 are not listed as chart-toppers according to the legacy criteria of the Charts Company.The first number one on the UK Singles Chart was Here in My Heart by Al Martino for the week ending date 14 November 1952. As of the week ending date 12 April 2018, the UK Singles Chart has had 1336 different number-one hits. The current number one single is Freaky Friday by Lil Dicky featuring Chris Brown.History[edit]Early charts[edit]Before the compilation of sales of records, the music market measured a song's popularity by sales of sheet music. The idea of compiling a chart based on sales originated in the United States, where the music-trade paper Billboard compiled the first chart incorporating sales figures on 20 July 1940. Record charts in the UK began in 1952, when Percy Dickins of the New Musical Express (NME) gathered a pool of 52 stores willing to report sales figures.[10][11] For the first British chart Dickins telephoned approximately 20 shops, asking for a list of the 10 best-selling songs. These results were then aggregated into a Top 12 chart[nb 1] published in NME on 14 November 1952, with Al Martino's Here in My Heart awarded the number-one position.[10][11] The chart became a successful feature of the periodical; it expanded into a Top 20 format on 1 October 1954, and rival publications began compiling their own charts in 1955.[14] Record Mirror compiled its own Top 10 chart for 22 January 1955; it was based on postal returns from record stores (which were financed by the newspaper). The NME chart was based on a telephone poll.[15] Both charts expanded in size, with Mirror's becoming a Top 20 in October 1955 and NME's becoming a Top 30 in April 1956.[14][16] Another rival publication, Melody Maker, began compiling its own chart; it telephoned 19 stores to produce a Top 20 for 7 April 1956. It was also the first chart to include Northern Ireland in its sample.[11] Record Mirror began running a Top 5 album chart in July 1956; from November 1958 onwards it was run by NME.[17][14] In March 1960, Record Retailer began compiling an EP (album) chart and had a Top 50 singles chart.[17] Although NME had the largest circulation of charts in the 1960s and was widely followed,[11][18] in March 1962 Record Mirror stopped compiling its own chart and published Record Retailer's instead.[11] Retailer began independent auditing in January 1963, and has been used by the UK Singles Chart as the source for number-ones since the week ending 12 March 1960.[14][17] The choice of Record Retailer as the source has been criticised;[19][11] however, the chart was unique in listing close to 50 positions for the whole decade.[19] With available lists of which record shops were sampled to compile the charts some shops were subjected to hyping but, with Record Retailer being less widely followed than some charts, it was subject to less hyping. Additionally, Retailer was set up by independent record shops and had no funding or affiliation with record companies. However, it had a significantly smaller sample size than some rival charts.[11]Before February 1969 (when the British Market Research Bureau (BMRB) chart was established), there was no official chart or universally accepted source.[11][18][19] Readers followed the charts in various periodicals and, during this time, the BBC used aggregated results of charts from the NME, Melody Maker, Disc and (later) Record Mirror to compile the Pick of the Pops chart.[15] The Official Charts Company and Guinness' British Hit Singles & Albums, use as sources for the unofficial period, the NME before 10 March 1960 and Record Retailer until 1969.[14] However, until 1969 the Record Retailer chart was only seen by people working in the industry. The most widely circulated chart was the NME one, as used by Radio Luxembourg's legendary Sunday night Top 20 show, as well as by ABC TV's Thank Your Lucky Stars, which had an audience of up to 6 million on ITV.Official chart[edit]Before 1969 there was no official singles chart.[11][18][19] Record Retailer and the BBC commissioned the British Market Research Bureau (BMRB) to compile charts, beginning 15 February 1969.[11][14] The BMRB compiled its first chart from postal returns of sales logs from 250 record shops.[14] The sampling cost approximately \u00a352,000; shops were randomly chosen from a pool of approximately 6,000, and submitted figures for sales taken up to the close of trade on Saturday. The sales diaries were translated into punch cards so the data could be interpreted by a computer. A computer then compiled the chart on Monday, and the BBC were informed of the Top 50 on Tuesday in time for it to be announced on Johnnie Walker's afternoon show. The charts were also published in Record Retailer (rebranded Record & Tape Retailer in 1971 and Music Week in 1972)[20] and Record Mirror.[11] However, the BMRB often struggled to have the full sample of sales figures returned by post. The 1971 postal strike meant data had to be collected by telephone, but this was deemed inadequate for a national chart; by 1973, the BMRB was using motorcycle couriers to collect sales figures.[11] In May 1978, the singles chart was expanded from a Top 50 to a Top 75. A World in Action documentary expose\u0301 in 1980 revealed corruption within the industry; stores' chart-returns dealers would frequently be offered bribes to falsify sales logs.[21]Electronic-age charts[edit]From 1983 to 1990, the chart was financed by BPI (50 percent), Music Week (38 percent) and the BBC (12 percent).[22] On 4 January 1983 the chart compilation was assumed by the Gallup Organization, which expanded the chart with a Next 25 in addition to the Top 75[nb 2] and began the introduction of computerised compilers, automating the data-collection process.[11][14] In July 1987, Gallup signed a new agreement with BPI, increasing the sample size to approximately 500 stores and introducing barcode scanners to read data.[24] The chart was based entirely on sales of vinyl single records from retail outlets and announced on Tuesday until October 1987, when the Top 40 was revealed each Sunday (due to the new, automated process).[25]The 1980s also saw the introduction of the cassette single (or cassingle) alongside the 7-inch and 12-inch record formats; in 1987, major record labels developed a common format for the compact disc single.[26] In May 1989, chart regulations kept Kylie Minogue's song Hand on Your Heart from entering at number one because sales from cassette singles were not included (they were sold for \u00a31.99 \u2013 cheaper than allowed at the time). Following this, the British Phonographic Industry (BPI) reduced the minimum price for cassette singles to influence sales figures.[27] In September 1989, W H Smith began to send sales data to Gallup directly through electronic point of sale (EPoS) terminals.[24]In January 1990, the BPI gave notice to Gallup, BBC and Music Week; on 30 June 1990, it terminated its contract with them because it could no longer afford the \u00a3600,000 a year cost.[28][29] From 1 July 1990, the Chart Information Network (CIN) was formed by Spotlight Publications[nb 3] (publisher of Music Week), in cooperation with the BBC and the British Association of Record Dealers (BARD) \u2013 representing retailers, including W H Smith, Woolworths, HMV and Virgin \u2013 who agreed to exclusively supply sales data to the CIN.[24][31] A Chart Supervisory Committee (CSC) represented the BBC, CIN and retailers. The BPI were reluctant to join and consider[ed] the option of launching a rival chart[29] but in September an agreement was reached, and it joined the CSC.[32] For this period, the chart was produced by Gallup and owned by CIN and Music Week (who would then sell it to the BBC and BPI).[33]In January 1991 the CIN became a joint venture between Link House Magazines (formerly Spotlight Publications, later Miller Freeman, Inc.)[34] and the BPI; they shared the revenue and costs (reportedly between \u00a3750,000 and \u00a31 million).[24][33][35] During this time, other retailers (such as Woolworths and John Menzies) began submitting data using EPoS terminals.[24] In late 1991 the sample consisted of 500 stores scanning barcodes of all record sales into an Epson PX-4 computer, and 650 other stores providing sales data through their own EPoS computerised tills. These computers were to be telephoned six times a week, providing the data to Gallup.[36] In June 1991, the BPI reduced the number of eligible formats from five to four.[37]In November 1990, the Next 25 section of the UK singles chart (positions 76\u2013100, with special rules) ceased to be printed in the trade magazine Music Week.[citation needed] In April 1991, Record Mirror ceased publication, along with the Next 25.[20][38][39] Virgin installed JDA EPoS terminals in September 1993, and began providing sales data to Gallup.[40]In February 1993 the research contract for the chart was put out to tender, with a new four-year contract beginning 1 February 1994 offered. Millward Brown, Research International and Nielsen Market Research were approached, and Gallup were invited to re-apply.[41] In May, it was announced that Millward Brown had been accepted as the next chart compilers, signing a \u00a31-million-a-year contract.[24] Millward Brown took over compiling the charts on 1 February 1994, increasing the sample size;[14][42] by the end of the month each shop sampled used a barcode scanner linking via an Epson terminal with a modem to a central computer (called Eric), which logged data from more than 2,500 stores.[42] Gallup attempted to block Millward Brown's new chart by complaining to the Office of Fair Trading about the contractual clause in which BARD retailers exclusively supplied sales data to the CIN, but the interim order was rejected.[43] In June 1995 the case was dropped, after the clause allowing BARD retailers to supply sales information to other chart compilers was deleted; because CIN retained the copyright, other compilers could not use (or sell) the information.[44]On 2 April 1995, the number of eligible formats was reduced from four to three.[37] The decision came after nine months of negotiations with BARD, which objected that it would adversely affect the vinyl record industry.[45] Although record labels were not prohibited from releasing singles in more than three formats, they were required to identify the three eligible formats.[37] This resulted in a reduction in the number of singles released in 7-inch format; the most common three formats were 12-inch single, cassette and CD, or a cassette and two CD versions.[46] The ruling resulted in the Oasis single Some Might Say charting twice in one week \u2013 at number 1 with sales from the three eligible formats, and at number 71 from sales in a fourth (12-inch) format.[47]Subsequently, CIN sought to develop new marketing opportunities and sponsorship deals; these included premium-rate fax and telephone services and the chart newsletters Charts+Plus (published from May 1991 to November 1994) and Hit Music (published from September 1992 to May 2001). Beginning in May 1991 Charts+Plus featured singles charts with positions 76\u2013200 (plus artist albums positions 76\u2013150, Top 50 compilations, and several genre and format charts). In September 1992, a second newsletter was created: Hit Music, a sister publication of Music Week featuring (among other charts) the singles Top 75 and a revived Next 25. In November 1994, Charts+Plus ceased publication; Hit Music expanded its chart coverage to an uncompressed (without special rules) Top 200 Singles, Top 150 Artists Albums and Top 50 Compilations. In November 1996, the Artist Albums chart extended to a Top 200. Hit Music ceased publication in May 2001 with issue number 439.[48]In February 1997, CIN and BARD agreed to a new 18-month deal for the charts.[49] In 1998 the CSC agreed to new rules reducing the number of tracks on a single from four to three, playing time from 25 minutes to 20 and the compact disc single minimum dealer price to \u00a31.79.[50] This particularly affected the dance music industry which had previously released CD's full of remixes, with some labels having to edit or fade out remixes early in order to fit them on a CD single. On 1 July 1998, BARD and BPI took over management of the chart from the CIN (a Miller Freeman and BPI venture) with new company Music Industry Chart Services (Mics);[51] however, in August they decided to return to compiling the charts under the name CIN.[52]In 1999, Millward Brown began re-chipping some retailers' machines, in anticipation of the millennium bug.[53] However, some independent retailers lost access to the record-label-funded Electronic Record Ordering System (Eros); it was too costly to make it Year 2000 compliant.[54] Towards the end of the 1990s companies anticipated distributing singles over the Internet, following the example of Beggars Banquet and Liquid Audio (who made 2,000 tracks available for digital download in the US).[55] In November 2001, Chart Information Network (CIN) changed its name to The Official UK Charts Company.Internet era[edit]In January 2004, MyCokeMusic launched as the first significant download retailer.[56] Legal downloading was initially small, with MyCokeMusic selling over 100,000 downloads during its first three months. In June the iTunes Store was launched in the UK, and more than 450,000 songs were downloaded during the first week.[57] In early September the UK Official Download Chart was launched, and a new live recording of Westlife's Flying Without Wings was the first number-one.[58]In 2005, Wes Butters presented his final UK Top 40 show, concluding his tenure at Radio 1. The chart show was then rebranded for the chart week ending 16 April, and the first singles chart combining physical-release sales with legal downloads began. Several test charts (and a download-sales chart) were published in 2004; this combination (within the official singles chart) reflected a changing era in which sales of physical singles fell and download sales rose. On 17 April 2005, hosts JK and Joel commented during their BBC Radio 1 broadcast that the incorporation of download sales resulted in an approximate doubling of singles sales for the week. For the first week's combined chart the impact of this doubling was not readily apparent at the top of the chart, although a few singles in the middle positions benefited.Initially, the British Association of Record Dealers was concerned that the popularity of downloading would siphon business from the High Street.[citation needed] It also complained that including singles not available physically would confuse customers and create gaps in stores' sale racks. However, it agreed to the new rules provided that digital sales were only included to a single's sales tally if there was a physical equivalent sold in shops at the time. Since there was no rule governing a minimum number of pressings, Gorillaz released only 300 vinyl copies of their single Feel Good Inc. on 12 April 2005 (a month before its general release). This allowed it to debut in the chart at number 22 (eventually reaching number 2), and remain in the Top 40 for a longer period.After pressure from elsewhere in the music industry a second compromise was reached in 2006, which now allowed singles to chart on downloads the week before their physical release. The first song to make the Top 40 on downloads alone was Pump It by The Black Eyed Peas, which charted at number 16 on 12 March 2006. Three weeks later, Crazy by Gnarls Barkley became the first song to top the charts on download sales alone. As part of the revised rules, singles would now be removed from the chart two weeks after the deletion of their physical formats; Crazy left the chart 11 weeks later from number 5 and a subsequent chart-topper, Nelly Furtado's Maneater, disappeared from number 10. This was in addition to the existing rule that to be eligible for the chart, the physical single had to have been released within the last twelve months, supporting the general view that the chart reflected the top-selling current releases.Over the coming months digital sales continued to increase whilst physical sales continued to fall; more artists entered the top 40 early, and fewer singles entered the chart directly at number 1. Whilst initially the proportion of digital sales to physical sales in the combined tally was relatively low, a majority of singles by 2012 saw more than 50 percent of their sales coming from online. Sales through mobile phones are also counted.[citation needed]On 1 January 2007 the integration of downloaded music into the charts became complete when all downloads \u2013 with or without a physical equivalent \u2013 became eligible to chart, redefining the UK singles chart by turning it into a songs chart. This saw a few singles gain publicity: Crazy and Maneater (still selling strongly on downloads some time after their physical equivalents had been withdrawn) returned to the chart with several others which had been removed in the preceding months. Chasing Cars by Snow Patrol returned at a Top 10 position (number 9, just three places below the peak it had reached the previous September), while Honey to the Bee by Billie Piper (following a tongue-in-cheek promotional push by Radio 1 DJ Chris Moyles to test the new chart rules) reappeared at number 17 (nearly eight years after its original appearance on the charts).The second song to return to the Top 40 several years after its first hit run was I'll Be Missing You by Puff Daddy and Faith Evans, which reappeared at number 32 a decade after it originally topped the chart. The impetus this time was Puff Daddy's recent performance of a new version of the track at the Concert for Diana at Wembley Stadium. Two months later Luciano Pavarotti's Nessun Dorma returned to the chart at number 24 during the week following his death (17 years after it was first a hit), climbing to number 12. A drumming gorilla in a Dairy Milk television advertisement helped In the Air Tonight by Phil Collins to climb to number 14, 26 years after it was first a hit and 19 years since its last chart appearance as a remix. None of these songs had been officially re-issued.Blag, Steal and Borrow by Koopa became the first song to chart without being released physically (and the first by an unsigned band to do so). Later they would do it again twice, with One Off Song for the Summer and The Crash reaching No. 21 and No. 16 respectively (while the band remained unsigned until the following year).Following the cancellation of its physical release, Say It Right by Nelly Furtado was the first Top 10 hit to pass through its chart career without a single copy appearing in a shop. Lord Don't Slow Me Down by Oasis became the second, Violet Hill by Coldplay the third, and Disturbia by Rihanna the fourth; Candyman by Christina Aguilera had a chart run that took it into the Top 20 (number 17) entirely on downloads.The first number-one hit never released physically was Run by Leona Lewis, the 11th song in total to reach number one on downloads alone. Unlike the previous 10, it did not receive a physical release in subsequent weeks (although it was released physically overseas, notably in Germany).The second occurrence was on 20 December 2009, when Killing in the Name by Rage Against the Machine became the first song that was not a new release to reach No. 1 on downloads alone. This was the result of a Facebook campaign urging people to download the song in a bid to prevent The X Factor winning song from becoming the Christmas No. 1 single again after four consecutive years. The song originally peaked at No. 25 in 1992.[59]New rules were added to the chart on 16 September 2007 to include one-track CD singles (with a limit of 15 minutes) and to retail at a minimum of 40p per one-track CD single.A notable effect of the new chart rules is to demonstrate the enduring appeal of many downloads, especially if a physical copy is no longer (or never has been) available. Despite a seven-week gap in its chart run in late 2006 while ineligible under the old rules, Snow Patrol's Chasing Cars clocked 108 weeks on the chart, a record bettered by only one single in chart history (My Way by Frank Sinatra with 124 weeks). Numerous other hits are on for more than 40 weeks.Jeff Buckley's 1994 cover of Leonard Cohen's Hallelujah charted at number 2 on 21 December 2008 on downloads alone, following the formation of a 110,000-strong protest group on Facebook to get it above (winner of The X Factor 2008) Alexandra Burke's version for the Christmas number one.Another consequence of the chart rules (that was expected but has not materialised) is that in the event of a new album release by a well-known artist, all (or most) of its tracks could appear on the singles chart due to buyers downloading individual songs rather than the complete album. There was no significant example of this until early October 2007, with the cast of High School Musical 2 placing six of its songs in the Top 75 (although these were credited to their individual performers) and a further four just outside. A month later, Leona Lewis placed five tracks from her album Spirit simultaneously on the singles chart. Another example was anticipated with the arrival of The Beatles' catalogue online, with forecasters predicting the entire top 10 being taken up by Beatles songs.[60][61] This chart domination never occurred; only four Beatles songs re-entered the Top 75, the highest-placed being Let It Be at number 38.Yet another effect of the new rules was the reappearance in the chart of a number of seasonal favourites during Christmas 2007. A total of 19 achieved this without being officially re-issued (on downloads alone). Two of these (by Mariah Carey and The Pogues), reached the Top 5. Eleven Christmas hits returned to the Top 75 for Christmas 2008, nine in 2009, eight in 2010 and twelve in 2011, with the Mariah Carey and Pogues songs faring best each year.The first unsigned artist to break the top 5 was Alex Day, who reached number 4 with his single Forever Yours in the Christmas chart, beating Coldplay and Olly Murs,[62] following a large-scale social media campaign. In February 2013, unsigned artists Macklemore and Ryan Lewis topped the chart with Thrift Shop.[63]The death of Michael Jackson on 25 June 2009 triggered a surge in sales of his recordings; this was the first time in the download era that the effect of a major star's death on the chart could be observed. During the week beginning 28 June, a total of 16 of his solo hits (plus 4 more by The Jackson 5) re-entered the chart. The following week, the momentum continued; 27 Jackson titles charted in the Top 75 (21 solo, one with his sister Janet and five by the Jacksons) with Man in the Mirror charting the highest, at number 2. The second chart invasion of the download era resulting from the death of a major artist was observed in late July 2011 following the death of Amy Winehouse, with seven former singles charting and one other song appearing for the first time.It was announced in June 2014 that as of Sunday, 29 June, audio streams from services such as Spotify, Deezer, Napster, O2 Tracks, Xbox Music, Sony Unlimited and rara would be counted towards the Official Singles Chart, in order to reflect changing music consumption in the United Kingdom.[64] The final number one on the UK Singles Chart to be based on sales alone was Gecko (Overdrive) by Oliver Heldens featuring Becky Hill.[65] On Sunday 6 July 2014, the Official Charts Company announced that Ariana Grande had earned a place in UK chart history when her single Problem, featuring Iggy Azalea becoming the first number-one single based on sales and streaming data.[66]On 7 December 2014, Ed Sheeran's Thinking Out Loud became the first single to reach number one as a direct result of streaming inclusion. Despite Union J's You Got It All topping the Sales Chart that week, Thinking Out Loud was streamed 1.6 million times in the same week, resulting in an overall lead of 13,000 chart sales.[67]On 10 March 2017, Ed Sheeran claimed 9 of the top 10 positions in the chart when his album \u00f7 was released.[68] The large number of tracks from the album on the singles chart, 16 in the top 20, led to a change in how the chart is compiled with tracks from a lead artist eligible for entry limited to three.[69]Comparison of singles charts (1952\u20131969)[edit]With no official chart before 1969, a number of periodicals compiled their own charts during the 1950s and 1960s. The five main charts (as used by BBC's Pick of the Pops) were:\nNew Musical Express (NME) (1952\u20131988): The first singles chart, a major source until March 1960, widely followed throughout the 1960s\nRecord Mirror (1955\u20131962): The second singles chart; compiled the first album chart, published Record Retailer chart from 1962. The Pick of the Pops average stopped using Record Mirror after 21 May 1960, due to the paper changing its weekly publication day\nMelody Maker (1956\u20131988): The third singles chart, major source for album charts from 1958 onwards\nDisc (1958\u20131967): The fourth singles chart\nRecord Retailer (1960\u20131969): The fifth singles chart; a trade paper, regarded as a major source from its inception; jointly formed BMRB chart in 1969. Not included in the Pick of the Pops average until 31 March 1962.\nInclusion criteria[edit]The full regulations may be downloaded from the Official Charts Company website (see External links, below).To qualify for inclusion in the UK singles chart, a single must be available in one or more of the following eligible formats:\nDigital audio download music track of up to 15 minutes\nDigital audio stream music track of up to 15 minutes\nDigital single bundle of up to four tracks with a maximum of 25 minutes playing time\nCD with up to two tracks\nCD, DVD or other digital memory device with up to four tracks with a maximum of 25 minutes playing time\n7 inch vinyl with up to three tracks or 12 inch vinyl with up to four tracks, and up to 25 minutes playing time\nOne song and any number of remixes up to a maximum playing time of 40 minutes\nThere are minimum sales prices for all formats apart from on demand digital streams which may be from subscription or advertising funded providers. The streams were initially counted at 100 streams equivalent to one paid download or physical sale, but changed to 150 to 1 in January 2017.[70] Starting with charts published 7 July 2017, tracks by a lead artist eligible for entry in the top 100 would be limited to three. The streams-to-sales ratio for tracks whose sales (including streams) have declined for three consecutive weeks and have charted for at least ten weeks is changed to 300:1 to accelerate removal of older songs.[71]Chart broadcasts[edit]The BBC aired Pick of the Pops on its Light Programme radio station on 4 October 1955.[11] Initially airing popular songs, it developed an aggregated chart in March 1958. Using the NME, Melody Maker, Disc and Record Mirror charts, the BBC averaged them by totalling points gained on the four charts (one point for a number one, two for a number two, etc.) to give a chart average; however, this method was prone to tied positions.[11] Record Retailer was included in the average on 31 March 1962, after Record Mirror ceased compiling its chart.[11] David Jacobs and Alan Freeman both had stints presenting the Pick of the Pops chart.[72] Freeman took Pick of the Pops to its regular Sunday afternoon slot in early 1962.[73] Freeman (along with Pete Murray, David Jacobs and Jimmy Savile) was one of the four original presenters on Top of the Pops, which first aired 1 January 1964 on BBC One (then known as BBC TV).[72][74] Top of the Pops, like Pick of the Pops, used a combination of predominant periodicals until the formation of the BMRB chart in 1969.[11]From 30 September 1967 BBC Radio 1 was launched along with BBC Radio 2, succeeding the Light Programme,[75] and the Top-20 Pick of the Pops chart was simulcast on both stations.[76] Freeman continued to present the show until 1972, and was succeeded by Tom Browne.[73][77] Simon Bates took over from Browne, and under Bates it became a Top-40 show in 1978.[77][78] Bates was succeeded by Tony Blackburn, who presented the show for two-and-a-half years; Tommy Vance, who presented for two years, Bates returned in January 1984 and presented the show until September that year, then Richard Skinner for eighteen months.[77][79][80] Bruno Brookes took over in 1986[81] and, in October 1987, automated data collection allowed the countdown to be announced on the Sunday chart show (instead of on Tuesdays).[25]In 1990, Brookes was replaced as presenter by Mark Goodier, but returned 18 months later. Goodier took over from Brookes once more in 1995 and continued presenting the show until 2002.[81] In February 2003 Wes Butters hosted the chart show; two years later his contract was not renewed, and he was replaced by JK and Joel.[77][82] The duo were made redundant by Radio 1 in September 2007; Fearne Cotton and Reggie Yates replaced them at the helm of the chart show.[83] Cotton left in September 2009, and until 2012 the chart show was hosted by Yates.[84] Yates left Radio 1 at the end of 2012, because he wanted to spend more time with his family, as well as focusing more on television. Jameela Jamil took over from him in January 2013, becoming the first woman to host, alone, the BBC Chart show[85] before being replaced by Clara Amfo. On 10 July 2015, Greg James took over from Amfo, when the new chart announcement was moved to Friday afternoons.[86]Midweek chart updates[edit]From March 2010 Greg James hosted a half-hour show at 3:30 pm on Wednesdays, announcing a chart update based on midweek sales figures previously only available to the industry. The chairman of the Official Charts Company said it would provide insight into how the race for number one is shaping up.[87] Scott Mills became the host of the Chart Update from April 2012, due to schedule changes which saw Mills host what was Greg's early afternoon show.[88] When the chart moved to Fridays in July 2015, the chart update moved to 5:30 pm on Mondays.[89] The show is once again hosted by Greg James and the top ten songs are quickly overviewed with the top three being played in full before Newsbeat at 5:45.Sponsorship[edit]In 1999, the chart was sponsored by worldpop.com with the company receiving name recognition during the BBC programme. However, the deal ended when the website went out of business in late 2001. As part of an agreement with Billboard to publish the UK chart in section of their magazine, Billboard required the chart to have a sponsor. In 2003, it was announced that Coca-Cola had signed a two-year contract with the Official Charts Company beginning 1 January 2004. Although the amount was not publicly disclosed, it was believed to be between \u00a31.5 million and \u00a32 million. Since advertising on the BBC is prohibited under the BBC Charter and the government was attempting to reduce childhood obesity, the decision was widely criticised. Coca-Cola was restricted to two on-air mentions during the chart show, with the BBC justifying the deal by saying it did not negotiate or benefit financially.[90] A few days into the contract, the BBC agreed to drop on-air mentions of the brand.[91]Records and statistics[edit]Most number-one singles[edit]The artists credited as a named artist on the most UK number-one singles are:[92]\n21 \u2013 Elvis Presley counting twice 3 recordings that reached number one in two separate releases\n17 \u2013 The Beatles including 1 as The Beatles with Billy Preston\n14 \u2013 Cliff Richard including 1 with The Drifters, 6 with The Shadows and 1 with The Young Ones\n14 \u2013 Westlife including 1 with Mariah Carey\n13 \u2013 Madonna including 1 featuring Justin Timberlake and Timbaland\n12 \u2013 The Shadows including 7 with Cliff Richard (1 as The Drifters)\n12 \u2013 Take That including 1 featuring Lulu\nMost weeks at number one[edit]The songs which spent the most weeks at number 1 are:[93]\n18 \u2013 I Believe by Frankie Laine*\n16 \u2013 (Everything I Do) I Do It for You by Bryan Adams\n15 \u2013 Love Is All Around by Wet Wet Wet\n15 \u2013 One Dance by Drake featuring Wizkid and Kyla\n14 \u2013 Bohemian Rhapsody by Queen*\n14 \u2013 Shape of You by Ed Sheeran*\n11 \u2013 Rose Marie by Slim Whitman\n11 \u2013 Despacito by Luis Fonsi and Daddy Yankee featuring Justin Bieber*\n10 \u2013 Cara Mia by David Whitfield\n10 \u2013 I Will Always Love You by Whitney Houston\n10 \u2013 Umbrella by Rihanna featuring Jay-Z\nNote: Songs denoted with an asterisk (*) spent non-consecutive weeks at number one.Best-selling singles[edit]See also[edit]\nList of artists who reached number one on the UK Singles Chart\nList of artists who have spent the most weeks on the UK music charts\nList of best-selling singles by year in the United Kingdom\nList of UK Singles Chart number ones\nLists of UK top 10 singles\nOfficial Classical Singles Chart\nOfficial Subscription Plays Chart\nList of one-hit wonders on the UK Singles Chart\nUK R&B Chart\nUK Albums Chart\nUK Indie Chart\n\nChart magazines\n\nUKChartsPlus\nMusic Week\nRecord Retailer\nHit Music\n\nRival charts\n\nThe Network Chart Show\nPepsi Chart\nHit40uk\nThe Big Top 40 Show\nThe eXpat Chart\n\nChart books\n\nGuinness Book of British Hit Singles & Albums\nComplete UK Hit Singles 1952\u20132006\nNotes[edit]References[edit]\nFootnotes\n\nSources\nExternal links[edit]\nOfficial website\nRules for Chart Eligibility: Singles\nUK Singles Chart at BBC Online\nMusic Week Top 75 (subscription only)\n", "subtitles": ["History", "Inclusion criteria", "Chart broadcasts", "Sponsorship", "Records and statistics", "See also", "Notes", "References", "External links"], "title": "UK Singles Chart"},
{"content": "The Knack was an American rock band based in Los Angeles that rose to fame with their first single, My Sharona, an international number-one hit in 1979.History[edit]Founding (1977\u20131978)[edit]Singer Doug Fieger was a native of Oak Park, Michigan, a northern suburb of Detroit, Michigan, and grew up in the 9 Mile/Coolidge area. The brother of attorney Geoffrey Fieger (later known for representing Dr. Jack Kevorkian in a series of assisted suicide cases) Fieger had previously played in an eclectic rock band called Sky as well as the Sunset Bombers. Although Sky had received a modest amount of acclaim, including being produced by Rolling Stones producer Jimmy Miller, the band broke up without having any chart success. As a result, Fieger made the decision to move to Los Angeles and start another band.Shortly after arriving in L.A., Fieger met Berton Averre (lead guitar, backing vocals and keyboards), and the two started a songwriting partnership. Fieger had also known Bruce Gary (drums) for years before forming the Knack in 1978 with Prescott Niles (bass). Niles was the last to join, a week before the band's first show in June 1978.[5] In the meantime, Fieger had been doubling on bass on a series of demos that the group had shopped to several record labels, all of which were rejected. Some of these songs later made up the band's debut album Get the Knack, and included Good Girls Don't.Get the Knack[edit]Within months of their live debut, popular club gigs on the Sunset Strip, as well as guest jams with musicians such as Bruce Springsteen, Tom Petty and Ray Manzarek, led to the band being the subject of a record label bidding war. (Bruce Gary was well known in the LA session scene; this became a source for later tensions.) They ultimately signed to Capitol Records.The band's debut album, Get the Knack, was one of the year's best-selling albums, holding the number one spot on Billboard magazine's album chart for five consecutive weeks and selling two million copies in the United States. The lead single, My Sharona, was a No. 1 hit in the US, and became the number-one song of 1979. Follow-up single Good Girls Don't peaked at No. 11 in the US, and reached No. 1 in Canada.However, the band's rise to the top of the charts also precipitated a backlash. Capitol's packaging of Get the Knack included a perceived cover likeness to Meet the Beatles![1] with the record's center label being the same design and style as the Beatles' early 1960s LPs. Coupled with the band's retro 1960s look and pop/rock sound, the company's stylings led detractors to accuse them of being Beatles rip-offs,[1] which the band and their record company denied. Nonetheless, this perception, and the perception that the object of some of the Knack's songs were teenaged girls, (subsequently acknowledged when the band were years older), quickly led to a Knuke the Knack campaign led by San Francisco artist Hugh Brown.[6]The follow-up albums (1980\u20131981)[edit]The Knack quickly recorded a follow-up album ...But the Little Girls Understand, which was released in early 1980. Though the album went gold in the US and Japan, and platinum in Canada,[5] it didn't meet with the same level of commercial success as their debut. Fieger claimed in later interviews that all of the tracks for Get the Knack and ...But the Little Girls Understand were written before the first LP was recorded and were intended to be put out as a double album. Additionally, the lead single Baby Talks Dirty only briefly made the US Top 40, stalling at No. 38 (but reaching No. 13 in Canada); follow-up single Can't Put a Price on Love missed the top 40 altogether, peaking at No. 62.After nearly a year of relentless touring in the US, Canada, Europe, New Zealand, Australia, and Japan, starting in April 1980 the band took a year off because of exhaustion and internal dissent.[5] They reconvened in the summer of 1981 to record their third album, Round Trip. However, the record (which came out in October 1981) was a serious commercial disappointment, only reaching No. 93 on the US charts, selling 150,000 copies. As well, lead single Pay the Devil (Ooo, Baby, Ooo) topped out at a mere No. 67 on the Billboard Hot 100. The group made several concert appearances during 1981 to promote Round Trip. Keyboardist Phil Jost was brought into the lineup at this time to enable the band to duplicate the more heavily layered sound of their new release.With the Knack experiencing rapidly diminishing chart success, and mounting critical backlash against them[7] Fieger left amidst internal squabbles on December 31, 1981, just months after the release of Round Trip. The band rehearsed briefly with Michael Des Barres as their new frontman in early 1982, but this line-up never gigged or recorded. By mid-1982, the Knack had split up while Fieger formed a new band, Doug Fieger's Taking Chances.Return of the Knack and final album (1986\u20132010)[edit]The Knack reunited in November 1986, to play a benefit for Michele Myers, who had been the first person to book the band for a show in 1978.[5] They continued to play club gigs for the next several years. In July 1989, Billy Ward replaced Bruce Gary as the band's drummer (after a brief interim by Pat Torpey of Mr. Big).[5] In 1990, the Knack signed with Charisma Records and recorded the album Serious Fun which was released in February 1991.[5] Lead single Rocket O' Love was a top 10 hit on US AOR stations (and a top 30 hit in Canada). To promote the song, they released a music video loaded with visual innuendo thematic to the song. Charisma collapsed after the death of the label's founder, Tony Stratton-Smith, and the group broke up again in 1992.In 1994, with Ward back on drums, the band reunited to make some concert appearances to capitalize on My Sharona's new popularity after its appearance in the movie Reality Bites.In 1996, all four original band members, including Bruce Gary, reunited in the studio one last time to record a track for a multi-artist compilation album, saluting the British band Badfinger (where the band covered Badfinger's hit No Matter What[8]).The Knack continued as a touring and recording act through the late 1990s and into the 2000s. Terry Bozzio replaced Ward as drummer for 1998's Zoom, and David Henderson (as Holmes Jones) took over on drums for 2001's Normal as the Next Guy and Live at the Rock N Roll Funhouse albums. Pat Torpey then returned to take over for Henderson and played with the group until Fieger's death in 2010.In 2005, the Knack made an appearance on the TV program Hit Me, Baby, One More Time, performing My Sharona and Jet's Are You Gonna Be My Girl.In 2006, Doug Fieger and Berton Averre filed a lawsuit against the rap music group Run\u2013D.M.C. for copyright infringement. The lawsuit alleges that the defining guitar riff from My Sharona was used without permission in the Run-D.M.C. track It's Tricky from their 1986 album Raising Hell.[9]In 2006, during a performance in Las Vegas, Fieger became disoriented, developing a dull headache, and grasping for the words to the songs that he had written and performed for years.[10] Diagnosed with two brain tumors, Fieger underwent surgery and radiosurgery and returned to performing. However, he still continued to battle brain and lung cancer until his death on February 14, 2010, in Woodland Hills, California, at the age of 57.Outside the Knack[edit]In the interim between the Knack's break-up and 1986 reunion, Doug Fieger worked as a guest vocalist on a few tracks by Was (Not Was). (Fieger had grown up with band member Don Was; Was later produced the Knack's album Serious Fun.[5]) Fieger also recorded a solo album in 2000, and appeared as a solo artist in the Countdown Spectacular 2 concert series in Australia between late-August and early-September 2007. He sang the Knack favorite My Sharona only. Averre, Niles and Gary briefly continued with former RoadMaster vocalist Stephen 'Mac' McNally as The Game after the Knack's initial break up.Bruce Gary became a respected producer (archive recordings of Jimi Hendrix and new recordings of The Ventures) and a very successful sideman performing live and on studio sessions with artists such as Jack Bruce, Mick Taylor, Bob Dylan, George Harrison, Cherie Currie, Robby Krieger, Spencer Davis, Stephen Stills, Rod Stewart, Emmett Chapman, and Sheryl Crow. Gary died from lymphoma on August 22, 2006 at the age of 55.Discography[edit]\nStudio albums\n\n1979: Get the Knack No. 1 US (5 weeks, 2\u00d7 Platinum), No. 65 UK,[11] No. 1 Canada (6 weeks, 4\u00d7 Platinum)[12][13]\n1980: ...But the Little Girls Understand No. 15 US (Gold), No. 12 Canada (Platinum)[14]\n1981: Round Trip No. 93 US\n1991: Serious Fun No. 56 CAN\n1998: Zoom\n2001: Normal as the Next Guy\n2003: Re-Zoom\n2012: Rock & Roll Is Good for You: The Fieger/Averre Demos\n\nLive albums\n\n1979: The Knack Live at Carnegie Hall (Laserdisc)\n2001: Live from the Rock n Roll Funhouse (CD, DVD)\n2007: World Cafe Live: The Knack in Concert (DVD)\n2012: Havin' a Rave-Up! Live in Los Angeles, 1978 (CD)\n\nCompilation albums\n\n1992: Retrospective\n1995: My Sharona\n1998: Proof: The Very Best of the Knack\n1999: The Best of the Knack: Ten Best Series\n\nDocumentary DVD\n\n2004: Getting the Knack\n\nSingles[11][13][15][16][17][18][19][20][21]\nReferences[edit]External links[edit]\nThe Knack official website\n", "subtitles": ["History", "Outside the Knack", "Discography", "References", "External links"], "title": "The Knack"},
{"content": "MusicBrainz is a project that aims to create an open data music database that is similar to the freedb project. MusicBrainz was founded in response to the restrictions placed on the Compact Disc Database (CDDB), a database for software applications to look up audio CD (compact disc) information on the Internet. MusicBrainz has expanded its goals to reach beyond a compact disc metadata (this is information about the performers, artists, songwriters, etc.) storehouse to become a structured open online database for music.[5][6]MusicBrainz captures information about artists, their recorded works, and the relationships between them. Recorded works entries capture at a minimum the album title, track titles, and the length of each track. These entries are maintained by volunteer editors who follow community written style guidelines. Recorded works can also store information about the release date and country, the CD ID, cover art, acoustic fingerprint, free-form annotation text and other metadata. As of 26 July 2016[update], MusicBrainz contained information about roughly 1.1 million artists, 1.6 million releases, and 16 million recordings.[3] End-users can use software that communicates with MusicBrainz to add metadata tags to their digital media files, such as FLAC, MP3, Ogg Vorbis or AAC.Cover Art Archive[edit]MusicBrainz allows contributors to upload cover art images of releases to the database; these images are hosted by Cover Art Archive (CAA), a joint project between Internet Archive and MusicBrainz started in 2012. Internet Archive provides the bandwidth, storage and legal protection for hosting the images, while MusicBrainz stores metadata and provides public access through the web and via an API for third parties to use. As with other contributions, the MusicBrainz community is in charge for maintaining and reviewing the data.[7] Cover art is also provided for items on sale at Amazon.com and some other online resources, but CAA is now preferred because it gives the community more control and flexibility for managing the images.Fingerprinting[edit]Besides collecting metadata about music, MusicBrainz also allows looking up recordings by their acoustic fingerprint. A separate application, such as MusicBrainz Picard, must be used for this.Proprietary services[edit]In 2000, MusicBrainz started using Relatable's patented TRM (a recursive acronym for TRM Recognizes Music) for acoustic fingerprint matching. This feature attracted many users and allowed the database to grow quickly. However, by 2005 TRM was showing scalability issues as the number of tracks in the database had reached into the millions. This issue was resolved in May 2006 when MusicBrainz partnered with MusicIP (now AmpliFIND), replacing TRM with MusicDNS.[8] TRMs were phased out and replaced by MusicDNS in November 2008.AcoustID and Chromaprint[edit]In October 2009 MusicIP was acquired by AmpliFIND.[9] Some time after the acquisition, the MusicDNS service began having intermittent problems. Since the future of the free identification service was uncertain, a replacement for it was sought. The Chromaprint acoustic fingerprinting algorithm, the basis for AcoustID identification service, was started in February 2010 by a long-time MusicBrainz contributor Luka\u0301s\u030c Lalinsky\u0301.[10] While AcoustID and Chromaprint are not officially MusicBrainz projects, they are closely tied with each other and both are open source. Chromaprint works by analyzing the first two minutes of a track, detecting the strength in each of 12 pitch classes, storing these 8 times per second. Additional post-processing is then applied to compress this fingerprint while retaining patterns.[11] The AcoustID search server then searches from the database of fingerprints by similarity and returns the AcoustID identifier along with MusicBrainz recording identifiers if known.Licensing[edit]Since 2003,[12] MusicBrainz's core data (artists, recordings, releases, and so on) are in the public domain, and additional content, including moderation data (essentially every original content contributed by users and its elaborations), is placed under the Creative Commons CC-BY-NC-SA-2.0 license.[13] The relational database management system is PostgreSQL. The server software is covered by the GNU General Public License. The MusicBrainz client software library, libmusicbrainz, is licensed under the GNU Lesser General Public License, which allows use of the code by proprietary software products. In December 2004, the MusicBrainz project was turned over to the MetaBrainz Foundation, a non-profit group, by its creator Robert Kaye.[14] On 20 January 2006, the first commercial venture to use MusicBrainz data was the Barcelona, Spain-based Linkara in their Linkara Mu\u0301sica service.[15] On 28 June 2007, BBC announced that it has licensed MusicBrainz's live data feed to augment their music Web pages. The BBC online music editors will also join the MusicBrainz community to contribute their knowledge to the database.[16] On 28 July 2008, the beta of the new BBC Music site was launched, which publishes a page for each MusicBrainz artist.[17][18]Client software[edit]\nAmarok \u2013 KDE audio player\nBanshee \u2013 multi-platform audio player\nBeets \u2013 automatic CLI music tagger/organiser for Unix-like systems\nClementine \u2013 multi-platform audio player\nCDex \u2013 Microsoft Windows CD ripper\nDemlo \u2013 a dynamic and extensible music manager using a CLI\niEatBrainz \u2013 Mac OS X deprecated\nfoo_musicbrainz component for Foobar 2000 \u2013 Music Library/Audio Player\nJaikoz \u2013 Java mass tag editor\nMax \u2013 Mac OS X CD ripper and audio transcoder\nMp3tag \u2013 Windows metadata editor and music organizer\nMusicBrainz Picard \u2013 cross-platform album-oriented tag editor\nMusicBrainz Tagger \u2013 deprecated Microsoft Windows tag editor\npuddletag \u2013 a tag editor for PyQt under the GPLv3\nRhythmbox music player \u2013 an audio player for Unix-like systems\nSound Juicer \u2013 GNOME CD ripper\nZortam Mp3 Media Studio \u2013 Windows music organizer and ID3 Tag Editor.\nFreedb clients can also access MusicBrainz data through the freedb protocol by using the MusicBrainz to FreeDB gateway service, mb2freedb.See also[edit]\nList of online music databases\nReferences[edit]Further reading[edit]\nMaking Metadata: The Case of MusicBrainz. Jess Hemerly. Master's project at UC Berkeley. 2011.\nExternal links[edit]\nMusicBrainz \u2013 official site\nMusicBrainz info at the BBC Music site\nCover Art Archive - official site\n", "subtitles": ["Cover Art Archive", "Fingerprinting", "Licensing", "Client software", "See also", "References", "Further reading", "External links"], "title": "MusicBrainz"},
{"content": "My Sharona is the debut single by the Knack. The song was written by Berton Averre and Doug Fieger, and released in 1979 from their album Get the Knack. It reached number one on the Billboard Hot 100 singles chart where it remained for 6 weeks, and was number one on Billboard's 1979 Top Pop Singles year-end chart.It was certified gold by the Recording Industry Association of America, representing one million copies sold, and was Capitol Records' fastest gold status debut single since the Beatles' I Want to Hold Your Hand in 1964.[4]Inspiration[edit]The characteristic riff of My Sharona was created by the band's lead guitarist, Berton Averre, years before he joined the Knack. Averre subsequently played the riff, as well as a drum groove, for Doug Fieger, the group's lead vocalist and rhythm guitarist, who greatly admired it and promised to include it in a composition, although he did not have any ideas for the lyrics.[citation needed]When Fieger was 25 years old, he met 17-year-old Sharona Alperin,[5] who inspired a two-month-long run of songwriting, as well as becoming Fieger's girlfriend for the next four years. Fieger recounted that It was like getting hit in the head with a baseball bat; I fell in love with her instantly. And when that happened, it sparked something and I started writing a lot of songs feverishly in a short amount of time. Fieger and Averre worked out the structure and melody of the song. Averre was originally averse to using Alperin's name in the song, but Fieger wanted it to be a direct expression of his feelings; Averre ultimately relented.[6] Fieger claimed that My Sharona was written in 15 minutes.[7]Music and lyrics[edit]The music of the song echoes many elements of songs from the 1960s. According to a Trouser Press reviewer, the song's main melodic hook is an inversion of the signature riff from Gimme Some Lovin', a 1967 song by the Spencer Davis Group.[8] Fieger has acknowledged that the song's tom-tom drum rhythm is just a rewrite of Going to a Go-Go, a song from Smokey Robinson and the Miracles from 1965.[8] Drummer Bruce Gary has stated that although he didn't particularly like the song when Fieger introduced it to the band, he came up with the stuttering beat for the song similar to a surf stomp.[9] He also decided to incorporate a flam, in which two drum strokes are staggered, creating a fuller sound, which Gary considered to be crucial to the song's success.[9]In an interview with The Washington Post, Fieger noted that the song was written from the perspective of a 14-year-old boy.[5]The song's stuttering vocal effect of the repeated muh muh muh my Sharona phrase is reminiscent of Roger Daltrey's vocals in the 1965 song My Generation by the Who.[8]Artwork[edit]In addition to being the inspiration for the song, Sharona Alperin posed for the single's picture sleeve holding a copy of The Knack's debut album Get the Knack.[10]Reception[edit]The song's clean production sound was also reminiscent of the sound of the 1960s British Invasion.[8] Dick Nusser of Billboard Magazine remarked on the song's catchy, deliberately awkward, stop-go drum and guitar breaks, its quirky lyrics and suggestive tone, and that the song will make you ready, willing and able to hum the refrain at the right moment.[11] In the Pazz & Jop 1979 Critic's Poll My Sharona and Fleetwood Mac's Tusk were tied for sixth place in the list of top singles of the year.[12] Chris Woodstra of Allmusic has subsequently referred to the song as an unforgettable hit.[13] The New Rolling Stone Album Guide claimed that the song was a hit for a good reason. The beat is urgent, the chorus calls out for drunken shouting along and the guitar solo is a firecracker flash.[14]Legacy[edit]The New York Times called the song an emblem of the new wave era in rock and a prime example of the brevity of pop fame.[7]In 1994, My Sharona re-entered the Billboard Hot 100 chart and peaked at number 91,[15] when it was released as part of the Reality Bites soundtrack album.[16][17] In the film itself, the characters dance to the song at a convenience store.[18] This version was remixed by Dave Jerden and features, among other changes, a much more prominent drum sound.[19]In 2005, the song gained some attention when it appeared on the playlist of U.S. President George W. Bush's iPod.[20]In 2008, My Sharona was ranked in two Billboard 50th anniversary charts. It ranked 75 on the Billboard Hot 100 All-Time Top Songs[21] and 16 on the Top Billboard Hot 100 Rock Songs.[22][23]In video games, My Sharona is featured as a downloadable content single for the Rock Band series. On March 1, 2011, an updated version of the cover song was made available to download for use in Rock Band 3 in PRO mode which takes advantage of the use of a real guitar / bass guitar, along with standard MIDI-compatible electronic drum kits / keyboards in addition to up to three-part harmony vocals.[24] The original version of the song, along with its music video, is featured on Lips: Party Classics on Xbox 360.In films, the song was heard in the 1997 Disney film RocketMan,[25] the trailer for Charlie's Angels: Full Throttle,[26] in J.J. Abrams' Super 8,[27] and in Richard Linklater's Everybody Wants Some!!.[28]Sharona Alperin, who was the inspiration for the hit, had been a major booster for the band, and brought many girls to their early shows.[6] She has since become a real estate agent in the Los Angeles area,[5][29][30] and uses the domain name mysharona.com for her business.[31]Charts and certifications[edit]Parodies, samples and homages[edit]With both the notoriety gained from being an international hit, and its distinctive rock guitar riff, My Sharona has been the subject of many parodies and samples, which include:Parodies[edit]\nMy Bologna by Weird Al Yankovic - The 1979 song kickstarted Yankovic's career in song parody.[52][53] The Knack approved of the parody and even had Yankovic inked to a one-off deal with their label, Capitol Records. A re-recorded version appeared on his eponymous de\u0301but album.\nAyatollah by Chicago radio personality Steve Dahl - The song covered current events related to the Iranian Revolution of 1979.[53]\nPull My Strings by the Dead Kennedys - The 1980 song used the guitar riff and changed the phrase from My Sharona to My Payola to satirize the music industry.\nMy Scrotum by Cheech Marin - The song was featured in the 1980 film Cheech & Chong's Next Movie.[53]\n9 Coronas by John Mammoser. - Originally recorded in 1987 with release in 1995, and with two follow-up versions (10 Coronas in 1996, and 9 Coronas ('99 version') in 1999) that were showcased on the Dr. Demento radio programs.[54]\nVaiche boa by the Galician band Heredeiros da Crus - Released in 1997, on their album Des minutos.\nBabylona by Christian parody band ApologetiX - In 2001, this song was on their Keep the Change album.\nComme des Connards (Like Jerks) by the French comedian Michae\u0308l Youn - A parody for the 2004 film Les 11 commandements.\nMy Menorah by American Comedy Network - a Flash parody in 2004 with singing candles.[53][55][56]\nMy Toyota by radio personality Bob Rivers - This was a video spoof of the Toyota Recall events in 2010.[57]\nMy Fevola - This was a parody sung on The AFL Footy Show about footballer Brendan Fevola.\nHong Kong pop singer Alan Tam included a Cantonese version of the song called \u611b\u5230\u4f60\u767c\u72c2 (English: Loving you make me crazy) in his 1980 same name album .\nParodies of the song have also been featured in several television commercials, including My Chalupa (Taco Bell), My Toyota (Toyota), My Mohegan (Mohegan Sun) and Pepperona (Hormel).Girl U Want by Devo, from the album Freedom of Choice, was allegedly inspired by My Sharona, although Devo's Gerald Casale has denied this.[58]Audio samples[edit]\nRun\u2013D.M.C. used an unauthorized audio sample from the song in their 1986 hit It's Tricky. In 2006, Berton Averre and Doug Fieger filed suit against Apple, Run DMC and others for electronically redistributing the work. The case was settled in 2009.[59]\nRogue Traders used re-recorded elements of the riff in their 2006 hit Watching You.\nHip hop artists Everlast and DJ Lethal sampled the song for the track I Got the Knack, which first appeared in the 1990 Everlast album Forever Everlasting.\nBritish girl group Girls Aloud incorporated parts of the song for the track No Good Advice.[60]\nLet Me Out[edit]The B-side of the My Sharona single was Let Me Out. It was written by Fieger and Averre to fill the band's need for a strong opening track for concerts and later for their Get the Knack album.[61] Averre has stated that the song is absurdly fast.[61] Drummer Bruce Gary felt that the words of Let Me Out helped make the song a perfect opener since the band wanted to let out, and bassist Prescott Niles noted that, with the song, the band was all of a sudden out of the box.[61] Gary has also claimed that the song was me trying to be Buddy Rich in a rock 'n' roll band. It was just full on.[61]Billboard Magazine described Let Me Out as a teen anthem delivered at full throttle and praised the song's delightful harmonies, slapping guitars and perfectly tuned drumming.[11] Superchunk and The Mountain Goats drummer Jon Wurster commented on the full force of Gary's drumming on Let Me Out.[62] Ira Robbins and Michael Sandlin of Trouser Press described the song as tight guitar pop.[63] Author John Borack described the song as a damn fine pop tune.[64] Audio magazine called it a basher with plenty of style.[65] Allmusic critic Mark Deming stated that the live version of Let Me Out has a joyous force nearly any act would envy.[66] Dave Swanson of Ultimate Classic Rock called it one of the most powerful album openers ever.[67]A 1979 live performance of Let Me Out from Carnegie Hall was included on the laser disc of Live at Carnegie Hall.[68] The song was included on their compilation album, Premium Gold Collection.[69] A 2012 vinyl EP for Record Store Day includes 1978 live performances of Let Me Out and My Sharona from Los Angeles and two other songs. The two performances are also included on the live CD of the entire 1978 Los Angeles concert Havin' a Rave-Up.[66][70]References[edit]External links[edit]\nBBC News: Who was My Sharona?\nClassic Tracks: The Knack 'My Sharona'\nNPR: The Woman Behind 'My Sharona'\nSharona Alperin's Web site\nLyrics of this song at MetroLyrics\n", "subtitles": ["Inspiration", "Music and lyrics", "Artwork", "Reception", "Legacy", "Charts and certifications", "Parodies, samples and homages", "\"Let Me Out\"", "References", "External links"], "title": "My Sharona"},
{"content": "An award is something given to a person, a group of people, like a sports team, or an organization in recognition of their excellence in a certain field.[1][2] An award may be accompanied by trophy, title, certificate, commemorative plaque, medal, badge, pin, or ribbon. An award may carry a monetary prize given to the recipient. For example: the Nobel Prize for contributions to society, or the Pulitzer prize for literary achievements. An award may also simply be a public acknowledgment of excellence, without any tangible token or prize of excellence.Overview[edit]Awards can be given by any person or institution, although the prestige of an award usually depends on the status of the awarder. Usually, awards are given by an organization of some sort, or by the office of an official within an organization or government.[3] For instance, a special presidential citation (as given by the President of the United States) is a public announcement giving an official place of honor (e.g., President Ronald Reagan gave a special presidential citation in 1984 to the Disney Channel for its excellent children's television programming.)However, there are exceptions like some quality labels, for which it is neither person nor organizations that are rewarded, but products. This is the case for the World Quality Selections organized by Monde Selection. These international awards are assigned to beverages, foods, cosmetics and diet products, which stand out for their quality.[4]People who have won certain prestigious awards, such as the Nobel Prize, a championship title in a sport, or an Academy Award (Oscar), can have the award become their identity, thereafter being known primarily for winning the award, rather than for any other achievement or occupation.[citation needed] To distinctly be categorized as an 'Award', rather than some other type of ceremonial or arbitrary recognition, there should be a clear process of nominations, award criteria, and appropriate judging process. Generally, recognition by a set of peers, acknowledging quality of work, rather than a 'popularity contest' is considered to be an authentic award. Some prestigious and authentic awards include:\nGolden Globes \u2013 The statuettes are manufactured by the New York firm Society Awards.[5]\nMTV Video Music Award \u2013 The moonman is manufactured by the New York firm Society Awards.[6]\nAcademy of Country Music Awards \u2013 The \u201chat\u201d trophy is manufactured by the New York firm Society Awards.[7]\nBillboard Music Award \u2013 The trophy is manufactured by the New York firm Society Awards.[8]\nThe Asian Awards \u2013 The worlds only pan-Sector, pan-Asian Awards ceremony.[9]\nNAACP Image Award \u2013 The trophy is manufactured by the New York firm Society Awards.[10]\nThe Nigeria Safety Award for Excellence Hall of Fame (9jaSAFE Award) \u2013 9jaSAFE Award is Nigeria most recognized Health Safety and Environment Award.[11]\nAfricaleadership award one of the most recognize in africa [12]\nOne common type of award in the United States is the Employee of the Month award, where typically the recipients' names are listed in a prominent place in the business for that month.Mock awards, which typically recognize failures or atypical achievements, are also popular.[13] They are usually given by people and organizations of lower or average prestige, such as comical organizations and individual writers. Popular mock awards include:\nGolden Raspberry Awards (Razzies), a satirical counterpart to the Academy Award which recognizes the worst acting, screenwriting, songwriting, directing, and films that the film industry had to offer\nIg Nobel Prize, a satirical counterpart to the Nobel Prize, given for achievements that first make people laugh, and then make them think.\nDarwin Awards, given to people who seem to improve the human gene pool by accidentally killing or sterilizing themselves during a foolish or careless mistake.\nA common mock award is the wooden spoon, given to an individual or team which has come last in a competition. A more common last place, mock award is the Half Fast award; most often the trophy given for this award is the back half of horse figure.Some awards are given only after a fee is paid by the recipient, such as the German Design Award.\nThe Kentucky Derby Trophy is an award worth $70,000 with an estimated 1000 man hours of labor.\nHonorable mention[edit]An honorable mention is an award, prize or recognition given to something that does not make it to a higher standing but is worth mentioning in an honorable way.States[edit]States may also use awards such as medals and orders of merit to honour their citizens. These awards usually form part of a system honouring people and is often refers to as an honours system.See also[edit]\nAward ceremony\nList of prizes, medals and awards\nOrder (distinction)\nSME One Asia Awards\nReferences[edit]External Links[edit]", "subtitles": ["Overview", "Honorable mention", "States", "See also", "References", "External Links"], "title": "Award"},
{"content": "Andrew Roy Gibb (5 March 1958 \u2013 10 March 1988) was a British singer, songwriter, performer, and teen idol.[1] He was the youngest brother of the Bee Gees: Barry, Robin, and Maurice Gibb.Gibb came to international prominence in the late 1970s with six singles that reached the Top 10 in the United States, starting with I Just Want to Be Your Everything (1977), followed by three other top 20 singles. Gibb's success was brief due to drug addiction and depression. He died just five days after turning 30.[3]Life and career[edit]1958\u20131975: Early life and first recordings[edit]Andrew Roy Gibb was born on 5 March 1958 in Manchester, England. He was the youngest of five children of Barbara and Hugh Gibb. His mother was of Irish and English descent and his father was of Scottish and Irish descent.[4] He had four siblings: his sister Lesley, and three brothers, Barry and fraternal twins Robin and Maurice.At the age of six months, Gibb emigrated with his family to Queensland, Australia, settling on Cribb Island just north of Brisbane. After moving several times around Brisbane and Sydney, Andy returned to the United Kingdom in January 1967 as his three older brothers began to gain international fame as the Bee Gees.In his childhood, his mother Barbara described Andy as A little devil, a little monster. I'd send him off to school, but he'd sneak off to the stable and sleep with his two horses all day. He'd wander back home around lunchtime smelling of horse manure, yet he'd swear he had been at school. Oh, he was a little monkey![5]Producer and film director Tom Kennedy described Andy's personality on his childhood:He quit school at the age of 13, and with an acoustic guitar given to him by his older brother Barry, he began playing at tourist clubs around Ibiza, Spain (when his parents moved there),[6] and later in the Isle of Man, his brothers' birthplace, where his parents were living at the time.In June 1974, Gibb formed his first group, Melody Fayre (named after a Bee Gees song), which included Isle of Man musicians John Alderson on guitar and John Stringer on drums. The group was managed by Andy's mother, Barbara, and had regular bookings on the small island's hotel circuit. Gibb's first recording, in August 1973, was a Maurice Gibb composition, My Father Was a Rebel, which Maurice also produced and played on. It was not released. Another track on the session performed by him was Windows of My World co-written by him with Maurice.[2]At the urging of his brother Barry, Gibb returned to Australia in 1974. Barry believed that as Australia had been a good training ground for the Bee Gees it would also help his youngest brother. Lesley Gibb had remained in Australia, where she raised a family with her husband. Both Alderson and Stringer followed Andy to Australia with the hope of forming a band there. With Col Joye producing, Andy, Alderson and Stringer recorded a number of Andy's compositions. The first song was a demo called To a Girl (with his brother Maurice playing organ), which he later performed on his television debut in Australia on The Ernie Sigley Show. Sigley later informed the audience that it was from Gibb's forthcoming album, but it was never released. In November the same year, he recorded six demos \u2013 again produced by Joye \u2013 including Words and Music, Westfield Mansions and Flowing Rivers (which was later released). What may have detracted from the training ground aspect of Australia for Andy compared to his brothers was that Andy was relatively independent financially, mainly because of his brothers' support and their largesse; hence, the group's sporadic work rate. Andy would disappear for periods of time, leaving Alderson and Stringer out of work with no income. Despondent, Alderson and Stringer returned to the UK.[7]Gibb later joined the band Zenta, consisting of Gibb on vocals, Rick Alford on guitar, Paddy Lelliot on bass, Glen Greenhalgh on vocals, and Trevor Norton on drums. Zenta supported international artists Sweet and the Bay City Rollers on the Sydney leg of their Australian tours. Can't Stop Dancing (which was a Ray Stevens song, later a US hit for duo The Captain and Tennille in May 1977) was mooted for release, but didn't eventuate, although Gibb did perform it on television at least once on the revitalised Bandstand show hosted by Daryl Somers. Zenta would appear later as a backing band for Gibb, but did not participate on Gibb's recording sessions around 1975, which featured Australian jazz fusion group Crossfire.[8]Words and Music was released on the ATA label only in Australia and New Zealand, owned by Joye. It was his first single, the song, backed by another Andy Gibb composition Westfield Mansions.[9] The single would eventually reach the Top Twenty on the Sydney music charts in 1976, although the ballad was one of his well-known hits.Around the same time, he married his girlfriend, Kim Reeder.1975\u20131980: International success[edit]Robert Stigwood, who at the time was the Bee Gees's manager, signed Andy to his label, RSO Records in early 1976, after he had heard some of Andy's demo tapes. Andy soon moved to Miami Beach, Florida, to begin working on songs with his brother Barry and co-producers Albhy Galuten and Karl Richardson. In late 1976 in Miami, Andy, with older brother Barry producing and recording in the famed Criteria Studios, set about making his first album, Flowing Rivers, around the same time as Eagles finishing their album Hotel California as Eagles guitarist Joe Walsh played on two songs on his first album. The first release from the album, and Gibb's first single released outside Australia, was I Just Want to Be Your Everything which was written by Barry, who also provided backup vocals. It reached number one in the United States and Australia and was the most played record of the year. In Britain it was a lesser hit, just scraping into the Top 30. Eight of the ten tracks on the album were Andy Gibb compositions, mostly songs written during his time in Australia. These included a re-recording of his previous single, Words and Music. In September 1977 Flowing Rivers, with another number one single (Love Is) Thicker Than Water (also co-written by Gibb and his brother Barry) to support it, quickly became a million selling album. That single broke in early 1978 during the time that the Bee Gees' contributions to the Saturday Night Fever soundtrack were dominating the world charts. In the United States it replaced Stayin' Alive at the top of the Hot 100 on the day before Andy's 20th birthday, only to be surpassed by Night Fever at number one there two weeks later.On 25 January 1978, he had a daughter, Peta Jaye, but the couple had already separated before Reeder discovered she was pregnant. They divorced later that year. Andy then began work with the Gibb-Galuten-Richardson production team on his second album, Shadow Dancing, which was released in April 1978. The title track, written by all four Gibb brothers, was released as a single in the United States in April 1978. In mid-June it began a seven-week run at number one, achieving platinum status and the honour of being Billboard's number one song of 1978. In the United States, Andy became the first male solo artist to have three consecutive number one singles on the Billboard Hot 100, with all of the weeks at #1 from those singles just barely inside a year, from 30 July 1977 through 29 July 1978. Two further Top Ten singles, An Everlasting Love (which reached number five) and (Our Love) Don't Throw It All Away (which reached number nine), were released from the album, which became another million seller.In 1979 Gibb performed along with Bee Gees, ABBA, and Olivia Newton-John (duet with Rest Your Love on Me) at the Music for UNICEF Concert at the United Nations General Assembly, which was broadcast worldwide. He returned to the studio to begin recording sessions for his final full studio album, After Dark. In March 1980 the last of Gibb's Top Ten singles charted just ahead of the album's release. Desire was recorded for the Bee Gees' 1979 album Spirits Having Flown and featured their original track, complete with Andy's original guest vocal track. A second single, I Can't Help It, a duet with family friend and fellow British and Australian expat Olivia Newton-John, reached the top 20.Later in the year, Andy Gibb's Greatest Hits was released as a finale to his contract with RSO Records, with two new songs: Time Is Time (number 15 in January 1981) and Me (Without You) (Gibb's last top 40 chart entry) shipped as singles, before RSO founder Robert Stigwood had to let him go due to his cocaine addiction and behavioural problems. After Dark and Will You Still Love Me Tomorrow were non-single songs added to the album, the latter of which was a duet with P. P. Arnold, who had previously worked with Barry Gibb, including singing uncredited backups on Bury Me Down by the River from Cucumber Castle. During his relationship with actress Victoria Principal, Gibb worked on several projects outside the recording studio, including performances in Andrew Lloyd Webber's Joseph and the Amazing Technicolor Dreamcoat on Broadway and Gilbert & Sullivan's The Pirates of Penzance in Los Angeles. He also co-hosted the television music show, Solid Gold, from 1980 to 1982.Around the same time, Gibb was invited to sing the first verse on Queen's Play the Game, and lead singer Freddie Mercury apparently was amazed with Gibb's abilities. According to some sources, the tape was found in 1990 in a search of Queen archives for bonus tracks for a CD but was not used. Since it has not been heard by any Queen collectors, its existence is somewhat doubtful, although record producer Mack has also confirmed that the version did exist.[10][11]1981\u20131986: Decline and live performances[edit]Gibb was ultimately fired from both Dreamcoat and Solid Gold because of absenteeism caused by cocaine binges.[12][13] Said Zev Buffman, a Broadway producer and financier for Joseph and the Amazing Technicolor Dreamcoat, When Andy was at the theater, he was a joy. But he wasn't there enough, adding that of the five people to play Joseph up to that point, Gibb was the best actor.[12] He also said after Gibb's death, We'd lose him over long weekends. He'd come back on Tuesday, and he'd look beat. He was like a little puppy \u2013 so ashamed when he did something wrong. He was all heart, but he didn't have enough muscle to carry through.[13] An unnamed co-star in Dreamcoat was quoted as saying, I hear he spent most of his time in his hotel room in front of the TV. I guess he was frightened and insecure. That's what happens when you're the baby brother of the Bee Gees.[12] Commenting after Gibb's death, Solid Gold producer Brad Lachman stated, ...[Andy] was a very charming, vulnerable and charismatic performer. He clearly meant well. He wasn't being difficult. He was going through problems he couldn't deal with. He wanted everyone to love him. He had so much going for him, and he just couldn't believe it.[13]His romance with Principal also ended shortly thereafter when she gave him an ultimatum to choose between her or drugs, but not before they recorded and released a duet of the Everly Brothers' All I Have to Do Is Dream in the summer of 1981. He reportedly heard her singing in the shower and convinced her to go into the studio with him.[14] This would be Gibb's last official single, and his last US chart entry, peaking at number 51. In 1984 and 1985 Gibb did finish two successful contracts at the Riviera Hotel in Las Vegas.His family convinced him to seek treatment for his drug addiction, which included a stay at the Betty Ford Center in the mid-1980s. It was during this time that Gibb began touring small venues with a stage show featuring his hits as well as covers. He also appeared in guest-starring roles on several television sitcoms including Gimme a Break! and Punky Brewster. Following an extensive tour of East Asia, he regularly performed shows in Las Vegas and Lake Tahoe. In 1984, he was the headline performer at the Vin\u0303a del Mar Festival in Chile, performing two nights in a row. He also held a two-week engagement at San Francisco's historic Fairmont Hotel in March 1986.1987\u20131988: Attempted comeback and final days[edit]In early 1987, Gibb went through another drug rehabilitation program and thought he had finally beaten his habits.Gibb now aimed to get a recording contract for release of a new album in 1988. He returned to the studio in June 1987 recording four songs; one of them, Man on Fire, was released posthumously in 1991 on a Polydor Records anthology. Another track, Arrow Through the Heart, was the final song Andy would ever record and was featured on an episode of VH1's series, Behind the Music, and released on the Bee Gees' Mythology 4-disc box set in November 2010. The songs are co-written by Gibb with his brothers Barry and Maurice. Their demo recordings with engineer Scott Glasel were heard by Clive Banks from the UK branch of Island Records. Gibb never formally signed a contract but the record label planned to release a single in Europe that spring, followed by another single that summer with the album to follow.[15]In early March 1988, Barry Gibb had arranged for Island in England to sign Andy, but when he went to England at the start of 1988, he panicked. Gibb missed meetings with the record company and blamed himself for his trouble writing songs. The deal was never signed.[16]Death[edit]By early February 1988, Gibb had seemingly beat his drug addiction, regained his health and was ready to begin recording new material for a new album.[17] However, he still battled clinical depression. According to Robin Gibb, his brother,...just went downhill so fast [...] he was in a terrible state of depression.[17] On 5 March 1988, Gibb celebrated his thirtieth birthday in London while working on the new album. Soon after, he entered John Radcliffe Hospital in Oxford complaining of chest pains.At around 8:30 am on 10 March 1988, Gibb's doctor told him that more tests were needed to determine the cause of his chest pains. Later that day, Gibb slumped into unconsciousness and died as a result of myocarditis, an inflammation of the heart muscle caused by a recent viral infection (a diagnosis supported by William Shell, a cardiologist who had previously treated Gibb),[18][6] which was exacerbated by his years of cocaine abuse.[19]With the announcement of Gibb's death, his ex-wife Kim Reeder was not surprised. I always knew that one day I'd get a call with news like this.  It was only a matter of time.[18] The Gibb family would also maintain it was not an overdose that killed Gibb \u2014 as some media reports suggested \u2014 but natural causes after years of drug and alcohol abuse.[17]Gibb's body was returned to the United States, where he was interred at Forest Lawn Memorial Park in Hollywood Hills, Los Angeles. The headstone reads Andy Gibb / March 5, 1958 \u2013 March 10, 1988 / An Everlasting Love.[20]Legacy[edit]The Andy Gibb Memorial Foundation was established to keep his name and memory alive by contributing to the charities that Gibb supported, such as the American Heart Association, the American Cancer Society, and the Diabetes Research Institute.[21] Following the 2003 death of brother Maurice Gibb at Mount Sinai Medical Center & Miami Heart Institute in Miami Beach, Florida, the family asked that donations be made to the Andy Gibb Memorial Foundation in lieu of flowers.[22]Discography[edit]Studio albums[edit]Compilations[edit]Singles[edit]Filmography[edit]Television[edit]References[edit]External links[edit]\nAndy Gibb at AllMusic\nAndy Gibb on IMDb\nAndy Gibb at the Internet Broadway Database \nAndy Gibb at Find a Grave\n", "subtitles": ["Life and career", "Death", "Legacy", "Discography", "Filmography", "References", "External links"], "title": "Andy Gibb"},
{"content": "Through its awards program, the Institute of Electrical and Electronics Engineers recognizes contributions that advance the fields of interest to the IEEE. For nearly a century, the IEEE Awards Program has paid tribute to technical professionals whose exceptional achievements and outstanding contributions have made a lasting impact on technology, society and the engineering profession. The IEEE Medals and IEEE Technical Field Awards are institution-level awards. They are considered more prestigious than IEEE Society level awards and are administered by IEEE Awards Board. Each year, the IEEE Board of Directors[1] approved the winners of these prestigious medals and awards at their annual board meeting. An IEEE Honors Ceremony[2] is organized and held in New York each year to present the medals and awards to the recipients.Funds for the awards program, other than those provided by corporate sponsors for some awards, are administered by the IEEE Foundation.IEEE Medals[edit]\nIEEE Medal of Honor - IEEE's top medal and highest honor\nIEEE Edison Medal - IEEE's principal medal for a meritorious career\nIEEE Alexander Graham Bell Medal (for communications engineering)\nIEEE/RSE James Clerk Maxwell Medal (for electronics and telecommunications)\nIEEE Richard W. Hamming Medal (for information theory and coding)\nIEEE John von Neumann Medal (for computer-related technology)\nIEEE Robert N. Noyce Medal (for microelectronics)\nIEEE Jack S. Kilby Signal Processing Medal (for signal processing)\nIEEE Dennis J. Picard Medal for Radar Technologies and Applications\nIEEE Simon Ramo Medal (for systems engineering)\nIEEE Medal for Environmental and Safety Technologies\nIEEE Medal in Power Engineering\nIEEE Jun-ichi Nishizawa Medal (for materials and device sciences)\nIEEE Medal for Innovations in Healthcare Technology\nIEEE Founders Medal (for leadership, planning, and administration)\nIEEE James H. Mulligan, Jr. Education Medal\nIEEE Technical field awards[edit]\nIEEE Biomedical Engineering Award\nIEEE Cledo Brunetti Award (for nanotechnology and miniaturization)\nIEEE Claude E. Shannon Award in Information Theory\nIEEE Components, Packaging, and Manufacturing Technologies Award\nIEEE Control Systems Award\nIEEE Electromagnetics Award\nIEEE James L. Flanagan Speech and Audio Processing Award\nIEEE Andrew S. Grove Award (for solid-state devices)\nIEEE Herman Halperin Electric Transmission and Distribution Award\nIEEE Masaru Ibuka Consumer Electronics Award\nIEEE Innovation in Societal Infrastructure Award\nIEEE Internet Award\nIEEE Reynold B. Johnson Data Storage Device Technology Award\nIEEE Reynold B. Johnson Information Storage Systems Award\nIEEE Richard Harold Kaufmann Award (for industrial systems engineering)\nIEEE Joseph F. Keithley Award in Instrumentation and Measurement\nIEEE Gustav Robert Kirchhoff Award (for electronic circuits and systems)\nIEEE Leon K. Kirchmayer Graduate Teaching Award\nIEEE Computer Science and Engineering Undergraduate Teaching Award\nIEEE Koji Kobayashi Computers and Communications Award\nIEEE William E. Newell Power Electronics Award\nIEEE Daniel E. Noble Award (for emerging technologies)\nIEEE Donald O. Pederson Award in Solid-State Circuits\nIEEE Frederik Philips Award (for management of research and development)\nIEEE Photonics Award\nIEEE Emanuel R. Piore Award (for information processing systems in computer science)\nIEEE Judith A. Resnik Award (for space engineering)\nIEEE Robotics and Automation Award\nIEEE Frank Rosenblatt Award (for biologically and linguistically motivated computational paradigms such as neural networks)\nIEEE David Sarnoff Award (for electronics)\nIEEE Charles Proteus Steinmetz Award (for standardization)\nIEEE Marie Sklodowska-Curie Award (for nuclear and plasma engineering)\nIEEE Eric E. Sumner Award (for communications technology)\nIEEE Undergraduate Teaching Award\nIEEE Nikola Tesla Award (for power technology)\nIEEE Kiyo Tomiyasu Award (for technologies holding the promise of innovative applications)\nIEEE Transportation Technologies Award\nOther IEEE Recognitions[edit]\nIEEE Haraden Pratt Award (for service to IEEE)\nIEEE Richard M. Emberson Award (for service to IEEE)\nIEEE Corporate Innovation Recognition\nIEEE Ernst Weber Engineering Leadership Recognition (for managerial leadership)\nIEEE Honorary Membership\nPaper Prize[edit]\nIEEE Donald G. Fink Prize Paper Award\nIEEE W.R.G. Baker Award\nScholarships[edit]\nIEEE Life Members Graduate Study Fellowship in Electrical Engineering was established by the IEEE in 2000. The fellowship is awarded annually to a first year, full-time graduate student obtaining their masters for work in the area of electrical engineering, at an engineering school/program of recognized standing worldwide.[3]\nIEEE Charles LeGeyt Fortescue Graduate Scholarship was established by the IRE in 1939 to commemorate Charles Legeyt Fortescue's contributions to electrical engineering. The scholarship is awarded for one year of full-time graduate work obtaining their masters in electrical engineering an ANE engineering school of recognized standing in the United States.[4]\nStudent activities[edit]IEEE offers many student awards, competitions and other opportunities to become actively involved.\nCompetitions\nIEEEXtreme Programming Competition\nIEEEmadC\nStudent Branch Awards\nScholarships, Grants, and Fellowships\nReferences[edit]", "subtitles": ["IEEE Medals", "IEEE Technical field awards", "Other IEEE Recognitions", "Paper Prize", "Scholarships", "Student activities", "References"], "title": "List of IEEE awards"},
{"content": "This list of IEEE Milestones describes the Institute of Electrical and Electronics Engineers (IEEE) milestones, representing key historical achievements in electrical and electronic engineering.\nPrior to 1800\n\n1751 \u2013 Book Experiments and Observations on Electricity by Benjamin Franklin\n1757\u20131775 \u2013 Benjamin Franklin's Work in London\n1799 \u2013 Volta's Electrical Battery Invention\n\n\n1800\u20131850\n\n1820 \u2013 \u00d8rsted first demonstrates that an electric current will generate a magnetic field - electromagnetism.\n1836 \u2013 Callan's Pioneering Contributions to Electrical Science and Technology\n1828\u20131837 \u2013 Schilling's Pioneering Contribution to Practical Telegraphy\n1838 \u2013 Demonstration of Practical Telegraphy\n\n\n\n1850\u20131870\n\n1852 \u2013 Electric Fire Alarm System\n1861\u20131870 \u2013 Maxwell's Equations\n1861 \u2013 Transcontinental Telegraph\n1866 \u2013 Landing of the Transatlantic Cable\n1866 \u2013 County Kerry Transatlantic Cable Stations\n\n\n1870\u20131890\n\n1876 \u2013 First Intelligible Voice Transmission over Electric Wire\n1876 \u2013 First Distant Speech Transmission in Canada\n1876 \u2013 Thomas Alva Edison Historic Site at Menlo Park\n1882 \u2013 Vulcan Street Plant\n1882 \u2013 Pearl Street Station\n1882 \u2013 First Central Station in South Carolina\n1884 \u2013 First AIEE Technical Meeting\n1886 \u2013 Alternating Current Electrification (demonstrated by William Stanley, Jr.)\n1886 \u2013 First Generation and Experimental Proof of Electromagnetic Waves\n1887 \u2013 Thomas A. Edison West Orange Laboratories and Factories\n1887 \u2013 Weston Meters, first portable current and voltage meters\n1888 \u2013 Richmond Union Passenger Railway\n1889 \u2013 Power System of Boston's Rapid Transit\n\n\n1890\u20131900\n\n1890 \u2013 Discovery of Radioconduction with a Coherer by E\u0301douard Branly\n1890 \u2013 Keage Power Station, Japan's First Commercial Hydroelectric Plant\n1891 \u2013 Ames Hydroelectric Generating Plant\n1893 \u2013 Birth and Growth of Battery Industries in Japan\n1893 \u2013 Mill Creek No. 1 Hydroelectric Plant\n1884 \u2013 Millimeter-wave Communication Experiments by Jagadish Chandra Bose\n1895 \u2013 Popov's Contribution to the Development of Wireless Communication\n1895 \u2013 Adams Hydroelectric Generating Plant\n1895 \u2013 Krka-S\u030cibenik Electric Power System\n1895 \u2013 Guglielmo Marconi's Experiments in Wireless Telegraphy\n1895 \u2013 Electrification by Baltimore and Ohio Railroad\n1897 \u2013 Early Swiss Wireless Experiments that sent a signal over one and a half kilometers.\n1897 \u2013 Chivilingo Hydroelectric Plant\n1898 \u2013 Decew Falls Hydro-Electric Plant\n1898 \u2013 Rheinfelden Hydroelectric Power Plant\n1899 \u2013 First Operational Use Of Wireless Telegraphy in the Anglo-Boer War\n\n\n1900\u20131920\n\n1900 \u2013 Georgetown Steam Hydro Generating Plant\n1901 \u2013 Transmission of Transatlantic Radio Signals\n1901 \u2013 Reception of Transatlantic Radio Signals\n1901 \u2013 Early Developments in Remote-Control by Leonardo Torres-Quevedo\n1902 \u2013 Poulsen-Arc Radio Transmitter\n1903 \u2013 Vucje Hydroelectric Plant\n1904 \u2013 Alexanderson Radio Alternator\n1904 \u2013 Fleming Valve\n1906 \u2013 Pinawa Hydroelectric Power Project\n1906 \u2013 First Wireless Radio Broadcast by Reginald A. Fessenden\n1906 \u2013 Grand Central Terminal Electrification\n1907 \u2013 Alternating-Current Electrification of the New York, New Haven & Hartford Railroad\n1909 \u2013 Shoshone Transmission Line\n1911 \u2013 Discovery of superconductivity\n1914 \u2013 Panama Canal Electrical and Control Installations\n\n\n1920\u20131930\n\n1920 \u2013 Westinghouse Radio Station KDKA (AM)\n1920 \u2013 Funkerberg Ko\u0308nigs Wusterhausen first radio broadcast in Germany\n1924 \u2013 Directive Short Wave Antenna (Yagi-Uda antenna)\n1924 \u2013 Enrico Fermi's Major Contribution to Semiconductor Statistics\n1924\u20131941 \u2013 Development of Electronic Television\n1925 \u2013 Bell Telephone Laboratories\n1928 \u2013 One-Way Police Radio Communication\n1929 \u2013 Shannon Scheme for the Electrification of the Irish Free State\n1929 \u2013 Yosami Radio Transmitting Station\n1929 \u2013 Largest Private (dc) Generating Plant in the U.S.A.\n1929 \u2013 First Blind Takeoff, Flight and Landing\n\n\n1930\u20131950\n\n1930\u20131945 \u2013 Development of Ferrite Materials and Their Applications\n1931 \u2013 Invention of Stereo Sound Reproduction\n1932 \u2013 First Breaking of Enigma Code by the Team of Polish Cipher Bureau\n1933 \u2013 Two-Way Police Radio Communication\n1934 \u2013 Long-Range Shortwave Voice Transmissions from Byrd's Antarctic Expedition\n1937 \u2013 Westinghouse Atom Smasher\n1939 \u2013 Atanasoff\u2013Berry Computer\n1939 \u2013 Shannon Development of Information Theory\n1939 \u2013 Single-element Unidirectional Microphone - Shure Unidyne\n1940 \u2013 FM Police Radio Communication\n1941 \u2013 Opana Radar Site\n1939\u20131945 \u2013 Code-breaking at Bletchley Park during World War II\n1940\u20131945 \u2013 MIT Radiation Laboratory\n1942\u20131945 \u2013 US Naval Computing Machine Laboratory\n1945 \u2013 Merrill Wheel-Balancing System\n1945 \u2013 Rinco\u0301n del Bonete Plant and Transmission System\n1946 \u2013 Electronic Numerical Integrator and Computer (ENIAC)\n1947 \u2013 Invention of the First Transistor at Bell Telephone Laboratories, Inc.\n1947 \u2013 Invention of Holography\n1948 \u2013 Birth of the Barcode\n\n\n1950\u20131960\n\n1950 \u2013 First External Cardiac Pacemaker\n1951 \u2013 Manufacture of Transistors\n1951 \u2013 Experimental Breeder Reactor I\n1946\u20131953 \u2013 Monochrome-Compatible Electronic Color Television\n1955 \u2013 WEIZAC Computer\n1956 \u2013 RAMAC\n1956 \u2013 Ampex Videotape Recorder\n1956 \u2013 The First Submarine Transatlantic Telephone Cable System (TAT-1)\n1957\u20131958 \u2013 First Wearable Cardiac Pacemaker\n1958 \u2013 First Semiconductor Integrated Circuit (IC)\n1959 \u2013 Semiconductor Planar Process and Integrated Circuit\n\n\n1960\u20131970\n\n1960\u20131984 \u2013 IBM Thomas J. Watson Research Center\n1961\u20131964 \u2013 First Optical Fiber Laser and Amplifier\n1962 \u2013 Mercury spacecraft MA-6, Col. John Glenn piloted the Mercury Friendship 7 spacecraft in the first United States human-orbital flight on 20 February 1962. (1)\n1962 \u2013 Stanford Linear Accelerator Center\n1962 \u2013 First Transatlantic Transmission of a Television Signal via Satellite\n1962 \u2013 First Transatlantic Television Signal via Satellite\n1962 \u2013 First Transatlantic Reception of a Television Signal via Satellite\n1962 \u2013 Alouette-ISIS Satellite Program\n1963 \u2013 NAIC/Arecibo Radiotelescope\n1963 \u2013 First Transpacific Reception of a Television (TV) Signal via Satellite\n1963 \u2013 Taum Sauk Pumped-Storage Electric Power Plant\n1963 \u2013 ASCII\n1964 \u2013 Mount Fuji Radar System\n1964 \u2013 Tokaido Shinkansen (Bullet Train)\n1964 \u2013 High-definition television\n1964 \u2013 TPC-1 Transpacific Cable System\n1965 \u2013 First 735 kV AC Transmission System\n1965 \u2013 Dadda multiplier\n1962\u20131967 \u2013 Pioneering Work on the Quartz Electronic Wristwatch\n1966 \u2013 Interactive Video Games\n1966 \u2013 Shakey, the first mobile robot to be able to reason about its own actions[1]\n1967 \u2013 First Astronomical Observations Using Very Long Baseline Interferometry\n1968 \u2013 Liquid Crystal Display by George H. Heilmeier\n1968 \u2013 CERN Experimental Instrumentation\n1969 \u2013 Birth of the Internet\n1969 \u2013 Inception of the ARPANET\n1950\u20131969 \u2013 Electronic Technology for Space Rocket Launches\n1969 \u2013 Electronic Quartz Wristwatch\n\n\n1970\u2013present\n\n1965\u20131971 \u2013 Railroad Ticketing Examining System (developed by OMRON of Japan)\n1972 \u2013 Nelson River HVDC Transmission System\n1964\u20131973 \u2013 Pioneering Work on Electronic Calculators\n1971\u20131978 \u2013 The First Word Processor for the Japanese Language\n1972 \u2013 Development of the HP-35, the First Handheld Scientific Calculator\n1974 \u2013 Birth of CP/M Operating System\n1975 \u2013 Gapless Metal Oxide Surge Arrester (MOSA) for electric power systems\n1975 \u2013 Line Spectrum Pair (LSP) for high-compression speech coding\n1976 \u2013 Development of VHS, a World Standard for Home Video Recording\n1976 \u2013 Introduction of the Apple I Computer\n1977 \u2013 Introduction of the Apple II Computer\n1977 \u2013 Lempel\u2013Ziv Data Compression Algorithm\n1977 \u2013 Vapor-phase Axial Deposition Method for Mass Production of High-quality Optical Fiber\n1978 \u2013 Digital Image from Synthetic Aperture Radar\n1978 \u2013 Speak & Spell, the First Use of a Digital Signal Processing IC for Speech Generation\n1979 \u2013 Compact Disc Audio Player\n1979 \u2013 20-inch Diameter Photomultiplier Tubes\n1980 \u2013 International Standardization of Group 3 Facsimile\n1980 \u2013 RISC (Reduced Instruction-Set Computing) Microprocessor\n1981 \u2013 16-Bit Monolithic Digital-to-Analog Converter (DAC) for Digital Audio\n1981 \u2013 Map-Based Automotive Navigation System\n1984 \u2013 First Direct-broadcast satellite Service\n1984 \u2013 The MU (Middle and Upper atmosphere) radar\n1985 \u2013 Toshiba T1100, for Contribution to the Development of Laptop PCs\n1985 \u2013 Emergency Warning Code Signal Broadcasting System\n1987 \u2013 High Temperature Superconductor\n1987 \u2013 SPARC RISC Architecture\n1988 \u2013 Sharp 14-Inch Thin Film Transistor Liquid-Crystal Display (TFT-LCD) for TV\n1988 \u2013 Solid State High Voltage DC Converter Station\n1988 \u2013 Trans-Atlantic Telephone Fiber-optic Submarine Cable, TAT-8\n1988 \u2013 Virginia Smith High-Voltage Direct-Current Converter Station\n\n\n\nSpecial citations\n\n1856\u20131943 \u2013 Nikola Tesla, Electrical Pioneer\n1979 \u2013 Computer History Museum\n\n\nReferences[edit]External links[edit]\nList of IEEE Milestones\nIEEE History Center: Milestones Introduction\nIEEE Global History Network: List of IEEE Milestones\nArchive by category 'IEEE Milestones'\n", "subtitles": [], "title": "List of IEEE milestones"},
{"content": "IEEE Smart Grid is an initiative launched by IEEE to help provide expertise and guidance for individuals and organizations involved in the modernization and optimization of the power grid, better known as the smart grid. IEEE Smart Grid encompasses an array of activities, including development of new smart grid-related standards, best practices, publications, and conferences and educational opportunities.[1]History[edit]IEEE's involvement in the emerging smart grid reaches back to its development of power and energy standards.[2] In 2007, the Energy Independence and Security Act (EISA) was signed into law by President George W. Bush. EISA directed that under the auspices of the US Department of Energy (US DOE), the National Institute of Standards and Technology (NIST) be tasked with the development of a framework including protocols and model standards for information management to achieve interoperability of smart grid devices and systems. In Title XIII, Section 1305(a)(2) of EISA, IEEE was named as one of the Standard Setting Organizations (SSOs) whose work would be vital in the development of standards for NIST's Smart Grid Interoperability Framework.[3] As part of the first phase of NIST's Smart Grid Interoperability Framework, 16 initial standards were offered for adoption, including three developed by IEEE: C37.118, IEEE 1547, and IEEE 1686-2007.[3]In May 2009, IEEE announced the launch of a new smart grid effort targeted to the power engineering, communications, and information technology disciplines. The first project in this effort, titled The IEEE Standard 2030 Guide for Smart Grid Interoperability of Energy Technology and Information Technology Operation with the Electric Power System (EPS) and End-Use Applications and Loads (IEEE 2030) established a knowledge framework for understanding and defining smart grid interoperability of the electric power system with end use applications, setting the stage for future smart grid-related standards.[4]In January 2010, IEEE launched the first phase of IEEE Smart Grid, a new global initiative designed to bring together the organization's broad array of resources to provide expertise and guidance for those involved in Smart Grid worldwide.[5] Later that year, IEEE published inaugural editions of two new publications, cross-discipline archival journals entitled IEEE Transactions on Smart Grid,[6] and IEEE Transactions on Sustainable Energy.[7]Current work[edit]IEEE's approach to the smart grid is to view it as a large System of Systems wherein individual smart grid domains based on the NIST Smart Grid Conceptual Model are expanded into three layers: Power and Energy, Communications, and IT/Computer. IEEE considers the Communications and IT/Computer layers to be enabling infrastructure for the Power and Energy layer.[8]IEEE Smart Grid Portal[edit]As part of the first phase of IEEE Smart Grid, IEEE unveiled the IEEE Smart Grid Portal in January 2010.[5] As originally designed, the site served as an online clearinghouse providing smart grid-focused news, information, commentary, videos, and event information for a broad audience including business and industry, academic, and government users, as well as consumers. The portal is also home to the initiative's monthly digest, the IEEE Smart Grid Newsletter.[9]The IEEE Smart Grid Portal was relaunched in September 2011. The redesigned site included improved search capabilities and other new features, such as a broader selection of video interviews and Q&A's with industry experts, business leaders, and researchers. It also facilitated greater user access to approved and in-development IEEE smart grid standards and an expanded conference calendar.[10]Standards[edit]IEEE continues to work closely with NIST on its standards roadmap and conformance testing/certification framework[11] for the smart grid. The organization also collaborates with other global standards bodies to effectively facilitate standards coordination and to ensure the intensifying smart grid movement\u2019s success.There are more than 100 standards that have been approved[12] or in development[13] relating to the smart grid. Among the broad number of systems and technologies addressed by these standards are broadband over power line, cyber security, distributed energy resources, Distributed Network Protocol (DNP3), and Greenhouse gas emissions credits, among others.Sampling of Approved IEEE Smart Grid Standards[edit]\nIEEE 1547-2003 Standard for Interconnecting Distributed Resources with Electric Power Systems[14]\nIEEE 1675-2008 Standard for Broadband over Power Line Hardware[15]\nIEEE 1686-2007 Standard for Substation Intelligent Electronic Devices (IEDs) Cyber Security Capabilities[16]\nIEEE 1815-2010 Standard for Electric Power Systems Communications\u2014Distributed Network Protocol (DNP3)[17]\nIEEE 2030-2011 Guide for Smart Grid Interoperability of Energy Technology and Information Technology Operation with the Electric Power System (EPS), End-Use Applications, and Loads[18]\nSampling of Proposed IEEE Smart Grid Standards[edit]\nIEEE P1377 Draft Standard for Utility Industry Metering Communication Protocol Application Layer (End Device Data Tables)[19]\nIEEE P1547.6 Draft Recommended Practice For Interconnecting Distributed Resources With Electric Power Systems Distribution Secondary Networks[20]\nIEEE P1595 Draft Standard for Quantifying Greenhouse Gas Emission Credits from Small Hydro and Wind Power Projects, and for Grid Baseline Conditions[21]\nIEEE P1613 Draft Standard Environmental and Testing Requirements for Communications Networking Devices Installed in Electric Power Substations[22]\nIEEE P1797 Draft Guide for Design and Application of Solar Technology in Commercial Power Generating Stations[23]\nEvents[edit]IEEE Smart Grid and its participating societies sponsor and host major conferences, symposiums, and other events on a global basis.[24] Dedicated to providing a forum for the sharing of ideas and information about smart grid concepts, deployments, and technology advancements, IEEE Smart Grid events generally span several days in length and attract attendees from around the world. Conference programs often consist of educational tracks with keynote speeches, panel discussions, and roundtables led by industry notables, researchers, engineers, academics, policymakers, and other key stakeholders.Among IEEE Smart Grid flagship events are its Innovative Smart Grid Technologies (ISGT) Conference,[25] SmartGridComm,[26] and Smart Grid World Forum.[27] Other recent major IEEE Smart Grid events include:2010[edit]\nAsia-Pacific Power & Energy Engineering Conference (APPEEC) 2010, sponsored by the IEEE Power & Energy Society and centered on best practices in power generation, transmission, and distribution, and conventional and renewable energy[28]\nInternational Symposium on Power Line Communications and its Applications (ISPLC) 2010, designed to stimulate discussions on electrical power distribution wires as a viable communication channel[29]\nConference On Innovative Technologies For An Efficient & Reliable Electricity Supply (ITERES) 2010, focused on examining the development of components for and planning and implementing of the new Smart/Resilient Electric Grid and integration of the various existing and alternative/renewable electric power system components[30]\n2011[edit]\nPower Systems Conference & Exhibition (PSCE) 2011, a plenary session dedicated to presenting power system tutorials and discussing the theme The Next Generation Grid \u2013 Putting It All Together[31]\nIEEE Technology Time Machine (TTM) 2011, a high level thought leadership conference about revolutionary technology platforms that will change lives during the next decade[32]\nPowerTech 2011, IEEE Power & Energy Society Europe's anchor conference, offering a platform for electric power engineering scientists and engineers to share knowledge, ideas, and results of scientific work[33]\nIEEE Smart Grid is also home to smaller workshops, sessions, and continuing education courses, like the IEEE PES Plain Talk About the Electric Power System series,[34] which are hosted by various societies and their chapters.Publications[edit]Through its Smart Grid Initiative, societies, working groups, committees and sub-committees, IEEE has published nearly 5,000 papers, manuscripts, guides, and other documents relating to the smart grid,[35] including:IEEE Smart Grid Newsletter[edit]In January 2011, IEEE unveiled the IEEE Smart Grid Newsletter,[36] a monthly electronic digest. The publication's content focuses on practical and technical information, as well as commentary and opinion on emerging smart grid technologies, new standards, global deployments, and other smart grid-related subject matter. Contributors include industry leaders, prominent researchers and academics, and advocates and policy experts. Dr. S. Massoud Amin, Director and Honeywell/H.W. Sweatt Chair, Technological Leadership Institute, and Professor of Electrical and Computer Engineering, University of Minnesota, is the publication's Chairman, and William Sweet, Emeritus News Editor, IEEE Spectrum, is its Managing Editor.[9]IEEE Transactions on Smart Grid[edit]Intended to disseminate smart grid research results on energy generation, transmission, distribution and delivery, IEEE Transactions on Smart Grid offers original research on smart grid theories, technologies, design, policies, and implementation. It also accepts manuscripts on smart grid design and implementation, and evaluation of energy systems involving smart grid technologies and applications. Published quarterly, IEEE Transactions on Smart Grid is jointly produced by multiple IEEE societies, including its Computational Intelligence Society, Communications Society, Computer Society, Control Systems Society, Industry Applications Society, Industrial Electronics Society, Instrumentation and Measurement Society, Power Electronics Society, Power & Energy Society, and Signal Processing Society.[37] In August 2011, the journal's Protecting Smart Grid Automation Systems Against Cyberattacks, authored by IEEE members Dong Wei and Yan Lu became the three millionth document in IEEE Xplore, IEEE's extensive digital library.[38] Mohammad Shahidehpour is the current Editor-in-Chief of IEEE Transactions on Smart Grid.[37]IEEE Transactions on Sustainable Energy[edit]A quarterly, cross-discipline journal featuring original research, IEEE Transactions on Sustainable Energy focuses on sustainable energy generation, transmission, distribution and delivery. Manuscripts concentrating on sustainable energy power systems design, implementation, and evaluations, as well as surveys of existing work are also accepted for consideration. Launched in April 2010, IEEE Transactions on Sustainable Energy is jointly published by IEEE's Industry Applications Society, Industrial Electronics Society, Instrumentation and Measurement Society, IEEE Oceanic Engineering Society, Power Electronics Society, Power & Energy Society, Photonics Society, and the Society on Social Implications of Technology. The journal's current Editor-in-Chief is Saifur Rahman, Joseph Loring Professor of ECE at Virginia Polytechnic Institute and State University (Virginia Tech).[39]Participating IEEE societies[edit]IEEE is home to 38 technical Societies encompassing a large array of disciplines and specialized fields of interest such as aerospace and electronic systems, medicine and biology engineering, magnetics, robotics, and vehicular technology.[40] Many of these societies are engaged in smart grid-related work, however, due to their specific areas of expertise, several have emerged as leaders in smart grid technology development and promotion:IEEE Communications Society[edit]The IEEE Communications Society (IEEE ComSoc) is an IEEE professional society of more than 8,800 communications industry professionals. As part of its goal to foster original work in all aspects of communications science, engineering, and technology, IEEE ComSoc sponsors a variety of publications, conferences, educational programs, local activities, and technical committees.[41] IEEE ComSoc is a key stakeholder in IEEE Smart Grid, sponsoring a variety of related standards like IEEE 1901-2010[42] and conferences like the IEEE International Symposium on Power Line Communications and its Applications (ISPLC)[43] and SmartGridComm, one of IEEE Smart Grid's flagship events. Along with a number of its sister societies, IEEE ComSoc jointly publishes IEEE Transactions on Smart Grid.[37]IEEE Computer Society[edit]The IEEE Computer Society is a professional society for computing professionals and researchers based in Washington, DC. With 85,000 members worldwide, it is the largest IEEE society. The group offers a variety of resources, including certification programs, printed and electronic books and journals, and conferences and events. The IEEE Computer Society is an active participant in IEEE Smart Grid, through the sponsorship of smart grid-applicable standards and practices, like IEEE 1471[44] and IEEE 42010-2011,[45] and events such as ISGT.[25] It is also one of the publishing societies for IEEE Transactions on Smart Grid.[37]IEEE Power & Energy Society[edit]The IEEE Power & Energy Society (IEEE PES) is home to 28,000 electric power energy professionals. Among the technical subject matter addressed by IEEE PES are electric power research, as well as system design, installation, and operation. The society aims to ensure the safe, sustainable, economic and reliable conversion, generation, transmission, distribution, storage and usage of electric energy, including its measurement and control. IEEE PES is one of the main proponents of IEEE Smart Grid, sponsoring numerous smart grid-related standards, such as IEEE 487-2007,[46] IEEE 1138-2009,[47] IEEE 1222-2003,[48] and IEEE 1615-2007.[49] The group frequently sponsors smart grid-related events on a national, international, and regional basis, including ISGT,[25] IEEE Power Systems Conference & Exposition (PSCE),[50] and the IEEE PES Plain Talk series.[34]IEEE Society on Social Implications of Technology[edit]The IEEE Society on Social Implications of Technology (SSIT) focuses on the environmental, health, and safety implications of technology. Among the topics addressed by its 2,000 global members are ethics and professional responsibility, the history of electrotechnology, public policy, and technology-related societal issues. IEEE SSIT members are generally professionals from multiple disciplines, including energy, information technology, and telecommunications. The group publishes IEEE Technology and Society Magazine, a quarterly journal.[51] IEEE SSIT sponsors or contributes regularly to IEEE Smart Grid standards and events, and is one of the publishing societies of IEEE Transactions on Sustainable Energy.[39]Influence and impact[edit]Many of the participating IEEE Smart Grid members have had demonstrable impact on the smart grid ecosystem. Often called upon as smart grid experts by the media, members appear frequently in magazines and newsletters such as Electric Energy Online,[52] Electric Light & Power magazine,[53] and FierceSmartGrid,[54] as well as on broadcast programs like NPR's Science Friday[55] and blogtalkradio.[56] greentechgrid unveiled The Networked Grid 100: Movers and Shakers of the Smart Grid in February 2010, naming IEEE Fellow, John D. McDonald, as one of their listees.[57] In November 2011, FierceEnergy magazine announced its inaugural Power Players -- The 15 Most Influential People in Energy list,[58] which included four IEEE Smart Grid members: IEEE Life Member Dick DeBlasio, IEEE Fellow Erich Gunther, McDonald, and IEEE Computer Society member, Andres Carvallo.[59]IEEE Smart Grid members have also had impact in other areas, including public policy. In May 2004, Erich Gunther was appointed by the US DOE as a member of its GridWise Architecture Council (GWAC), and currently serves as its chair.[60] IEEE Smart Grid member, John D. McDonald, was selected as the inaugural member of the US DOE Electric Advisory Committee,[61] which he served on during 2008.[62] He was followed by IEEE Smart Grid Chair, Wanda Reder, who was appointed to the committee in 2010.[63]On July 1, 2010, McDonald along with Dr. George W. Arnold, National Coordinator for Smart Grid, NIST; Mason W. Emnett, Associate Director of The Office of Energy Policy and Innovation, Federal Energy Regulatory Commission (FERC); Conrad Eustis, Director of Retail Technology Development, Portland General Electric; and Lillie Coney, Associate Director, Electronic Privacy Information Center were called upon to brief the U.S. House of Representatives\u2019 Subcommittee on Technology and Innovation, House Committee on Science and Technology.[64] At the hearing entitled Smart Grid Architecture and Standards: Assessing Coordination and Progress, he provided testimony on the progress of standards for Smart Grid interoperability and cyber security, stating: Also crucial to this undertaking are developing system architecture and standards that provide the essential foundation for bringing together the electrical and communications infrastructure, and for evolving technology to meet many and disparate needs. Both the IEEE through its Standards Association and NIST have already shown tremendous progress in these areas.[65]See also[edit]\nDistributed Generation\nEnergy Policy\nIntermittent Power Sources\nRenewables\nSmart Grid\nSmart Grids by Country\nSmart Meter\nExternal links[edit]\nElectricity Advisory Committee (EAC)\nGridWise Architecture Council, official web site\nNIST Smart Grid Homepage\nReferences[edit]", "subtitles": ["History", "Current work", "Participating IEEE societies", "Influence and impact", "See also", "External links", "References"], "title": "IEEE Smart Grid"}]